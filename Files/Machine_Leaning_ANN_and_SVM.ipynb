{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/elhamshaerirahbar-bot/my-colab-project/blob/main/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otavDhzyPYem",
    "outputId": "2345ff3d-dc8e-4124-9a08-a578dffdba1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.20.0rc0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.11.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4-eIK-3JPt-U"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for machine learning project\n",
    "\n",
    "# Basic data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re                    # For text processing\n",
    "import unicodedata          # For handling special characters\n",
    "\n",
    "# Machine learning tools\n",
    "from sklearn.model_selection import train_test_split    # Split data into train/test\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler    # Scale data\n",
    "\n",
    "# Deep learning with TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "# Model evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "UJHer3KHPye3",
    "outputId": "48cd4fe3-c825-47d9-a703-0edb55bad9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Run  Factor A  Factor B  Factor C  Factor D  Response 1 (Experimental)  \\\n",
      "0    1       110         7        50        10                    1127.19   \n",
      "1    2        85        13        50        10                    1024.97   \n",
      "2    3       101         1       500        60                    1950.00   \n",
      "3    4       101         1       500        60                    2223.17   \n",
      "4    5        50        10        50        10                    1845.60   \n",
      "\n",
      "   Response 2 (Experimental)  \n",
      "0                    1321.65  \n",
      "1                    1339.35  \n",
      "2                    2878.90  \n",
      "3                    2989.00  \n",
      "4                    2690.50  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Just read the file\n",
    "df = pd.read_csv('Exp_Mn_Mw_Value.txt', sep='\\t')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GiSJow4OP23F",
    "outputId": "c1bbcf8c-5351-4c8a-fd8d-a26a7c02a3b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (25, 4)  y: (25, 2)\n"
     ]
    }
   ],
   "source": [
    "#select columns by position\n",
    "X = df.iloc[:, 1:5].astype(float).to_numpy()  # First 4 columns as features\n",
    "y = df.iloc[:, 5:7].astype(float).to_numpy()  # Next 2 columns as targets\n",
    "\n",
    "print(\"X:\", X.shape, \" y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plN6vSHXqeYk",
    "outputId": "48b51718-22ff-4084-8844-e5672df84edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  X: (19, 4) (3, 4) (3, 4)\n",
      "  y: (19, 2) (3, 2) (3, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:296: FutureWarning: The current default behavior, quantile_method='linear', will be changed to quantile_method='averaged_inverted_cdf' in scikit-learn version 1.9 to naturally support sample weight equivalence properties by default. Pass quantile_method='averaged_inverted_cdf' explicitly to silence this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:296: FutureWarning: The current default behavior, quantile_method='linear', will be changed to quantile_method='averaged_inverted_cdf' in scikit-learn version 1.9 to naturally support sample weight equivalence properties by default. Pass quantile_method='averaged_inverted_cdf' explicitly to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "SEED = 5\n",
    "\n",
    "def choose_bins(n_samples, min_per_bin=3, max_bins=5):\n",
    "    # Pick a safe upper bound before knowing split sizes\n",
    "    return max(2, min(max_bins, n_samples // min_per_bin))\n",
    "\n",
    "# Build combined rank key from both targets\n",
    "y_score = rankdata(y[:,0]) + rankdata(y[:,1])\n",
    "\n",
    "# FIRST SPLIT: TrainVal / Test\n",
    "test_frac = 0.10\n",
    "n_test = int(np.ceil(len(y) * test_frac))\n",
    "n_bins_1 = choose_bins(len(y))\n",
    "n_bins_1 = max(2, min(n_bins_1, n_test))  # Hard cap by test samples\n",
    "\n",
    "kbin1 = KBinsDiscretizer(n_bins=n_bins_1, encode='ordinal', strategy='quantile')\n",
    "y_bins_1 = kbin1.fit_transform(y_score.reshape(-1,1)).ravel().astype(int)\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test, bins_tv_init, bins_te = train_test_split(\n",
    "    X, y, y_bins_1, test_size=test_frac, shuffle=True, random_state=SEED, stratify=y_bins_1\n",
    ")\n",
    "\n",
    "# SECOND SPLIT: Train / Val\n",
    "val_frac_of_trainval = 0.1111\n",
    "n_val = int(np.ceil(len(y_trainval) * val_frac_of_trainval))\n",
    "y_score_tv = rankdata(y_trainval[:,0]) + rankdata(y_trainval[:,1])\n",
    "n_bins_2 = choose_bins(len(y_trainval))\n",
    "n_bins_2 = max(2, min(n_bins_2, n_val))\n",
    "\n",
    "kbin2 = KBinsDiscretizer(n_bins=n_bins_2, encode='ordinal', strategy='quantile')\n",
    "y_bins_2 = kbin2.fit_transform(y_score_tv.reshape(-1,1)).ravel().astype(int)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=val_frac_of_trainval,\n",
    "    shuffle=True, random_state=SEED, stratify=y_bins_2\n",
    ")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"  y:\", y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPAQURsZqpCl",
    "outputId": "9cb359e5-af7b-4a52-e520-9c9c646d432a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_s range per column (should be within [-1,1]):\n",
      "[-1. -1.] [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Scale input features (X) using StandardScaler\n",
    "x_scaler = StandardScaler().fit(X_train)\n",
    "X_train_z = x_scaler.transform(X_train)\n",
    "X_val_z   = x_scaler.transform(X_val)\n",
    "X_test_z  = x_scaler.transform(X_test)\n",
    "\n",
    "# Scale target values (y) using MinMaxScaler to range [-1,1]\n",
    "y_scaler = MinMaxScaler(feature_range=(-1, 1)).fit(y_train)\n",
    "y_train_s = y_scaler.transform(y_train)\n",
    "y_val_s   = y_scaler.transform(y_val)\n",
    "y_test_s  = y_scaler.transform(y_test)\n",
    "\n",
    "# Functions to convert predictions back to original scale\n",
    "def inv_y(y_scaled):\n",
    "    return y_scaler.inverse_transform(y_scaled)\n",
    "\n",
    "def inv_y_cols(y_scaled):\n",
    "    mn = y_scaler.inverse_transform(y_scaled)[:,0]\n",
    "    mw = y_scaler.inverse_transform(y_scaled)[:,1]\n",
    "    return mn, mw\n",
    "\n",
    "print(\"y_train_s range per column (should be within [-1,1]):\")\n",
    "print(y_train_s.min(axis=0), y_train_s.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z1tl8aKjqpAQ"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5pnjjSLqo-K",
    "outputId": "05209f0f-2957-464a-be68-69866b70f802"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras import layers, regularizers, callbacks\n",
    "\n",
    "SEED = 55\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Custom callback to stop training when MSE goal is reached\n",
    "class StopOnMSEGoal(Callback):\n",
    "    def __init__(self, goal=1e-5):\n",
    "        super().__init__()\n",
    "        self.goal = goal\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is not None and logs.get('loss', 1.0) <= self.goal:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Build neural network model\n",
    "# Single hidden layer with 13 neurons, tanh activation\n",
    "model = Sequential([\n",
    "    Dense(13, activation='tanh', input_shape=(4,)),  # Hidden layer: 13 neurons\n",
    "    Dense(2, activation='tanh')                      # Output: 2 neurons (Mn, Mw)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bl9C1t43qo70",
    "outputId": "e6be6bb0-7738-49c6-ac5a-0c4022d8d7b0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.5738 - mae: 0.6180 - mape: 168.2290 - val_loss: 0.1354 - val_mae: 0.3267 - val_mape: 249.2565\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5444 - mae: 0.6022 - mape: 163.0690 - val_loss: 0.1335 - val_mae: 0.3277 - val_mape: 248.8945\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5164 - mae: 0.5874 - mape: 158.9162 - val_loss: 0.1314 - val_mae: 0.3280 - val_mape: 247.7719\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4889 - mae: 0.5723 - mape: 154.7919 - val_loss: 0.1292 - val_mae: 0.3276 - val_mape: 245.8473\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4621 - mae: 0.5568 - mape: 150.6182 - val_loss: 0.1268 - val_mae: 0.3265 - val_mape: 243.0849\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4361 - mae: 0.5411 - mape: 146.3854 - val_loss: 0.1243 - val_mae: 0.3247 - val_mape: 239.4736\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4111 - mae: 0.5253 - mape: 142.1071 - val_loss: 0.1217 - val_mae: 0.3222 - val_mape: 235.0283\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3873 - mae: 0.5093 - mape: 137.8094 - val_loss: 0.1189 - val_mae: 0.3190 - val_mape: 229.7887\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3648 - mae: 0.4948 - mape: 133.8213 - val_loss: 0.1160 - val_mae: 0.3153 - val_mape: 223.8170\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3437 - mae: 0.4820 - mape: 130.3049 - val_loss: 0.1130 - val_mae: 0.3110 - val_mape: 217.1944\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3241 - mae: 0.4696 - mape: 126.8867 - val_loss: 0.1101 - val_mae: 0.3064 - val_mape: 210.0173\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3062 - mae: 0.4576 - mape: 123.5957 - val_loss: 0.1073 - val_mae: 0.3014 - val_mape: 202.3934\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2899 - mae: 0.4477 - mape: 120.9413 - val_loss: 0.1045 - val_mae: 0.2961 - val_mape: 194.4368\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2753 - mae: 0.4384 - mape: 118.4253 - val_loss: 0.1019 - val_mae: 0.2907 - val_mape: 186.2643\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2622 - mae: 0.4295 - mape: 116.0497 - val_loss: 0.0995 - val_mae: 0.2852 - val_mape: 177.9908\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2506 - mae: 0.4211 - mape: 113.8168 - val_loss: 0.0973 - val_mae: 0.2797 - val_mape: 169.7249\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2404 - mae: 0.4133 - mape: 111.7236 - val_loss: 0.0952 - val_mae: 0.2743 - val_mape: 161.5657\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2315 - mae: 0.4059 - mape: 109.7625 - val_loss: 0.0933 - val_mae: 0.2689 - val_mape: 153.5994\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2236 - mae: 0.3991 - mape: 107.9228 - val_loss: 0.0916 - val_mae: 0.2637 - val_mape: 145.8974\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2168 - mae: 0.3928 - mape: 106.1920 - val_loss: 0.0900 - val_mae: 0.2586 - val_mape: 138.5150\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2109 - mae: 0.3885 - mape: 105.4983 - val_loss: 0.0886 - val_mae: 0.2537 - val_mape: 131.4915\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2057 - mae: 0.3859 - mape: 105.5725 - val_loss: 0.0872 - val_mae: 0.2490 - val_mape: 124.8514\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2012 - mae: 0.3837 - mape: 105.7088 - val_loss: 0.0860 - val_mae: 0.2444 - val_mape: 118.6054\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1972 - mae: 0.3816 - mape: 105.7633 - val_loss: 0.0848 - val_mae: 0.2401 - val_mape: 112.7532\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1937 - mae: 0.3796 - mape: 105.7411 - val_loss: 0.0837 - val_mae: 0.2365 - val_mape: 108.4348\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1906 - mae: 0.3776 - mape: 105.6488 - val_loss: 0.0827 - val_mae: 0.2364 - val_mape: 111.8888\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1878 - mae: 0.3757 - mape: 105.4933 - val_loss: 0.0817 - val_mae: 0.2361 - val_mape: 114.9614\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1853 - mae: 0.3739 - mape: 105.2823 - val_loss: 0.0807 - val_mae: 0.2357 - val_mape: 117.6875\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1831 - mae: 0.3721 - mape: 105.0232 - val_loss: 0.0798 - val_mae: 0.2352 - val_mape: 120.1020\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1810 - mae: 0.3704 - mape: 104.7236 - val_loss: 0.0789 - val_mae: 0.2346 - val_mape: 122.2389\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1792 - mae: 0.3687 - mape: 104.3908 - val_loss: 0.0780 - val_mae: 0.2339 - val_mape: 124.1307\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1774 - mae: 0.3670 - mape: 104.0313 - val_loss: 0.0772 - val_mae: 0.2331 - val_mape: 125.8074\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1759 - mae: 0.3654 - mape: 103.6515 - val_loss: 0.0764 - val_mae: 0.2323 - val_mape: 127.2963\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1744 - mae: 0.3638 - mape: 103.2568 - val_loss: 0.0756 - val_mae: 0.2314 - val_mape: 128.6220\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1731 - mae: 0.3623 - mape: 102.8523 - val_loss: 0.0748 - val_mae: 0.2305 - val_mape: 129.8063\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1718 - mae: 0.3608 - mape: 102.4422 - val_loss: 0.0740 - val_mae: 0.2296 - val_mape: 130.8679\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1706 - mae: 0.3593 - mape: 102.0303 - val_loss: 0.0733 - val_mae: 0.2286 - val_mape: 131.8231\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1695 - mae: 0.3578 - mape: 101.6196 - val_loss: 0.0726 - val_mae: 0.2277 - val_mape: 132.6855\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1685 - mae: 0.3564 - mape: 101.2126 - val_loss: 0.0719 - val_mae: 0.2273 - val_mape: 133.5983\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1675 - mae: 0.3552 - mape: 100.8513 - val_loss: 0.0712 - val_mae: 0.2276 - val_mape: 134.6310\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1666 - mae: 0.3541 - mape: 100.5068 - val_loss: 0.0705 - val_mae: 0.2279 - val_mape: 135.5801\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1658 - mae: 0.3529 - mape: 100.1677 - val_loss: 0.0699 - val_mae: 0.2282 - val_mape: 136.4531\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1649 - mae: 0.3518 - mape: 99.8347 - val_loss: 0.0693 - val_mae: 0.2283 - val_mape: 137.2564\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1642 - mae: 0.3507 - mape: 99.5086 - val_loss: 0.0687 - val_mae: 0.2284 - val_mape: 137.9952\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1634 - mae: 0.3496 - mape: 99.1897 - val_loss: 0.0681 - val_mae: 0.2284 - val_mape: 138.6739\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1627 - mae: 0.3486 - mape: 98.8783 - val_loss: 0.0675 - val_mae: 0.2284 - val_mape: 139.2960\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1620 - mae: 0.3475 - mape: 98.5742 - val_loss: 0.0669 - val_mae: 0.2283 - val_mape: 139.8647\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1614 - mae: 0.3465 - mape: 98.2774 - val_loss: 0.0663 - val_mae: 0.2281 - val_mape: 140.3825\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1607 - mae: 0.3455 - mape: 97.9877 - val_loss: 0.0657 - val_mae: 0.2279 - val_mape: 140.8516\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1601 - mae: 0.3444 - mape: 97.7047 - val_loss: 0.0652 - val_mae: 0.2276 - val_mape: 141.2739\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1595 - mae: 0.3434 - mape: 97.4281 - val_loss: 0.0646 - val_mae: 0.2273 - val_mape: 141.6513\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1589 - mae: 0.3425 - mape: 97.1575 - val_loss: 0.0641 - val_mae: 0.2270 - val_mape: 141.9851\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1584 - mae: 0.3415 - mape: 96.8924 - val_loss: 0.0635 - val_mae: 0.2266 - val_mape: 142.2769\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1579 - mae: 0.3405 - mape: 96.6326 - val_loss: 0.0630 - val_mae: 0.2261 - val_mape: 142.5280\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1573 - mae: 0.3395 - mape: 96.3775 - val_loss: 0.0624 - val_mae: 0.2256 - val_mape: 142.7395\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1568 - mae: 0.3386 - mape: 96.1268 - val_loss: 0.0618 - val_mae: 0.2251 - val_mape: 142.9128\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1563 - mae: 0.3377 - mape: 95.8800 - val_loss: 0.0613 - val_mae: 0.2246 - val_mape: 143.0490\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1559 - mae: 0.3367 - mape: 95.6369 - val_loss: 0.0607 - val_mae: 0.2240 - val_mape: 143.1492\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1554 - mae: 0.3358 - mape: 95.3970 - val_loss: 0.0602 - val_mae: 0.2233 - val_mape: 143.2145\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1549 - mae: 0.3349 - mape: 95.1601 - val_loss: 0.0596 - val_mae: 0.2226 - val_mape: 143.2460\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1545 - mae: 0.3340 - mape: 94.9258 - val_loss: 0.0590 - val_mae: 0.2219 - val_mape: 143.2449\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1540 - mae: 0.3331 - mape: 94.6938 - val_loss: 0.0585 - val_mae: 0.2212 - val_mape: 143.2120\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1536 - mae: 0.3322 - mape: 94.4639 - val_loss: 0.0579 - val_mae: 0.2204 - val_mape: 143.1484\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1532 - mae: 0.3314 - mape: 94.2358 - val_loss: 0.0573 - val_mae: 0.2196 - val_mape: 143.0550\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1527 - mae: 0.3305 - mape: 94.0094 - val_loss: 0.0568 - val_mae: 0.2188 - val_mape: 142.9330\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1523 - mae: 0.3296 - mape: 93.7844 - val_loss: 0.0562 - val_mae: 0.2179 - val_mape: 142.7832\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1519 - mae: 0.3288 - mape: 93.5606 - val_loss: 0.0556 - val_mae: 0.2170 - val_mape: 142.6066\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1515 - mae: 0.3279 - mape: 93.3379 - val_loss: 0.0550 - val_mae: 0.2161 - val_mape: 142.4039\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1511 - mae: 0.3271 - mape: 93.1160 - val_loss: 0.0544 - val_mae: 0.2152 - val_mape: 142.1763\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1508 - mae: 0.3262 - mape: 92.8950 - val_loss: 0.0539 - val_mae: 0.2142 - val_mape: 141.9244\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1504 - mae: 0.3254 - mape: 92.6746 - val_loss: 0.0533 - val_mae: 0.2132 - val_mape: 141.6492\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1500 - mae: 0.3246 - mape: 92.4547 - val_loss: 0.0527 - val_mae: 0.2122 - val_mape: 141.3515\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1496 - mae: 0.3238 - mape: 92.2352 - val_loss: 0.0521 - val_mae: 0.2111 - val_mape: 141.0320\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1493 - mae: 0.3230 - mape: 92.0162 - val_loss: 0.0515 - val_mae: 0.2101 - val_mape: 140.6915\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1489 - mae: 0.3222 - mape: 91.7973 - val_loss: 0.0509 - val_mae: 0.2090 - val_mape: 140.3307\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1486 - mae: 0.3214 - mape: 91.5786 - val_loss: 0.0503 - val_mae: 0.2079 - val_mape: 139.9503\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1482 - mae: 0.3206 - mape: 91.3601 - val_loss: 0.0497 - val_mae: 0.2068 - val_mape: 139.5511\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1479 - mae: 0.3198 - mape: 91.1417 - val_loss: 0.0491 - val_mae: 0.2057 - val_mape: 139.1339\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1475 - mae: 0.3190 - mape: 90.9232 - val_loss: 0.0485 - val_mae: 0.2045 - val_mape: 138.6990\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1472 - mae: 0.3182 - mape: 90.7048 - val_loss: 0.0479 - val_mae: 0.2034 - val_mape: 138.2473\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1468 - mae: 0.3174 - mape: 90.4863 - val_loss: 0.0474 - val_mae: 0.2022 - val_mape: 137.7792\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1465 - mae: 0.3167 - mape: 90.2677 - val_loss: 0.0468 - val_mae: 0.2010 - val_mape: 137.2955\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1462 - mae: 0.3159 - mape: 90.0490 - val_loss: 0.0462 - val_mae: 0.1998 - val_mape: 136.7967\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1459 - mae: 0.3151 - mape: 89.8302 - val_loss: 0.0456 - val_mae: 0.1986 - val_mape: 136.2833\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1455 - mae: 0.3144 - mape: 89.6113 - val_loss: 0.0450 - val_mae: 0.1974 - val_mape: 135.7559\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1452 - mae: 0.3136 - mape: 89.3922 - val_loss: 0.0444 - val_mae: 0.1961 - val_mape: 135.2150\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1449 - mae: 0.3129 - mape: 89.1730 - val_loss: 0.0439 - val_mae: 0.1949 - val_mape: 134.6610\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1446 - mae: 0.3122 - mape: 88.9536 - val_loss: 0.0433 - val_mae: 0.1936 - val_mape: 134.0945\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1443 - mae: 0.3114 - mape: 88.7340 - val_loss: 0.0427 - val_mae: 0.1924 - val_mape: 133.5159\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1440 - mae: 0.3107 - mape: 88.5143 - val_loss: 0.0421 - val_mae: 0.1911 - val_mape: 132.9258\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1437 - mae: 0.3100 - mape: 88.2945 - val_loss: 0.0416 - val_mae: 0.1899 - val_mape: 132.3243\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1434 - mae: 0.3092 - mape: 88.0745 - val_loss: 0.0410 - val_mae: 0.1886 - val_mape: 131.7122\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1431 - mae: 0.3085 - mape: 87.8543 - val_loss: 0.0405 - val_mae: 0.1873 - val_mape: 131.0897\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1428 - mae: 0.3078 - mape: 87.6340 - val_loss: 0.0399 - val_mae: 0.1861 - val_mape: 130.4572\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1425 - mae: 0.3071 - mape: 87.4137 - val_loss: 0.0394 - val_mae: 0.1848 - val_mape: 129.8151\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1422 - mae: 0.3064 - mape: 87.1932 - val_loss: 0.0388 - val_mae: 0.1835 - val_mape: 129.1637\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1419 - mae: 0.3057 - mape: 86.9726 - val_loss: 0.0383 - val_mae: 0.1822 - val_mape: 128.5035\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1417 - mae: 0.3050 - mape: 86.7519 - val_loss: 0.0378 - val_mae: 0.1809 - val_mape: 127.8347\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1414 - mae: 0.3043 - mape: 86.5312 - val_loss: 0.0373 - val_mae: 0.1797 - val_mape: 127.1577\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1411 - mae: 0.3036 - mape: 86.3104 - val_loss: 0.0367 - val_mae: 0.1784 - val_mape: 126.4728\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Setup callbacks\n",
    "es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "goal_cb = StopOnMSEGoal(goal=1e-5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_z, y_train_s,\n",
    "    validation_data=(X_val_z, y_val_s),\n",
    "    epochs=100, batch_size=4, verbose=1,\n",
    "    callbacks=[es, goal_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRdLXB8gqo5u",
    "outputId": "05bf4725-393c-4d07-a4b0-b66913ea8f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    }
   ],
   "source": [
    "# Function to convert scaled predictions back to original values\n",
    "def inv_y(y_s):\n",
    "    return y_scaler.inverse_transform(y_s)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred_test_s = model.predict(X_test_z)  # Scaled predictions\n",
    "y_pred_test   = inv_y(y_pred_test_s)     # Convert back to original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "cj-G3m1Yqo3q",
    "outputId": "2f7f6675-c0db-4361-8fa4-3ba4be41b6a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(Mn) real = 3848.7276 | MSE(Mw) real = 464755.7013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)                  │              \u001b[38;5;34m65\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m28\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">281</span> (1.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m281\u001b[0m (1.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93</span> (372.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93\u001b[0m (372.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">188</span> (756.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m188\u001b[0m (756.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate MSE for each output separately\n",
    "mse_Mn = mean_squared_error(y_test[:,0], y_pred_test[:,0])\n",
    "mse_Mw = mean_squared_error(y_test[:,1], y_pred_test[:,1])\n",
    "\n",
    "print(f\"MSE(Mn) real = {mse_Mn:.4f} | MSE(Mw) real = {mse_Mw:.4f}\")\n",
    "\n",
    "# Show model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGAiViE8qo1T",
    "outputId": "c7c54c7e-49d2-4e63-9b55-01e8424cd921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "MSE(Mn) real = 3848.727613 | MSE(Mw) real = 464755.701260\n",
      "R² (Mn)      = 0.9835  | R² (Mw)      = -13.1481  | R²_avg = -6.0823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test_s = model.predict(X_test_z)\n",
    "y_pred_test   = y_scaler.inverse_transform(y_pred_test_s)\n",
    "\n",
    "# Calculate metrics for each output\n",
    "mse_Mn = mean_squared_error(y_test[:,0], y_pred_test[:,0])\n",
    "mse_Mw = mean_squared_error(y_test[:,1], y_pred_test[:,1])\n",
    "r2_Mn  = r2_score(y_test[:,0], y_pred_test[:,0])\n",
    "r2_Mw  = r2_score(y_test[:,1], y_pred_test[:,1])\n",
    "r2_avg = r2_score(y_test, y_pred_test, multioutput='uniform_average')\n",
    "\n",
    "print(f\"MSE(Mn) real = {mse_Mn:.6f} | MSE(Mw) real = {mse_Mw:.6f}\")\n",
    "print(f\"R² (Mn)      = {r2_Mn:.4f}  | R² (Mw)      = {r2_Mw:.4f}  | R²_avg = {r2_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDUAjXC-qoy-",
    "outputId": "0c151640-c74a-4920-ab78-2086e68de511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mn: RMSE=62.038 | R²=0.9835 | SEP=75.981\n",
      "Mw: RMSE=681.730 | R²=-13.1481 | SEP=834.945\n"
     ]
    }
   ],
   "source": [
    "# Define additional evaluation metrics\n",
    "def rmse(a, b): \n",
    "    return np.sqrt(mean_squared_error(a, b))\n",
    "\n",
    "def sep(a, b):\n",
    "    n = len(a)\n",
    "    return np.sqrt(np.sum((a-b)**2)/(n-1)) #root function\n",
    "\n",
    "# Evaluate each output with multiple metrics\n",
    "for j, name in enumerate(['Mn', 'Mw']):\n",
    "    print(f'{name}: RMSE={rmse(y_test[:,j], y_pred_test[:,j]):.3f} | '\n",
    "          f'R²={r2_score(y_test[:,j], y_pred_test[:,j]):.4f} | '\n",
    "          f'SEP={sep(y_test[:,j], y_pred_test[:,j]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdOaW3EUqow5",
    "outputId": "ba3c6a5c-d869-451f-89da-ff5143a6c416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on all datasets (scaled space first, then convert to real units)\n",
    "y_hat_train_s = model.predict(X_train_z, verbose=1)  # Train predictions (scaled)\n",
    "y_hat_val_s   = model.predict(X_val_z,   verbose=1)  # Validation predictions (scaled)\n",
    "y_hat_test_s  = model.predict(X_test_z,  verbose=1)  # Test predictions (scaled)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_hat_train = inv_y(y_hat_train_s)  # Train predictions (real units)\n",
    "y_hat_val   = inv_y(y_hat_val_s)    # Validation predictions (real units)\n",
    "y_hat_test  = inv_y(y_hat_test_s)   # Test predictions (real units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "q3hRm63yqouy"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def report_2out(name, yt, yp, labels=(\"Mn\", \"Mw\")):\n",
    "    # yt and yp should be (n,2) arrays\n",
    "    for i, label in enumerate(labels):\n",
    "        y_true = yt[:, i].reshape(-1)\n",
    "        y_pred = yp[:, i].reshape(-1)\n",
    "        \n",
    "        mae  = mean_absolute_error(y_true, y_pred)\n",
    "        mse  = mean_squared_error(y_true, y_pred)\n",
    "        r2   = r2_score(y_true, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "        \n",
    "        print(f\"[{name}] {label}: MAE={mae:.6f}  MSE={mse:.6f}  R²={r2:.4f}  MAPE={mape:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "naPN3BLAqosc",
    "outputId": "3be5c735-0a8f-4562-89e7-30c5c9c1e9e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Mn: MAE=476.610387  MSE=388125.670932  R²=0.6494  MAPE=0.215762\n",
      "[Train] Mw: MAE=791.616960  MSE=869600.668607  R²=0.6025  MAPE=0.274821\n",
      "[Val  ] Mn: MAE=289.001493  MSE=107050.073151  R²=-1.4086  MAPE=0.119096\n",
      "[Val  ] Mw: MAE=455.264733  MSE=217647.265093  R²=-2.3712  MAPE=0.146577\n",
      "[Test ] Mn: MAE=54.671335  MSE=3848.727613  R²=0.9835  MAPE=0.024822\n",
      "[Test ] Mw: MAE=483.710072  MSE=464755.701260  R²=-13.1481  MAPE=0.163630\n"
     ]
    }
   ],
   "source": [
    "report_2out(\"Train\", y_train, y_hat_train)\n",
    "report_2out(\"Val  \", y_val,   y_hat_val)\n",
    "report_2out(\"Test \", y_test,  y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Jm8Am9KqoqW",
    "outputId": "d35162d2-1738-4c65-f94c-6a7e9e1869da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "y_train real min/max per col: [1024.97 1321.65] [4663.77 5921.61]\n",
      "Train R2: [0.64938358 0.60247255]\n",
      "Val   R2: [-1.40863543 -2.37124696]\n",
      "Test  R2: [  0.98348107 -13.14813839]\n",
      "Train -> MSE=[388125.67093235 869600.66860713], RMSE=[622.99732819 932.52381664], MAE=[476.61038728 791.61695955], MAPE%=[21.57622813 27.48212798]\n",
      "Val -> MSE=[107050.07315054 217647.26509333], RMSE=[327.18507477 466.52681069], MAE=[289.00149349 455.26473307], MAPE%=[11.90964369 14.65769136]\n",
      "Test -> MSE=[  3848.72761283 464755.70126038], RMSE=[ 62.03811419 681.72993279], MAE=[ 54.67133464 483.71007161], MAPE%=[ 2.48218451 16.36296434]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 1) Make predictions in scaled space\n",
    "y_pred_train_s = model.predict(X_train_z)\n",
    "y_pred_val_s   = model.predict(X_val_z)\n",
    "y_pred_test_s  = model.predict(X_test_z)\n",
    "\n",
    "# 2) Convert predictions back to real units (IMPORTANT)\n",
    "y_pred_train = y_scaler.inverse_transform(y_pred_train_s)\n",
    "y_pred_val   = y_scaler.inverse_transform(y_pred_val_s)\n",
    "y_pred_test  = y_scaler.inverse_transform(y_pred_test_s)\n",
    "\n",
    "# Check that y_true is in real units\n",
    "print('y_train real min/max per col:', y_train.min(axis=0), y_train.max(axis=0))\n",
    "\n",
    "# 3) R² scores for Mn and Mw separately\n",
    "print(\"Train R2:\", r2_score(y_train, y_pred_train, multioutput='raw_values'))\n",
    "print(\"Val   R2:\", r2_score(y_val,   y_pred_val,   multioutput='raw_values'))\n",
    "print(\"Test  R2:\", r2_score(y_test,  y_pred_test,  multioutput='raw_values'))\n",
    "\n",
    "# 4) Other metrics in real units\n",
    "def eval_block(name, y_true, y_pred):\n",
    "    mse  = mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
    "    rmse = (mse**0.5)\n",
    "    mae  = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "    \n",
    "    # Manual MAPE calculation (avoid division by zero)\n",
    "    eps = 1e-12\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), eps)), axis=0) * 100\n",
    "    \n",
    "    print(f\"{name} -> MSE={mse}, RMSE={rmse}, MAE={mae}, MAPE%={mape}\")\n",
    "\n",
    "# Evaluate all datasets\n",
    "for split, y_true, y_pred in [\n",
    "    (\"Train\", y_train, y_pred_train),\n",
    "    (\"Val\",   y_val,   y_pred_val),\n",
    "    (\"Test\",  y_test,  y_pred_test)\n",
    "]:\n",
    "    eval_block(split, y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAwnPU4CqooR",
    "outputId": "aaed4bbf-0255-4c52-fbf0-ff250ff43283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Var=[1168479.8233924  2309052.66440058] | R2=[0.64938358 0.60247255] | RMSE=[622.99732819 932.52381664] | MAE=[476.61038728 791.61695955]\n",
      "       (Baseline R2=[0. 0.], Baseline RMSE=[1052.13159126 1479.02791617])\n",
      "Val: Var=[66666.423513   96839.80493333] | R2=[-1.40863543 -2.37124696] | RMSE=[327.18507477 466.52681069] | MAE=[289.00149349 455.26473307]\n",
      "       (Baseline R2=[0. 0.], Baseline RMSE=[210.81812622 254.0863435 ])\n",
      "Test: Var=[349483.3351      49273.87143333] | R2=[  0.98348107 -13.14813839] | RMSE=[ 62.03811419 681.72993279] | MAE=[ 54.67133464 483.71007161]\n",
      "       (Baseline R2=[0. 0.], Baseline RMSE=[482.68922721 181.24361402])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def summarize_split(name, y_true, y_pred):\n",
    "    var = np.var(y_true, axis=0, ddof=1)\n",
    "    mse = mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "    r2  = r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "    \n",
    "    # Baseline = predicting mean of y_true\n",
    "    y_mean = np.tile(np.mean(y_true, axis=0, keepdims=True), (y_true.shape[0],1))\n",
    "    mse_base = mean_squared_error(y_true, y_mean, multioutput='raw_values')\n",
    "    r2_base  = r2_score(y_true, y_mean, multioutput='raw_values')\n",
    "    \n",
    "    print(f\"{name}: Var={var} | R2={r2} | RMSE={rmse} | MAE={mae}\")\n",
    "    print(f\"       (Baseline R2={r2_base}, Baseline RMSE={np.sqrt(mse_base)})\")\n",
    "\n",
    "# Evaluate all splits with baseline comparison\n",
    "summarize_split(\"Train\", y_train, y_pred_train)\n",
    "summarize_split(\"Val\",   y_val,   y_pred_val)\n",
    "summarize_split(\"Test\",  y_test,  y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3Q6-NVSqol8",
    "outputId": "e3a688f5-53ab-4e42-90ec-781e56b04913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "M6Ri7U5TGhxo"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYeuMmOjGhvm",
    "outputId": "576c1360-8836-4c88-f3eb-90d5f2250254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split target   actual   predicted     residual   abs_error  pct_error\n",
      "Train     Mn 2322.830 2005.047607   317.782393  317.782393  13.680829\n",
      "Train     Mn 3764.530 3525.262695   239.267305  239.267305   6.355835\n",
      "Train     Mn 1264.440 1653.019775  -388.579775  388.579775  30.731373\n",
      "Train     Mn 3762.880 3525.262695   237.617305  237.617305   6.314772\n",
      "Train     Mn 2951.900 3009.844482   -57.944482   57.944482   1.962955\n",
      "Train     Mn 1846.180 1936.507080   -90.327080   90.327080   4.892648\n",
      "Train     Mn 1950.000 2257.272949  -307.272949  307.272949  15.757587\n",
      "Train     Mn 4663.770 3488.834229  1174.935771 1174.935771  25.192833\n",
      "Train     Mn 2525.910 1940.624268   585.285732  585.285732  23.171282\n",
      "Train     Mn 2073.900 1986.119141    87.780859   87.780859   4.232647\n",
      "Train     Mn 2525.270 1940.624268   584.645732  584.645732  23.151811\n",
      "Train     Mn 2298.650 3480.682617 -1182.032617 1182.032617  51.422905\n",
      "Train     Mn 1265.880 1653.019775  -387.139775  387.139775  30.582660\n",
      "Train     Mn 2298.620 3480.682617 -1182.062617 1182.062617  51.424882\n",
      "Train     Mn 1024.970 1528.664062  -503.694062  503.694062  49.142322\n",
      "Train     Mn 2752.800 2733.747559    19.052441   19.052441   0.692111\n",
      "Train     Mn 4663.040 3488.834229  1174.205771 1174.205771  25.181122\n",
      "Train     Mn 1127.190 1629.057495  -501.867495  501.867495  44.523771\n",
      "Train     Mn 2223.170 2257.273193   -34.103193   34.103193   1.533989\n",
      "Train     Mw 2987.310 2390.489990   596.820010  596.820010  19.978509\n",
      "Train     Mw 5752.150 4715.428711  1036.721289 1036.721289  18.023196\n",
      "Train     Mw 1456.220 2108.109375  -651.889375  651.889375  44.765858\n",
      "Train     Mw 5752.810 4715.428711  1037.381289 1037.381289  18.032601\n",
      "Train     Mw 2965.540 4129.835449 -1164.295449 1164.295449  39.260824\n",
      "Train     Mw 2689.910 2559.464600   130.445400  130.445400   4.849434\n",
      "Train     Mw 2878.900 3154.014648  -275.114648  275.114648   9.556242\n",
      "Train     Mw 5921.610 4533.731445  1387.878555 1387.878555  23.437520\n",
      "Train     Mw 3440.430 2825.007324   615.422676  615.422676  17.887958\n",
      "Train     Mw 2974.510 2562.868408   411.641592  411.641592  13.838972\n",
      "Train     Mw 3441.190 2825.007324   616.182676  616.182676  17.906093\n",
      "Train     Mw 2972.940 4679.853027 -1706.913027 1706.913027  57.414984\n",
      "Train     Mw 1458.130 2108.109375  -649.979375  649.979375  44.576229\n",
      "Train     Mw 2972.980 4679.853027 -1706.873027 1706.873027  57.412866\n",
      "Train     Mw 1339.350 1729.327759  -389.977759  389.977759  29.116942\n",
      "Train     Mw 3129.610 2972.400146   157.209854  157.209854   5.023305\n",
      "Train     Mw 5921.490 4533.731445  1387.758555 1387.758555  23.435969\n",
      "Train     Mw 1321.650 2274.853027  -953.203027  953.203027  72.122198\n",
      "Train     Mw 2989.000 3154.014648  -165.014648  165.014648   5.520731\n",
      "  Val     Mn 2322.860 2005.047607   317.812393  317.812393  13.681943\n",
      "  Val     Mn 2074.517 1986.119141    88.397859   88.397859   4.261130\n",
      "  Val     Mn 2590.790 3051.584229  -460.794229  460.794229  17.785858\n",
      "  Val     Mw 2987.280 2390.489990   596.790010  596.790010  19.977706\n",
      "  Val     Mw 2970.820 2562.868408   407.951592  407.951592  13.731953\n",
      "  Val     Mw 3517.860 3878.912598  -361.052598  361.052598  10.263416\n",
      " Test     Mn 1845.600 1936.507080   -90.907080   90.907080   4.925611\n",
      " Test     Mn 2955.830 3009.844482   -54.014482   54.014482   1.827388\n",
      " Test     Mn 2752.840 2733.747559    19.092441   19.092441   0.693554\n",
      " Test     Mw 2690.500 2559.464600   131.035400  131.035400   4.870299\n",
      " Test     Mw 2966.910 4129.834961 -1162.924961 1162.924961  39.196503\n",
      " Test     Mw 3129.570 2972.400146   157.169854  157.169854   5.022091\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "def make_table_multi(split, y_true, y_pred, target_names=(\"Mn\",\"Mw\"), n=None):\n",
    "    \"\"\"\n",
    "    Build table for 2 (or more) outputs.\n",
    "    y_true, y_pred: shape (n, k) -> k = number of outputs (here 2: Mn, Mw)\n",
    "    pct_error in percent (0–100).\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    assert y_true.shape == y_pred.shape and y_true.ndim == 2, \"y must be (n,k)\"\n",
    "    k = y_true.shape[1]\n",
    "    assert k == len(target_names), \"target_names length doesn't match y.shape[1]\"\n",
    "    \n",
    "    parts = []\n",
    "    for j, name in enumerate(target_names):\n",
    "        df = pd.DataFrame({\n",
    "            \"split\":     split,\n",
    "            \"target\":    name,\n",
    "            \"actual\":    y_true[:, j],\n",
    "            \"predicted\": y_pred[:, j],\n",
    "        })\n",
    "        df[\"residual\"]  = df[\"actual\"] - df[\"predicted\"]\n",
    "        df[\"abs_error\"] = df[\"residual\"].abs()\n",
    "        # Percent error (×100)\n",
    "        df[\"pct_error\"] = 100 * df[\"abs_error\"] / df[\"actual\"].abs().clip(lower=1e-8)\n",
    "        \n",
    "        parts.append(df if n is None else df.head(n))\n",
    "    \n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "# Create tables for all datasets\n",
    "tbl_train = make_table_multi(\"Train\", y_train, y_hat_train, target_names=(\"Mn\",\"Mw\"))\n",
    "tbl_val   = make_table_multi(\"Val\",   y_val,   y_hat_val,   target_names=(\"Mn\",\"Mw\"))\n",
    "tbl_test  = make_table_multi(\"Test\",  y_test,  y_hat_test,  target_names=(\"Mn\",\"Mw\"))\n",
    "\n",
    "# Combine all tables\n",
    "tbl_all = pd.concat([tbl_train, tbl_val, tbl_test], ignore_index=True)\n",
    "print(tbl_all.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "sMGWfV-fGhtc"
   },
   "outputs": [],
   "source": [
    "#reproducibility\n",
    "SEED = 5\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Ie2EcwI3GhrH"
   },
   "outputs": [],
   "source": [
    "# Activation (Transfer Function) sweep on hidden layers\n",
    "import random, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers\n",
    "\n",
    "activations = ['relu', 'tanh', 'sigmoid', 'softplus']\n",
    "labels      = ['ReLU', 'Tanh', 'Sigmoid', 'Softplus']\n",
    "val_mse_real  = []\n",
    "test_mse_real = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gImuk66sGhpE",
    "outputId": "b0329a4f-af42-46ae-c71d-e1f3e243ad24",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.9669 - mae: 0.8478 - val_loss: 0.5025 - val_mae: 0.6332\n",
      "Epoch 2/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9502 - mae: 0.8392 - val_loss: 0.4945 - val_mae: 0.6264\n",
      "Epoch 3/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.9349 - mae: 0.8313 - val_loss: 0.4865 - val_mae: 0.6197\n",
      "Epoch 4/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.9198 - mae: 0.8233 - val_loss: 0.4784 - val_mae: 0.6128\n",
      "Epoch 5/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.9049 - mae: 0.8154 - val_loss: 0.4704 - val_mae: 0.6061\n",
      "Epoch 6/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.8902 - mae: 0.8075 - val_loss: 0.4624 - val_mae: 0.6020\n",
      "Epoch 7/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.8757 - mae: 0.7995 - val_loss: 0.4544 - val_mae: 0.5979\n",
      "Epoch 8/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8614 - mae: 0.7915 - val_loss: 0.4464 - val_mae: 0.5937\n",
      "Epoch 9/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.8473 - mae: 0.7834 - val_loss: 0.4385 - val_mae: 0.5895\n",
      "Epoch 10/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.8333 - mae: 0.7753 - val_loss: 0.4306 - val_mae: 0.5852\n",
      "Epoch 11/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.8196 - mae: 0.7672 - val_loss: 0.4227 - val_mae: 0.5808\n",
      "Epoch 12/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.8061 - mae: 0.7589 - val_loss: 0.4149 - val_mae: 0.5764\n",
      "Epoch 13/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.7928 - mae: 0.7507 - val_loss: 0.4072 - val_mae: 0.5719\n",
      "Epoch 14/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7798 - mae: 0.7424 - val_loss: 0.3994 - val_mae: 0.5673\n",
      "Epoch 15/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.7671 - mae: 0.7349 - val_loss: 0.3917 - val_mae: 0.5626\n",
      "Epoch 16/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.7546 - mae: 0.7281 - val_loss: 0.3841 - val_mae: 0.5578\n",
      "Epoch 17/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7423 - mae: 0.7214 - val_loss: 0.3765 - val_mae: 0.5529\n",
      "Epoch 18/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.7302 - mae: 0.7147 - val_loss: 0.3690 - val_mae: 0.5479\n",
      "Epoch 19/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7186 - mae: 0.7080 - val_loss: 0.3615 - val_mae: 0.5428\n",
      "Epoch 20/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7072 - mae: 0.7014 - val_loss: 0.3544 - val_mae: 0.5377\n",
      "Epoch 21/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6962 - mae: 0.6955 - val_loss: 0.3473 - val_mae: 0.5326\n",
      "Epoch 22/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6854 - mae: 0.6901 - val_loss: 0.3404 - val_mae: 0.5273\n",
      "Epoch 23/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6749 - mae: 0.6848 - val_loss: 0.3335 - val_mae: 0.5220\n",
      "Epoch 24/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.6647 - mae: 0.6796 - val_loss: 0.3267 - val_mae: 0.5166\n",
      "Epoch 25/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6547 - mae: 0.6744 - val_loss: 0.3200 - val_mae: 0.5111\n",
      "Epoch 26/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6450 - mae: 0.6692 - val_loss: 0.3134 - val_mae: 0.5055\n",
      "Epoch 27/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6357 - mae: 0.6641 - val_loss: 0.3070 - val_mae: 0.4999\n",
      "Epoch 28/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6265 - mae: 0.6595 - val_loss: 0.3006 - val_mae: 0.4942\n",
      "Epoch 29/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6176 - mae: 0.6553 - val_loss: 0.2943 - val_mae: 0.4885\n",
      "Epoch 30/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.6088 - mae: 0.6511 - val_loss: 0.2882 - val_mae: 0.4828\n",
      "Epoch 31/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.6001 - mae: 0.6469 - val_loss: 0.2821 - val_mae: 0.4770\n",
      "Epoch 32/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5917 - mae: 0.6426 - val_loss: 0.2762 - val_mae: 0.4712\n",
      "Epoch 33/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5834 - mae: 0.6383 - val_loss: 0.2704 - val_mae: 0.4653\n",
      "Epoch 34/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5753 - mae: 0.6339 - val_loss: 0.2647 - val_mae: 0.4595\n",
      "Epoch 35/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5674 - mae: 0.6296 - val_loss: 0.2591 - val_mae: 0.4536\n",
      "Epoch 36/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5597 - mae: 0.6253 - val_loss: 0.2536 - val_mae: 0.4477\n",
      "Epoch 37/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5521 - mae: 0.6209 - val_loss: 0.2483 - val_mae: 0.4419\n",
      "Epoch 38/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5447 - mae: 0.6166 - val_loss: 0.2431 - val_mae: 0.4361\n",
      "Epoch 39/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5375 - mae: 0.6122 - val_loss: 0.2380 - val_mae: 0.4304\n",
      "Epoch 40/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5305 - mae: 0.6078 - val_loss: 0.2331 - val_mae: 0.4246\n",
      "Epoch 41/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5236 - mae: 0.6035 - val_loss: 0.2283 - val_mae: 0.4190\n",
      "Epoch 42/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5170 - mae: 0.5993 - val_loss: 0.2237 - val_mae: 0.4134\n",
      "Epoch 43/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5107 - mae: 0.5951 - val_loss: 0.2192 - val_mae: 0.4079\n",
      "Epoch 44/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5047 - mae: 0.5911 - val_loss: 0.2149 - val_mae: 0.4025\n",
      "Epoch 45/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4988 - mae: 0.5872 - val_loss: 0.2107 - val_mae: 0.3972\n",
      "Epoch 46/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4931 - mae: 0.5834 - val_loss: 0.2067 - val_mae: 0.3920\n",
      "Epoch 47/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4875 - mae: 0.5796 - val_loss: 0.2028 - val_mae: 0.3869\n",
      "Epoch 48/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4820 - mae: 0.5759 - val_loss: 0.1990 - val_mae: 0.3818\n",
      "Epoch 49/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4767 - mae: 0.5722 - val_loss: 0.1954 - val_mae: 0.3769\n",
      "Epoch 50/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4714 - mae: 0.5687 - val_loss: 0.1918 - val_mae: 0.3720\n",
      "Epoch 51/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4665 - mae: 0.5652 - val_loss: 0.1884 - val_mae: 0.3673\n",
      "Epoch 52/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4617 - mae: 0.5618 - val_loss: 0.1851 - val_mae: 0.3627\n",
      "Epoch 53/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4569 - mae: 0.5584 - val_loss: 0.1818 - val_mae: 0.3582\n",
      "Epoch 54/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4523 - mae: 0.5551 - val_loss: 0.1787 - val_mae: 0.3537\n",
      "Epoch 55/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4477 - mae: 0.5519 - val_loss: 0.1756 - val_mae: 0.3494\n",
      "Epoch 56/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4431 - mae: 0.5486 - val_loss: 0.1727 - val_mae: 0.3451\n",
      "Epoch 57/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4388 - mae: 0.5455 - val_loss: 0.1698 - val_mae: 0.3409\n",
      "Epoch 58/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4347 - mae: 0.5425 - val_loss: 0.1670 - val_mae: 0.3368\n",
      "Epoch 59/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4307 - mae: 0.5395 - val_loss: 0.1642 - val_mae: 0.3328\n",
      "Epoch 60/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4267 - mae: 0.5366 - val_loss: 0.1616 - val_mae: 0.3288\n",
      "Epoch 61/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4228 - mae: 0.5337 - val_loss: 0.1590 - val_mae: 0.3250\n",
      "Epoch 62/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4190 - mae: 0.5308 - val_loss: 0.1564 - val_mae: 0.3212\n",
      "Epoch 63/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4152 - mae: 0.5280 - val_loss: 0.1540 - val_mae: 0.3175\n",
      "Epoch 64/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4114 - mae: 0.5252 - val_loss: 0.1516 - val_mae: 0.3138\n",
      "Epoch 65/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4077 - mae: 0.5225 - val_loss: 0.1492 - val_mae: 0.3102\n",
      "Epoch 66/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4041 - mae: 0.5198 - val_loss: 0.1469 - val_mae: 0.3067\n",
      "Epoch 67/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4004 - mae: 0.5172 - val_loss: 0.1447 - val_mae: 0.3032\n",
      "Epoch 68/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3969 - mae: 0.5146 - val_loss: 0.1425 - val_mae: 0.2998\n",
      "Epoch 69/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3933 - mae: 0.5120 - val_loss: 0.1404 - val_mae: 0.2964\n",
      "Epoch 70/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3898 - mae: 0.5095 - val_loss: 0.1383 - val_mae: 0.2931\n",
      "Epoch 71/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3863 - mae: 0.5069 - val_loss: 0.1362 - val_mae: 0.2899\n",
      "Epoch 72/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3829 - mae: 0.5045 - val_loss: 0.1342 - val_mae: 0.2866\n",
      "Epoch 73/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3796 - mae: 0.5020 - val_loss: 0.1322 - val_mae: 0.2835\n",
      "Epoch 74/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3762 - mae: 0.4996 - val_loss: 0.1302 - val_mae: 0.2803\n",
      "Epoch 75/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3729 - mae: 0.4972 - val_loss: 0.1283 - val_mae: 0.2772\n",
      "Epoch 76/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3697 - mae: 0.4949 - val_loss: 0.1264 - val_mae: 0.2741\n",
      "Epoch 77/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3664 - mae: 0.4926 - val_loss: 0.1246 - val_mae: 0.2714\n",
      "Epoch 78/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3632 - mae: 0.4902 - val_loss: 0.1227 - val_mae: 0.2693\n",
      "Epoch 79/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3601 - mae: 0.4880 - val_loss: 0.1209 - val_mae: 0.2672\n",
      "Epoch 80/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3569 - mae: 0.4857 - val_loss: 0.1192 - val_mae: 0.2651\n",
      "Epoch 81/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3539 - mae: 0.4834 - val_loss: 0.1174 - val_mae: 0.2630\n",
      "Epoch 82/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3509 - mae: 0.4812 - val_loss: 0.1157 - val_mae: 0.2609\n",
      "Epoch 83/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3478 - mae: 0.4790 - val_loss: 0.1140 - val_mae: 0.2589\n",
      "Epoch 84/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3448 - mae: 0.4767 - val_loss: 0.1123 - val_mae: 0.2568\n",
      "Epoch 85/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3419 - mae: 0.4745 - val_loss: 0.1106 - val_mae: 0.2547\n",
      "Epoch 86/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3389 - mae: 0.4723 - val_loss: 0.1090 - val_mae: 0.2526\n",
      "Epoch 87/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3360 - mae: 0.4701 - val_loss: 0.1074 - val_mae: 0.2505\n",
      "Epoch 88/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3331 - mae: 0.4679 - val_loss: 0.1058 - val_mae: 0.2484\n",
      "Epoch 89/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3302 - mae: 0.4657 - val_loss: 0.1042 - val_mae: 0.2463\n",
      "Epoch 90/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3274 - mae: 0.4636 - val_loss: 0.1026 - val_mae: 0.2442\n",
      "Epoch 91/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3246 - mae: 0.4615 - val_loss: 0.1011 - val_mae: 0.2422\n",
      "Epoch 92/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3218 - mae: 0.4594 - val_loss: 0.0996 - val_mae: 0.2401\n",
      "Epoch 93/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3190 - mae: 0.4573 - val_loss: 0.0981 - val_mae: 0.2381\n",
      "Epoch 94/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3162 - mae: 0.4552 - val_loss: 0.0966 - val_mae: 0.2361\n",
      "Epoch 95/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3135 - mae: 0.4531 - val_loss: 0.0952 - val_mae: 0.2340\n",
      "Epoch 96/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3108 - mae: 0.4510 - val_loss: 0.0937 - val_mae: 0.2320\n",
      "Epoch 97/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3081 - mae: 0.4489 - val_loss: 0.0923 - val_mae: 0.2300\n",
      "Epoch 98/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3054 - mae: 0.4468 - val_loss: 0.0909 - val_mae: 0.2280\n",
      "Epoch 99/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3027 - mae: 0.4448 - val_loss: 0.0895 - val_mae: 0.2260\n",
      "Epoch 100/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3001 - mae: 0.4427 - val_loss: 0.0881 - val_mae: 0.2240\n",
      "Epoch 101/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2975 - mae: 0.4406 - val_loss: 0.0867 - val_mae: 0.2220\n",
      "Epoch 102/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2949 - mae: 0.4386 - val_loss: 0.0854 - val_mae: 0.2201\n",
      "Epoch 103/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2923 - mae: 0.4365 - val_loss: 0.0841 - val_mae: 0.2181\n",
      "Epoch 104/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2897 - mae: 0.4346 - val_loss: 0.0827 - val_mae: 0.2162\n",
      "Epoch 105/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2872 - mae: 0.4327 - val_loss: 0.0814 - val_mae: 0.2142\n",
      "Epoch 106/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2847 - mae: 0.4307 - val_loss: 0.0801 - val_mae: 0.2122\n",
      "Epoch 107/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2822 - mae: 0.4288 - val_loss: 0.0789 - val_mae: 0.2103\n",
      "Epoch 108/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2797 - mae: 0.4268 - val_loss: 0.0776 - val_mae: 0.2084\n",
      "Epoch 109/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2772 - mae: 0.4249 - val_loss: 0.0763 - val_mae: 0.2065\n",
      "Epoch 110/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2748 - mae: 0.4233 - val_loss: 0.0751 - val_mae: 0.2046\n",
      "Epoch 111/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2723 - mae: 0.4216 - val_loss: 0.0739 - val_mae: 0.2027\n",
      "Epoch 112/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2697 - mae: 0.4199 - val_loss: 0.0727 - val_mae: 0.2008\n",
      "Epoch 113/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2669 - mae: 0.4180 - val_loss: 0.0714 - val_mae: 0.1989\n",
      "Epoch 114/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2639 - mae: 0.4161 - val_loss: 0.0703 - val_mae: 0.1970\n",
      "Epoch 115/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2608 - mae: 0.4141 - val_loss: 0.0691 - val_mae: 0.1951\n",
      "Epoch 116/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2577 - mae: 0.4121 - val_loss: 0.0679 - val_mae: 0.1932\n",
      "Epoch 117/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2546 - mae: 0.4101 - val_loss: 0.0668 - val_mae: 0.1913\n",
      "Epoch 118/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2515 - mae: 0.4080 - val_loss: 0.0656 - val_mae: 0.1894\n",
      "Epoch 119/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2484 - mae: 0.4059 - val_loss: 0.0645 - val_mae: 0.1875\n",
      "Epoch 120/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2454 - mae: 0.4038 - val_loss: 0.0633 - val_mae: 0.1855\n",
      "Epoch 121/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2424 - mae: 0.4017 - val_loss: 0.0623 - val_mae: 0.1836\n",
      "Epoch 122/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2395 - mae: 0.3996 - val_loss: 0.0613 - val_mae: 0.1815\n",
      "Epoch 123/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2367 - mae: 0.3975 - val_loss: 0.0604 - val_mae: 0.1795\n",
      "Epoch 124/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2339 - mae: 0.3954 - val_loss: 0.0594 - val_mae: 0.1774\n",
      "Epoch 125/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2312 - mae: 0.3933 - val_loss: 0.0585 - val_mae: 0.1753\n",
      "Epoch 126/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2285 - mae: 0.3912 - val_loss: 0.0575 - val_mae: 0.1733\n",
      "Epoch 127/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2258 - mae: 0.3891 - val_loss: 0.0566 - val_mae: 0.1712\n",
      "Epoch 128/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2232 - mae: 0.3870 - val_loss: 0.0557 - val_mae: 0.1691\n",
      "Epoch 129/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2207 - mae: 0.3849 - val_loss: 0.0548 - val_mae: 0.1670\n",
      "Epoch 130/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2183 - mae: 0.3829 - val_loss: 0.0539 - val_mae: 0.1649\n",
      "Epoch 131/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2159 - mae: 0.3808 - val_loss: 0.0530 - val_mae: 0.1632\n",
      "Epoch 132/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2136 - mae: 0.3788 - val_loss: 0.0521 - val_mae: 0.1620\n",
      "Epoch 133/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2113 - mae: 0.3769 - val_loss: 0.0513 - val_mae: 0.1608\n",
      "Epoch 134/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2090 - mae: 0.3750 - val_loss: 0.0504 - val_mae: 0.1596\n",
      "Epoch 135/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2069 - mae: 0.3731 - val_loss: 0.0496 - val_mae: 0.1584\n",
      "Epoch 136/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2047 - mae: 0.3713 - val_loss: 0.0488 - val_mae: 0.1573\n",
      "Epoch 137/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2026 - mae: 0.3694 - val_loss: 0.0481 - val_mae: 0.1562\n",
      "Epoch 138/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2005 - mae: 0.3676 - val_loss: 0.0473 - val_mae: 0.1552\n",
      "Epoch 139/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1985 - mae: 0.3658 - val_loss: 0.0466 - val_mae: 0.1541\n",
      "Epoch 140/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1965 - mae: 0.3640 - val_loss: 0.0459 - val_mae: 0.1531\n",
      "Epoch 141/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1945 - mae: 0.3622 - val_loss: 0.0453 - val_mae: 0.1521\n",
      "Epoch 142/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1925 - mae: 0.3604 - val_loss: 0.0446 - val_mae: 0.1510\n",
      "Epoch 143/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1906 - mae: 0.3587 - val_loss: 0.0440 - val_mae: 0.1501\n",
      "Epoch 144/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1887 - mae: 0.3569 - val_loss: 0.0434 - val_mae: 0.1491\n",
      "Epoch 145/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1868 - mae: 0.3552 - val_loss: 0.0428 - val_mae: 0.1481\n",
      "Epoch 146/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1850 - mae: 0.3534 - val_loss: 0.0422 - val_mae: 0.1472\n",
      "Epoch 147/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1832 - mae: 0.3517 - val_loss: 0.0417 - val_mae: 0.1462\n",
      "Epoch 148/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1814 - mae: 0.3500 - val_loss: 0.0411 - val_mae: 0.1453\n",
      "Epoch 149/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1796 - mae: 0.3483 - val_loss: 0.0406 - val_mae: 0.1443\n",
      "Epoch 150/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1779 - mae: 0.3467 - val_loss: 0.0401 - val_mae: 0.1433\n",
      "Epoch 151/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1762 - mae: 0.3450 - val_loss: 0.0396 - val_mae: 0.1424\n",
      "Epoch 152/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1745 - mae: 0.3433 - val_loss: 0.0391 - val_mae: 0.1414\n",
      "Epoch 153/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1728 - mae: 0.3417 - val_loss: 0.0387 - val_mae: 0.1411\n",
      "Epoch 154/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1712 - mae: 0.3401 - val_loss: 0.0382 - val_mae: 0.1410\n",
      "Epoch 155/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1696 - mae: 0.3384 - val_loss: 0.0378 - val_mae: 0.1408\n",
      "Epoch 156/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1680 - mae: 0.3368 - val_loss: 0.0373 - val_mae: 0.1407\n",
      "Epoch 157/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1665 - mae: 0.3352 - val_loss: 0.0369 - val_mae: 0.1405\n",
      "Epoch 158/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1650 - mae: 0.3336 - val_loss: 0.0365 - val_mae: 0.1403\n",
      "Epoch 159/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1634 - mae: 0.3320 - val_loss: 0.0361 - val_mae: 0.1402\n",
      "Epoch 160/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1620 - mae: 0.3304 - val_loss: 0.0357 - val_mae: 0.1400\n",
      "Epoch 161/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1605 - mae: 0.3289 - val_loss: 0.0354 - val_mae: 0.1399\n",
      "Epoch 162/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1591 - mae: 0.3273 - val_loss: 0.0350 - val_mae: 0.1398\n",
      "Epoch 163/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1577 - mae: 0.3258 - val_loss: 0.0347 - val_mae: 0.1396\n",
      "Epoch 164/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1563 - mae: 0.3243 - val_loss: 0.0344 - val_mae: 0.1395\n",
      "Epoch 165/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1549 - mae: 0.3228 - val_loss: 0.0341 - val_mae: 0.1394\n",
      "Epoch 166/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1536 - mae: 0.3213 - val_loss: 0.0338 - val_mae: 0.1392\n",
      "Epoch 167/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1522 - mae: 0.3198 - val_loss: 0.0335 - val_mae: 0.1390\n",
      "Epoch 168/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1509 - mae: 0.3183 - val_loss: 0.0333 - val_mae: 0.1389\n",
      "Epoch 169/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1497 - mae: 0.3168 - val_loss: 0.0330 - val_mae: 0.1387\n",
      "Epoch 170/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1484 - mae: 0.3154 - val_loss: 0.0328 - val_mae: 0.1386\n",
      "Epoch 171/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1472 - mae: 0.3139 - val_loss: 0.0326 - val_mae: 0.1384\n",
      "Epoch 172/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1460 - mae: 0.3125 - val_loss: 0.0324 - val_mae: 0.1383\n",
      "Epoch 173/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1448 - mae: 0.3111 - val_loss: 0.0322 - val_mae: 0.1382\n",
      "Epoch 174/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1436 - mae: 0.3097 - val_loss: 0.0320 - val_mae: 0.1380\n",
      "Epoch 175/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1424 - mae: 0.3083 - val_loss: 0.0318 - val_mae: 0.1378\n",
      "Epoch 176/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1413 - mae: 0.3069 - val_loss: 0.0317 - val_mae: 0.1377\n",
      "Epoch 177/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1402 - mae: 0.3055 - val_loss: 0.0315 - val_mae: 0.1375\n",
      "Epoch 178/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1391 - mae: 0.3041 - val_loss: 0.0314 - val_mae: 0.1378\n",
      "Epoch 179/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1381 - mae: 0.3028 - val_loss: 0.0313 - val_mae: 0.1384\n",
      "Epoch 180/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1371 - mae: 0.3017 - val_loss: 0.0312 - val_mae: 0.1390\n",
      "Epoch 181/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1362 - mae: 0.3005 - val_loss: 0.0311 - val_mae: 0.1397\n",
      "Epoch 182/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1352 - mae: 0.2993 - val_loss: 0.0310 - val_mae: 0.1403\n",
      "Epoch 183/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1343 - mae: 0.2981 - val_loss: 0.0309 - val_mae: 0.1409\n",
      "Epoch 184/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1334 - mae: 0.2969 - val_loss: 0.0308 - val_mae: 0.1415\n",
      "Epoch 185/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1326 - mae: 0.2957 - val_loss: 0.0308 - val_mae: 0.1422\n",
      "Epoch 186/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1317 - mae: 0.2945 - val_loss: 0.0308 - val_mae: 0.1429\n",
      "Epoch 187/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1308 - mae: 0.2932 - val_loss: 0.0308 - val_mae: 0.1437\n",
      "Epoch 188/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1300 - mae: 0.2920 - val_loss: 0.0308 - val_mae: 0.1444\n",
      "Epoch 189/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1292 - mae: 0.2908 - val_loss: 0.0308 - val_mae: 0.1451\n",
      "Epoch 190/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1284 - mae: 0.2896 - val_loss: 0.0308 - val_mae: 0.1457\n",
      "Epoch 191/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1276 - mae: 0.2885 - val_loss: 0.0308 - val_mae: 0.1462\n",
      "Epoch 192/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1268 - mae: 0.2873 - val_loss: 0.0308 - val_mae: 0.1468\n",
      "Epoch 193/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1260 - mae: 0.2862 - val_loss: 0.0308 - val_mae: 0.1473\n",
      "Epoch 194/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1253 - mae: 0.2851 - val_loss: 0.0308 - val_mae: 0.1478\n",
      "Epoch 195/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1245 - mae: 0.2840 - val_loss: 0.0309 - val_mae: 0.1484\n",
      "Epoch 196/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1238 - mae: 0.2831 - val_loss: 0.0309 - val_mae: 0.1489\n",
      "Epoch 197/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1230 - mae: 0.2822 - val_loss: 0.0310 - val_mae: 0.1495\n",
      "Epoch 198/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1223 - mae: 0.2812 - val_loss: 0.0311 - val_mae: 0.1501\n",
      "Epoch 199/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1216 - mae: 0.2803 - val_loss: 0.0312 - val_mae: 0.1507\n",
      "Epoch 200/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1209 - mae: 0.2794 - val_loss: 0.0312 - val_mae: 0.1512\n",
      "Epoch 1/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.8714 - mae: 0.8061 - val_loss: 0.4996 - val_mae: 0.5378\n",
      "Epoch 2/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.8577 - mae: 0.7984 - val_loss: 0.4970 - val_mae: 0.5338\n",
      "Epoch 3/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8449 - mae: 0.7912 - val_loss: 0.4947 - val_mae: 0.5299\n",
      "Epoch 4/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.8322 - mae: 0.7839 - val_loss: 0.4925 - val_mae: 0.5260\n",
      "Epoch 5/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8197 - mae: 0.7765 - val_loss: 0.4904 - val_mae: 0.5220\n",
      "Epoch 6/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8074 - mae: 0.7691 - val_loss: 0.4885 - val_mae: 0.5180\n",
      "Epoch 7/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.7953 - mae: 0.7616 - val_loss: 0.4867 - val_mae: 0.5140\n",
      "Epoch 8/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.7834 - mae: 0.7541 - val_loss: 0.4851 - val_mae: 0.5099\n",
      "Epoch 9/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.7717 - mae: 0.7465 - val_loss: 0.4836 - val_mae: 0.5057\n",
      "Epoch 10/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.7602 - mae: 0.7389 - val_loss: 0.4822 - val_mae: 0.5041\n",
      "Epoch 11/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.7489 - mae: 0.7312 - val_loss: 0.4809 - val_mae: 0.5074\n",
      "Epoch 12/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.7377 - mae: 0.7236 - val_loss: 0.4797 - val_mae: 0.5107\n",
      "Epoch 13/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.7266 - mae: 0.7158 - val_loss: 0.4786 - val_mae: 0.5139\n",
      "Epoch 14/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.7156 - mae: 0.7080 - val_loss: 0.4775 - val_mae: 0.5169\n",
      "Epoch 15/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.7046 - mae: 0.7002 - val_loss: 0.4765 - val_mae: 0.5198\n",
      "Epoch 16/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.6936 - mae: 0.6923 - val_loss: 0.4755 - val_mae: 0.5226\n",
      "Epoch 17/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.6826 - mae: 0.6843 - val_loss: 0.4745 - val_mae: 0.5253\n",
      "Epoch 18/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.6715 - mae: 0.6762 - val_loss: 0.4735 - val_mae: 0.5278\n",
      "Epoch 19/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.6603 - mae: 0.6680 - val_loss: 0.4724 - val_mae: 0.5301\n",
      "Epoch 20/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.6490 - mae: 0.6596 - val_loss: 0.4712 - val_mae: 0.5324\n",
      "Epoch 21/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.6375 - mae: 0.6511 - val_loss: 0.4700 - val_mae: 0.5344\n",
      "Epoch 22/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.6258 - mae: 0.6424 - val_loss: 0.4686 - val_mae: 0.5364\n",
      "Epoch 23/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.6140 - mae: 0.6337 - val_loss: 0.4671 - val_mae: 0.5381\n",
      "Epoch 24/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.6019 - mae: 0.6252 - val_loss: 0.4655 - val_mae: 0.5398\n",
      "Epoch 25/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5897 - mae: 0.6165 - val_loss: 0.4637 - val_mae: 0.5413\n",
      "Epoch 26/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5772 - mae: 0.6075 - val_loss: 0.4618 - val_mae: 0.5426\n",
      "Epoch 27/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5646 - mae: 0.5983 - val_loss: 0.4597 - val_mae: 0.5438\n",
      "Epoch 28/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.5519 - mae: 0.5889 - val_loss: 0.4575 - val_mae: 0.5448\n",
      "Epoch 29/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5390 - mae: 0.5805 - val_loss: 0.4550 - val_mae: 0.5457\n",
      "Epoch 30/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5261 - mae: 0.5720 - val_loss: 0.4524 - val_mae: 0.5465\n",
      "Epoch 31/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5132 - mae: 0.5633 - val_loss: 0.4496 - val_mae: 0.5471\n",
      "Epoch 32/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5003 - mae: 0.5544 - val_loss: 0.4467 - val_mae: 0.5476\n",
      "Epoch 33/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4876 - mae: 0.5456 - val_loss: 0.4436 - val_mae: 0.5479\n",
      "Epoch 34/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4751 - mae: 0.5382 - val_loss: 0.4403 - val_mae: 0.5481\n",
      "Epoch 35/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4629 - mae: 0.5306 - val_loss: 0.4369 - val_mae: 0.5481\n",
      "Epoch 36/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4510 - mae: 0.5230 - val_loss: 0.4333 - val_mae: 0.5480\n",
      "Epoch 37/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4395 - mae: 0.5154 - val_loss: 0.4297 - val_mae: 0.5477\n",
      "Epoch 38/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4286 - mae: 0.5078 - val_loss: 0.4259 - val_mae: 0.5473\n",
      "Epoch 39/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4182 - mae: 0.5007 - val_loss: 0.4220 - val_mae: 0.5468\n",
      "Epoch 40/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4083 - mae: 0.4972 - val_loss: 0.4181 - val_mae: 0.5461\n",
      "Epoch 41/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3991 - mae: 0.4946 - val_loss: 0.4141 - val_mae: 0.5453\n",
      "Epoch 42/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3905 - mae: 0.4927 - val_loss: 0.4101 - val_mae: 0.5444\n",
      "Epoch 43/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3826 - mae: 0.4907 - val_loss: 0.4060 - val_mae: 0.5433\n",
      "Epoch 44/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3752 - mae: 0.4887 - val_loss: 0.4019 - val_mae: 0.5421\n",
      "Epoch 45/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3684 - mae: 0.4867 - val_loss: 0.3978 - val_mae: 0.5408\n",
      "Epoch 46/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3621 - mae: 0.4847 - val_loss: 0.3937 - val_mae: 0.5394\n",
      "Epoch 47/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3564 - mae: 0.4827 - val_loss: 0.3896 - val_mae: 0.5379\n",
      "Epoch 48/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3511 - mae: 0.4806 - val_loss: 0.3855 - val_mae: 0.5363\n",
      "Epoch 49/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3462 - mae: 0.4786 - val_loss: 0.3815 - val_mae: 0.5345\n",
      "Epoch 50/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3417 - mae: 0.4766 - val_loss: 0.3774 - val_mae: 0.5327\n",
      "Epoch 51/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3375 - mae: 0.4746 - val_loss: 0.3734 - val_mae: 0.5308\n",
      "Epoch 52/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3336 - mae: 0.4726 - val_loss: 0.3694 - val_mae: 0.5288\n",
      "Epoch 53/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3299 - mae: 0.4707 - val_loss: 0.3654 - val_mae: 0.5267\n",
      "Epoch 54/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3265 - mae: 0.4688 - val_loss: 0.3614 - val_mae: 0.5245\n",
      "Epoch 55/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3233 - mae: 0.4669 - val_loss: 0.3575 - val_mae: 0.5223\n",
      "Epoch 56/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3203 - mae: 0.4651 - val_loss: 0.3535 - val_mae: 0.5199\n",
      "Epoch 57/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3173 - mae: 0.4633 - val_loss: 0.3495 - val_mae: 0.5175\n",
      "Epoch 58/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3146 - mae: 0.4615 - val_loss: 0.3456 - val_mae: 0.5151\n",
      "Epoch 59/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3119 - mae: 0.4597 - val_loss: 0.3417 - val_mae: 0.5125\n",
      "Epoch 60/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3094 - mae: 0.4579 - val_loss: 0.3377 - val_mae: 0.5099\n",
      "Epoch 61/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3069 - mae: 0.4562 - val_loss: 0.3338 - val_mae: 0.5072\n",
      "Epoch 62/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3045 - mae: 0.4545 - val_loss: 0.3299 - val_mae: 0.5044\n",
      "Epoch 63/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3022 - mae: 0.4528 - val_loss: 0.3260 - val_mae: 0.5016\n",
      "Epoch 64/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2999 - mae: 0.4511 - val_loss: 0.3221 - val_mae: 0.4988\n",
      "Epoch 65/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2977 - mae: 0.4494 - val_loss: 0.3182 - val_mae: 0.4958\n",
      "Epoch 66/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2955 - mae: 0.4477 - val_loss: 0.3143 - val_mae: 0.4929\n",
      "Epoch 67/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2934 - mae: 0.4461 - val_loss: 0.3104 - val_mae: 0.4898\n",
      "Epoch 68/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2913 - mae: 0.4444 - val_loss: 0.3065 - val_mae: 0.4868\n",
      "Epoch 69/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2893 - mae: 0.4428 - val_loss: 0.3026 - val_mae: 0.4837\n",
      "Epoch 70/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2873 - mae: 0.4412 - val_loss: 0.2988 - val_mae: 0.4805\n",
      "Epoch 71/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2853 - mae: 0.4395 - val_loss: 0.2949 - val_mae: 0.4774\n",
      "Epoch 72/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2833 - mae: 0.4379 - val_loss: 0.2911 - val_mae: 0.4742\n",
      "Epoch 73/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2814 - mae: 0.4363 - val_loss: 0.2873 - val_mae: 0.4709\n",
      "Epoch 74/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2795 - mae: 0.4347 - val_loss: 0.2835 - val_mae: 0.4677\n",
      "Epoch 75/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2776 - mae: 0.4330 - val_loss: 0.2797 - val_mae: 0.4644\n",
      "Epoch 76/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2757 - mae: 0.4314 - val_loss: 0.2760 - val_mae: 0.4611\n",
      "Epoch 77/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2739 - mae: 0.4298 - val_loss: 0.2722 - val_mae: 0.4578\n",
      "Epoch 78/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2721 - mae: 0.4282 - val_loss: 0.2685 - val_mae: 0.4545\n",
      "Epoch 79/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2703 - mae: 0.4267 - val_loss: 0.2649 - val_mae: 0.4511\n",
      "Epoch 80/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2685 - mae: 0.4251 - val_loss: 0.2612 - val_mae: 0.4477\n",
      "Epoch 81/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2667 - mae: 0.4235 - val_loss: 0.2576 - val_mae: 0.4444\n",
      "Epoch 82/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2650 - mae: 0.4219 - val_loss: 0.2540 - val_mae: 0.4410\n",
      "Epoch 83/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2633 - mae: 0.4204 - val_loss: 0.2504 - val_mae: 0.4376\n",
      "Epoch 84/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2616 - mae: 0.4188 - val_loss: 0.2469 - val_mae: 0.4343\n",
      "Epoch 85/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2599 - mae: 0.4172 - val_loss: 0.2434 - val_mae: 0.4309\n",
      "Epoch 86/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2582 - mae: 0.4157 - val_loss: 0.2400 - val_mae: 0.4275\n",
      "Epoch 87/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2566 - mae: 0.4142 - val_loss: 0.2366 - val_mae: 0.4241\n",
      "Epoch 88/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2549 - mae: 0.4127 - val_loss: 0.2332 - val_mae: 0.4208\n",
      "Epoch 89/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2533 - mae: 0.4111 - val_loss: 0.2299 - val_mae: 0.4174\n",
      "Epoch 90/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2517 - mae: 0.4096 - val_loss: 0.2266 - val_mae: 0.4141\n",
      "Epoch 91/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2501 - mae: 0.4081 - val_loss: 0.2233 - val_mae: 0.4107\n",
      "Epoch 92/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2485 - mae: 0.4066 - val_loss: 0.2201 - val_mae: 0.4074\n",
      "Epoch 93/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2470 - mae: 0.4052 - val_loss: 0.2169 - val_mae: 0.4041\n",
      "Epoch 94/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2455 - mae: 0.4037 - val_loss: 0.2137 - val_mae: 0.4007\n",
      "Epoch 95/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2439 - mae: 0.4023 - val_loss: 0.2106 - val_mae: 0.3974\n",
      "Epoch 96/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2424 - mae: 0.4009 - val_loss: 0.2076 - val_mae: 0.3942\n",
      "Epoch 97/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2410 - mae: 0.3996 - val_loss: 0.2046 - val_mae: 0.3909\n",
      "Epoch 98/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2395 - mae: 0.3982 - val_loss: 0.2016 - val_mae: 0.3876\n",
      "Epoch 99/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2381 - mae: 0.3969 - val_loss: 0.1986 - val_mae: 0.3844\n",
      "Epoch 100/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2366 - mae: 0.3955 - val_loss: 0.1957 - val_mae: 0.3811\n",
      "Epoch 101/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2352 - mae: 0.3942 - val_loss: 0.1929 - val_mae: 0.3779\n",
      "Epoch 102/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2338 - mae: 0.3929 - val_loss: 0.1901 - val_mae: 0.3747\n",
      "Epoch 103/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2324 - mae: 0.3916 - val_loss: 0.1873 - val_mae: 0.3716\n",
      "Epoch 104/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2311 - mae: 0.3903 - val_loss: 0.1845 - val_mae: 0.3684\n",
      "Epoch 105/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2297 - mae: 0.3890 - val_loss: 0.1818 - val_mae: 0.3653\n",
      "Epoch 106/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2284 - mae: 0.3878 - val_loss: 0.1792 - val_mae: 0.3622\n",
      "Epoch 107/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2270 - mae: 0.3865 - val_loss: 0.1766 - val_mae: 0.3596\n",
      "Epoch 108/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2257 - mae: 0.3854 - val_loss: 0.1740 - val_mae: 0.3571\n",
      "Epoch 109/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2245 - mae: 0.3842 - val_loss: 0.1714 - val_mae: 0.3545\n",
      "Epoch 110/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2232 - mae: 0.3831 - val_loss: 0.1689 - val_mae: 0.3520\n",
      "Epoch 111/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2219 - mae: 0.3819 - val_loss: 0.1665 - val_mae: 0.3495\n",
      "Epoch 112/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2207 - mae: 0.3808 - val_loss: 0.1640 - val_mae: 0.3470\n",
      "Epoch 113/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2195 - mae: 0.3798 - val_loss: 0.1616 - val_mae: 0.3445\n",
      "Epoch 114/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2182 - mae: 0.3787 - val_loss: 0.1593 - val_mae: 0.3420\n",
      "Epoch 115/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2171 - mae: 0.3776 - val_loss: 0.1569 - val_mae: 0.3395\n",
      "Epoch 116/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2159 - mae: 0.3765 - val_loss: 0.1546 - val_mae: 0.3371\n",
      "Epoch 117/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2147 - mae: 0.3754 - val_loss: 0.1524 - val_mae: 0.3347\n",
      "Epoch 118/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2136 - mae: 0.3744 - val_loss: 0.1502 - val_mae: 0.3322\n",
      "Epoch 119/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2124 - mae: 0.3733 - val_loss: 0.1480 - val_mae: 0.3298\n",
      "Epoch 120/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2113 - mae: 0.3723 - val_loss: 0.1458 - val_mae: 0.3274\n",
      "Epoch 121/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2102 - mae: 0.3712 - val_loss: 0.1437 - val_mae: 0.3250\n",
      "Epoch 122/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2091 - mae: 0.3702 - val_loss: 0.1416 - val_mae: 0.3226\n",
      "Epoch 123/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2080 - mae: 0.3692 - val_loss: 0.1395 - val_mae: 0.3203\n",
      "Epoch 124/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2069 - mae: 0.3682 - val_loss: 0.1375 - val_mae: 0.3179\n",
      "Epoch 125/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2059 - mae: 0.3672 - val_loss: 0.1355 - val_mae: 0.3156\n",
      "Epoch 126/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2048 - mae: 0.3662 - val_loss: 0.1335 - val_mae: 0.3133\n",
      "Epoch 127/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2038 - mae: 0.3652 - val_loss: 0.1316 - val_mae: 0.3109\n",
      "Epoch 128/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2028 - mae: 0.3642 - val_loss: 0.1297 - val_mae: 0.3086\n",
      "Epoch 129/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2018 - mae: 0.3632 - val_loss: 0.1278 - val_mae: 0.3064\n",
      "Epoch 130/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2008 - mae: 0.3622 - val_loss: 0.1260 - val_mae: 0.3041\n",
      "Epoch 131/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1998 - mae: 0.3612 - val_loss: 0.1241 - val_mae: 0.3018\n",
      "Epoch 132/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1989 - mae: 0.3603 - val_loss: 0.1223 - val_mae: 0.2996\n",
      "Epoch 133/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1979 - mae: 0.3593 - val_loss: 0.1206 - val_mae: 0.2974\n",
      "Epoch 134/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1970 - mae: 0.3584 - val_loss: 0.1188 - val_mae: 0.2951\n",
      "Epoch 135/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1961 - mae: 0.3574 - val_loss: 0.1171 - val_mae: 0.2929\n",
      "Epoch 136/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1952 - mae: 0.3565 - val_loss: 0.1154 - val_mae: 0.2907\n",
      "Epoch 137/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1943 - mae: 0.3555 - val_loss: 0.1138 - val_mae: 0.2886\n",
      "Epoch 138/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1934 - mae: 0.3546 - val_loss: 0.1121 - val_mae: 0.2864\n",
      "Epoch 139/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1925 - mae: 0.3537 - val_loss: 0.1105 - val_mae: 0.2842\n",
      "Epoch 140/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1916 - mae: 0.3528 - val_loss: 0.1089 - val_mae: 0.2821\n",
      "Epoch 141/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1908 - mae: 0.3519 - val_loss: 0.1074 - val_mae: 0.2800\n",
      "Epoch 142/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1899 - mae: 0.3510 - val_loss: 0.1058 - val_mae: 0.2779\n",
      "Epoch 143/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1891 - mae: 0.3501 - val_loss: 0.1043 - val_mae: 0.2758\n",
      "Epoch 144/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1883 - mae: 0.3492 - val_loss: 0.1028 - val_mae: 0.2737\n",
      "Epoch 145/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1875 - mae: 0.3484 - val_loss: 0.1014 - val_mae: 0.2716\n",
      "Epoch 146/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1867 - mae: 0.3475 - val_loss: 0.0999 - val_mae: 0.2695\n",
      "Epoch 147/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1859 - mae: 0.3467 - val_loss: 0.0985 - val_mae: 0.2675\n",
      "Epoch 148/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1851 - mae: 0.3458 - val_loss: 0.0971 - val_mae: 0.2654\n",
      "Epoch 149/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1844 - mae: 0.3450 - val_loss: 0.0957 - val_mae: 0.2634\n",
      "Epoch 150/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1836 - mae: 0.3442 - val_loss: 0.0943 - val_mae: 0.2614\n",
      "Epoch 151/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1829 - mae: 0.3433 - val_loss: 0.0930 - val_mae: 0.2594\n",
      "Epoch 152/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1822 - mae: 0.3425 - val_loss: 0.0917 - val_mae: 0.2574\n",
      "Epoch 153/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1814 - mae: 0.3417 - val_loss: 0.0904 - val_mae: 0.2554\n",
      "Epoch 154/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1807 - mae: 0.3409 - val_loss: 0.0891 - val_mae: 0.2535\n",
      "Epoch 155/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1800 - mae: 0.3401 - val_loss: 0.0879 - val_mae: 0.2515\n",
      "Epoch 156/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1793 - mae: 0.3393 - val_loss: 0.0866 - val_mae: 0.2496\n",
      "Epoch 157/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1787 - mae: 0.3385 - val_loss: 0.0854 - val_mae: 0.2477\n",
      "Epoch 158/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1780 - mae: 0.3377 - val_loss: 0.0842 - val_mae: 0.2458\n",
      "Epoch 159/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1773 - mae: 0.3369 - val_loss: 0.0830 - val_mae: 0.2439\n",
      "Epoch 160/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1767 - mae: 0.3361 - val_loss: 0.0819 - val_mae: 0.2420\n",
      "Epoch 161/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1760 - mae: 0.3354 - val_loss: 0.0807 - val_mae: 0.2401\n",
      "Epoch 162/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1754 - mae: 0.3346 - val_loss: 0.0796 - val_mae: 0.2382\n",
      "Epoch 163/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1748 - mae: 0.3338 - val_loss: 0.0785 - val_mae: 0.2364\n",
      "Epoch 164/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1742 - mae: 0.3331 - val_loss: 0.0774 - val_mae: 0.2345\n",
      "Epoch 165/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1736 - mae: 0.3323 - val_loss: 0.0764 - val_mae: 0.2327\n",
      "Epoch 166/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1730 - mae: 0.3315 - val_loss: 0.0753 - val_mae: 0.2309\n",
      "Epoch 167/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1724 - mae: 0.3308 - val_loss: 0.0743 - val_mae: 0.2291\n",
      "Epoch 168/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1718 - mae: 0.3300 - val_loss: 0.0733 - val_mae: 0.2273\n",
      "Epoch 169/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1712 - mae: 0.3293 - val_loss: 0.0723 - val_mae: 0.2255\n",
      "Epoch 170/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1707 - mae: 0.3286 - val_loss: 0.0713 - val_mae: 0.2238\n",
      "Epoch 171/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1701 - mae: 0.3278 - val_loss: 0.0703 - val_mae: 0.2220\n",
      "Epoch 172/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1696 - mae: 0.3271 - val_loss: 0.0693 - val_mae: 0.2203\n",
      "Epoch 173/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1690 - mae: 0.3264 - val_loss: 0.0684 - val_mae: 0.2185\n",
      "Epoch 174/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1685 - mae: 0.3257 - val_loss: 0.0675 - val_mae: 0.2168\n",
      "Epoch 175/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1680 - mae: 0.3250 - val_loss: 0.0666 - val_mae: 0.2151\n",
      "Epoch 176/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1675 - mae: 0.3243 - val_loss: 0.0657 - val_mae: 0.2134\n",
      "Epoch 177/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1670 - mae: 0.3236 - val_loss: 0.0648 - val_mae: 0.2117\n",
      "Epoch 178/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.1665 - mae: 0.3229 - val_loss: 0.0639 - val_mae: 0.2101\n",
      "Epoch 179/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1660 - mae: 0.3222 - val_loss: 0.0631 - val_mae: 0.2084\n",
      "Epoch 180/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1655 - mae: 0.3215 - val_loss: 0.0623 - val_mae: 0.2067\n",
      "Epoch 181/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1650 - mae: 0.3208 - val_loss: 0.0614 - val_mae: 0.2051\n",
      "Epoch 182/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1646 - mae: 0.3201 - val_loss: 0.0606 - val_mae: 0.2035\n",
      "Epoch 183/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1641 - mae: 0.3194 - val_loss: 0.0598 - val_mae: 0.2019\n",
      "Epoch 184/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1637 - mae: 0.3188 - val_loss: 0.0590 - val_mae: 0.2003\n",
      "Epoch 185/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1632 - mae: 0.3181 - val_loss: 0.0583 - val_mae: 0.1987\n",
      "Epoch 186/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.1628 - mae: 0.3174 - val_loss: 0.0575 - val_mae: 0.1971\n",
      "Epoch 187/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1624 - mae: 0.3168 - val_loss: 0.0568 - val_mae: 0.1955\n",
      "Epoch 188/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1619 - mae: 0.3161 - val_loss: 0.0561 - val_mae: 0.1939\n",
      "Epoch 189/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1615 - mae: 0.3155 - val_loss: 0.0553 - val_mae: 0.1924\n",
      "Epoch 190/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1611 - mae: 0.3148 - val_loss: 0.0546 - val_mae: 0.1909\n",
      "Epoch 191/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1607 - mae: 0.3142 - val_loss: 0.0539 - val_mae: 0.1893\n",
      "Epoch 192/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1603 - mae: 0.3136 - val_loss: 0.0533 - val_mae: 0.1878\n",
      "Epoch 193/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1599 - mae: 0.3129 - val_loss: 0.0526 - val_mae: 0.1863\n",
      "Epoch 194/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1595 - mae: 0.3123 - val_loss: 0.0519 - val_mae: 0.1848\n",
      "Epoch 195/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1591 - mae: 0.3117 - val_loss: 0.0513 - val_mae: 0.1833\n",
      "Epoch 196/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1588 - mae: 0.3111 - val_loss: 0.0507 - val_mae: 0.1819\n",
      "Epoch 197/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1584 - mae: 0.3105 - val_loss: 0.0500 - val_mae: 0.1804\n",
      "Epoch 198/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1580 - mae: 0.3098 - val_loss: 0.0494 - val_mae: 0.1789\n",
      "Epoch 199/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1577 - mae: 0.3092 - val_loss: 0.0488 - val_mae: 0.1775\n",
      "Epoch 200/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1573 - mae: 0.3086 - val_loss: 0.0482 - val_mae: 0.1761\n",
      "Epoch 1/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 1.1138 - mae: 0.8714 - val_loss: 0.7543 - val_mae: 0.7625\n",
      "Epoch 2/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.1072 - mae: 0.8676 - val_loss: 0.7493 - val_mae: 0.7588\n",
      "Epoch 3/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.1017 - mae: 0.8644 - val_loss: 0.7441 - val_mae: 0.7551\n",
      "Epoch 4/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0962 - mae: 0.8613 - val_loss: 0.7389 - val_mae: 0.7512\n",
      "Epoch 5/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.0908 - mae: 0.8581 - val_loss: 0.7336 - val_mae: 0.7473\n",
      "Epoch 6/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.0855 - mae: 0.8549 - val_loss: 0.7284 - val_mae: 0.7434\n",
      "Epoch 7/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.0801 - mae: 0.8516 - val_loss: 0.7232 - val_mae: 0.7394\n",
      "Epoch 8/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.0748 - mae: 0.8484 - val_loss: 0.7180 - val_mae: 0.7355\n",
      "Epoch 9/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.0695 - mae: 0.8450 - val_loss: 0.7129 - val_mae: 0.7316\n",
      "Epoch 10/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0642 - mae: 0.8417 - val_loss: 0.7077 - val_mae: 0.7277\n",
      "Epoch 11/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.0588 - mae: 0.8383 - val_loss: 0.7026 - val_mae: 0.7238\n",
      "Epoch 12/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0535 - mae: 0.8348 - val_loss: 0.6974 - val_mae: 0.7199\n",
      "Epoch 13/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.0481 - mae: 0.8314 - val_loss: 0.6922 - val_mae: 0.7160\n",
      "Epoch 14/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.0427 - mae: 0.8279 - val_loss: 0.6870 - val_mae: 0.7121\n",
      "Epoch 15/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0371 - mae: 0.8243 - val_loss: 0.6818 - val_mae: 0.7083\n",
      "Epoch 16/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0316 - mae: 0.8210 - val_loss: 0.6765 - val_mae: 0.7044\n",
      "Epoch 17/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.0259 - mae: 0.8177 - val_loss: 0.6712 - val_mae: 0.7005\n",
      "Epoch 18/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.0201 - mae: 0.8144 - val_loss: 0.6657 - val_mae: 0.6967\n",
      "Epoch 19/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.0142 - mae: 0.8110 - val_loss: 0.6602 - val_mae: 0.6928\n",
      "Epoch 20/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0082 - mae: 0.8076 - val_loss: 0.6546 - val_mae: 0.6890\n",
      "Epoch 21/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0020 - mae: 0.8042 - val_loss: 0.6488 - val_mae: 0.6851\n",
      "Epoch 22/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.9957 - mae: 0.8009 - val_loss: 0.6429 - val_mae: 0.6812\n",
      "Epoch 23/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.9892 - mae: 0.7986 - val_loss: 0.6369 - val_mae: 0.6773\n",
      "Epoch 24/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.9824 - mae: 0.7963 - val_loss: 0.6307 - val_mae: 0.6733\n",
      "Epoch 25/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9755 - mae: 0.7938 - val_loss: 0.6243 - val_mae: 0.6693\n",
      "Epoch 26/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9684 - mae: 0.7913 - val_loss: 0.6177 - val_mae: 0.6652\n",
      "Epoch 27/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9610 - mae: 0.7887 - val_loss: 0.6108 - val_mae: 0.6611\n",
      "Epoch 28/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.9533 - mae: 0.7860 - val_loss: 0.6038 - val_mae: 0.6569\n",
      "Epoch 29/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9454 - mae: 0.7832 - val_loss: 0.5964 - val_mae: 0.6526\n",
      "Epoch 30/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.9372 - mae: 0.7803 - val_loss: 0.5889 - val_mae: 0.6482\n",
      "Epoch 31/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.9287 - mae: 0.7773 - val_loss: 0.5810 - val_mae: 0.6437\n",
      "Epoch 32/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.9199 - mae: 0.7742 - val_loss: 0.5729 - val_mae: 0.6391\n",
      "Epoch 33/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.9108 - mae: 0.7709 - val_loss: 0.5644 - val_mae: 0.6344\n",
      "Epoch 34/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9014 - mae: 0.7676 - val_loss: 0.5557 - val_mae: 0.6295\n",
      "Epoch 35/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.8916 - mae: 0.7641 - val_loss: 0.5466 - val_mae: 0.6245\n",
      "Epoch 36/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.8814 - mae: 0.7604 - val_loss: 0.5371 - val_mae: 0.6194\n",
      "Epoch 37/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.8709 - mae: 0.7567 - val_loss: 0.5274 - val_mae: 0.6140\n",
      "Epoch 38/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.8601 - mae: 0.7528 - val_loss: 0.5173 - val_mae: 0.6085\n",
      "Epoch 39/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8488 - mae: 0.7490 - val_loss: 0.5068 - val_mae: 0.6028\n",
      "Epoch 40/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.8373 - mae: 0.7451 - val_loss: 0.4960 - val_mae: 0.5969\n",
      "Epoch 41/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.8253 - mae: 0.7410 - val_loss: 0.4848 - val_mae: 0.5907\n",
      "Epoch 42/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.8130 - mae: 0.7368 - val_loss: 0.4733 - val_mae: 0.5844\n",
      "Epoch 43/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.8003 - mae: 0.7324 - val_loss: 0.4614 - val_mae: 0.5778\n",
      "Epoch 44/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.7873 - mae: 0.7279 - val_loss: 0.4492 - val_mae: 0.5710\n",
      "Epoch 45/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.7740 - mae: 0.7232 - val_loss: 0.4367 - val_mae: 0.5639\n",
      "Epoch 46/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.7603 - mae: 0.7183 - val_loss: 0.4239 - val_mae: 0.5566\n",
      "Epoch 47/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.7464 - mae: 0.7133 - val_loss: 0.4108 - val_mae: 0.5490\n",
      "Epoch 48/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7322 - mae: 0.7080 - val_loss: 0.3974 - val_mae: 0.5412\n",
      "Epoch 49/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.7178 - mae: 0.7027 - val_loss: 0.3839 - val_mae: 0.5331\n",
      "Epoch 50/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7032 - mae: 0.6971 - val_loss: 0.3701 - val_mae: 0.5247\n",
      "Epoch 51/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.6884 - mae: 0.6914 - val_loss: 0.3562 - val_mae: 0.5161\n",
      "Epoch 52/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.6736 - mae: 0.6855 - val_loss: 0.3421 - val_mae: 0.5073\n",
      "Epoch 53/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.6586 - mae: 0.6795 - val_loss: 0.3281 - val_mae: 0.4982\n",
      "Epoch 54/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.6437 - mae: 0.6734 - val_loss: 0.3139 - val_mae: 0.4889\n",
      "Epoch 55/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.6288 - mae: 0.6671 - val_loss: 0.2999 - val_mae: 0.4793\n",
      "Epoch 56/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.6140 - mae: 0.6606 - val_loss: 0.2859 - val_mae: 0.4696\n",
      "Epoch 57/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.5994 - mae: 0.6541 - val_loss: 0.2720 - val_mae: 0.4597\n",
      "Epoch 58/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5849 - mae: 0.6474 - val_loss: 0.2583 - val_mae: 0.4496\n",
      "Epoch 59/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5707 - mae: 0.6407 - val_loss: 0.2449 - val_mae: 0.4394\n",
      "Epoch 60/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5569 - mae: 0.6338 - val_loss: 0.2317 - val_mae: 0.4291\n",
      "Epoch 61/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.5434 - mae: 0.6270 - val_loss: 0.2189 - val_mae: 0.4187\n",
      "Epoch 62/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.5303 - mae: 0.6200 - val_loss: 0.2064 - val_mae: 0.4082\n",
      "Epoch 63/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5176 - mae: 0.6131 - val_loss: 0.1944 - val_mae: 0.3977\n",
      "Epoch 64/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5055 - mae: 0.6061 - val_loss: 0.1828 - val_mae: 0.3872\n",
      "Epoch 65/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4939 - mae: 0.5992 - val_loss: 0.1717 - val_mae: 0.3767\n",
      "Epoch 66/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4828 - mae: 0.5924 - val_loss: 0.1611 - val_mae: 0.3663\n",
      "Epoch 67/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4723 - mae: 0.5858 - val_loss: 0.1510 - val_mae: 0.3560\n",
      "Epoch 68/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4624 - mae: 0.5792 - val_loss: 0.1415 - val_mae: 0.3458\n",
      "Epoch 69/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4530 - mae: 0.5727 - val_loss: 0.1325 - val_mae: 0.3357\n",
      "Epoch 70/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4443 - mae: 0.5663 - val_loss: 0.1241 - val_mae: 0.3258\n",
      "Epoch 71/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4361 - mae: 0.5600 - val_loss: 0.1162 - val_mae: 0.3161\n",
      "Epoch 72/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4285 - mae: 0.5538 - val_loss: 0.1088 - val_mae: 0.3066\n",
      "Epoch 73/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4214 - mae: 0.5478 - val_loss: 0.1020 - val_mae: 0.2973\n",
      "Epoch 74/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4149 - mae: 0.5419 - val_loss: 0.0956 - val_mae: 0.2883\n",
      "Epoch 75/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4089 - mae: 0.5361 - val_loss: 0.0898 - val_mae: 0.2795\n",
      "Epoch 76/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4033 - mae: 0.5305 - val_loss: 0.0844 - val_mae: 0.2709\n",
      "Epoch 77/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3982 - mae: 0.5250 - val_loss: 0.0794 - val_mae: 0.2627\n",
      "Epoch 78/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3936 - mae: 0.5197 - val_loss: 0.0749 - val_mae: 0.2547\n",
      "Epoch 79/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3893 - mae: 0.5146 - val_loss: 0.0708 - val_mae: 0.2470\n",
      "Epoch 80/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3854 - mae: 0.5097 - val_loss: 0.0670 - val_mae: 0.2396\n",
      "Epoch 81/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3818 - mae: 0.5049 - val_loss: 0.0636 - val_mae: 0.2325\n",
      "Epoch 82/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3785 - mae: 0.5002 - val_loss: 0.0604 - val_mae: 0.2256\n",
      "Epoch 83/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3755 - mae: 0.4958 - val_loss: 0.0576 - val_mae: 0.2191\n",
      "Epoch 84/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3727 - mae: 0.4915 - val_loss: 0.0551 - val_mae: 0.2128\n",
      "Epoch 85/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3702 - mae: 0.4873 - val_loss: 0.0528 - val_mae: 0.2068\n",
      "Epoch 86/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3678 - mae: 0.4833 - val_loss: 0.0507 - val_mae: 0.2010\n",
      "Epoch 87/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3657 - mae: 0.4798 - val_loss: 0.0488 - val_mae: 0.1955\n",
      "Epoch 88/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3637 - mae: 0.4766 - val_loss: 0.0471 - val_mae: 0.1903\n",
      "Epoch 89/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3618 - mae: 0.4736 - val_loss: 0.0456 - val_mae: 0.1853\n",
      "Epoch 90/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3601 - mae: 0.4706 - val_loss: 0.0442 - val_mae: 0.1805\n",
      "Epoch 91/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3585 - mae: 0.4678 - val_loss: 0.0430 - val_mae: 0.1760\n",
      "Epoch 92/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3569 - mae: 0.4651 - val_loss: 0.0418 - val_mae: 0.1717\n",
      "Epoch 93/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3555 - mae: 0.4624 - val_loss: 0.0409 - val_mae: 0.1676\n",
      "Epoch 94/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3541 - mae: 0.4599 - val_loss: 0.0400 - val_mae: 0.1637\n",
      "Epoch 95/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3528 - mae: 0.4574 - val_loss: 0.0392 - val_mae: 0.1599\n",
      "Epoch 96/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3516 - mae: 0.4551 - val_loss: 0.0385 - val_mae: 0.1564\n",
      "Epoch 97/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3503 - mae: 0.4528 - val_loss: 0.0378 - val_mae: 0.1530\n",
      "Epoch 98/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3492 - mae: 0.4505 - val_loss: 0.0373 - val_mae: 0.1499\n",
      "Epoch 99/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3480 - mae: 0.4484 - val_loss: 0.0367 - val_mae: 0.1479\n",
      "Epoch 100/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3469 - mae: 0.4465 - val_loss: 0.0363 - val_mae: 0.1468\n",
      "Epoch 101/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3458 - mae: 0.4447 - val_loss: 0.0359 - val_mae: 0.1456\n",
      "Epoch 102/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3448 - mae: 0.4431 - val_loss: 0.0356 - val_mae: 0.1445\n",
      "Epoch 103/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3437 - mae: 0.4417 - val_loss: 0.0352 - val_mae: 0.1435\n",
      "Epoch 104/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3427 - mae: 0.4404 - val_loss: 0.0350 - val_mae: 0.1425\n",
      "Epoch 105/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3416 - mae: 0.4391 - val_loss: 0.0347 - val_mae: 0.1415\n",
      "Epoch 106/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3406 - mae: 0.4379 - val_loss: 0.0345 - val_mae: 0.1406\n",
      "Epoch 107/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3396 - mae: 0.4367 - val_loss: 0.0343 - val_mae: 0.1397\n",
      "Epoch 108/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3386 - mae: 0.4356 - val_loss: 0.0342 - val_mae: 0.1389\n",
      "Epoch 109/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3376 - mae: 0.4345 - val_loss: 0.0341 - val_mae: 0.1380\n",
      "Epoch 110/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3366 - mae: 0.4334 - val_loss: 0.0340 - val_mae: 0.1373\n",
      "Epoch 111/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3356 - mae: 0.4324 - val_loss: 0.0339 - val_mae: 0.1365\n",
      "Epoch 112/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3346 - mae: 0.4313 - val_loss: 0.0338 - val_mae: 0.1358\n",
      "Epoch 113/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3336 - mae: 0.4304 - val_loss: 0.0338 - val_mae: 0.1351\n",
      "Epoch 114/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3326 - mae: 0.4294 - val_loss: 0.0337 - val_mae: 0.1344\n",
      "Epoch 115/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3316 - mae: 0.4285 - val_loss: 0.0337 - val_mae: 0.1338\n",
      "Epoch 116/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3306 - mae: 0.4276 - val_loss: 0.0337 - val_mae: 0.1333\n",
      "Epoch 117/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3296 - mae: 0.4267 - val_loss: 0.0337 - val_mae: 0.1329\n",
      "Epoch 118/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3285 - mae: 0.4259 - val_loss: 0.0337 - val_mae: 0.1328\n",
      "Epoch 119/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3275 - mae: 0.4250 - val_loss: 0.0337 - val_mae: 0.1335\n",
      "Epoch 120/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3265 - mae: 0.4242 - val_loss: 0.0338 - val_mae: 0.1342\n",
      "Epoch 121/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3255 - mae: 0.4234 - val_loss: 0.0338 - val_mae: 0.1348\n",
      "Epoch 122/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3245 - mae: 0.4226 - val_loss: 0.0339 - val_mae: 0.1354\n",
      "Epoch 123/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3235 - mae: 0.4219 - val_loss: 0.0339 - val_mae: 0.1360\n",
      "Epoch 124/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3225 - mae: 0.4211 - val_loss: 0.0340 - val_mae: 0.1366\n",
      "Epoch 125/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3215 - mae: 0.4204 - val_loss: 0.0341 - val_mae: 0.1372\n",
      "Epoch 126/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3205 - mae: 0.4197 - val_loss: 0.0341 - val_mae: 0.1377\n",
      "Epoch 127/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3195 - mae: 0.4190 - val_loss: 0.0342 - val_mae: 0.1382\n",
      "Epoch 128/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3185 - mae: 0.4183 - val_loss: 0.0343 - val_mae: 0.1388\n",
      "Epoch 129/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3175 - mae: 0.4177 - val_loss: 0.0344 - val_mae: 0.1395\n",
      "Epoch 130/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3165 - mae: 0.4170 - val_loss: 0.0345 - val_mae: 0.1402\n",
      "Epoch 131/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3155 - mae: 0.4166 - val_loss: 0.0346 - val_mae: 0.1409\n",
      "Epoch 132/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3145 - mae: 0.4163 - val_loss: 0.0347 - val_mae: 0.1416\n",
      "Epoch 133/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3135 - mae: 0.4159 - val_loss: 0.0348 - val_mae: 0.1424\n",
      "Epoch 134/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3125 - mae: 0.4156 - val_loss: 0.0350 - val_mae: 0.1431\n",
      "Epoch 135/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3115 - mae: 0.4153 - val_loss: 0.0351 - val_mae: 0.1439\n",
      "Epoch 136/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3105 - mae: 0.4150 - val_loss: 0.0352 - val_mae: 0.1446\n",
      "Epoch 137/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3095 - mae: 0.4146 - val_loss: 0.0353 - val_mae: 0.1454\n",
      "Epoch 138/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3085 - mae: 0.4143 - val_loss: 0.0355 - val_mae: 0.1462\n",
      "Epoch 139/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3076 - mae: 0.4140 - val_loss: 0.0356 - val_mae: 0.1469\n",
      "Epoch 140/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3066 - mae: 0.4137 - val_loss: 0.0357 - val_mae: 0.1477\n",
      "Epoch 141/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3056 - mae: 0.4134 - val_loss: 0.0359 - val_mae: 0.1485\n",
      "Epoch 142/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3046 - mae: 0.4131 - val_loss: 0.0360 - val_mae: 0.1492\n",
      "Epoch 143/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3037 - mae: 0.4128 - val_loss: 0.0362 - val_mae: 0.1500\n",
      "Epoch 144/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3027 - mae: 0.4126 - val_loss: 0.0363 - val_mae: 0.1508\n",
      "Epoch 145/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3018 - mae: 0.4123 - val_loss: 0.0365 - val_mae: 0.1516\n",
      "Epoch 146/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3008 - mae: 0.4120 - val_loss: 0.0366 - val_mae: 0.1523\n",
      "Epoch 147/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2999 - mae: 0.4117 - val_loss: 0.0368 - val_mae: 0.1531\n",
      "Epoch 148/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2989 - mae: 0.4114 - val_loss: 0.0369 - val_mae: 0.1539\n",
      "Epoch 149/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2980 - mae: 0.4112 - val_loss: 0.0371 - val_mae: 0.1547\n",
      "Epoch 150/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2970 - mae: 0.4109 - val_loss: 0.0373 - val_mae: 0.1554\n",
      "Epoch 151/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2961 - mae: 0.4106 - val_loss: 0.0374 - val_mae: 0.1562\n",
      "Epoch 152/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2952 - mae: 0.4104 - val_loss: 0.0376 - val_mae: 0.1570\n",
      "Epoch 153/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2943 - mae: 0.4101 - val_loss: 0.0378 - val_mae: 0.1577\n",
      "Epoch 154/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2934 - mae: 0.4099 - val_loss: 0.0379 - val_mae: 0.1585\n",
      "Epoch 155/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2925 - mae: 0.4096 - val_loss: 0.0381 - val_mae: 0.1593\n",
      "Epoch 156/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2916 - mae: 0.4093 - val_loss: 0.0383 - val_mae: 0.1600\n",
      "Epoch 157/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2907 - mae: 0.4091 - val_loss: 0.0384 - val_mae: 0.1608\n",
      "Epoch 158/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2898 - mae: 0.4088 - val_loss: 0.0386 - val_mae: 0.1615\n",
      "Epoch 159/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2889 - mae: 0.4086 - val_loss: 0.0388 - val_mae: 0.1623\n",
      "Epoch 160/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2880 - mae: 0.4083 - val_loss: 0.0390 - val_mae: 0.1630\n",
      "Epoch 161/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2871 - mae: 0.4081 - val_loss: 0.0391 - val_mae: 0.1637\n",
      "Epoch 162/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2863 - mae: 0.4079 - val_loss: 0.0393 - val_mae: 0.1645\n",
      "Epoch 163/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2854 - mae: 0.4076 - val_loss: 0.0395 - val_mae: 0.1652\n",
      "Epoch 164/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2846 - mae: 0.4074 - val_loss: 0.0397 - val_mae: 0.1659\n",
      "Epoch 165/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2837 - mae: 0.4071 - val_loss: 0.0399 - val_mae: 0.1667\n",
      "Epoch 166/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2829 - mae: 0.4069 - val_loss: 0.0400 - val_mae: 0.1674\n",
      "Epoch 167/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2821 - mae: 0.4067 - val_loss: 0.0402 - val_mae: 0.1681\n",
      "Epoch 168/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2812 - mae: 0.4064 - val_loss: 0.0404 - val_mae: 0.1688\n",
      "Epoch 169/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2804 - mae: 0.4062 - val_loss: 0.0406 - val_mae: 0.1695\n",
      "Epoch 170/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2796 - mae: 0.4059 - val_loss: 0.0408 - val_mae: 0.1702\n",
      "Epoch 171/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2788 - mae: 0.4057 - val_loss: 0.0410 - val_mae: 0.1709\n",
      "Epoch 172/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2780 - mae: 0.4055 - val_loss: 0.0412 - val_mae: 0.1716\n",
      "Epoch 173/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2772 - mae: 0.4053 - val_loss: 0.0414 - val_mae: 0.1723\n",
      "Epoch 174/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2764 - mae: 0.4050 - val_loss: 0.0416 - val_mae: 0.1730\n",
      "Epoch 175/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2756 - mae: 0.4048 - val_loss: 0.0417 - val_mae: 0.1737\n",
      "Epoch 176/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2749 - mae: 0.4046 - val_loss: 0.0419 - val_mae: 0.1743\n",
      "Epoch 177/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2741 - mae: 0.4043 - val_loss: 0.0421 - val_mae: 0.1750\n",
      "Epoch 178/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2733 - mae: 0.4041 - val_loss: 0.0423 - val_mae: 0.1757\n",
      "Epoch 179/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2726 - mae: 0.4039 - val_loss: 0.0425 - val_mae: 0.1763\n",
      "Epoch 180/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2719 - mae: 0.4037 - val_loss: 0.0427 - val_mae: 0.1770\n",
      "Epoch 181/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2711 - mae: 0.4034 - val_loss: 0.0429 - val_mae: 0.1776\n",
      "Epoch 182/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2704 - mae: 0.4032 - val_loss: 0.0431 - val_mae: 0.1783\n",
      "Epoch 183/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2697 - mae: 0.4030 - val_loss: 0.0433 - val_mae: 0.1789\n",
      "Epoch 184/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2689 - mae: 0.4028 - val_loss: 0.0435 - val_mae: 0.1795\n",
      "Epoch 185/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2682 - mae: 0.4026 - val_loss: 0.0437 - val_mae: 0.1802\n",
      "Epoch 186/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2675 - mae: 0.4023 - val_loss: 0.0439 - val_mae: 0.1808\n",
      "Epoch 187/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2668 - mae: 0.4021 - val_loss: 0.0441 - val_mae: 0.1814\n",
      "Epoch 188/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2662 - mae: 0.4019 - val_loss: 0.0443 - val_mae: 0.1820\n",
      "Epoch 189/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2655 - mae: 0.4017 - val_loss: 0.0445 - val_mae: 0.1826\n",
      "Epoch 190/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2648 - mae: 0.4015 - val_loss: 0.0447 - val_mae: 0.1832\n",
      "Epoch 191/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2641 - mae: 0.4012 - val_loss: 0.0449 - val_mae: 0.1838\n",
      "Epoch 192/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2635 - mae: 0.4010 - val_loss: 0.0451 - val_mae: 0.1844\n",
      "Epoch 193/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2628 - mae: 0.4008 - val_loss: 0.0453 - val_mae: 0.1850\n",
      "Epoch 194/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2622 - mae: 0.4006 - val_loss: 0.0455 - val_mae: 0.1855\n",
      "Epoch 195/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2615 - mae: 0.4004 - val_loss: 0.0457 - val_mae: 0.1861\n",
      "Epoch 196/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2609 - mae: 0.4002 - val_loss: 0.0458 - val_mae: 0.1867\n",
      "Epoch 197/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2602 - mae: 0.3999 - val_loss: 0.0460 - val_mae: 0.1872\n",
      "Epoch 198/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2596 - mae: 0.3997 - val_loss: 0.0462 - val_mae: 0.1878\n",
      "Epoch 199/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2590 - mae: 0.3995 - val_loss: 0.0464 - val_mae: 0.1884\n",
      "Epoch 200/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2584 - mae: 0.3993 - val_loss: 0.0466 - val_mae: 0.1889\n",
      "Epoch 1/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 1.3240 - mae: 0.9873 - val_loss: 0.8788 - val_mae: 0.8661\n",
      "Epoch 2/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.3143 - mae: 0.9819 - val_loss: 0.8716 - val_mae: 0.8608\n",
      "Epoch 3/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.3057 - mae: 0.9767 - val_loss: 0.8643 - val_mae: 0.8552\n",
      "Epoch 4/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.2974 - mae: 0.9714 - val_loss: 0.8571 - val_mae: 0.8497\n",
      "Epoch 5/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.2892 - mae: 0.9661 - val_loss: 0.8500 - val_mae: 0.8441\n",
      "Epoch 6/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.2813 - mae: 0.9608 - val_loss: 0.8432 - val_mae: 0.8385\n",
      "Epoch 7/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.2735 - mae: 0.9554 - val_loss: 0.8365 - val_mae: 0.8330\n",
      "Epoch 8/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.2659 - mae: 0.9500 - val_loss: 0.8301 - val_mae: 0.8275\n",
      "Epoch 9/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.2584 - mae: 0.9446 - val_loss: 0.8239 - val_mae: 0.8222\n",
      "Epoch 10/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.2510 - mae: 0.9392 - val_loss: 0.8179 - val_mae: 0.8169\n",
      "Epoch 11/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.2438 - mae: 0.9337 - val_loss: 0.8120 - val_mae: 0.8117\n",
      "Epoch 12/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.2366 - mae: 0.9282 - val_loss: 0.8064 - val_mae: 0.8066\n",
      "Epoch 13/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.2296 - mae: 0.9227 - val_loss: 0.8009 - val_mae: 0.8016\n",
      "Epoch 14/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.2226 - mae: 0.9172 - val_loss: 0.7956 - val_mae: 0.7967\n",
      "Epoch 15/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.2156 - mae: 0.9116 - val_loss: 0.7905 - val_mae: 0.7919\n",
      "Epoch 16/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.2087 - mae: 0.9061 - val_loss: 0.7854 - val_mae: 0.7872\n",
      "Epoch 17/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.2018 - mae: 0.9005 - val_loss: 0.7805 - val_mae: 0.7826\n",
      "Epoch 18/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.1950 - mae: 0.8949 - val_loss: 0.7756 - val_mae: 0.7781\n",
      "Epoch 19/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.1881 - mae: 0.8892 - val_loss: 0.7709 - val_mae: 0.7737\n",
      "Epoch 20/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.1812 - mae: 0.8836 - val_loss: 0.7661 - val_mae: 0.7694\n",
      "Epoch 21/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.1743 - mae: 0.8797 - val_loss: 0.7614 - val_mae: 0.7652\n",
      "Epoch 22/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.1673 - mae: 0.8764 - val_loss: 0.7567 - val_mae: 0.7611\n",
      "Epoch 23/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.1602 - mae: 0.8730 - val_loss: 0.7519 - val_mae: 0.7570\n",
      "Epoch 24/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.1530 - mae: 0.8694 - val_loss: 0.7471 - val_mae: 0.7530\n",
      "Epoch 25/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.1456 - mae: 0.8658 - val_loss: 0.7422 - val_mae: 0.7491\n",
      "Epoch 26/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.1381 - mae: 0.8620 - val_loss: 0.7372 - val_mae: 0.7452\n",
      "Epoch 27/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.1304 - mae: 0.8581 - val_loss: 0.7320 - val_mae: 0.7413\n",
      "Epoch 28/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.1225 - mae: 0.8539 - val_loss: 0.7267 - val_mae: 0.7375\n",
      "Epoch 29/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.1143 - mae: 0.8497 - val_loss: 0.7211 - val_mae: 0.7337\n",
      "Epoch 30/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.1058 - mae: 0.8452 - val_loss: 0.7152 - val_mae: 0.7298\n",
      "Epoch 31/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0970 - mae: 0.8405 - val_loss: 0.7091 - val_mae: 0.7259\n",
      "Epoch 32/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0877 - mae: 0.8356 - val_loss: 0.7026 - val_mae: 0.7219\n",
      "Epoch 33/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.0780 - mae: 0.8305 - val_loss: 0.6958 - val_mae: 0.7178\n",
      "Epoch 34/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0679 - mae: 0.8255 - val_loss: 0.6884 - val_mae: 0.7137\n",
      "Epoch 35/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0572 - mae: 0.8205 - val_loss: 0.6806 - val_mae: 0.7093\n",
      "Epoch 36/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.0460 - mae: 0.8153 - val_loss: 0.6723 - val_mae: 0.7048\n",
      "Epoch 37/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.0341 - mae: 0.8105 - val_loss: 0.6634 - val_mae: 0.7000\n",
      "Epoch 38/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.0216 - mae: 0.8061 - val_loss: 0.6538 - val_mae: 0.6949\n",
      "Epoch 39/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.0083 - mae: 0.8015 - val_loss: 0.6435 - val_mae: 0.6896\n",
      "Epoch 40/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9943 - mae: 0.7966 - val_loss: 0.6324 - val_mae: 0.6839\n",
      "Epoch 41/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.9795 - mae: 0.7914 - val_loss: 0.6205 - val_mae: 0.6777\n",
      "Epoch 42/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.9638 - mae: 0.7859 - val_loss: 0.6076 - val_mae: 0.6711\n",
      "Epoch 43/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.9472 - mae: 0.7814 - val_loss: 0.5939 - val_mae: 0.6640\n",
      "Epoch 44/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9297 - mae: 0.7766 - val_loss: 0.5791 - val_mae: 0.6564\n",
      "Epoch 45/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9113 - mae: 0.7715 - val_loss: 0.5633 - val_mae: 0.6482\n",
      "Epoch 46/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8920 - mae: 0.7659 - val_loss: 0.5465 - val_mae: 0.6393\n",
      "Epoch 47/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8719 - mae: 0.7599 - val_loss: 0.5286 - val_mae: 0.6297\n",
      "Epoch 48/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.8510 - mae: 0.7534 - val_loss: 0.5097 - val_mae: 0.6194\n",
      "Epoch 49/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.8294 - mae: 0.7464 - val_loss: 0.4898 - val_mae: 0.6083\n",
      "Epoch 50/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.8073 - mae: 0.7389 - val_loss: 0.4691 - val_mae: 0.5966\n",
      "Epoch 51/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.7848 - mae: 0.7310 - val_loss: 0.4475 - val_mae: 0.5840\n",
      "Epoch 52/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.7622 - mae: 0.7226 - val_loss: 0.4253 - val_mae: 0.5707\n",
      "Epoch 53/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.7396 - mae: 0.7138 - val_loss: 0.4026 - val_mae: 0.5567\n",
      "Epoch 54/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7171 - mae: 0.7045 - val_loss: 0.3796 - val_mae: 0.5421\n",
      "Epoch 55/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.6951 - mae: 0.6949 - val_loss: 0.3565 - val_mae: 0.5268\n",
      "Epoch 56/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.6737 - mae: 0.6851 - val_loss: 0.3336 - val_mae: 0.5111\n",
      "Epoch 57/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.6530 - mae: 0.6749 - val_loss: 0.3111 - val_mae: 0.4949\n",
      "Epoch 58/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.6332 - mae: 0.6646 - val_loss: 0.2892 - val_mae: 0.4784\n",
      "Epoch 59/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.6143 - mae: 0.6542 - val_loss: 0.2681 - val_mae: 0.4618\n",
      "Epoch 60/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.5964 - mae: 0.6437 - val_loss: 0.2479 - val_mae: 0.4450\n",
      "Epoch 61/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.5796 - mae: 0.6332 - val_loss: 0.2289 - val_mae: 0.4283\n",
      "Epoch 62/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5639 - mae: 0.6227 - val_loss: 0.2110 - val_mae: 0.4117\n",
      "Epoch 63/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5492 - mae: 0.6129 - val_loss: 0.1944 - val_mae: 0.3954\n",
      "Epoch 64/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5357 - mae: 0.6047 - val_loss: 0.1791 - val_mae: 0.3794\n",
      "Epoch 65/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5232 - mae: 0.5984 - val_loss: 0.1651 - val_mae: 0.3639\n",
      "Epoch 66/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5117 - mae: 0.5919 - val_loss: 0.1524 - val_mae: 0.3488\n",
      "Epoch 67/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5011 - mae: 0.5854 - val_loss: 0.1410 - val_mae: 0.3343\n",
      "Epoch 68/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4915 - mae: 0.5787 - val_loss: 0.1307 - val_mae: 0.3205\n",
      "Epoch 69/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4827 - mae: 0.5730 - val_loss: 0.1215 - val_mae: 0.3072\n",
      "Epoch 70/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4746 - mae: 0.5678 - val_loss: 0.1133 - val_mae: 0.2947\n",
      "Epoch 71/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.4673 - mae: 0.5626 - val_loss: 0.1061 - val_mae: 0.2829\n",
      "Epoch 72/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.4607 - mae: 0.5574 - val_loss: 0.0997 - val_mae: 0.2717\n",
      "Epoch 73/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4545 - mae: 0.5521 - val_loss: 0.0941 - val_mae: 0.2613\n",
      "Epoch 74/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4489 - mae: 0.5470 - val_loss: 0.0891 - val_mae: 0.2515\n",
      "Epoch 75/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4438 - mae: 0.5419 - val_loss: 0.0847 - val_mae: 0.2425\n",
      "Epoch 76/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4390 - mae: 0.5369 - val_loss: 0.0809 - val_mae: 0.2341\n",
      "Epoch 77/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4345 - mae: 0.5320 - val_loss: 0.0775 - val_mae: 0.2278\n",
      "Epoch 78/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4303 - mae: 0.5274 - val_loss: 0.0745 - val_mae: 0.2255\n",
      "Epoch 79/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4263 - mae: 0.5235 - val_loss: 0.0718 - val_mae: 0.2232\n",
      "Epoch 80/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4225 - mae: 0.5196 - val_loss: 0.0695 - val_mae: 0.2211\n",
      "Epoch 81/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.4188 - mae: 0.5158 - val_loss: 0.0674 - val_mae: 0.2191\n",
      "Epoch 82/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4153 - mae: 0.5121 - val_loss: 0.0655 - val_mae: 0.2172\n",
      "Epoch 83/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4118 - mae: 0.5084 - val_loss: 0.0638 - val_mae: 0.2154\n",
      "Epoch 84/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4084 - mae: 0.5048 - val_loss: 0.0624 - val_mae: 0.2137\n",
      "Epoch 85/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4051 - mae: 0.5013 - val_loss: 0.0610 - val_mae: 0.2122\n",
      "Epoch 86/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4018 - mae: 0.4979 - val_loss: 0.0598 - val_mae: 0.2107\n",
      "Epoch 87/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3986 - mae: 0.4945 - val_loss: 0.0588 - val_mae: 0.2094\n",
      "Epoch 88/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3954 - mae: 0.4912 - val_loss: 0.0578 - val_mae: 0.2081\n",
      "Epoch 89/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3921 - mae: 0.4880 - val_loss: 0.0569 - val_mae: 0.2070\n",
      "Epoch 90/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3889 - mae: 0.4848 - val_loss: 0.0561 - val_mae: 0.2059\n",
      "Epoch 91/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3857 - mae: 0.4816 - val_loss: 0.0554 - val_mae: 0.2050\n",
      "Epoch 92/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3825 - mae: 0.4785 - val_loss: 0.0548 - val_mae: 0.2041\n",
      "Epoch 93/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3793 - mae: 0.4754 - val_loss: 0.0542 - val_mae: 0.2033\n",
      "Epoch 94/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3761 - mae: 0.4724 - val_loss: 0.0537 - val_mae: 0.2025\n",
      "Epoch 95/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3729 - mae: 0.4694 - val_loss: 0.0532 - val_mae: 0.2018\n",
      "Epoch 96/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3697 - mae: 0.4664 - val_loss: 0.0528 - val_mae: 0.2012\n",
      "Epoch 97/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3665 - mae: 0.4634 - val_loss: 0.0525 - val_mae: 0.2007\n",
      "Epoch 98/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3634 - mae: 0.4606 - val_loss: 0.0522 - val_mae: 0.2002\n",
      "Epoch 99/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3602 - mae: 0.4581 - val_loss: 0.0519 - val_mae: 0.1997\n",
      "Epoch 100/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3571 - mae: 0.4557 - val_loss: 0.0517 - val_mae: 0.1993\n",
      "Epoch 101/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3539 - mae: 0.4534 - val_loss: 0.0515 - val_mae: 0.1989\n",
      "Epoch 102/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3508 - mae: 0.4510 - val_loss: 0.0514 - val_mae: 0.1986\n",
      "Epoch 103/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3478 - mae: 0.4487 - val_loss: 0.0513 - val_mae: 0.1982\n",
      "Epoch 104/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3447 - mae: 0.4464 - val_loss: 0.0512 - val_mae: 0.1979\n",
      "Epoch 105/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3417 - mae: 0.4441 - val_loss: 0.0511 - val_mae: 0.1977\n",
      "Epoch 106/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3387 - mae: 0.4419 - val_loss: 0.0511 - val_mae: 0.1974\n",
      "Epoch 107/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3358 - mae: 0.4396 - val_loss: 0.0511 - val_mae: 0.1972\n",
      "Epoch 108/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3329 - mae: 0.4374 - val_loss: 0.0511 - val_mae: 0.1969\n",
      "Epoch 109/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3300 - mae: 0.4352 - val_loss: 0.0511 - val_mae: 0.1967\n",
      "Epoch 110/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3272 - mae: 0.4330 - val_loss: 0.0512 - val_mae: 0.1965\n",
      "Epoch 111/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3244 - mae: 0.4308 - val_loss: 0.0513 - val_mae: 0.1963\n",
      "Epoch 112/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3217 - mae: 0.4286 - val_loss: 0.0514 - val_mae: 0.1961\n",
      "Epoch 113/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3191 - mae: 0.4265 - val_loss: 0.0515 - val_mae: 0.1958\n",
      "Epoch 114/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3164 - mae: 0.4250 - val_loss: 0.0516 - val_mae: 0.1956\n",
      "Epoch 115/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3139 - mae: 0.4234 - val_loss: 0.0517 - val_mae: 0.1954\n",
      "Epoch 116/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3113 - mae: 0.4219 - val_loss: 0.0518 - val_mae: 0.1952\n",
      "Epoch 117/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3089 - mae: 0.4203 - val_loss: 0.0520 - val_mae: 0.1949\n",
      "Epoch 118/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3065 - mae: 0.4193 - val_loss: 0.0521 - val_mae: 0.1947\n",
      "Epoch 119/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3041 - mae: 0.4183 - val_loss: 0.0522 - val_mae: 0.1944\n",
      "Epoch 120/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3018 - mae: 0.4174 - val_loss: 0.0524 - val_mae: 0.1941\n",
      "Epoch 121/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2996 - mae: 0.4164 - val_loss: 0.0525 - val_mae: 0.1950\n",
      "Epoch 122/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2974 - mae: 0.4155 - val_loss: 0.0527 - val_mae: 0.1958\n",
      "Epoch 123/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2952 - mae: 0.4145 - val_loss: 0.0528 - val_mae: 0.1967\n",
      "Epoch 124/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.2931 - mae: 0.4136 - val_loss: 0.0530 - val_mae: 0.1975\n",
      "Epoch 125/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2910 - mae: 0.4126 - val_loss: 0.0531 - val_mae: 0.1983\n",
      "Epoch 126/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2890 - mae: 0.4117 - val_loss: 0.0532 - val_mae: 0.1991\n",
      "Epoch 127/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2871 - mae: 0.4107 - val_loss: 0.0534 - val_mae: 0.1998\n",
      "Epoch 128/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2852 - mae: 0.4101 - val_loss: 0.0535 - val_mae: 0.2006\n",
      "Epoch 129/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2833 - mae: 0.4097 - val_loss: 0.0536 - val_mae: 0.2013\n",
      "Epoch 130/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2815 - mae: 0.4092 - val_loss: 0.0537 - val_mae: 0.2019\n",
      "Epoch 131/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2797 - mae: 0.4087 - val_loss: 0.0538 - val_mae: 0.2025\n",
      "Epoch 132/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2780 - mae: 0.4082 - val_loss: 0.0539 - val_mae: 0.2031\n",
      "Epoch 133/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2763 - mae: 0.4077 - val_loss: 0.0540 - val_mae: 0.2037\n",
      "Epoch 134/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2747 - mae: 0.4072 - val_loss: 0.0541 - val_mae: 0.2043\n",
      "Epoch 135/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2731 - mae: 0.4067 - val_loss: 0.0542 - val_mae: 0.2048\n",
      "Epoch 136/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2715 - mae: 0.4062 - val_loss: 0.0543 - val_mae: 0.2053\n",
      "Epoch 137/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2699 - mae: 0.4057 - val_loss: 0.0544 - val_mae: 0.2058\n",
      "Epoch 138/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2684 - mae: 0.4051 - val_loss: 0.0544 - val_mae: 0.2062\n",
      "Epoch 139/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2670 - mae: 0.4046 - val_loss: 0.0545 - val_mae: 0.2066\n",
      "Epoch 140/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2655 - mae: 0.4041 - val_loss: 0.0545 - val_mae: 0.2070\n",
      "Epoch 141/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2641 - mae: 0.4036 - val_loss: 0.0546 - val_mae: 0.2074\n",
      "Epoch 142/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2628 - mae: 0.4031 - val_loss: 0.0546 - val_mae: 0.2078\n",
      "Epoch 143/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2614 - mae: 0.4025 - val_loss: 0.0546 - val_mae: 0.2081\n",
      "Epoch 144/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2601 - mae: 0.4020 - val_loss: 0.0547 - val_mae: 0.2084\n",
      "Epoch 145/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2588 - mae: 0.4015 - val_loss: 0.0547 - val_mae: 0.2087\n",
      "Epoch 146/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2576 - mae: 0.4010 - val_loss: 0.0547 - val_mae: 0.2089\n",
      "Epoch 147/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2564 - mae: 0.4004 - val_loss: 0.0547 - val_mae: 0.2092\n",
      "Epoch 148/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2551 - mae: 0.3999 - val_loss: 0.0547 - val_mae: 0.2094\n",
      "Epoch 149/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2540 - mae: 0.3994 - val_loss: 0.0547 - val_mae: 0.2096\n",
      "Epoch 150/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2528 - mae: 0.3988 - val_loss: 0.0547 - val_mae: 0.2098\n",
      "Epoch 151/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2517 - mae: 0.3983 - val_loss: 0.0547 - val_mae: 0.2100\n",
      "Epoch 152/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2506 - mae: 0.3977 - val_loss: 0.0546 - val_mae: 0.2101\n",
      "Epoch 153/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2495 - mae: 0.3972 - val_loss: 0.0546 - val_mae: 0.2103\n",
      "Epoch 154/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2484 - mae: 0.3967 - val_loss: 0.0546 - val_mae: 0.2104\n",
      "Epoch 155/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2473 - mae: 0.3961 - val_loss: 0.0546 - val_mae: 0.2105\n",
      "Epoch 156/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2463 - mae: 0.3956 - val_loss: 0.0545 - val_mae: 0.2106\n",
      "Epoch 157/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2453 - mae: 0.3950 - val_loss: 0.0545 - val_mae: 0.2107\n",
      "Epoch 158/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2443 - mae: 0.3945 - val_loss: 0.0545 - val_mae: 0.2107\n",
      "Epoch 159/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2433 - mae: 0.3939 - val_loss: 0.0544 - val_mae: 0.2108\n",
      "Epoch 160/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2424 - mae: 0.3934 - val_loss: 0.0544 - val_mae: 0.2108\n",
      "Epoch 161/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2414 - mae: 0.3929 - val_loss: 0.0543 - val_mae: 0.2108\n",
      "Epoch 162/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2405 - mae: 0.3923 - val_loss: 0.0543 - val_mae: 0.2108\n",
      "Epoch 163/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2396 - mae: 0.3918 - val_loss: 0.0542 - val_mae: 0.2108\n",
      "Epoch 164/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2387 - mae: 0.3912 - val_loss: 0.0541 - val_mae: 0.2108\n",
      "Epoch 165/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2378 - mae: 0.3907 - val_loss: 0.0541 - val_mae: 0.2108\n",
      "Epoch 166/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2369 - mae: 0.3901 - val_loss: 0.0540 - val_mae: 0.2107\n",
      "Epoch 167/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2360 - mae: 0.3896 - val_loss: 0.0539 - val_mae: 0.2107\n",
      "Epoch 168/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2352 - mae: 0.3891 - val_loss: 0.0539 - val_mae: 0.2106\n",
      "Epoch 169/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2344 - mae: 0.3885 - val_loss: 0.0538 - val_mae: 0.2106\n",
      "Epoch 170/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2335 - mae: 0.3880 - val_loss: 0.0537 - val_mae: 0.2105\n",
      "Epoch 171/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2327 - mae: 0.3874 - val_loss: 0.0536 - val_mae: 0.2104\n",
      "Epoch 172/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2319 - mae: 0.3869 - val_loss: 0.0536 - val_mae: 0.2103\n",
      "Epoch 173/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2311 - mae: 0.3863 - val_loss: 0.0535 - val_mae: 0.2102\n",
      "Epoch 174/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2304 - mae: 0.3858 - val_loss: 0.0534 - val_mae: 0.2101\n",
      "Epoch 175/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2296 - mae: 0.3853 - val_loss: 0.0533 - val_mae: 0.2099\n",
      "Epoch 176/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2288 - mae: 0.3847 - val_loss: 0.0532 - val_mae: 0.2098\n",
      "Epoch 177/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2281 - mae: 0.3842 - val_loss: 0.0531 - val_mae: 0.2096\n",
      "Epoch 178/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2273 - mae: 0.3837 - val_loss: 0.0530 - val_mae: 0.2095\n",
      "Epoch 179/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2266 - mae: 0.3831 - val_loss: 0.0529 - val_mae: 0.2093\n",
      "Epoch 180/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2259 - mae: 0.3826 - val_loss: 0.0529 - val_mae: 0.2092\n",
      "Epoch 181/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2252 - mae: 0.3820 - val_loss: 0.0528 - val_mae: 0.2090\n",
      "Epoch 182/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2245 - mae: 0.3815 - val_loss: 0.0527 - val_mae: 0.2088\n",
      "Epoch 183/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2238 - mae: 0.3810 - val_loss: 0.0526 - val_mae: 0.2086\n",
      "Epoch 184/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2231 - mae: 0.3805 - val_loss: 0.0524 - val_mae: 0.2084\n",
      "Epoch 185/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2224 - mae: 0.3800 - val_loss: 0.0523 - val_mae: 0.2082\n",
      "Epoch 186/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2217 - mae: 0.3795 - val_loss: 0.0522 - val_mae: 0.2080\n",
      "Epoch 187/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2210 - mae: 0.3790 - val_loss: 0.0521 - val_mae: 0.2078\n",
      "Epoch 188/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2204 - mae: 0.3785 - val_loss: 0.0520 - val_mae: 0.2076\n",
      "Epoch 189/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2197 - mae: 0.3780 - val_loss: 0.0519 - val_mae: 0.2073\n",
      "Epoch 190/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2191 - mae: 0.3775 - val_loss: 0.0518 - val_mae: 0.2071\n",
      "Epoch 191/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2184 - mae: 0.3770 - val_loss: 0.0517 - val_mae: 0.2069\n",
      "Epoch 192/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2178 - mae: 0.3765 - val_loss: 0.0516 - val_mae: 0.2066\n",
      "Epoch 193/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2172 - mae: 0.3760 - val_loss: 0.0514 - val_mae: 0.2064\n",
      "Epoch 194/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2165 - mae: 0.3755 - val_loss: 0.0513 - val_mae: 0.2061\n",
      "Epoch 195/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2159 - mae: 0.3750 - val_loss: 0.0512 - val_mae: 0.2058\n",
      "Epoch 196/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2153 - mae: 0.3745 - val_loss: 0.0511 - val_mae: 0.2056\n",
      "Epoch 197/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2147 - mae: 0.3740 - val_loss: 0.0510 - val_mae: 0.2053\n",
      "Epoch 198/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2141 - mae: 0.3735 - val_loss: 0.0508 - val_mae: 0.2050\n",
      "Epoch 199/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2135 - mae: 0.3730 - val_loss: 0.0507 - val_mae: 0.2047\n",
      "Epoch 200/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2129 - mae: 0.3725 - val_loss: 0.0506 - val_mae: 0.2044\n"
     ]
    }
   ],
   "source": [
    "for act in activations:\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(X_train_z.shape[1],)),\n",
    "        layers.Dense(16, activation=act),\n",
    "        layers.Dense(2,  activation='tanh')     # zwei Ausgänge: [Mn, Mw]\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_z, y_train_s,                    # y_train_s: (n,2)\n",
    "        validation_data=(X_val_z, y_val_s),\n",
    "        epochs=200, batch_size=16, shuffle=True, verbose=1,\n",
    "        callbacks=[]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Fuz9lZO-Ghm8"
   },
   "outputs": [],
   "source": [
    "    # Vorhersage (skaliert) -> zurückskalieren\n",
    "    y_hat_train_s = model.predict(X_train_z, verbose=0)\n",
    "    y_hat_val_s   = model.predict(X_val_z,   verbose=0)\n",
    "    y_hat_test_s  = model.predict(X_test_z,  verbose=0)\n",
    "\n",
    "    y_hat_train = inv_y(y_hat_train_s)          # (n,2) in realen Einheiten\n",
    "    y_hat_val   = inv_y(y_hat_val_s)\n",
    "    y_hat_test  = inv_y(y_hat_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "MoYCGbIeGhkm",
    "outputId": "0fb1562c-2077-479a-a3f9-2fdd5ce8b615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000015C8020C860> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000015C802A20C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transfer_functions = {\n",
    "    'relu': 'ReLU',\n",
    "    'tanh': 'Tanh',\n",
    "    'sigmoid': 'Sigmoid',\n",
    "    'softplus': 'Softplus'\n",
    "}\n",
    "\n",
    "mse_results = []\n",
    "\n",
    "for activation, name in transfer_functions.items():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(16, activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='tanh'))   #  zwei Outputs: [Mn, Mw]\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, batch_size=4, epochs=50, verbose=0)\n",
    "    y_pred = model.predict(X_test, verbose=0)  # Form (n,2)\n",
    "    # Durchschnitts-MSE über beide Outputs (Mn & Mw)\n",
    "    mse = mean_squared_error(y_test, y_pred)   # = uniform_average\n",
    "    mse_results.append(mse)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(list(transfer_functions.values()), mse_results, marker='o', linestyle='-')\n",
    "plt.title('Mean MSE (Mn & Mw) vs. Transfer Function')\n",
    "plt.xlabel('Transfer Function')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "QPRrqEbfGhiy"
   },
   "outputs": [],
   "source": [
    "# Reshape y to match X dimensions\n",
    "y = y.reshape(X.shape[0], 2)   # Now y.shape == (25, 2)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "\n",
    "# Create pipeline with scaling and linear regression\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Get cross-validated predictions\n",
    "y_pred = cross_val_predict(pipe, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "-HYFsO8EGhgw",
    "outputId": "227ea511-4657-469d-cc8a-e00cbe255210"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "names = [\"Mn\", \"Mw\"]\n",
    "\n",
    "for j in range(2):\n",
    "    PredictionErrorDisplay.from_predictions(\n",
    "        y_true=y[:, j], y_pred=y_pred[:, j],\n",
    "        kind=\"actual_vs_predicted\", subsample=None, ax=axs[0, j], random_state=42\n",
    "    )\n",
    "    axs[0, j].set_title(f\"{names[j]}: Actual vs Predicted\")\n",
    "\n",
    "    PredictionErrorDisplay.from_predictions(\n",
    "        y_true=y[:, j], y_pred=y_pred[:, j],\n",
    "        kind=\"residual_vs_predicted\", subsample=None, ax=axs[1, j], random_state=42\n",
    "    )\n",
    "    axs[1, j].set_title(f\"{names[j]}: Residuals vs Predicted\")\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "1o9IqE3vGhea"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_percentage_error, mean_squared_error,\n",
    "    mean_squared_log_error, explained_variance_score, max_error,\n",
    "    median_absolute_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcIzkwmeGhcY",
    "outputId": "15ec7f1f-c605-41e7-c5c2-9adac815da5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Run  Factor A  Factor B  Factor C  Factor D  Response 1 (Experimental)  \\\n",
      "0    1       110         7        50        10                    1127.19   \n",
      "1    2        85        13        50        10                    1024.97   \n",
      "2    3       101         1       500        60                    1950.00   \n",
      "3    4       101         1       500        60                    2223.17   \n",
      "4    5        50        10        50        10                    1845.60   \n",
      "\n",
      "   Response 2 (Experimental)  \n",
      "0                    1321.65  \n",
      "1                    1339.35  \n",
      "2                    2878.90  \n",
      "3                    2989.00  \n",
      "4                    2690.50  \n",
      "X: (25, 4)  y: (25, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Just read the file\n",
    "df = pd.read_csv('Exp_Mn_Mw_Value.txt', sep='\\t')\n",
    "print(df.head())\n",
    "#select columns by position\n",
    "X = df.iloc[:, 1:5].astype(float).to_numpy()  # First 4 columns as features\n",
    "y = df.iloc[:, 5:7].astype(float).to_numpy()  # Next 2 columns as targets\n",
    "\n",
    "print(\"X:\", X.shape, \" y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uz1oWwRXGhat",
    "outputId": "9bda89bd-697a-45eb-9438-9b3bc62ed013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 20 samples\n",
      "Validation set: 20 samples\n",
      "Test set: 5 samples\n",
      "Total: 25 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "X_trval, X_test, y_trval, y_test = train_test_split(\n",
    "    X, y, test_size=5, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_trval.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Total: {n_samples} samples\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "vxYfPQS6GhWw",
    "outputId": "6c02a819-4b30-4c2f-c273-97b2356b939a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                StandardScaler()),\n",
       "                                               (&#x27;svr&#x27;,\n",
       "                                                SVR(C=1, kernel=&#x27;poly&#x27;))]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultiOutputRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.multioutput.MultiOutputRegressor.html\">?<span>Documentation for MultiOutputRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">Pipeline(step...nel=&#x27;poly&#x27;))])</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__\"></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__standardscaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">with_mean&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">with_std&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVR</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.svm.SVR.html\">?<span>Documentation for SVR</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__svr__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('kernel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">kernel&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;poly&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('degree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">degree&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;scale&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('coef0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">coef0&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('epsilon',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">epsilon&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinking',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shrinking&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cache_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cache_size&nbsp;</td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "MultiOutputRegressor(estimator=Pipeline(steps=[('standardscaler',\n",
       "                                                StandardScaler()),\n",
       "                                               ('svr',\n",
       "                                                SVR(C=1, kernel='poly'))]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Create SVR pipeline with scaling\n",
    "base_svr = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(kernel='poly', C=1, epsilon=0.1, gamma='scale')\n",
    ")\n",
    "\n",
    "# Wrap for multi-output regression (Mn and Mw)\n",
    "model = MultiOutputRegressor(base_svr)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1tAqJ1lGhVV",
    "outputId": "f662c82f-7d6e-499f-dbe7-0033a074acf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: (5, 2)\n",
      "SVM Results:\n",
      "Explained Variance: 0.002493\n",
      "Max Error: 2775.172025\n",
      "MAPE: 0.340183\n",
      "MSE: 1434268.194172\n",
      "MSLE: 0.190013\n",
      "Median AE: 327.910881\n",
      "R²: -0.032165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_log_error,\n",
    "    median_absolute_error\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the shape of the predicted output\n",
    "print(\"Test predictions shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "# Define a function to calculate multiple evaluation metrics\n",
    "def overall_metrics(y_true, y_pred):\n",
    "    # R² score: how well predictions approximate real data\n",
    "    r2 = r2_score(y_true, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    # Explained variance score: proportion of variance explained by the model\n",
    "    evs = explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    # Mean Absolute Percentage Error (MAPE): average percentage error\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    # Mean Squared Error (MSE): average of squared errors\n",
    "    mse = mean_squared_error(y_true, y_pred, multioutput='uniform_average')\n",
    "    \n",
    "    # Mean Squared Logarithmic Error (MSLE): penalizes underestimation (may fail if y < 0)\n",
    "    try:\n",
    "        msle = mean_squared_log_error(y_true, y_pred, multioutput='uniform_average')\n",
    "    except ValueError:\n",
    "        msle = np.nan  # If negative values exist, MSLE is not valid\n",
    "    \n",
    "    # Median Absolute Error (Median AE): median of absolute errors, averaged across outputs\n",
    "    mae_med = np.mean([median_absolute_error(y_true[:, i], y_pred[:, i]) \n",
    "                       for i in range(y_true.shape[1])])\n",
    "    \n",
    "    # Max Error: largest absolute error among all predictions\n",
    "    maxerr = np.max(np.abs(y_true - y_pred))\n",
    "    \n",
    "    return evs, maxerr, mape, mse, msle, mae_med, r2\n",
    "\n",
    "\n",
    "# Calculate metrics on the test set\n",
    "evs, maxerr, mape, mse, msle, mae_med, r2 = overall_metrics(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"SVM Results:\")\n",
    "print(f\"Explained Variance: {evs:.6f}\")\n",
    "print(f\"Max Error: {maxerr:.6f}\")\n",
    "print(f\"MAPE: {mape:.6f}\")\n",
    "print(f\"MSE: {mse:.6f}\")\n",
    "print(f\"MSLE: {msle:.6f}\")\n",
    "print(f\"Median AE: {mae_med:.6f}\")\n",
    "print(f\"R²: {r2:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avDL58EHGhS5",
    "outputId": "1e4eaaa1-43e7-42c6-f1e5-e7c00d73d37f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual vs Predicted Comparison (Test):\n",
      " Actual_Mn  Actual_Mw  Predicted_Mn  Predicted_Mw\n",
      "   2298.62    2972.98   2311.262111   2977.820177\n",
      "   3762.88    5752.81   2311.230178   2977.637975\n",
      "   1127.19    1321.65   2307.094083   2972.456813\n",
      "   2955.83    2966.91   2310.916810   2977.137801\n",
      "   2322.83    2987.31   2310.247889   2976.401428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to compare actual vs predicted values for Mn and Mw\n",
    "test_df = pd.DataFrame({\n",
    "    \"Actual_Mn\":    y_test[:, 0],   # True values for Mn\n",
    "    \"Actual_Mw\":    y_test[:, 1],   # True values for Mw\n",
    "    \"Predicted_Mn\": y_pred[:, 0],   # Predicted values for Mn\n",
    "    \"Predicted_Mw\": y_pred[:, 1],   # Predicted values for Mw\n",
    "})\n",
    "\n",
    "# Print comparison table without row indices\n",
    "print(\"Actual vs Predicted Comparison (Test):\")\n",
    "print(test_df.to_string(index=False))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7IldrqYGhQs",
    "outputId": "2308a428-648f-4749-a64f-5c15f7ebc13a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5-FOLD CROSS VALIDATION RESULTS\n",
      "R² Mean:   -0.1353 (±0.0820)\n",
      "MSE Mean:  1328342.8102 (±1036830.9413)\n",
      "MAPE Mean: 0.3033 (±0.1688)\n",
      "\n",
      "Individual R² scores: [-0.0322 -0.1757 -0.1002 -0.0965 -0.2717]\n",
      "Individual MSE scores: [1434268.1942  529840.2238   99664.4658 3116920.9216 1461020.2455]\n",
      "Individual MAPE scores: [0.3402 0.3302 0.1134 0.5858 0.1467]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize KFold cross-validation with 5 folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "r2_list, mse_list, mape_list = [], [], []\n",
    "\n",
    "# Perform cross-validation\n",
    "for tr_idx, va_idx in kf.split(X):\n",
    "    # Split data into training and validation sets\n",
    "    X_tr, X_va = X[tr_idx], X[va_idx]\n",
    "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "    \n",
    "    # Define model: Multi-output regression with pipeline (scaler + polynomial SVR)\n",
    "    m = MultiOutputRegressor(\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            SVR(kernel='poly', C=1, epsilon=0.1, gamma='scale')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Train the model on training fold\n",
    "    m.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Predict on validation fold\n",
    "    y_va_pred = m.predict(X_va)\n",
    "    \n",
    "    # Append evaluation metrics\n",
    "    r2_list.append(r2_score(y_va, y_va_pred, multioutput='uniform_average'))\n",
    "    mse_list.append(mean_squared_error(y_va, y_va_pred, multioutput='uniform_average'))\n",
    "    mape_list.append(mean_absolute_percentage_error(y_va, y_va_pred, multioutput='uniform_average'))\n",
    "\n",
    "# Convert lists to numpy arrays for easier aggregation\n",
    "r2_arr   = np.array(r2_list)\n",
    "mse_arr  = np.array(mse_list)\n",
    "mape_arr = np.array(mape_list)\n",
    "\n",
    "# Print summary of cross-validation results\n",
    "print(\"\\n5-FOLD CROSS VALIDATION RESULTS\")\n",
    "\n",
    "print(f\"R² Mean:   {r2_arr.mean():.4f} (±{r2_arr.std():.4f})\")\n",
    "print(f\"MSE Mean:  {mse_arr.mean():.4f} (±{mse_arr.std():.4f})\")\n",
    "print(f\"MAPE Mean: {mape_arr.mean():.4f} (±{mape_arr.std():.4f})\\n\")\n",
    "\n",
    "# Print individual fold scores\n",
    "print(\"Individual R² scores:\", np.array2string(r2_arr, precision=4))\n",
    "print(\"Individual MSE scores:\", np.array2string(mse_arr, precision=4))\n",
    "print(\"Individual MAPE scores:\", np.array2string(mape_arr, precision=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufdWy6GgIB9m",
    "outputId": "81667c9c-acf7-4bc3-f5f4-34a09e6f2a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual vs Predicted Comparison (All samples):\n",
      "Sample  1: Actual=[ 1127.19, 1321.65 ] | Predicted=[ 2278.61, 2939.98 ]\n",
      "Sample  2: Actual=[ 1024.97, 1339.35 ] | Predicted=[ 2280.49, 2944.25 ]\n",
      "Sample  3: Actual=[ 1950.00, 2878.90 ] | Predicted=[ 2295.80, 2971.61 ]\n",
      "Sample  4: Actual=[ 2223.17, 2989.00 ] | Predicted=[ 2295.80, 2971.61 ]\n",
      "Sample  5: Actual=[ 1845.60, 2690.50 ] | Predicted=[ 2292.39, 2955.20 ]\n",
      "Sample  6: Actual=[ 1846.18, 2689.91 ] | Predicted=[ 2292.39, 2955.20 ]\n",
      "Sample  7: Actual=[ 2073.90, 2974.51 ] | Predicted=[ 2307.34, 2972.61 ]\n",
      "Sample  8: Actual=[ 2074.52, 2970.82 ] | Predicted=[ 2307.34, 2972.61 ]\n",
      "Sample  9: Actual=[ 2298.62, 2972.98 ] | Predicted=[ 2343.73, 2981.66 ]\n",
      "Sample 10: Actual=[ 2298.65, 2972.94 ] | Predicted=[ 2343.73, 2981.66 ]\n",
      "Sample 11: Actual=[ 2322.86, 2987.28 ] | Predicted=[ 2322.83, 2987.28 ]\n",
      "Sample 12: Actual=[ 2322.83, 2987.31 ] | Predicted=[ 2322.83, 2987.28 ]\n",
      "Sample 13: Actual=[ 2752.80, 3129.61 ] | Predicted=[ 2334.40, 2993.36 ]\n",
      "Sample 14: Actual=[ 2752.84, 3129.57 ] | Predicted=[ 2334.40, 2993.36 ]\n",
      "Sample 15: Actual=[ 2525.27, 3441.19 ] | Predicted=[ 2302.95, 2963.18 ]\n",
      "Sample 16: Actual=[ 2525.91, 3440.43 ] | Predicted=[ 2302.95, 2963.18 ]\n",
      "Sample 17: Actual=[ 3762.88, 5752.81 ] | Predicted=[ 2343.60, 2981.58 ]\n",
      "Sample 18: Actual=[ 3764.53, 5752.15 ] | Predicted=[ 2343.60, 2981.58 ]\n",
      "Sample 19: Actual=[ 4663.04, 5921.49 ] | Predicted=[ 2341.14, 2989.47 ]\n",
      "Sample 20: Actual=[ 4663.77, 5921.61 ] | Predicted=[ 2341.14, 2989.47 ]\n",
      "Sample 21: Actual=[ 1264.44, 1456.22 ] | Predicted=[ 2280.75, 2941.89 ]\n",
      "Sample 22: Actual=[ 1265.88, 1458.13 ] | Predicted=[ 2280.75, 2941.89 ]\n",
      "Sample 23: Actual=[ 2951.90, 2965.54 ] | Predicted=[ 2339.42, 2972.97 ]\n",
      "Sample 24: Actual=[ 2955.83, 2966.91 ] | Predicted=[ 2339.42, 2972.97 ]\n",
      "Sample 25: Actual=[ 2590.79, 3517.86 ] | Predicted=[ 2335.17, 2972.28 ]\n",
      "\n",
      "Detailed Comparison Table:\n",
      " Sample  Actual_Mn  Actual_Mw  Predicted_Mn  Predicted_Mw     Error_Mn     Error_Mw\n",
      "      1   1127.190    1321.65   2278.608246   2939.977407 1.151418e+03 1.618327e+03\n",
      "      2   1024.970    1339.35   2280.488730   2944.247708 1.255519e+03 1.604898e+03\n",
      "      3   1950.000    2878.90   2295.804166   2971.612145 3.458042e+02 9.271214e+01\n",
      "      4   2223.170    2989.00   2295.804166   2971.612145 7.263417e+01 1.738786e+01\n",
      "      5   1845.600    2690.50   2292.387525   2955.195923 4.467875e+02 2.646959e+02\n",
      "      6   1846.180    2689.91   2292.387525   2955.195923 4.462075e+02 2.652859e+02\n",
      "      7   2073.900    2974.51   2307.341625   2972.612267 2.334416e+02 1.897733e+00\n",
      "      8   2074.517    2970.82   2307.341625   2972.612267 2.328246e+02 1.792267e+00\n",
      "      9   2298.620    2972.98   2343.728656   2981.663295 4.510866e+01 8.683295e+00\n",
      "     10   2298.650    2972.94   2343.728656   2981.663295 4.507866e+01 8.723295e+00\n",
      "     11   2322.860    2987.28   2322.830000   2987.280000 3.000011e-02 6.165328e-08\n",
      "     12   2322.830    2987.31   2322.830000   2987.280000 1.056887e-07 2.999994e-02\n",
      "     13   2752.800    3129.61   2334.401531   2993.363629 4.183985e+02 1.362464e+02\n",
      "     14   2752.840    3129.57   2334.401531   2993.363629 4.184385e+02 1.362064e+02\n",
      "     15   2525.270    3441.19   2302.950115   2963.181124 2.223199e+02 4.780089e+02\n",
      "     16   2525.910    3440.43   2302.950115   2963.181124 2.229599e+02 4.772489e+02\n",
      "     17   3762.880    5752.81   2343.596198   2981.577432 1.419284e+03 2.771233e+03\n",
      "     18   3764.530    5752.15   2343.596198   2981.577432 1.420934e+03 2.770573e+03\n",
      "     19   4663.040    5921.49   2341.144478   2989.468035 2.321896e+03 2.932022e+03\n",
      "     20   4663.770    5921.61   2341.144478   2989.468035 2.322626e+03 2.932142e+03\n",
      "     21   1264.440    1456.22   2280.751783   2941.890035 1.016312e+03 1.485670e+03\n",
      "     22   1265.880    1458.13   2280.751783   2941.890035 1.014872e+03 1.483760e+03\n",
      "     23   2951.900    2965.54   2339.424872   2972.968679 6.124751e+02 7.428679e+00\n",
      "     24   2955.830    2966.91   2339.424872   2972.968679 6.164051e+02 6.058679e+00\n",
      "     25   2590.790    3517.86   2335.172480   2972.279120 2.556175e+02 5.455809e+02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Train final model on all available data (using RBF kernel SVR)\n",
    "model_all = MultiOutputRegressor(\n",
    "    make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVR(kernel='rbf', C=10.0, epsilon=0.01, gamma='scale')\n",
    "    )\n",
    ")\n",
    "model_all.fit(X, y)\n",
    "\n",
    "# Predict on the full dataset\n",
    "y_all_pred = model_all.predict(X)\n",
    "\n",
    "# Build a DataFrame to compare actual vs predicted values\n",
    "all_df = pd.DataFrame({\n",
    "    \"Sample\": np.arange(1, X.shape[0] + 1),  # Sample numbering\n",
    "    \"Actual_Mn\":    y[:, 0],\n",
    "    \"Actual_Mw\":    y[:, 1],\n",
    "    \"Predicted_Mn\": y_all_pred[:, 0],\n",
    "    \"Predicted_Mw\": y_all_pred[:, 1],\n",
    "})\n",
    "\n",
    "# Compute absolute errors for each sample\n",
    "all_df[\"Error_Mn\"] = (all_df[\"Actual_Mn\"] - all_df[\"Predicted_Mn\"]).abs()\n",
    "all_df[\"Error_Mw\"] = (all_df[\"Actual_Mw\"] - all_df[\"Predicted_Mw\"]).abs()\n",
    "\n",
    "# Print sample-by-sample comparison\n",
    "print(\"\\nActual vs Predicted Comparison (All samples):\")\n",
    "for i, row in all_df.iterrows():\n",
    "    a_mn, a_mw = row[\"Actual_Mn\"], row[\"Actual_Mw\"]\n",
    "    p_mn, p_mw = row[\"Predicted_Mn\"], row[\"Predicted_Mw\"]\n",
    "    print(f\"Sample {int(row['Sample']):2d}: Actual=[ {a_mn:7.2f}, {a_mw:7.2f} ] | \"\n",
    "          f\"Predicted=[ {p_mn:7.2f}, {p_mw:7.2f} ]\")\n",
    "\n",
    "# Print full comparison table\n",
    "print(\"\\nDetailed Comparison Table:\")\n",
    "print(all_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_aorshPIB7i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zv_EHrARIB5D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukI3niT8IB2o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM0oZCWGw/nEXIefYWBRgQG",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
