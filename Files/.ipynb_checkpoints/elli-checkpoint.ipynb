{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/elhamshaerirahbar-bot/my-colab-project/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8S8VCECinI2",
    "outputId": "442f5205-7a69-49da-a8a5-1f42a4fc8e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.20.0rc0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.11.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0Syqe_mYiwTx"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, re, unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "mQM3DjQNi0he",
    "outputId": "b018038a-6aec-4a81-e135-9ae3d186ce03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Run  Factor A  Factor B  Factor C  Factor D  Response 1 (Experimental)  \\\n",
      "0    1       110         7        50        10                    1127.19   \n",
      "1    2        85        13        50        10                    1024.97   \n",
      "2    3       101         1       500        60                    1950.00   \n",
      "3    4       101         1       500        60                    2223.17   \n",
      "4    5        50        10        50        10                    1845.60   \n",
      "\n",
      "   Response 2 (Experimental)  \n",
      "0                    1321.65  \n",
      "1                    1339.35  \n",
      "2                    2878.90  \n",
      "3                    2989.00  \n",
      "4                    2690.50  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Just read the file\n",
    "df = pd.read_csv('Exp_Mn_Mw_Value.txt', sep='\\t')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Y9BwNofi4-T",
    "outputId": "92a5901e-bb2a-48a0-bd86-613b27ddaa22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (25, 4)  y: (25, 2)\n"
     ]
    }
   ],
   "source": [
    "# Use iloc to select columns by position\n",
    "\n",
    "X = df.iloc[:, 1:5].astype(float).to_numpy()  # columns 1-4 as features\n",
    "y = df.iloc[:, 5:7].astype(float).to_numpy()  # Next 2 columns as targets\n",
    "\n",
    "print(\"X:\", X.shape, \" y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2AA1C6Wi77R",
    "outputId": "187af667-98c6-49ba-857a-f7dab735a70b"
   },
   "outputs": [],
   "source": [
    "#Data splitting\n",
    "# For 20% test, 16% val, 64% train:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, shuffle=True, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.20, shuffle=True, random_state=SEED  # 0.20 of 0.80 = 0.16 overall\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WAeiXioBjGXg"
   },
   "outputs": [],
   "source": [
    "#Scaling\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Ensure y has correct shape (samples, 2_targets)\n",
    "assert y_train.ndim == 2 and y_train.shape[1] == 2, \"y muss (n,2) sein\"\n",
    "\n",
    "# Scale features (X) using StandardScaler \n",
    "# Fit scaler only on training data to prevent data leakage\n",
    "x_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Transform all sets using the same scaler (mean=0, std=1)\n",
    "X_train_z = x_scaler.transform(X_train)  # Standardized training features\n",
    "X_val_z   = x_scaler.transform(X_val)    # Standardized validation features  \n",
    "X_test_z  = x_scaler.transform(X_test)   # Standardized test features\n",
    "\n",
    "#  Scale targets (y) to [-1,1] range for tanh activation\n",
    "# Fit scaler only on training targets to prevent data leakage\n",
    "y_scaler  = MinMaxScaler(feature_range=(-1, 1)).fit(y_train)  # y_train: (n,2)\n",
    "\n",
    "# Transform all target sets using the same scaler\n",
    "y_train_s = y_scaler.transform(y_train)  # Scaled training targets [-1,1]\n",
    "y_val_s   = y_scaler.transform(y_val)    # Scaled validation targets [-1,1]\n",
    "y_test_s  = y_scaler.transform(y_test)   # Scaled test targets [-1,1]\n",
    "\n",
    "def inv_y(y_s):\n",
    "    \"\"\"\n",
    "    Inverse transform scaled predictions back to original units.\n",
    "    Args: y_s - scaled predictions in [-1,1] range\n",
    "    Returns: predictions in original scale (Mn, Mw units)\n",
    "    \"\"\"\n",
    "    return y_scaler.inverse_transform(y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "dBaYl7yWjKR5"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otPjam8rjLqF",
    "outputId": "c6ef832c-fff8-46ad-d52a-389edaf598dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Build Neural Network: 4 inputs -> 3 hidden layers (16,8,8) -> 2 outputs\n",
    "# Architecture: fully connected feedforward network with regularization\n",
    "# Purpose: predict 2 molecular weight responses (Mn, Mw) from 4 factors\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Verify target shape (samples, 2_outputs)\n",
    "assert y_train_s.ndim == 2 and y_train_s.shape[1] == 2, \"y muss (n,2) sein!\"\n",
    "\n",
    "# Build neural network model\n",
    "model = Sequential([\n",
    "    # Input layer: 4 features -> 16 neurons\n",
    "    # ReLU activation for non-linearity\n",
    "    # L2 regularization to prevent overfitting\n",
    "    layers.Dense(16, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-5),\n",
    "                 input_shape=(X_train_z.shape[1],)),\n",
    "    \n",
    "    # Dropout to reduce overfitting (randomly disable 10% of neurons)\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    # Hidden layer: 16 -> 8 neurons\n",
    "    layers.Dense(8, activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(1e-5)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    # Hidden layer: 8 -> 8 neurons  \n",
    "    layers.Dense(8, activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(1e-5)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    # Output layer: 8 -> 2 outputs (Mn, Mw)\n",
    "    # Tanh activation outputs [-1,1] to match our scaled targets\n",
    "    layers.Dense(2, activation='tanh')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "# MSE loss for regression, MAE and MAPE as additional metrics\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse', \n",
    "              metrics=['mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SiGI9kdjLoU",
    "outputId": "a56e7194-c800-4b0d-945d-a91716792ef7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980ms/step - loss: 0.6683 - mae: 0.7379 - mape: 98.9474 - val_loss: 0.5160 - val_mae: 0.5902 - val_mape: 92.1058\n",
      "Epoch 2/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6328 - mae: 0.7180 - mape: 95.3717 - val_loss: 0.5141 - val_mae: 0.5887 - val_mape: 91.3043\n",
      "Epoch 3/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6839 - mae: 0.7422 - mape: 92.1620 - val_loss: 0.5121 - val_mae: 0.5872 - val_mape: 90.3851\n",
      "Epoch 4/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6355 - mae: 0.7174 - mape: 93.1972 - val_loss: 0.5105 - val_mae: 0.5857 - val_mape: 89.1109\n",
      "Epoch 5/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6460 - mae: 0.7240 - mape: 99.7138 - val_loss: 0.5092 - val_mae: 0.5841 - val_mape: 87.4795\n",
      "Epoch 6/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6196 - mae: 0.7073 - mape: 94.6744 - val_loss: 0.5084 - val_mae: 0.5826 - val_mape: 85.7408\n",
      "Epoch 7/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5889 - mae: 0.6877 - mape: 89.7729 - val_loss: 0.5079 - val_mae: 0.5811 - val_mape: 83.8909\n",
      "Epoch 8/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5977 - mae: 0.6888 - mape: 87.8132 - val_loss: 0.5072 - val_mae: 0.5796 - val_mape: 82.0984\n",
      "Epoch 9/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6423 - mae: 0.7188 - mape: 90.7465 - val_loss: 0.5063 - val_mae: 0.5780 - val_mape: 80.5104\n",
      "Epoch 10/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.6466 - mae: 0.7191 - mape: 94.6789 - val_loss: 0.5051 - val_mae: 0.5763 - val_mape: 79.0102\n",
      "Epoch 11/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6075 - mae: 0.6978 - mape: 88.4651 - val_loss: 0.5038 - val_mae: 0.5745 - val_mape: 77.5669\n",
      "Epoch 12/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6117 - mae: 0.6981 - mape: 88.8442 - val_loss: 0.5025 - val_mae: 0.5729 - val_mape: 76.1747\n",
      "Epoch 13/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6191 - mae: 0.7036 - mape: 87.5235 - val_loss: 0.5013 - val_mae: 0.5712 - val_mape: 74.8134\n",
      "Epoch 14/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6381 - mae: 0.7177 - mape: 91.7179 - val_loss: 0.5001 - val_mae: 0.5706 - val_mape: 75.6041\n",
      "Epoch 15/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6197 - mae: 0.7090 - mape: 98.8301 - val_loss: 0.4988 - val_mae: 0.5699 - val_mape: 76.2429\n",
      "Epoch 16/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5738 - mae: 0.6779 - mape: 89.5437 - val_loss: 0.4974 - val_mae: 0.5692 - val_mape: 76.9389\n",
      "Epoch 17/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6096 - mae: 0.7021 - mape: 98.6691 - val_loss: 0.4962 - val_mae: 0.5686 - val_mape: 77.6580\n",
      "Epoch 18/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6060 - mae: 0.6972 - mape: 98.5086 - val_loss: 0.4950 - val_mae: 0.5681 - val_mape: 78.5234\n",
      "Epoch 19/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5781 - mae: 0.6809 - mape: 89.9851 - val_loss: 0.4939 - val_mae: 0.5676 - val_mape: 79.4128\n",
      "Epoch 20/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5682 - mae: 0.6733 - mape: 87.3202 - val_loss: 0.4927 - val_mae: 0.5670 - val_mape: 80.1398\n",
      "Epoch 21/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5617 - mae: 0.6677 - mape: 85.3289 - val_loss: 0.4912 - val_mae: 0.5661 - val_mape: 80.6823\n",
      "Epoch 22/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6161 - mae: 0.7026 - mape: 95.5683 - val_loss: 0.4896 - val_mae: 0.5652 - val_mape: 81.0673\n",
      "Epoch 23/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5834 - mae: 0.6836 - mape: 96.6627 - val_loss: 0.4883 - val_mae: 0.5645 - val_mape: 81.7451\n",
      "Epoch 24/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5373 - mae: 0.6517 - mape: 89.5972 - val_loss: 0.4869 - val_mae: 0.5637 - val_mape: 82.3565\n",
      "Epoch 25/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5720 - mae: 0.6699 - mape: 83.8501 - val_loss: 0.4860 - val_mae: 0.5633 - val_mape: 83.2633\n",
      "Epoch 26/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5940 - mae: 0.6810 - mape: 91.1218 - val_loss: 0.4848 - val_mae: 0.5627 - val_mape: 83.9340\n",
      "Epoch 27/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5241 - mae: 0.6408 - mape: 88.7300 - val_loss: 0.4836 - val_mae: 0.5621 - val_mape: 84.6287\n",
      "Epoch 28/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.5690 - mae: 0.6698 - mape: 97.8679 - val_loss: 0.4824 - val_mae: 0.5615 - val_mape: 85.2885\n",
      "Epoch 29/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5725 - mae: 0.6671 - mape: 84.2623 - val_loss: 0.4814 - val_mae: 0.5610 - val_mape: 86.0203\n",
      "Epoch 30/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5795 - mae: 0.6791 - mape: 91.1483 - val_loss: 0.4801 - val_mae: 0.5603 - val_mape: 86.6525\n",
      "Epoch 31/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5202 - mae: 0.6320 - mape: 82.2777 - val_loss: 0.4785 - val_mae: 0.5594 - val_mape: 87.1404\n",
      "Epoch 32/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5682 - mae: 0.6638 - mape: 85.6504 - val_loss: 0.4771 - val_mae: 0.5586 - val_mape: 87.5113\n",
      "Epoch 33/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5017 - mae: 0.6228 - mape: 87.8180 - val_loss: 0.4756 - val_mae: 0.5577 - val_mape: 87.8769\n",
      "Epoch 34/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5314 - mae: 0.6481 - mape: 94.4222 - val_loss: 0.4742 - val_mae: 0.5570 - val_mape: 88.3960\n",
      "Epoch 35/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5642 - mae: 0.6582 - mape: 84.7295 - val_loss: 0.4726 - val_mae: 0.5561 - val_mape: 88.8091\n",
      "Epoch 36/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4942 - mae: 0.6151 - mape: 78.8273 - val_loss: 0.4710 - val_mae: 0.5552 - val_mape: 89.2271\n",
      "Epoch 37/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5622 - mae: 0.6608 - mape: 81.1485 - val_loss: 0.4694 - val_mae: 0.5542 - val_mape: 89.6666\n",
      "Epoch 38/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5608 - mae: 0.6628 - mape: 85.7822 - val_loss: 0.4676 - val_mae: 0.5530 - val_mape: 89.8453\n",
      "Epoch 39/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5634 - mae: 0.6689 - mape: 96.7572 - val_loss: 0.4656 - val_mae: 0.5517 - val_mape: 89.8789\n",
      "Epoch 40/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5901 - mae: 0.6747 - mape: 87.1404 - val_loss: 0.4636 - val_mae: 0.5503 - val_mape: 89.8402\n",
      "Epoch 41/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5284 - mae: 0.6381 - mape: 79.8525 - val_loss: 0.4617 - val_mae: 0.5490 - val_mape: 89.8915\n",
      "Epoch 42/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5167 - mae: 0.6392 - mape: 86.3033 - val_loss: 0.4599 - val_mae: 0.5477 - val_mape: 89.9510\n",
      "Epoch 43/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4876 - mae: 0.6137 - mape: 84.6061 - val_loss: 0.4582 - val_mae: 0.5465 - val_mape: 90.0048\n",
      "Epoch 44/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5377 - mae: 0.6528 - mape: 95.0040 - val_loss: 0.4563 - val_mae: 0.5451 - val_mape: 89.9396\n",
      "Epoch 45/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5167 - mae: 0.6311 - mape: 89.4475 - val_loss: 0.4542 - val_mae: 0.5436 - val_mape: 89.6912\n",
      "Epoch 46/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5121 - mae: 0.6284 - mape: 85.3461 - val_loss: 0.4522 - val_mae: 0.5422 - val_mape: 89.4258\n",
      "Epoch 47/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5374 - mae: 0.6253 - mape: 74.7706 - val_loss: 0.4501 - val_mae: 0.5406 - val_mape: 89.0777\n",
      "Epoch 48/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4784 - mae: 0.6076 - mape: 82.5091 - val_loss: 0.4480 - val_mae: 0.5391 - val_mape: 88.7919\n",
      "Epoch 49/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5014 - mae: 0.6123 - mape: 82.1142 - val_loss: 0.4458 - val_mae: 0.5374 - val_mape: 88.4027\n",
      "Epoch 50/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.5397 - mae: 0.6468 - mape: 93.8819 - val_loss: 0.4434 - val_mae: 0.5357 - val_mape: 87.9970\n",
      "Epoch 51/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4963 - mae: 0.6066 - mape: 82.7577 - val_loss: 0.4411 - val_mae: 0.5340 - val_mape: 87.6493\n",
      "Epoch 52/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4892 - mae: 0.5974 - mape: 78.2978 - val_loss: 0.4392 - val_mae: 0.5327 - val_mape: 87.5776\n",
      "Epoch 53/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4830 - mae: 0.6151 - mape: 88.1526 - val_loss: 0.4375 - val_mae: 0.5316 - val_mape: 87.7066\n",
      "Epoch 54/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4469 - mae: 0.5738 - mape: 80.2058 - val_loss: 0.4361 - val_mae: 0.5308 - val_mape: 88.0605\n",
      "Epoch 55/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5197 - mae: 0.6259 - mape: 94.1429 - val_loss: 0.4347 - val_mae: 0.5300 - val_mape: 88.3900\n",
      "Epoch 56/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4824 - mae: 0.6147 - mape: 97.1090 - val_loss: 0.4332 - val_mae: 0.5292 - val_mape: 88.5969\n",
      "Epoch 57/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4721 - mae: 0.5916 - mape: 85.2109 - val_loss: 0.4319 - val_mae: 0.5284 - val_mape: 88.8853\n",
      "Epoch 58/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4577 - mae: 0.5891 - mape: 83.0096 - val_loss: 0.4305 - val_mae: 0.5277 - val_mape: 89.1861\n",
      "Epoch 59/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5126 - mae: 0.6263 - mape: 93.2003 - val_loss: 0.4293 - val_mae: 0.5270 - val_mape: 89.5015\n",
      "Epoch 60/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4936 - mae: 0.6020 - mape: 77.6077 - val_loss: 0.4281 - val_mae: 0.5263 - val_mape: 89.7339\n",
      "Epoch 61/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5237 - mae: 0.6468 - mape: 98.9972 - val_loss: 0.4270 - val_mae: 0.5257 - val_mape: 90.0734\n",
      "Epoch 62/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5583 - mae: 0.6460 - mape: 88.3526 - val_loss: 0.4255 - val_mae: 0.5247 - val_mape: 90.1182\n",
      "Epoch 63/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4856 - mae: 0.6033 - mape: 82.9632 - val_loss: 0.4240 - val_mae: 0.5237 - val_mape: 90.0931\n",
      "Epoch 64/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5868 - mae: 0.6572 - mape: 89.5123 - val_loss: 0.4226 - val_mae: 0.5227 - val_mape: 90.1219\n",
      "Epoch 65/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4468 - mae: 0.5717 - mape: 76.2485 - val_loss: 0.4214 - val_mae: 0.5220 - val_mape: 90.3276\n",
      "Epoch 66/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4217 - mae: 0.5629 - mape: 85.9915 - val_loss: 0.4201 - val_mae: 0.5211 - val_mape: 90.4671\n",
      "Epoch 67/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4540 - mae: 0.5819 - mape: 74.2570 - val_loss: 0.4189 - val_mae: 0.5205 - val_mape: 90.6802\n",
      "Epoch 68/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5252 - mae: 0.6256 - mape: 95.1480 - val_loss: 0.4175 - val_mae: 0.5195 - val_mape: 90.5489\n",
      "Epoch 69/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4020 - mae: 0.5403 - mape: 75.3875 - val_loss: 0.4162 - val_mae: 0.5186 - val_mape: 90.3778\n",
      "Epoch 70/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4695 - mae: 0.5830 - mape: 77.4804 - val_loss: 0.4149 - val_mae: 0.5178 - val_mape: 90.3451\n",
      "Epoch 71/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4545 - mae: 0.5864 - mape: 92.9643 - val_loss: 0.4137 - val_mae: 0.5170 - val_mape: 90.4105\n",
      "Epoch 72/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4467 - mae: 0.5559 - mape: 81.0997 - val_loss: 0.4124 - val_mae: 0.5161 - val_mape: 90.3490\n",
      "Epoch 73/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5346 - mae: 0.6332 - mape: 103.7794 - val_loss: 0.4113 - val_mae: 0.5154 - val_mape: 90.4446\n",
      "Epoch 74/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4897 - mae: 0.6087 - mape: 86.2492 - val_loss: 0.4100 - val_mae: 0.5145 - val_mape: 90.3455\n",
      "Epoch 75/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4729 - mae: 0.5900 - mape: 85.7900 - val_loss: 0.4086 - val_mae: 0.5135 - val_mape: 90.0302\n",
      "Epoch 76/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4457 - mae: 0.5741 - mape: 79.4935 - val_loss: 0.4074 - val_mae: 0.5128 - val_mape: 89.9006\n",
      "Epoch 77/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4740 - mae: 0.5818 - mape: 72.1283 - val_loss: 0.4064 - val_mae: 0.5121 - val_mape: 89.8767\n",
      "Epoch 78/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4244 - mae: 0.5569 - mape: 91.1990 - val_loss: 0.4053 - val_mae: 0.5114 - val_mape: 89.8308\n",
      "Epoch 79/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4330 - mae: 0.5780 - mape: 91.0878 - val_loss: 0.4044 - val_mae: 0.5109 - val_mape: 89.8746\n",
      "Epoch 80/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4447 - mae: 0.5691 - mape: 78.5252 - val_loss: 0.4036 - val_mae: 0.5104 - val_mape: 90.0310\n",
      "Epoch 81/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3809 - mae: 0.5329 - mape: 86.2285 - val_loss: 0.4027 - val_mae: 0.5099 - val_mape: 90.1201\n",
      "Epoch 82/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.4029 - mae: 0.5441 - mape: 86.3665 - val_loss: 0.4018 - val_mae: 0.5095 - val_mape: 90.2305\n",
      "Epoch 83/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3857 - mae: 0.5181 - mape: 65.7820 - val_loss: 0.4011 - val_mae: 0.5092 - val_mape: 90.4367\n",
      "Epoch 84/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4144 - mae: 0.5519 - mape: 83.1744 - val_loss: 0.3998 - val_mae: 0.5085 - val_mape: 90.2161\n",
      "Epoch 85/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4583 - mae: 0.5685 - mape: 77.0543 - val_loss: 0.3984 - val_mae: 0.5075 - val_mape: 89.7509\n",
      "Epoch 86/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3857 - mae: 0.5218 - mape: 83.4796 - val_loss: 0.3968 - val_mae: 0.5064 - val_mape: 89.0901\n",
      "Epoch 87/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3650 - mae: 0.5054 - mape: 72.9877 - val_loss: 0.3956 - val_mae: 0.5055 - val_mape: 88.6778\n",
      "Epoch 88/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4408 - mae: 0.5524 - mape: 68.3775 - val_loss: 0.3942 - val_mae: 0.5046 - val_mape: 88.2752\n",
      "Epoch 89/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4012 - mae: 0.5306 - mape: 82.1421 - val_loss: 0.3929 - val_mae: 0.5037 - val_mape: 87.8457\n",
      "Epoch 90/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4282 - mae: 0.5536 - mape: 68.2732 - val_loss: 0.3916 - val_mae: 0.5028 - val_mape: 87.4561\n",
      "Epoch 91/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3791 - mae: 0.5221 - mape: 78.4750 - val_loss: 0.3906 - val_mae: 0.5020 - val_mape: 87.2126\n",
      "Epoch 92/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3642 - mae: 0.4980 - mape: 77.4892 - val_loss: 0.3892 - val_mae: 0.5010 - val_mape: 86.7993\n",
      "Epoch 93/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4078 - mae: 0.5263 - mape: 78.5781 - val_loss: 0.3878 - val_mae: 0.4998 - val_mape: 86.1890\n",
      "Epoch 94/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5570 - mae: 0.6167 - mape: 96.6271 - val_loss: 0.3862 - val_mae: 0.4985 - val_mape: 85.4642\n",
      "Epoch 95/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3416 - mae: 0.4952 - mape: 93.9465 - val_loss: 0.3845 - val_mae: 0.4971 - val_mape: 84.5580\n",
      "Epoch 96/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3606 - mae: 0.5073 - mape: 96.8868 - val_loss: 0.3829 - val_mae: 0.4957 - val_mape: 83.5806\n",
      "Epoch 97/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4634 - mae: 0.5900 - mape: 82.8441 - val_loss: 0.3813 - val_mae: 0.4944 - val_mape: 82.7097\n",
      "Epoch 98/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4113 - mae: 0.5367 - mape: 70.2745 - val_loss: 0.3799 - val_mae: 0.4933 - val_mape: 82.1365\n",
      "Epoch 99/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4147 - mae: 0.5446 - mape: 69.2510 - val_loss: 0.3789 - val_mae: 0.4926 - val_mape: 81.8199\n",
      "Epoch 100/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3929 - mae: 0.5250 - mape: 85.7160 - val_loss: 0.3778 - val_mae: 0.4918 - val_mape: 81.4241\n",
      "Epoch 101/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3893 - mae: 0.5334 - mape: 98.7586 - val_loss: 0.3765 - val_mae: 0.4909 - val_mape: 80.8725\n",
      "Epoch 102/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4908 - mae: 0.6027 - mape: 93.2974 - val_loss: 0.3755 - val_mae: 0.4902 - val_mape: 80.4113\n",
      "Epoch 103/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3369 - mae: 0.4799 - mape: 75.7289 - val_loss: 0.3743 - val_mae: 0.4893 - val_mape: 79.8766\n",
      "Epoch 104/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4583 - mae: 0.5656 - mape: 77.5671 - val_loss: 0.3735 - val_mae: 0.4886 - val_mape: 79.7303\n",
      "Epoch 105/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3598 - mae: 0.5095 - mape: 99.0595 - val_loss: 0.3726 - val_mae: 0.4878 - val_mape: 79.3427\n",
      "Epoch 106/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4013 - mae: 0.5106 - mape: 71.0787 - val_loss: 0.3718 - val_mae: 0.4869 - val_mape: 78.9118\n",
      "Epoch 107/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4142 - mae: 0.5255 - mape: 85.2674 - val_loss: 0.3705 - val_mae: 0.4857 - val_mape: 78.2251\n",
      "Epoch 108/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4393 - mae: 0.5742 - mape: 79.3401 - val_loss: 0.3691 - val_mae: 0.4842 - val_mape: 77.4337\n",
      "Epoch 109/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3784 - mae: 0.5148 - mape: 75.7685 - val_loss: 0.3677 - val_mae: 0.4828 - val_mape: 76.7730\n",
      "Epoch 110/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5340 - mae: 0.6020 - mape: 75.2225 - val_loss: 0.3660 - val_mae: 0.4812 - val_mape: 75.8435\n",
      "Epoch 111/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3761 - mae: 0.5217 - mape: 101.3395 - val_loss: 0.3643 - val_mae: 0.4795 - val_mape: 74.8204\n",
      "Epoch 112/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4156 - mae: 0.5418 - mape: 107.6293 - val_loss: 0.3626 - val_mae: 0.4777 - val_mape: 73.7432\n",
      "Epoch 113/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3266 - mae: 0.4726 - mape: 78.0866 - val_loss: 0.3612 - val_mae: 0.4761 - val_mape: 72.8168\n",
      "Epoch 114/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3092 - mae: 0.4591 - mape: 64.7190 - val_loss: 0.3596 - val_mae: 0.4744 - val_mape: 71.7289\n",
      "Epoch 115/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4887 - mae: 0.5743 - mape: 73.0984 - val_loss: 0.3583 - val_mae: 0.4729 - val_mape: 70.8925\n",
      "Epoch 116/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4373 - mae: 0.5295 - mape: 86.4056 - val_loss: 0.3567 - val_mae: 0.4717 - val_mape: 70.1799\n",
      "Epoch 117/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3528 - mae: 0.4764 - mape: 73.0497 - val_loss: 0.3549 - val_mae: 0.4704 - val_mape: 69.2835\n",
      "Epoch 118/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3434 - mae: 0.4837 - mape: 74.7237 - val_loss: 0.3535 - val_mae: 0.4694 - val_mape: 68.7474\n",
      "Epoch 119/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3093 - mae: 0.4503 - mape: 94.9721 - val_loss: 0.3520 - val_mae: 0.4683 - val_mape: 68.2612\n",
      "Epoch 120/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3949 - mae: 0.5074 - mape: 74.5147 - val_loss: 0.3507 - val_mae: 0.4674 - val_mape: 67.8589\n",
      "Epoch 121/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3934 - mae: 0.5439 - mape: 89.4043 - val_loss: 0.3495 - val_mae: 0.4665 - val_mape: 67.5954\n",
      "Epoch 122/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4376 - mae: 0.5593 - mape: 73.9668 - val_loss: 0.3484 - val_mae: 0.4658 - val_mape: 67.4795\n",
      "Epoch 123/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4204 - mae: 0.5278 - mape: 107.1534 - val_loss: 0.3471 - val_mae: 0.4650 - val_mape: 67.1457\n",
      "Epoch 124/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3607 - mae: 0.4947 - mape: 112.1449 - val_loss: 0.3458 - val_mae: 0.4640 - val_mape: 66.6182\n",
      "Epoch 125/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2837 - mae: 0.4317 - mape: 62.3111 - val_loss: 0.3445 - val_mae: 0.4629 - val_mape: 66.0030\n",
      "Epoch 126/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3058 - mae: 0.4631 - mape: 72.4555 - val_loss: 0.3436 - val_mae: 0.4622 - val_mape: 65.6437\n",
      "Epoch 127/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3595 - mae: 0.4848 - mape: 71.6132 - val_loss: 0.3426 - val_mae: 0.4616 - val_mape: 65.6005\n",
      "Epoch 128/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4794 - mae: 0.5645 - mape: 89.1839 - val_loss: 0.3416 - val_mae: 0.4610 - val_mape: 65.4859\n",
      "Epoch 129/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2745 - mae: 0.4225 - mape: 64.0851 - val_loss: 0.3407 - val_mae: 0.4604 - val_mape: 65.3395\n",
      "Epoch 130/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4261 - mae: 0.5301 - mape: 78.8435 - val_loss: 0.3398 - val_mae: 0.4601 - val_mape: 65.5144\n",
      "Epoch 131/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3115 - mae: 0.4485 - mape: 66.3013 - val_loss: 0.3386 - val_mae: 0.4595 - val_mape: 65.5020\n",
      "Epoch 132/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3810 - mae: 0.5184 - mape: 80.9421 - val_loss: 0.3379 - val_mae: 0.4591 - val_mape: 65.5993\n",
      "Epoch 133/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2699 - mae: 0.4308 - mape: 61.9264 - val_loss: 0.3374 - val_mae: 0.4589 - val_mape: 65.9424\n",
      "Epoch 134/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3470 - mae: 0.4707 - mape: 77.2109 - val_loss: 0.3364 - val_mae: 0.4582 - val_mape: 65.6823\n",
      "Epoch 135/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2353 - mae: 0.3699 - mape: 48.4015 - val_loss: 0.3355 - val_mae: 0.4574 - val_mape: 65.4471\n",
      "Epoch 136/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2969 - mae: 0.4404 - mape: 59.0691 - val_loss: 0.3347 - val_mae: 0.4563 - val_mape: 64.8773\n",
      "Epoch 137/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2446 - mae: 0.3999 - mape: 66.2506 - val_loss: 0.3339 - val_mae: 0.4557 - val_mape: 65.0042\n",
      "Epoch 138/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2764 - mae: 0.4390 - mape: 73.8678 - val_loss: 0.3331 - val_mae: 0.4551 - val_mape: 65.4216\n",
      "Epoch 139/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2599 - mae: 0.4216 - mape: 65.0278 - val_loss: 0.3323 - val_mae: 0.4545 - val_mape: 65.5901\n",
      "Epoch 140/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3560 - mae: 0.4872 - mape: 75.4165 - val_loss: 0.3319 - val_mae: 0.4539 - val_mape: 65.4583\n",
      "Epoch 141/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3207 - mae: 0.4500 - mape: 77.9203 - val_loss: 0.3309 - val_mae: 0.4534 - val_mape: 65.7257\n",
      "Epoch 142/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4623 - mae: 0.5458 - mape: 89.1691 - val_loss: 0.3300 - val_mae: 0.4528 - val_mape: 65.9656\n",
      "Epoch 143/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3944 - mae: 0.5085 - mape: 75.5098 - val_loss: 0.3290 - val_mae: 0.4522 - val_mape: 66.1443\n",
      "Epoch 144/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2377 - mae: 0.3865 - mape: 60.0610 - val_loss: 0.3281 - val_mae: 0.4517 - val_mape: 66.4968\n",
      "Epoch 145/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2979 - mae: 0.4463 - mape: 69.6656 - val_loss: 0.3271 - val_mae: 0.4510 - val_mape: 66.6961\n",
      "Epoch 146/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2555 - mae: 0.3867 - mape: 62.2135 - val_loss: 0.3260 - val_mae: 0.4504 - val_mape: 66.9047\n",
      "Epoch 147/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3045 - mae: 0.4338 - mape: 91.8677 - val_loss: 0.3249 - val_mae: 0.4499 - val_mape: 67.2306\n",
      "Epoch 148/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2471 - mae: 0.3938 - mape: 67.6488 - val_loss: 0.3238 - val_mae: 0.4493 - val_mape: 67.5226\n",
      "Epoch 149/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1968 - mae: 0.3477 - mape: 72.9075 - val_loss: 0.3224 - val_mae: 0.4487 - val_mape: 67.8477\n",
      "Epoch 150/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3334 - mae: 0.4524 - mape: 88.7372 - val_loss: 0.3210 - val_mae: 0.4481 - val_mape: 68.4506\n",
      "Epoch 151/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3080 - mae: 0.4334 - mape: 69.5029 - val_loss: 0.3200 - val_mae: 0.4476 - val_mape: 68.5939\n",
      "Epoch 152/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2789 - mae: 0.4325 - mape: 81.4563 - val_loss: 0.3193 - val_mae: 0.4473 - val_mape: 69.1129\n",
      "Epoch 153/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2520 - mae: 0.4015 - mape: 81.7580 - val_loss: 0.3186 - val_mae: 0.4472 - val_mape: 69.8772\n",
      "Epoch 154/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2920 - mae: 0.4373 - mape: 76.6976 - val_loss: 0.3179 - val_mae: 0.4469 - val_mape: 70.5816\n",
      "Epoch 155/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3305 - mae: 0.4645 - mape: 76.6471 - val_loss: 0.3170 - val_mae: 0.4466 - val_mape: 71.1865\n",
      "Epoch 156/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2954 - mae: 0.4220 - mape: 72.8450 - val_loss: 0.3160 - val_mae: 0.4461 - val_mape: 71.6492\n",
      "Epoch 157/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3880 - mae: 0.4950 - mape: 90.3569 - val_loss: 0.3150 - val_mae: 0.4457 - val_mape: 72.0348\n",
      "Epoch 158/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2642 - mae: 0.3970 - mape: 61.4541 - val_loss: 0.3140 - val_mae: 0.4452 - val_mape: 72.4029\n",
      "Epoch 159/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3329 - mae: 0.4743 - mape: 76.6524 - val_loss: 0.3131 - val_mae: 0.4448 - val_mape: 72.7997\n",
      "Epoch 160/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3192 - mae: 0.4343 - mape: 63.1546 - val_loss: 0.3125 - val_mae: 0.4446 - val_mape: 73.3746\n",
      "Epoch 161/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2616 - mae: 0.3861 - mape: 63.3172 - val_loss: 0.3119 - val_mae: 0.4444 - val_mape: 74.0664\n",
      "Epoch 162/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3691 - mae: 0.4654 - mape: 77.4132 - val_loss: 0.3110 - val_mae: 0.4440 - val_mape: 74.6167\n",
      "Epoch 163/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2818 - mae: 0.4082 - mape: 64.7206 - val_loss: 0.3099 - val_mae: 0.4436 - val_mape: 75.0640\n",
      "Epoch 164/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2426 - mae: 0.3837 - mape: 86.2297 - val_loss: 0.3083 - val_mae: 0.4429 - val_mape: 75.4252\n",
      "Epoch 165/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1707 - mae: 0.3086 - mape: 55.5281 - val_loss: 0.3066 - val_mae: 0.4422 - val_mape: 75.7638\n",
      "Epoch 166/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3785 - mae: 0.5053 - mape: 80.2833 - val_loss: 0.3048 - val_mae: 0.4416 - val_mape: 76.2149\n",
      "Epoch 167/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2358 - mae: 0.3824 - mape: 67.2192 - val_loss: 0.3029 - val_mae: 0.4409 - val_mape: 76.5606\n",
      "Epoch 168/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2406 - mae: 0.3758 - mape: 64.6670 - val_loss: 0.3010 - val_mae: 0.4402 - val_mape: 76.9867\n",
      "Epoch 169/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3080 - mae: 0.4258 - mape: 64.3315 - val_loss: 0.2995 - val_mae: 0.4396 - val_mape: 77.0149\n",
      "Epoch 170/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2613 - mae: 0.4028 - mape: 62.2268 - val_loss: 0.2980 - val_mae: 0.4388 - val_mape: 76.8669\n",
      "Epoch 171/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3630 - mae: 0.4874 - mape: 85.6481 - val_loss: 0.2964 - val_mae: 0.4381 - val_mape: 76.8256\n",
      "Epoch 172/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3378 - mae: 0.4491 - mape: 79.6644 - val_loss: 0.2952 - val_mae: 0.4374 - val_mape: 76.4209\n",
      "Epoch 173/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2211 - mae: 0.3733 - mape: 63.9241 - val_loss: 0.2941 - val_mae: 0.4367 - val_mape: 76.0733\n",
      "Epoch 174/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2021 - mae: 0.3591 - mape: 78.8472 - val_loss: 0.2929 - val_mae: 0.4361 - val_mape: 76.2114\n",
      "Epoch 175/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2172 - mae: 0.3848 - mape: 65.9556 - val_loss: 0.2919 - val_mae: 0.4355 - val_mape: 76.1651\n",
      "Epoch 176/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3514 - mae: 0.4646 - mape: 82.8568 - val_loss: 0.2907 - val_mae: 0.4350 - val_mape: 76.1867\n",
      "Epoch 177/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1940 - mae: 0.3383 - mape: 77.1880 - val_loss: 0.2892 - val_mae: 0.4343 - val_mape: 76.4044\n",
      "Epoch 178/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2904 - mae: 0.3942 - mape: 82.5063 - val_loss: 0.2872 - val_mae: 0.4336 - val_mape: 77.0845\n",
      "Epoch 179/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2863 - mae: 0.4175 - mape: 91.5192 - val_loss: 0.2851 - val_mae: 0.4329 - val_mape: 78.0091\n",
      "Epoch 180/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2236 - mae: 0.3510 - mape: 65.9327 - val_loss: 0.2827 - val_mae: 0.4321 - val_mape: 79.0579\n",
      "Epoch 181/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2435 - mae: 0.3756 - mape: 71.3604 - val_loss: 0.2807 - val_mae: 0.4314 - val_mape: 79.9803\n",
      "Epoch 182/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2280 - mae: 0.3865 - mape: 75.7404 - val_loss: 0.2788 - val_mae: 0.4306 - val_mape: 80.6252\n",
      "Epoch 183/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2864 - mae: 0.4077 - mape: 67.1726 - val_loss: 0.2768 - val_mae: 0.4298 - val_mape: 81.3208\n",
      "Epoch 184/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2694 - mae: 0.4052 - mape: 64.7329 - val_loss: 0.2752 - val_mae: 0.4291 - val_mape: 81.7354\n",
      "Epoch 185/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2480 - mae: 0.3631 - mape: 63.0254 - val_loss: 0.2736 - val_mae: 0.4284 - val_mape: 82.3338\n",
      "Epoch 186/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2836 - mae: 0.4098 - mape: 79.9792 - val_loss: 0.2720 - val_mae: 0.4277 - val_mape: 83.0081\n",
      "Epoch 187/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2318 - mae: 0.3717 - mape: 85.2977 - val_loss: 0.2708 - val_mae: 0.4271 - val_mape: 83.3100\n",
      "Epoch 188/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2867 - mae: 0.4121 - mape: 66.5984 - val_loss: 0.2695 - val_mae: 0.4264 - val_mape: 83.7247\n",
      "Epoch 189/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2479 - mae: 0.3927 - mape: 73.1985 - val_loss: 0.2683 - val_mae: 0.4257 - val_mape: 83.9045\n",
      "Epoch 190/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2937 - mae: 0.4158 - mape: 70.3151 - val_loss: 0.2672 - val_mae: 0.4250 - val_mape: 83.9096\n",
      "Epoch 191/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2320 - mae: 0.3791 - mape: 75.3486 - val_loss: 0.2660 - val_mae: 0.4243 - val_mape: 83.9315\n",
      "Epoch 192/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2408 - mae: 0.3852 - mape: 71.4781 - val_loss: 0.2647 - val_mae: 0.4236 - val_mape: 84.0010\n",
      "Epoch 193/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1322 - mae: 0.2828 - mape: 60.3804 - val_loss: 0.2635 - val_mae: 0.4228 - val_mape: 83.8190\n",
      "Epoch 194/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2884 - mae: 0.4155 - mape: 77.5423 - val_loss: 0.2623 - val_mae: 0.4220 - val_mape: 83.6391\n",
      "Epoch 195/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2880 - mae: 0.4134 - mape: 68.1878 - val_loss: 0.2612 - val_mae: 0.4212 - val_mape: 83.5860\n",
      "Epoch 196/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2404 - mae: 0.3765 - mape: 78.9343 - val_loss: 0.2599 - val_mae: 0.4204 - val_mape: 83.7503\n",
      "Epoch 197/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1766 - mae: 0.3268 - mape: 66.5507 - val_loss: 0.2586 - val_mae: 0.4195 - val_mape: 83.8273\n",
      "Epoch 198/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2225 - mae: 0.3673 - mape: 68.0201 - val_loss: 0.2574 - val_mae: 0.4186 - val_mape: 83.7160\n",
      "Epoch 199/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2434 - mae: 0.3804 - mape: 93.8174 - val_loss: 0.2560 - val_mae: 0.4176 - val_mape: 83.3118\n",
      "Epoch 200/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3146 - mae: 0.4365 - mape: 70.2672 - val_loss: 0.2548 - val_mae: 0.4165 - val_mape: 82.7177\n",
      "Epoch 201/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2833 - mae: 0.4034 - mape: 79.3625 - val_loss: 0.2537 - val_mae: 0.4154 - val_mape: 82.0579\n",
      "Epoch 202/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3345 - mae: 0.4176 - mape: 64.7283 - val_loss: 0.2527 - val_mae: 0.4142 - val_mape: 81.0838\n",
      "Epoch 203/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1953 - mae: 0.3198 - mape: 65.4780 - val_loss: 0.2517 - val_mae: 0.4130 - val_mape: 80.2407\n",
      "Epoch 204/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3072 - mae: 0.4359 - mape: 80.2009 - val_loss: 0.2506 - val_mae: 0.4117 - val_mape: 79.3233\n",
      "Epoch 205/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2725 - mae: 0.3939 - mape: 58.8379 - val_loss: 0.2495 - val_mae: 0.4103 - val_mape: 78.4809\n",
      "Epoch 206/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1999 - mae: 0.3169 - mape: 60.7543 - val_loss: 0.2483 - val_mae: 0.4090 - val_mape: 77.9161\n",
      "Epoch 207/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2344 - mae: 0.3560 - mape: 58.7314 - val_loss: 0.2473 - val_mae: 0.4080 - val_mape: 77.6491\n",
      "Epoch 208/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.2675 - mae: 0.4056 - mape: 75.5740 - val_loss: 0.2461 - val_mae: 0.4070 - val_mape: 77.4238\n",
      "Epoch 209/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1582 - mae: 0.2878 - mape: 45.8962 - val_loss: 0.2451 - val_mae: 0.4061 - val_mape: 77.3495\n",
      "Epoch 210/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2297 - mae: 0.3697 - mape: 91.2572 - val_loss: 0.2440 - val_mae: 0.4052 - val_mape: 77.3144\n",
      "Epoch 211/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2041 - mae: 0.3432 - mape: 88.3452 - val_loss: 0.2426 - val_mae: 0.4041 - val_mape: 77.0627\n",
      "Epoch 212/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2153 - mae: 0.3354 - mape: 51.0039 - val_loss: 0.2411 - val_mae: 0.4030 - val_mape: 77.0346\n",
      "Epoch 213/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1597 - mae: 0.2972 - mape: 50.2263 - val_loss: 0.2395 - val_mae: 0.4020 - val_mape: 77.0245\n",
      "Epoch 214/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1655 - mae: 0.2994 - mape: 64.9450 - val_loss: 0.2378 - val_mae: 0.4008 - val_mape: 76.8961\n",
      "Epoch 215/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2916 - mae: 0.3965 - mape: 69.9319 - val_loss: 0.2365 - val_mae: 0.4000 - val_mape: 77.0329\n",
      "Epoch 216/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1843 - mae: 0.3442 - mape: 69.4994 - val_loss: 0.2349 - val_mae: 0.3990 - val_mape: 77.0480\n",
      "Epoch 217/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1670 - mae: 0.3040 - mape: 69.6562 - val_loss: 0.2333 - val_mae: 0.3979 - val_mape: 77.0396\n",
      "Epoch 218/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2426 - mae: 0.4085 - mape: 78.9118 - val_loss: 0.2320 - val_mae: 0.3970 - val_mape: 77.0202\n",
      "Epoch 219/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2551 - mae: 0.3646 - mape: 94.0829 - val_loss: 0.2306 - val_mae: 0.3961 - val_mape: 77.1470\n",
      "Epoch 220/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2181 - mae: 0.3383 - mape: 68.1249 - val_loss: 0.2292 - val_mae: 0.3951 - val_mape: 76.9902\n",
      "Epoch 221/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1702 - mae: 0.3113 - mape: 62.6777 - val_loss: 0.2277 - val_mae: 0.3940 - val_mape: 76.9529\n",
      "Epoch 222/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1668 - mae: 0.2970 - mape: 64.9321 - val_loss: 0.2260 - val_mae: 0.3930 - val_mape: 76.9114\n",
      "Epoch 223/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2310 - mae: 0.3286 - mape: 58.9132 - val_loss: 0.2243 - val_mae: 0.3917 - val_mape: 76.5968\n",
      "Epoch 224/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2756 - mae: 0.3898 - mape: 66.2718 - val_loss: 0.2226 - val_mae: 0.3906 - val_mape: 76.4757\n",
      "Epoch 225/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1858 - mae: 0.3422 - mape: 65.8854 - val_loss: 0.2207 - val_mae: 0.3893 - val_mape: 76.2720\n",
      "Epoch 226/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3278 - mae: 0.4166 - mape: 100.6137 - val_loss: 0.2186 - val_mae: 0.3878 - val_mape: 75.7475\n",
      "Epoch 227/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2208 - mae: 0.3371 - mape: 66.1467 - val_loss: 0.2167 - val_mae: 0.3862 - val_mape: 75.0636\n",
      "Epoch 228/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2540 - mae: 0.3889 - mape: 75.0145 - val_loss: 0.2150 - val_mae: 0.3847 - val_mape: 74.5412\n",
      "Epoch 229/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2511 - mae: 0.3867 - mape: 84.9409 - val_loss: 0.2128 - val_mae: 0.3828 - val_mape: 73.8672\n",
      "Epoch 230/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1915 - mae: 0.3144 - mape: 62.2731 - val_loss: 0.2108 - val_mae: 0.3813 - val_mape: 73.6099\n",
      "Epoch 231/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3368 - mae: 0.4504 - mape: 86.0638 - val_loss: 0.2086 - val_mae: 0.3799 - val_mape: 73.8401\n",
      "Epoch 232/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2554 - mae: 0.3912 - mape: 59.9524 - val_loss: 0.2068 - val_mae: 0.3787 - val_mape: 74.0191\n",
      "Epoch 233/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2928 - mae: 0.3981 - mape: 108.2183 - val_loss: 0.2050 - val_mae: 0.3776 - val_mape: 74.6211\n",
      "Epoch 234/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1603 - mae: 0.2896 - mape: 39.2306 - val_loss: 0.2034 - val_mae: 0.3766 - val_mape: 75.2045\n",
      "Epoch 235/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2007 - mae: 0.3346 - mape: 63.2028 - val_loss: 0.2016 - val_mae: 0.3755 - val_mape: 75.6488\n",
      "Epoch 236/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1768 - mae: 0.2988 - mape: 71.4665 - val_loss: 0.1997 - val_mae: 0.3742 - val_mape: 76.1210\n",
      "Epoch 237/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1767 - mae: 0.3141 - mape: 82.9610 - val_loss: 0.1977 - val_mae: 0.3729 - val_mape: 76.2081\n",
      "Epoch 238/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1256 - mae: 0.2717 - mape: 57.9784 - val_loss: 0.1960 - val_mae: 0.3716 - val_mape: 76.2854\n",
      "Epoch 239/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2286 - mae: 0.3498 - mape: 67.5370 - val_loss: 0.1944 - val_mae: 0.3704 - val_mape: 76.3113\n",
      "Epoch 240/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1712 - mae: 0.3094 - mape: 71.0826 - val_loss: 0.1928 - val_mae: 0.3692 - val_mape: 76.4020\n",
      "Epoch 241/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2857 - mae: 0.3670 - mape: 61.4708 - val_loss: 0.1916 - val_mae: 0.3682 - val_mape: 76.3274\n",
      "Epoch 242/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1562 - mae: 0.2995 - mape: 65.9808 - val_loss: 0.1905 - val_mae: 0.3674 - val_mape: 76.3533\n",
      "Epoch 243/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2263 - mae: 0.3283 - mape: 79.6735 - val_loss: 0.1895 - val_mae: 0.3667 - val_mape: 76.4058\n",
      "Epoch 244/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2003 - mae: 0.3027 - mape: 58.7415 - val_loss: 0.1888 - val_mae: 0.3661 - val_mape: 76.4708\n",
      "Epoch 245/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1436 - mae: 0.2554 - mape: 54.1729 - val_loss: 0.1879 - val_mae: 0.3654 - val_mape: 76.3603\n",
      "Epoch 246/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3162 - mae: 0.4265 - mape: 84.9299 - val_loss: 0.1872 - val_mae: 0.3647 - val_mape: 76.1454\n",
      "Epoch 247/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2784 - mae: 0.3968 - mape: 73.1595 - val_loss: 0.1861 - val_mae: 0.3638 - val_mape: 75.9147\n",
      "Epoch 248/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1497 - mae: 0.2915 - mape: 68.3523 - val_loss: 0.1849 - val_mae: 0.3629 - val_mape: 75.5873\n",
      "Epoch 249/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2347 - mae: 0.3610 - mape: 68.7024 - val_loss: 0.1837 - val_mae: 0.3617 - val_mape: 75.1083\n",
      "Epoch 250/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1990 - mae: 0.3367 - mape: 72.0464 - val_loss: 0.1824 - val_mae: 0.3605 - val_mape: 74.4468\n",
      "Epoch 251/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1111 - mae: 0.2591 - mape: 53.0145 - val_loss: 0.1812 - val_mae: 0.3593 - val_mape: 73.7917\n",
      "Epoch 252/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2195 - mae: 0.3318 - mape: 81.0883 - val_loss: 0.1799 - val_mae: 0.3582 - val_mape: 73.5307\n",
      "Epoch 253/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2152 - mae: 0.3546 - mape: 71.8156 - val_loss: 0.1786 - val_mae: 0.3576 - val_mape: 74.1320\n",
      "Epoch 254/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1065 - mae: 0.2317 - mape: 52.3652 - val_loss: 0.1774 - val_mae: 0.3570 - val_mape: 74.8449\n",
      "Epoch 255/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2893 - mae: 0.3778 - mape: 66.0257 - val_loss: 0.1763 - val_mae: 0.3566 - val_mape: 75.5292\n",
      "Epoch 256/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2560 - mae: 0.3586 - mape: 95.6532 - val_loss: 0.1753 - val_mae: 0.3561 - val_mape: 76.1638\n",
      "Epoch 257/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1862 - mae: 0.3035 - mape: 71.0666 - val_loss: 0.1744 - val_mae: 0.3557 - val_mape: 76.8828\n",
      "Epoch 258/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2263 - mae: 0.3641 - mape: 72.8343 - val_loss: 0.1734 - val_mae: 0.3554 - val_mape: 77.7276\n",
      "Epoch 259/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2621 - mae: 0.3826 - mape: 77.4752 - val_loss: 0.1725 - val_mae: 0.3549 - val_mape: 78.3377\n",
      "Epoch 260/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1370 - mae: 0.2663 - mape: 51.5374 - val_loss: 0.1716 - val_mae: 0.3544 - val_mape: 78.8802\n",
      "Epoch 261/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1769 - mae: 0.3262 - mape: 65.6581 - val_loss: 0.1708 - val_mae: 0.3540 - val_mape: 79.4867\n",
      "Epoch 262/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2420 - mae: 0.3586 - mape: 53.7624 - val_loss: 0.1698 - val_mae: 0.3532 - val_mape: 79.6971\n",
      "Epoch 263/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1043 - mae: 0.2667 - mape: 59.8373 - val_loss: 0.1689 - val_mae: 0.3524 - val_mape: 79.9541\n",
      "Epoch 264/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2180 - mae: 0.3339 - mape: 69.4569 - val_loss: 0.1679 - val_mae: 0.3516 - val_mape: 80.0450\n",
      "Epoch 265/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1698 - mae: 0.3024 - mape: 71.0599 - val_loss: 0.1670 - val_mae: 0.3508 - val_mape: 80.0818\n",
      "Epoch 266/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1077 - mae: 0.2537 - mape: 60.4325 - val_loss: 0.1659 - val_mae: 0.3497 - val_mape: 79.9440\n",
      "Epoch 267/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1988 - mae: 0.3493 - mape: 88.2498 - val_loss: 0.1650 - val_mae: 0.3488 - val_mape: 79.8936\n",
      "Epoch 268/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1160 - mae: 0.2516 - mape: 59.6231 - val_loss: 0.1639 - val_mae: 0.3479 - val_mape: 79.8894\n",
      "Epoch 269/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2123 - mae: 0.3591 - mape: 77.1696 - val_loss: 0.1630 - val_mae: 0.3470 - val_mape: 79.9323\n",
      "Epoch 270/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1596 - mae: 0.2832 - mape: 71.3519 - val_loss: 0.1621 - val_mae: 0.3462 - val_mape: 79.9425\n",
      "Epoch 271/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2082 - mae: 0.3032 - mape: 63.6482 - val_loss: 0.1613 - val_mae: 0.3454 - val_mape: 79.8344\n",
      "Epoch 272/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2406 - mae: 0.3693 - mape: 68.4714 - val_loss: 0.1606 - val_mae: 0.3446 - val_mape: 79.7546\n",
      "Epoch 273/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3689 - mae: 0.4623 - mape: 95.1227 - val_loss: 0.1599 - val_mae: 0.3438 - val_mape: 79.4311\n",
      "Epoch 274/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1732 - mae: 0.3109 - mape: 76.2927 - val_loss: 0.1591 - val_mae: 0.3429 - val_mape: 79.0431\n",
      "Epoch 275/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1894 - mae: 0.3196 - mape: 74.5930 - val_loss: 0.1582 - val_mae: 0.3418 - val_mape: 78.5405\n",
      "Epoch 276/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0845 - mae: 0.2171 - mape: 61.0974 - val_loss: 0.1573 - val_mae: 0.3408 - val_mape: 78.2452\n",
      "Epoch 277/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2531 - mae: 0.3562 - mape: 67.9443 - val_loss: 0.1566 - val_mae: 0.3400 - val_mape: 77.8791\n",
      "Epoch 278/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1738 - mae: 0.3042 - mape: 63.8464 - val_loss: 0.1560 - val_mae: 0.3391 - val_mape: 77.4939\n",
      "Epoch 279/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2733 - mae: 0.4010 - mape: 85.6274 - val_loss: 0.1554 - val_mae: 0.3383 - val_mape: 77.2355\n",
      "Epoch 280/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2571 - mae: 0.3578 - mape: 75.5952 - val_loss: 0.1545 - val_mae: 0.3374 - val_mape: 76.8066\n",
      "Epoch 281/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1602 - mae: 0.3147 - mape: 64.5120 - val_loss: 0.1538 - val_mae: 0.3365 - val_mape: 76.4466\n",
      "Epoch 282/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1200 - mae: 0.2517 - mape: 57.2197 - val_loss: 0.1529 - val_mae: 0.3354 - val_mape: 75.9862\n",
      "Epoch 283/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1716 - mae: 0.2935 - mape: 73.9447 - val_loss: 0.1520 - val_mae: 0.3343 - val_mape: 75.3166\n",
      "Epoch 284/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1146 - mae: 0.2174 - mape: 52.7876 - val_loss: 0.1513 - val_mae: 0.3332 - val_mape: 74.7100\n",
      "Epoch 285/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1229 - mae: 0.2604 - mape: 52.4423 - val_loss: 0.1506 - val_mae: 0.3322 - val_mape: 74.2102\n",
      "Epoch 286/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.2075 - mae: 0.3369 - mape: 70.0821 - val_loss: 0.1501 - val_mae: 0.3315 - val_mape: 73.9392\n",
      "Epoch 287/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1852 - mae: 0.3293 - mape: 82.5593 - val_loss: 0.1496 - val_mae: 0.3309 - val_mape: 73.9664\n",
      "Epoch 288/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2843 - mae: 0.4159 - mape: 87.5075 - val_loss: 0.1492 - val_mae: 0.3302 - val_mape: 73.7124\n",
      "Epoch 289/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2268 - mae: 0.3593 - mape: 72.1183 - val_loss: 0.1487 - val_mae: 0.3297 - val_mape: 74.0357\n",
      "Epoch 290/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2272 - mae: 0.3412 - mape: 80.9657 - val_loss: 0.1481 - val_mae: 0.3292 - val_mape: 74.6627\n",
      "Epoch 291/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3103 - mae: 0.4297 - mape: 69.8427 - val_loss: 0.1473 - val_mae: 0.3286 - val_mape: 75.3893\n",
      "Epoch 292/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0908 - mae: 0.2352 - mape: 56.6936 - val_loss: 0.1464 - val_mae: 0.3279 - val_mape: 76.0020\n",
      "Epoch 293/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2869 - mae: 0.3664 - mape: 83.5100 - val_loss: 0.1455 - val_mae: 0.3272 - val_mape: 76.7446\n",
      "Epoch 294/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2426 - mae: 0.3643 - mape: 73.3083 - val_loss: 0.1448 - val_mae: 0.3266 - val_mape: 77.3058\n",
      "Epoch 295/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2489 - mae: 0.3400 - mape: 93.4623 - val_loss: 0.1440 - val_mae: 0.3258 - val_mape: 77.5588\n",
      "Epoch 296/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1638 - mae: 0.3124 - mape: 76.3154 - val_loss: 0.1432 - val_mae: 0.3250 - val_mape: 77.6813\n",
      "Epoch 297/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1725 - mae: 0.3042 - mape: 72.0034 - val_loss: 0.1425 - val_mae: 0.3241 - val_mape: 77.6788\n",
      "Epoch 298/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1762 - mae: 0.2787 - mape: 69.4404 - val_loss: 0.1418 - val_mae: 0.3232 - val_mape: 77.5990\n",
      "Epoch 299/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1789 - mae: 0.2987 - mape: 79.5537 - val_loss: 0.1411 - val_mae: 0.3224 - val_mape: 77.5311\n",
      "Epoch 300/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1420 - mae: 0.2655 - mape: 66.8856 - val_loss: 0.1403 - val_mae: 0.3215 - val_mape: 77.4779\n",
      "Epoch 301/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0977 - mae: 0.2184 - mape: 60.0135 - val_loss: 0.1394 - val_mae: 0.3206 - val_mape: 77.4647\n",
      "Epoch 302/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2059 - mae: 0.3170 - mape: 76.0575 - val_loss: 0.1385 - val_mae: 0.3197 - val_mape: 77.4798\n",
      "Epoch 303/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2320 - mae: 0.3499 - mape: 62.1219 - val_loss: 0.1380 - val_mae: 0.3191 - val_mape: 77.4890\n",
      "Epoch 304/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0803 - mae: 0.2272 - mape: 70.7547 - val_loss: 0.1375 - val_mae: 0.3185 - val_mape: 77.4317\n",
      "Epoch 305/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1921 - mae: 0.2880 - mape: 67.6279 - val_loss: 0.1372 - val_mae: 0.3181 - val_mape: 77.5007\n",
      "Epoch 306/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1312 - mae: 0.2796 - mape: 71.1824 - val_loss: 0.1370 - val_mae: 0.3176 - val_mape: 77.5463\n",
      "Epoch 307/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1329 - mae: 0.2673 - mape: 69.5524 - val_loss: 0.1368 - val_mae: 0.3172 - val_mape: 77.4741\n",
      "Epoch 308/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1048 - mae: 0.2223 - mape: 43.6893 - val_loss: 0.1364 - val_mae: 0.3167 - val_mape: 77.5697\n",
      "Epoch 309/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1635 - mae: 0.2682 - mape: 72.8454 - val_loss: 0.1359 - val_mae: 0.3161 - val_mape: 77.7041\n",
      "Epoch 310/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1210 - mae: 0.2429 - mape: 75.3157 - val_loss: 0.1355 - val_mae: 0.3155 - val_mape: 77.7963\n",
      "Epoch 311/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1294 - mae: 0.2532 - mape: 57.1735 - val_loss: 0.1350 - val_mae: 0.3149 - val_mape: 78.0659\n",
      "Epoch 312/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1425 - mae: 0.2695 - mape: 61.7335 - val_loss: 0.1346 - val_mae: 0.3144 - val_mape: 78.2727\n",
      "Epoch 313/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1563 - mae: 0.2629 - mape: 53.0850 - val_loss: 0.1342 - val_mae: 0.3138 - val_mape: 78.4751\n",
      "Epoch 314/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1776 - mae: 0.3306 - mape: 76.4721 - val_loss: 0.1338 - val_mae: 0.3133 - val_mape: 78.7015\n",
      "Epoch 315/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1091 - mae: 0.2536 - mape: 76.5204 - val_loss: 0.1332 - val_mae: 0.3127 - val_mape: 79.0312\n",
      "Epoch 316/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0777 - mae: 0.2059 - mape: 52.6270 - val_loss: 0.1326 - val_mae: 0.3121 - val_mape: 79.2832\n",
      "Epoch 317/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2119 - mae: 0.2972 - mape: 71.8351 - val_loss: 0.1317 - val_mae: 0.3113 - val_mape: 79.5491\n",
      "Epoch 318/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2995 - mae: 0.3708 - mape: 74.2024 - val_loss: 0.1309 - val_mae: 0.3106 - val_mape: 79.7040\n",
      "Epoch 319/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0779 - mae: 0.2138 - mape: 54.1305 - val_loss: 0.1303 - val_mae: 0.3100 - val_mape: 79.7470\n",
      "Epoch 320/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3351 - mae: 0.4304 - mape: 104.0232 - val_loss: 0.1297 - val_mae: 0.3094 - val_mape: 79.8420\n",
      "Epoch 321/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1833 - mae: 0.3164 - mape: 57.2252 - val_loss: 0.1294 - val_mae: 0.3089 - val_mape: 79.7343\n",
      "Epoch 322/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2159 - mae: 0.2975 - mape: 74.3463 - val_loss: 0.1288 - val_mae: 0.3083 - val_mape: 79.7902\n",
      "Epoch 323/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1428 - mae: 0.2601 - mape: 59.7092 - val_loss: 0.1285 - val_mae: 0.3078 - val_mape: 79.5880\n",
      "Epoch 324/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1223 - mae: 0.2491 - mape: 68.1807 - val_loss: 0.1279 - val_mae: 0.3071 - val_mape: 79.4538\n",
      "Epoch 325/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1605 - mae: 0.2660 - mape: 57.9797 - val_loss: 0.1276 - val_mae: 0.3065 - val_mape: 79.4626\n",
      "Epoch 326/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0867 - mae: 0.2095 - mape: 62.4387 - val_loss: 0.1271 - val_mae: 0.3059 - val_mape: 79.3212\n",
      "Epoch 327/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1603 - mae: 0.3017 - mape: 61.8756 - val_loss: 0.1265 - val_mae: 0.3052 - val_mape: 79.2646\n",
      "Epoch 328/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1405 - mae: 0.2930 - mape: 91.8447 - val_loss: 0.1260 - val_mae: 0.3044 - val_mape: 79.1672\n",
      "Epoch 329/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1304 - mae: 0.2476 - mape: 69.1666 - val_loss: 0.1253 - val_mae: 0.3035 - val_mape: 78.9797\n",
      "Epoch 330/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0629 - mae: 0.2083 - mape: 54.2370 - val_loss: 0.1246 - val_mae: 0.3026 - val_mape: 78.9182\n",
      "Epoch 331/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2074 - mae: 0.3213 - mape: 73.1697 - val_loss: 0.1239 - val_mae: 0.3019 - val_mape: 78.8667\n",
      "Epoch 332/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2064 - mae: 0.2911 - mape: 103.0969 - val_loss: 0.1232 - val_mae: 0.3011 - val_mape: 79.0233\n",
      "Epoch 333/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2818 - mae: 0.3881 - mape: 73.5148 - val_loss: 0.1226 - val_mae: 0.3006 - val_mape: 79.4316\n",
      "Epoch 334/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1479 - mae: 0.2595 - mape: 54.4867 - val_loss: 0.1218 - val_mae: 0.3000 - val_mape: 79.5843\n",
      "Epoch 335/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1001 - mae: 0.2321 - mape: 63.8889 - val_loss: 0.1211 - val_mae: 0.2993 - val_mape: 79.6912\n",
      "Epoch 336/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1828 - mae: 0.3191 - mape: 78.1396 - val_loss: 0.1206 - val_mae: 0.2988 - val_mape: 79.7661\n",
      "Epoch 337/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1580 - mae: 0.2870 - mape: 76.1472 - val_loss: 0.1203 - val_mae: 0.2985 - val_mape: 79.7499\n",
      "Epoch 338/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0944 - mae: 0.2238 - mape: 50.8734 - val_loss: 0.1202 - val_mae: 0.2983 - val_mape: 79.8548\n",
      "Epoch 339/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0981 - mae: 0.2110 - mape: 64.7688 - val_loss: 0.1200 - val_mae: 0.2979 - val_mape: 79.7960\n",
      "Epoch 340/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2448 - mae: 0.3281 - mape: 58.1578 - val_loss: 0.1199 - val_mae: 0.2976 - val_mape: 79.7076\n",
      "Epoch 341/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2807 - mae: 0.3857 - mape: 99.5837 - val_loss: 0.1197 - val_mae: 0.2974 - val_mape: 79.7442\n",
      "Epoch 342/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1591 - mae: 0.2924 - mape: 99.3174 - val_loss: 0.1194 - val_mae: 0.2970 - val_mape: 79.6226\n",
      "Epoch 343/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2061 - mae: 0.3521 - mape: 61.9931 - val_loss: 0.1190 - val_mae: 0.2965 - val_mape: 79.5962\n",
      "Epoch 344/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1978 - mae: 0.3423 - mape: 80.1129 - val_loss: 0.1186 - val_mae: 0.2960 - val_mape: 79.6524\n",
      "Epoch 345/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0642 - mae: 0.1774 - mape: 62.9938 - val_loss: 0.1183 - val_mae: 0.2955 - val_mape: 79.6441\n",
      "Epoch 346/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1930 - mae: 0.2941 - mape: 48.8689 - val_loss: 0.1179 - val_mae: 0.2950 - val_mape: 79.6204\n",
      "Epoch 347/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1659 - mae: 0.2742 - mape: 79.8441 - val_loss: 0.1176 - val_mae: 0.2944 - val_mape: 79.3795\n",
      "Epoch 348/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0952 - mae: 0.2378 - mape: 59.8701 - val_loss: 0.1173 - val_mae: 0.2938 - val_mape: 79.1817\n",
      "Epoch 349/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1025 - mae: 0.2136 - mape: 51.3715 - val_loss: 0.1170 - val_mae: 0.2932 - val_mape: 78.8594\n",
      "Epoch 350/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2189 - mae: 0.3197 - mape: 76.1200 - val_loss: 0.1166 - val_mae: 0.2925 - val_mape: 78.6421\n",
      "Epoch 351/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1982 - mae: 0.3150 - mape: 64.0822 - val_loss: 0.1163 - val_mae: 0.2918 - val_mape: 78.2211\n",
      "Epoch 352/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1861 - mae: 0.2928 - mape: 82.6001 - val_loss: 0.1162 - val_mae: 0.2913 - val_mape: 77.6809\n",
      "Epoch 353/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1720 - mae: 0.2891 - mape: 69.2110 - val_loss: 0.1160 - val_mae: 0.2908 - val_mape: 77.4772\n",
      "Epoch 354/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1110 - mae: 0.2456 - mape: 64.3077 - val_loss: 0.1156 - val_mae: 0.2903 - val_mape: 77.3004\n",
      "Epoch 355/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0626 - mae: 0.1852 - mape: 54.1072 - val_loss: 0.1154 - val_mae: 0.2898 - val_mape: 77.0077\n",
      "Epoch 356/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1880 - mae: 0.3280 - mape: 76.6113 - val_loss: 0.1151 - val_mae: 0.2893 - val_mape: 76.9396\n",
      "Epoch 357/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1182 - mae: 0.2270 - mape: 65.0490 - val_loss: 0.1149 - val_mae: 0.2890 - val_mape: 77.0696\n",
      "Epoch 358/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1824 - mae: 0.3072 - mape: 86.2179 - val_loss: 0.1148 - val_mae: 0.2887 - val_mape: 77.2098\n",
      "Epoch 359/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.2057 - mae: 0.3202 - mape: 75.2460 - val_loss: 0.1147 - val_mae: 0.2884 - val_mape: 76.9890\n",
      "Epoch 360/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2358 - mae: 0.3087 - mape: 80.5561 - val_loss: 0.1145 - val_mae: 0.2879 - val_mape: 76.7656\n",
      "Epoch 361/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1453 - mae: 0.2763 - mape: 60.2220 - val_loss: 0.1143 - val_mae: 0.2874 - val_mape: 76.5097\n",
      "Epoch 362/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2630 - mae: 0.3476 - mape: 67.5772 - val_loss: 0.1143 - val_mae: 0.2872 - val_mape: 76.3267\n",
      "Epoch 363/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0933 - mae: 0.2041 - mape: 53.9261 - val_loss: 0.1144 - val_mae: 0.2870 - val_mape: 76.2612\n",
      "Epoch 364/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1221 - mae: 0.2476 - mape: 53.8515 - val_loss: 0.1143 - val_mae: 0.2867 - val_mape: 76.1822\n",
      "Epoch 365/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1127 - mae: 0.2258 - mape: 71.2675 - val_loss: 0.1143 - val_mae: 0.2864 - val_mape: 75.9504\n",
      "Epoch 366/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1058 - mae: 0.2565 - mape: 73.3021 - val_loss: 0.1143 - val_mae: 0.2860 - val_mape: 75.7578\n",
      "Epoch 367/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1072 - mae: 0.2190 - mape: 44.0237 - val_loss: 0.1143 - val_mae: 0.2855 - val_mape: 75.2646\n",
      "Epoch 368/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2572 - mae: 0.3379 - mape: 82.4284 - val_loss: 0.1140 - val_mae: 0.2850 - val_mape: 75.3584\n",
      "Epoch 369/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0768 - mae: 0.1990 - mape: 70.7158 - val_loss: 0.1137 - val_mae: 0.2845 - val_mape: 75.3527\n",
      "Epoch 370/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1320 - mae: 0.2521 - mape: 74.6680 - val_loss: 0.1132 - val_mae: 0.2840 - val_mape: 75.5408\n",
      "Epoch 371/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1295 - mae: 0.2607 - mape: 47.6110 - val_loss: 0.1127 - val_mae: 0.2835 - val_mape: 75.8955\n",
      "Epoch 372/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1499 - mae: 0.2747 - mape: 61.2840 - val_loss: 0.1124 - val_mae: 0.2830 - val_mape: 76.0200\n",
      "Epoch 373/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1851 - mae: 0.2841 - mape: 94.5204 - val_loss: 0.1122 - val_mae: 0.2827 - val_mape: 76.0999\n",
      "Epoch 374/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0678 - mae: 0.1886 - mape: 54.1441 - val_loss: 0.1119 - val_mae: 0.2823 - val_mape: 76.0701\n",
      "Epoch 375/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1758 - mae: 0.3136 - mape: 96.3543 - val_loss: 0.1114 - val_mae: 0.2816 - val_mape: 76.1749\n",
      "Epoch 376/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1226 - mae: 0.2510 - mape: 67.4498 - val_loss: 0.1106 - val_mae: 0.2808 - val_mape: 76.2063\n",
      "Epoch 377/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1495 - mae: 0.2584 - mape: 51.4589 - val_loss: 0.1100 - val_mae: 0.2800 - val_mape: 76.2076\n",
      "Epoch 378/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2172 - mae: 0.2961 - mape: 67.3797 - val_loss: 0.1092 - val_mae: 0.2793 - val_mape: 76.5018\n",
      "Epoch 379/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1080 - mae: 0.2367 - mape: 75.0580 - val_loss: 0.1084 - val_mae: 0.2786 - val_mape: 77.1484\n",
      "Epoch 380/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2187 - mae: 0.3211 - mape: 96.6692 - val_loss: 0.1073 - val_mae: 0.2779 - val_mape: 78.0330\n",
      "Epoch 381/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0619 - mae: 0.1864 - mape: 56.5024 - val_loss: 0.1063 - val_mae: 0.2772 - val_mape: 78.8343\n",
      "Epoch 382/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1750 - mae: 0.2789 - mape: 70.7825 - val_loss: 0.1055 - val_mae: 0.2764 - val_mape: 79.2582\n",
      "Epoch 383/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1224 - mae: 0.2388 - mape: 46.7198 - val_loss: 0.1046 - val_mae: 0.2757 - val_mape: 79.7065\n",
      "Epoch 384/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1275 - mae: 0.2478 - mape: 75.3970 - val_loss: 0.1040 - val_mae: 0.2750 - val_mape: 79.8887\n",
      "Epoch 385/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0602 - mae: 0.1685 - mape: 42.2810 - val_loss: 0.1032 - val_mae: 0.2741 - val_mape: 80.0537\n",
      "Epoch 386/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1461 - mae: 0.2463 - mape: 97.4102 - val_loss: 0.1024 - val_mae: 0.2733 - val_mape: 80.2039\n",
      "Epoch 387/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2506 - mae: 0.3535 - mape: 80.3873 - val_loss: 0.1017 - val_mae: 0.2726 - val_mape: 80.2923\n",
      "Epoch 388/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.2777 - mae: 0.3635 - mape: 76.6527 - val_loss: 0.1012 - val_mae: 0.2721 - val_mape: 80.6923\n",
      "Epoch 389/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0823 - mae: 0.2067 - mape: 61.1025 - val_loss: 0.1006 - val_mae: 0.2716 - val_mape: 81.0813\n",
      "Epoch 390/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0467 - mae: 0.1545 - mape: 51.3681 - val_loss: 0.1000 - val_mae: 0.2711 - val_mape: 81.4247\n",
      "Epoch 391/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2671 - mae: 0.3827 - mape: 105.3004 - val_loss: 0.0995 - val_mae: 0.2706 - val_mape: 81.7100\n",
      "Epoch 392/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0993 - mae: 0.2052 - mape: 52.6683 - val_loss: 0.0991 - val_mae: 0.2701 - val_mape: 81.6825\n",
      "Epoch 393/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.1582 - mae: 0.3148 - mape: 101.0765 - val_loss: 0.0988 - val_mae: 0.2696 - val_mape: 81.4863\n",
      "Epoch 394/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.2452 - mae: 0.3532 - mape: 72.4219 - val_loss: 0.0982 - val_mae: 0.2688 - val_mape: 81.4964\n",
      "Epoch 395/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1080 - mae: 0.2131 - mape: 67.5724 - val_loss: 0.0976 - val_mae: 0.2680 - val_mape: 81.1314\n",
      "Epoch 396/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1929 - mae: 0.2903 - mape: 51.8412 - val_loss: 0.0972 - val_mae: 0.2673 - val_mape: 80.6302\n",
      "Epoch 397/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1916 - mae: 0.2846 - mape: 57.1786 - val_loss: 0.0970 - val_mae: 0.2667 - val_mape: 80.1228\n",
      "Epoch 398/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0891 - mae: 0.2062 - mape: 55.6823 - val_loss: 0.0968 - val_mae: 0.2661 - val_mape: 79.6496\n",
      "Epoch 399/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1933 - mae: 0.3013 - mape: 61.7904 - val_loss: 0.0966 - val_mae: 0.2658 - val_mape: 79.3574\n",
      "Epoch 400/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0815 - mae: 0.1881 - mape: 62.8745 - val_loss: 0.0965 - val_mae: 0.2654 - val_mape: 79.1288\n",
      "Epoch 401/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1267 - mae: 0.2592 - mape: 59.4891 - val_loss: 0.0963 - val_mae: 0.2651 - val_mape: 79.1555\n",
      "Epoch 402/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0721 - mae: 0.1958 - mape: 60.9604 - val_loss: 0.0961 - val_mae: 0.2647 - val_mape: 79.0221\n",
      "Epoch 403/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1080 - mae: 0.2126 - mape: 49.0199 - val_loss: 0.0958 - val_mae: 0.2642 - val_mape: 78.9474\n",
      "Epoch 404/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0971 - mae: 0.2232 - mape: 58.6195 - val_loss: 0.0955 - val_mae: 0.2638 - val_mape: 79.0545\n",
      "Epoch 405/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1442 - mae: 0.2764 - mape: 67.1993 - val_loss: 0.0952 - val_mae: 0.2634 - val_mape: 79.2745\n",
      "Epoch 406/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1647 - mae: 0.2916 - mape: 70.4784 - val_loss: 0.0949 - val_mae: 0.2631 - val_mape: 79.5348\n",
      "Epoch 407/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1464 - mae: 0.2861 - mape: 71.5424 - val_loss: 0.0945 - val_mae: 0.2627 - val_mape: 79.7990\n",
      "Epoch 408/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0511 - mae: 0.1631 - mape: 35.3244 - val_loss: 0.0942 - val_mae: 0.2622 - val_mape: 80.0195\n",
      "Epoch 409/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0783 - mae: 0.1951 - mape: 56.8331 - val_loss: 0.0939 - val_mae: 0.2617 - val_mape: 80.0298\n",
      "Epoch 410/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2222 - mae: 0.3199 - mape: 94.2724 - val_loss: 0.0939 - val_mae: 0.2614 - val_mape: 79.7864\n",
      "Epoch 411/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1627 - mae: 0.2382 - mape: 56.2368 - val_loss: 0.0940 - val_mae: 0.2610 - val_mape: 79.2208\n",
      "Epoch 412/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1439 - mae: 0.2527 - mape: 57.2122 - val_loss: 0.0940 - val_mae: 0.2604 - val_mape: 78.4590\n",
      "Epoch 413/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1112 - mae: 0.2284 - mape: 46.3543 - val_loss: 0.0940 - val_mae: 0.2598 - val_mape: 77.5652\n",
      "Epoch 414/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1435 - mae: 0.2718 - mape: 58.7078 - val_loss: 0.0941 - val_mae: 0.2593 - val_mape: 76.5929\n",
      "Epoch 415/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1788 - mae: 0.2824 - mape: 80.4116 - val_loss: 0.0941 - val_mae: 0.2587 - val_mape: 75.8745\n",
      "Epoch 416/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2259 - mae: 0.3107 - mape: 90.8179 - val_loss: 0.0941 - val_mae: 0.2580 - val_mape: 74.9128\n",
      "Epoch 417/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1006 - mae: 0.2127 - mape: 63.6057 - val_loss: 0.0940 - val_mae: 0.2572 - val_mape: 73.8690\n",
      "Epoch 418/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1336 - mae: 0.2543 - mape: 63.7797 - val_loss: 0.0937 - val_mae: 0.2562 - val_mape: 72.9885\n",
      "Epoch 419/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0628 - mae: 0.1682 - mape: 49.0849 - val_loss: 0.0935 - val_mae: 0.2553 - val_mape: 72.0914\n",
      "Epoch 420/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0872 - mae: 0.2074 - mape: 71.2810 - val_loss: 0.0933 - val_mae: 0.2543 - val_mape: 71.1142\n",
      "Epoch 421/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1229 - mae: 0.2293 - mape: 65.6708 - val_loss: 0.0929 - val_mae: 0.2533 - val_mape: 70.2443\n",
      "Epoch 422/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1832 - mae: 0.3141 - mape: 84.3992 - val_loss: 0.0927 - val_mae: 0.2525 - val_mape: 69.5072\n",
      "Epoch 423/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0755 - mae: 0.1806 - mape: 62.2295 - val_loss: 0.0924 - val_mae: 0.2518 - val_mape: 68.9090\n",
      "Epoch 424/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1605 - mae: 0.2569 - mape: 73.5631 - val_loss: 0.0922 - val_mae: 0.2510 - val_mape: 68.2217\n",
      "Epoch 425/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1021 - mae: 0.2056 - mape: 56.5727 - val_loss: 0.0919 - val_mae: 0.2503 - val_mape: 67.6608\n",
      "Epoch 426/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0515 - mae: 0.1721 - mape: 62.2361 - val_loss: 0.0917 - val_mae: 0.2496 - val_mape: 67.0792\n",
      "Epoch 427/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0739 - mae: 0.1780 - mape: 63.8623 - val_loss: 0.0916 - val_mae: 0.2489 - val_mape: 66.2664\n",
      "Epoch 428/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1044 - mae: 0.2138 - mape: 55.3270 - val_loss: 0.0915 - val_mae: 0.2482 - val_mape: 65.5660\n",
      "Epoch 429/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1186 - mae: 0.2423 - mape: 65.0212 - val_loss: 0.0914 - val_mae: 0.2476 - val_mape: 64.9815\n",
      "Epoch 430/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1282 - mae: 0.2299 - mape: 54.4415 - val_loss: 0.0911 - val_mae: 0.2469 - val_mape: 64.6309\n",
      "Epoch 431/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1329 - mae: 0.2277 - mape: 63.5669 - val_loss: 0.0909 - val_mae: 0.2464 - val_mape: 64.2823\n",
      "Epoch 432/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0513 - mae: 0.1629 - mape: 45.8207 - val_loss: 0.0908 - val_mae: 0.2459 - val_mape: 63.9283\n",
      "Epoch 433/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0996 - mae: 0.2354 - mape: 50.8863 - val_loss: 0.0905 - val_mae: 0.2452 - val_mape: 63.6482\n",
      "Epoch 434/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0932 - mae: 0.2078 - mape: 75.0934 - val_loss: 0.0903 - val_mae: 0.2445 - val_mape: 63.0820\n",
      "Epoch 435/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2137 - mae: 0.2964 - mape: 67.2164 - val_loss: 0.0902 - val_mae: 0.2439 - val_mape: 62.6426\n",
      "Epoch 436/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0773 - mae: 0.2151 - mape: 69.6213 - val_loss: 0.0901 - val_mae: 0.2433 - val_mape: 62.1122\n",
      "Epoch 437/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0865 - mae: 0.2011 - mape: 70.4452 - val_loss: 0.0900 - val_mae: 0.2426 - val_mape: 61.5099\n",
      "Epoch 438/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1199 - mae: 0.2282 - mape: 59.9446 - val_loss: 0.0899 - val_mae: 0.2419 - val_mape: 60.9048\n",
      "Epoch 439/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1300 - mae: 0.2289 - mape: 71.3123 - val_loss: 0.0898 - val_mae: 0.2412 - val_mape: 60.4248\n",
      "Epoch 440/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1247 - mae: 0.2299 - mape: 69.2706 - val_loss: 0.0895 - val_mae: 0.2406 - val_mape: 60.2104\n",
      "Epoch 441/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1756 - mae: 0.3183 - mape: 69.7103 - val_loss: 0.0890 - val_mae: 0.2398 - val_mape: 60.3000\n",
      "Epoch 442/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1204 - mae: 0.2476 - mape: 48.4171 - val_loss: 0.0884 - val_mae: 0.2391 - val_mape: 60.5096\n",
      "Epoch 443/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0957 - mae: 0.2197 - mape: 48.3096 - val_loss: 0.0880 - val_mae: 0.2385 - val_mape: 60.6314\n",
      "Epoch 444/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0834 - mae: 0.1764 - mape: 55.5935 - val_loss: 0.0873 - val_mae: 0.2379 - val_mape: 61.0599\n",
      "Epoch 445/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0947 - mae: 0.2236 - mape: 61.9879 - val_loss: 0.0869 - val_mae: 0.2375 - val_mape: 61.4769\n",
      "Epoch 446/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1041 - mae: 0.2116 - mape: 61.3978 - val_loss: 0.0865 - val_mae: 0.2371 - val_mape: 61.9002\n",
      "Epoch 447/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0585 - mae: 0.1658 - mape: 50.9224 - val_loss: 0.0860 - val_mae: 0.2367 - val_mape: 62.3463\n",
      "Epoch 448/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2349 - mae: 0.3179 - mape: 84.8678 - val_loss: 0.0854 - val_mae: 0.2362 - val_mape: 62.8768\n",
      "Epoch 449/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1289 - mae: 0.2439 - mape: 64.1426 - val_loss: 0.0847 - val_mae: 0.2358 - val_mape: 63.4364\n",
      "Epoch 450/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2072 - mae: 0.2927 - mape: 50.8539 - val_loss: 0.0843 - val_mae: 0.2355 - val_mape: 64.0124\n",
      "Epoch 451/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0947 - mae: 0.2272 - mape: 60.4373 - val_loss: 0.0837 - val_mae: 0.2352 - val_mape: 64.7274\n",
      "Epoch 452/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1081 - mae: 0.2323 - mape: 60.1556 - val_loss: 0.0831 - val_mae: 0.2348 - val_mape: 65.5013\n",
      "Epoch 453/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0707 - mae: 0.1827 - mape: 62.1134 - val_loss: 0.0826 - val_mae: 0.2344 - val_mape: 66.0592\n",
      "Epoch 454/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1151 - mae: 0.2361 - mape: 68.1561 - val_loss: 0.0821 - val_mae: 0.2341 - val_mape: 66.6459\n",
      "Epoch 455/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0944 - mae: 0.2067 - mape: 60.3520 - val_loss: 0.0816 - val_mae: 0.2337 - val_mape: 67.2209\n",
      "Epoch 456/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1181 - mae: 0.2585 - mape: 68.8372 - val_loss: 0.0811 - val_mae: 0.2333 - val_mape: 67.8741\n",
      "Epoch 457/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0478 - mae: 0.1554 - mape: 45.2785 - val_loss: 0.0808 - val_mae: 0.2330 - val_mape: 68.2941\n",
      "Epoch 458/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1440 - mae: 0.2202 - mape: 46.0058 - val_loss: 0.0806 - val_mae: 0.2327 - val_mape: 68.3611\n",
      "Epoch 459/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0594 - mae: 0.1763 - mape: 44.2995 - val_loss: 0.0806 - val_mae: 0.2324 - val_mape: 68.3003\n",
      "Epoch 460/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0843 - mae: 0.1808 - mape: 40.4878 - val_loss: 0.0808 - val_mae: 0.2322 - val_mape: 68.0298\n",
      "Epoch 461/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1198 - mae: 0.2216 - mape: 54.9575 - val_loss: 0.0807 - val_mae: 0.2319 - val_mape: 68.0013\n",
      "Epoch 462/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0658 - mae: 0.1694 - mape: 68.9050 - val_loss: 0.0805 - val_mae: 0.2316 - val_mape: 68.0383\n",
      "Epoch 463/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0872 - mae: 0.2207 - mape: 56.4294 - val_loss: 0.0804 - val_mae: 0.2312 - val_mape: 67.8897\n",
      "Epoch 464/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1569 - mae: 0.2163 - mape: 44.0006 - val_loss: 0.0804 - val_mae: 0.2307 - val_mape: 67.5135\n",
      "Epoch 465/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2395 - mae: 0.2781 - mape: 60.6532 - val_loss: 0.0804 - val_mae: 0.2303 - val_mape: 67.1907\n",
      "Epoch 466/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0990 - mae: 0.2033 - mape: 62.6624 - val_loss: 0.0802 - val_mae: 0.2299 - val_mape: 67.0576\n",
      "Epoch 467/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0658 - mae: 0.1708 - mape: 65.4621 - val_loss: 0.0801 - val_mae: 0.2293 - val_mape: 66.8817\n",
      "Epoch 468/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0663 - mae: 0.1757 - mape: 53.9061 - val_loss: 0.0802 - val_mae: 0.2288 - val_mape: 66.4385\n",
      "Epoch 469/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1144 - mae: 0.2123 - mape: 56.1499 - val_loss: 0.0803 - val_mae: 0.2284 - val_mape: 65.9943\n",
      "Epoch 470/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1303 - mae: 0.2426 - mape: 56.2657 - val_loss: 0.0804 - val_mae: 0.2279 - val_mape: 65.6285\n",
      "Epoch 471/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2201 - mae: 0.3023 - mape: 63.3331 - val_loss: 0.0803 - val_mae: 0.2274 - val_mape: 65.3286\n",
      "Epoch 472/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0812 - mae: 0.2091 - mape: 68.1285 - val_loss: 0.0801 - val_mae: 0.2268 - val_mape: 64.9848\n",
      "Epoch 473/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1468 - mae: 0.2790 - mape: 77.3461 - val_loss: 0.0799 - val_mae: 0.2262 - val_mape: 64.7219\n",
      "Epoch 474/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0641 - mae: 0.1681 - mape: 44.8780 - val_loss: 0.0795 - val_mae: 0.2256 - val_mape: 64.8304\n",
      "Epoch 475/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2445 - mae: 0.2857 - mape: 71.6110 - val_loss: 0.0789 - val_mae: 0.2251 - val_mape: 65.2868\n",
      "Epoch 476/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0704 - mae: 0.1860 - mape: 65.3621 - val_loss: 0.0783 - val_mae: 0.2246 - val_mape: 65.7922\n",
      "Epoch 477/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0799 - mae: 0.1867 - mape: 63.8702 - val_loss: 0.0779 - val_mae: 0.2243 - val_mape: 66.3244\n",
      "Epoch 478/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1406 - mae: 0.2484 - mape: 81.3956 - val_loss: 0.0773 - val_mae: 0.2238 - val_mape: 67.0429\n",
      "Epoch 479/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2328 - mae: 0.2754 - mape: 49.9835 - val_loss: 0.0769 - val_mae: 0.2236 - val_mape: 67.8429\n",
      "Epoch 480/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1038 - mae: 0.2313 - mape: 85.8003 - val_loss: 0.0764 - val_mae: 0.2234 - val_mape: 68.5745\n",
      "Epoch 481/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1221 - mae: 0.2509 - mape: 73.4490 - val_loss: 0.0759 - val_mae: 0.2232 - val_mape: 69.4158\n",
      "Epoch 482/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1447 - mae: 0.2524 - mape: 85.6900 - val_loss: 0.0757 - val_mae: 0.2230 - val_mape: 70.0849\n",
      "Epoch 483/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1357 - mae: 0.2502 - mape: 84.4994 - val_loss: 0.0755 - val_mae: 0.2228 - val_mape: 70.4373\n",
      "Epoch 484/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0494 - mae: 0.1509 - mape: 53.9278 - val_loss: 0.0753 - val_mae: 0.2226 - val_mape: 70.7717\n",
      "Epoch 485/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0958 - mae: 0.1958 - mape: 63.7261 - val_loss: 0.0751 - val_mae: 0.2222 - val_mape: 70.9862\n",
      "Epoch 486/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0929 - mae: 0.2062 - mape: 58.9570 - val_loss: 0.0749 - val_mae: 0.2219 - val_mape: 71.1122\n",
      "Epoch 487/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0804 - mae: 0.1693 - mape: 52.2404 - val_loss: 0.0748 - val_mae: 0.2216 - val_mape: 71.2213\n",
      "Epoch 488/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1584 - mae: 0.2714 - mape: 63.8836 - val_loss: 0.0747 - val_mae: 0.2213 - val_mape: 71.1980\n",
      "Epoch 489/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0433 - mae: 0.1406 - mape: 38.1615 - val_loss: 0.0747 - val_mae: 0.2211 - val_mape: 71.1272\n",
      "Epoch 490/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0725 - mae: 0.1875 - mape: 47.1059 - val_loss: 0.0748 - val_mae: 0.2209 - val_mape: 70.9737\n",
      "Epoch 491/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1194 - mae: 0.2010 - mape: 59.4700 - val_loss: 0.0750 - val_mae: 0.2208 - val_mape: 70.7281\n",
      "Epoch 492/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0754 - mae: 0.2050 - mape: 55.9381 - val_loss: 0.0751 - val_mae: 0.2206 - val_mape: 70.5807\n",
      "Epoch 493/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1403 - mae: 0.2420 - mape: 73.5030 - val_loss: 0.0750 - val_mae: 0.2203 - val_mape: 70.6353\n",
      "Epoch 494/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0759 - mae: 0.1507 - mape: 38.8387 - val_loss: 0.0750 - val_mae: 0.2200 - val_mape: 70.5591\n",
      "Epoch 495/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0478 - mae: 0.1601 - mape: 51.1288 - val_loss: 0.0751 - val_mae: 0.2197 - val_mape: 70.3307\n",
      "Epoch 496/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0705 - mae: 0.1697 - mape: 57.6516 - val_loss: 0.0752 - val_mae: 0.2194 - val_mape: 69.9952\n",
      "Epoch 497/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0925 - mae: 0.2113 - mape: 56.6484 - val_loss: 0.0754 - val_mae: 0.2192 - val_mape: 69.6806\n",
      "Epoch 498/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0885 - mae: 0.1743 - mape: 50.9579 - val_loss: 0.0755 - val_mae: 0.2190 - val_mape: 69.4753\n",
      "Epoch 499/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0668 - mae: 0.1476 - mape: 32.4431 - val_loss: 0.0755 - val_mae: 0.2187 - val_mape: 69.4145\n",
      "Epoch 500/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1782 - mae: 0.2854 - mape: 71.0218 - val_loss: 0.0755 - val_mae: 0.2185 - val_mape: 69.3008\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Compile model with optimizer and loss function\n",
    "model.compile(optimizer='adam',    # Adaptive learning rate optimizer\n",
    "              loss='mse',          # Mean Squared Error for regression\n",
    "              metrics=['mae', 'mape'])  # Track Mean Absolute Error and Mean Absolute Percentage Error\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "# Stops training when validation loss doesn't improve for 25 epochs\n",
    "# Restores the best weights found during training\n",
    "early = EarlyStopping(monitor='val_loss',        # Watch validation loss\n",
    "                     patience=25,                # Wait 25 epochs without improvement\n",
    "                     restore_best_weights=True)  # Keep best model weights\n",
    "\n",
    "# Train the model\n",
    "# Uses scaled features (X_train_z) and scaled targets (y_train_s) in [-1,1] range\n",
    "# Validates on separate validation set to monitor overfitting\n",
    "history = model.fit(\n",
    "    X_train_z, y_train_s,                    # Training data (scaled)\n",
    "    validation_data=(X_val_z, y_val_s),     # Validation data (scaled)\n",
    "    epochs=500,                              # Maximum 500 epochs\n",
    "    batch_size=16,                           # Process 16 samples at a time\n",
    "    verbose=1,                               # Print progress during training\n",
    "    callbacks=[early]                        # Apply early stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLV4VDdDjLmG",
    "outputId": "e06804a3-2b4d-4bc0-ad9d-206f2ab4cdb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on all sets\n",
    "y_hat_train_s = model.predict(X_train_z)\n",
    "y_hat_val_s   = model.predict(X_val_z)\n",
    "y_hat_test_s  = model.predict(X_test_z)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_hat_train = inv_y(y_hat_train_s)\n",
    "y_hat_val   = inv_y(y_hat_val_s)\n",
    "y_hat_test  = inv_y(y_hat_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "xeWwgdE0jLkG"
   },
   "outputs": [],
   "source": [
    "#Evaluate code performance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def report_2out(name, y_true, y_pred, labels=(\"Mn\", \"Mw\")):\n",
    "    \"\"\"\n",
    "    Calculate and print regression metrics for 2-output model\n",
    "    Args: name - dataset name, y_true/y_pred - shape (n,2), labels - output names\n",
    "    \"\"\"\n",
    "    for i, label in enumerate(labels):\n",
    "        # Extract single output column\n",
    "        yt = y_true[:, i]\n",
    "        yp = y_pred[:, i]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae  = mean_absolute_error(yt, yp)\n",
    "        mse  = mean_squared_error(yt, yp)\n",
    "        r2   = r2_score(yt, yp)\n",
    "        mape = mean_absolute_percentage_error(yt, yp)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"[{name}] {label}: MAE={mae:.6f}  MSE={mse:.6f}  R²={r2:.4f}  MAPE={mape:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptHevHX-jLh_",
    "outputId": "ca2a17b0-6b4b-4e41-8e90-50bde0ab8b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Mn: MAE=418.815694  MSE=454503.787176  R²=0.6523  MAPE=0.127492\n",
      "[Train] Mw: MAE=561.508452  MSE=799189.338028  R²=0.6257  MAPE=0.127961\n",
      "[Val  ] Mn: MAE=369.988094  MSE=318464.849942  R²=0.1809  MAPE=0.146121\n",
      "[Val  ] Mw: MAE=529.929165  MSE=846812.767161  R²=0.2107  MAPE=0.121886\n",
      "[Test ] Mn: MAE=408.749437  MSE=289768.203487  R²=0.4381  MAPE=0.179023\n",
      "[Test ] Mw: MAE=516.897972  MSE=640635.927017  R²=0.5489  MAPE=0.148113\n"
     ]
    }
   ],
   "source": [
    "#print metrics\n",
    "report_2out(\"Train\", y_train, y_hat_train)\n",
    "report_2out(\"Val  \", y_val,   y_hat_val)\n",
    "report_2out(\"Test \", y_test,  y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGS2LHAAjLfx",
    "outputId": "c5ef78f4-c870-4658-9a4c-388ffdd530b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZovIuGAXjLd4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-ZWVSsjjLby",
    "outputId": "224eda97-b2d7-4034-eb93-9c2c243abade"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split target   actual   predicted     residual   abs_error  pct_error\n",
      "Train     Mn   60.000   59.825718     0.174282    0.174282   0.290470\n",
      "Train     Mn   60.000   59.833717     0.166283    0.166283   0.277138\n",
      "Train     Mn   60.000   58.983959     1.016041    1.016041   1.693401\n",
      "Train     Mn   60.000   57.567089     2.432911    2.432911   4.054852\n",
      "Train     Mn   60.000   59.527618     0.472382    0.472382   0.787303\n",
      "Train     Mn   60.000   56.899101     3.100899    3.100899   5.168165\n",
      "Train     Mn   60.000   59.533024     0.466976    0.466976   0.778294\n",
      "Train     Mn   10.000   10.693752    -0.693752    0.693752   6.937523\n",
      "Train     Mn   10.000   11.703868    -1.703868    1.703868  17.038679\n",
      "Train     Mn   60.000   52.888393     7.111607    7.111607  11.852678\n",
      "Train     Mn   10.000   11.721342    -1.721342    1.721342  17.213421\n",
      "Train     Mn   10.000   11.011300    -1.011300    1.011300  10.113001\n",
      "Train     Mn   10.000   15.594433    -5.594433    5.594433  55.944328\n",
      "Train     Mn   10.000   11.030908    -1.030908    1.030908  10.309076\n",
      "Train     Mn   60.000   58.568783     1.431217    1.431217   2.385362\n",
      "Train     Mn   60.000   57.898598     2.101402    2.101402   3.502337\n",
      "Train     Mw 2223.170 2189.489014    33.680986   33.680986   1.514998\n",
      "Train     Mw 1950.000 2159.614014  -209.614014  209.614014  10.749437\n",
      "Train     Mw 3764.530 3595.843018   168.686982  168.686982   4.480957\n",
      "Train     Mw 2951.900 3331.509033  -379.609033  379.609033  12.859820\n",
      "Train     Mw 4663.770 3717.239258   946.530742  946.530742  20.295399\n",
      "Train     Mw 2322.860 2511.564697  -188.704697  188.704697   8.123808\n",
      "Train     Mw 4663.040 3693.574219   969.465781  969.465781  20.790424\n",
      "Train     Mw 1024.970 1198.103882  -173.133882  173.133882  16.891605\n",
      "Train     Mw 1845.600 1578.991699   266.608301  266.608301  14.445617\n",
      "Train     Mw 2073.900 2579.968262  -506.068262  506.068262  24.401768\n",
      "Train     Mw 1846.180 1607.413330   238.766670  238.766670  12.933011\n",
      "Train     Mw 1265.880 1332.546875   -66.666875   66.666875   5.266445\n",
      "Train     Mw 2525.910 2086.379883   439.530117  439.530117  17.400862\n",
      "Train     Mw 1264.440 1335.548706   -71.108706   71.108706   5.623731\n",
      "Train     Mw 2590.790 3301.430420  -710.640420  710.640420  27.429488\n",
      "Train     Mw 2752.800 2598.826660   153.973340  153.973340   5.593336\n",
      "  Val     Mn   60.000   59.109219     0.890781    0.890781   1.484636\n",
      "  Val     Mn   10.000   15.671691    -5.671691    5.671691  56.716909\n",
      "  Val     Mn   60.000   52.268951     7.731049    7.731049  12.885081\n",
      "  Val     Mn   60.000   57.715469     2.284531    2.284531   3.807551\n",
      "  Val     Mw 2298.650 3328.741211 -1030.091211 1030.091211  44.812878\n",
      "  Val     Mw 2525.270 2102.652344   422.617656  422.617656  16.735543\n",
      "  Val     Mw 2074.517 2519.543457  -445.026457  445.026457  21.452052\n",
      "  Val     Mw 2752.840 2639.617432   113.222568  113.222568   4.112937\n",
      " Test     Mn   60.000   59.086506     0.913494    0.913494   1.522490\n",
      " Test     Mn   60.000   58.960426     1.039574    1.039574   1.732623\n",
      " Test     Mn   10.000   11.172997    -1.172997    1.172997  11.729975\n",
      " Test     Mn   60.000   57.686848     2.313152    2.313152   3.855254\n",
      " Test     Mn   60.000   56.828022     3.171978    3.171978   5.286630\n",
      " Test     Mw 2298.620 3257.467773  -958.847773  958.847773  41.714062\n",
      " Test     Mw 3762.880 3584.973145   177.906855  177.906855   4.727944\n",
      " Test     Mw 1127.190 1270.776978  -143.586978  143.586978  12.738489\n",
      " Test     Mw 2955.830 3351.904053  -396.074053  396.074053  13.399758\n",
      " Test     Mw 2322.830 2499.965088  -177.135088  177.135088   7.625831\n"
     ]
    }
   ],
   "source": [
    "# Create detailed comparison table showing actual vs predicted values\n",
    "# Shows sample-by-sample performance for both outputs (Mn, Mw) across all datasets\n",
    "# Includes error metrics: residual, absolute error, and percentage error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_table_multi(split, y_true, y_pred, target_names=(\"Mn\",\"Mw\"), n=None):\n",
    "    \"\"\"Create comparison table for actual vs predicted values\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    parts = []\n",
    "    for j, name in enumerate(target_names):\n",
    "        df = pd.DataFrame({\n",
    "            \"split\":     split,\n",
    "            \"target\":    name,\n",
    "            \"actual\":    y_true[:, j],\n",
    "            \"predicted\": y_pred[:, j],\n",
    "        })\n",
    "        # Calculate error metrics\n",
    "        df[\"residual\"]  = df[\"actual\"] - df[\"predicted\"]\n",
    "        df[\"abs_error\"] = df[\"residual\"].abs()\n",
    "        df[\"pct_error\"] = 100 * df[\"abs_error\"] / df[\"actual\"].abs().clip(lower=1e-8)\n",
    "        \n",
    "        parts.append(df if n is None else df.head(n))\n",
    "    \n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "# Create comparison tables for all datasets\n",
    "tbl_train = make_table_multi(\"Train\", y_train, y_hat_train)\n",
    "tbl_val   = make_table_multi(\"Val\",   y_val,   y_hat_val)\n",
    "tbl_test  = make_table_multi(\"Test\",  y_test,  y_hat_test)\n",
    "\n",
    "# Combine all tables\n",
    "tbl_all = pd.concat([tbl_train, tbl_val, tbl_test], ignore_index=True)\n",
    "print(tbl_all.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "t9miTBP8jLXi"
   },
   "outputs": [],
   "source": [
    "# ---- 5) Activation (Transfer Function) sweep on hidden layers ----\n",
    "import random, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers\n",
    "\n",
    "activations = ['relu', 'tanh', 'sigmoid', 'softplus']\n",
    "labels      = ['ReLU', 'Tanh', 'Sigmoid', 'Softplus']\n",
    "\n",
    "val_mse_real  = []\n",
    "test_mse_real = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJDODufEBSbC",
    "outputId": "cfa4e88f-ea10-4467-fde0-b49ff2fbd8ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step - loss: 0.7409 - mae: 0.6907 - val_loss: 0.5693 - val_mae: 0.6294\n",
      "Epoch 2/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7336 - mae: 0.6864 - val_loss: 0.5640 - val_mae: 0.6253\n",
      "Epoch 3/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7263 - mae: 0.6820 - val_loss: 0.5590 - val_mae: 0.6213\n",
      "Epoch 4/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.7190 - mae: 0.6777 - val_loss: 0.5541 - val_mae: 0.6174\n",
      "Epoch 5/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7119 - mae: 0.6733 - val_loss: 0.5491 - val_mae: 0.6134\n",
      "Epoch 6/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7048 - mae: 0.6689 - val_loss: 0.5441 - val_mae: 0.6093\n",
      "Epoch 7/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6977 - mae: 0.6645 - val_loss: 0.5391 - val_mae: 0.6053\n",
      "Epoch 8/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6907 - mae: 0.6601 - val_loss: 0.5343 - val_mae: 0.6012\n",
      "Epoch 9/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.6838 - mae: 0.6557 - val_loss: 0.5294 - val_mae: 0.5971\n",
      "Epoch 10/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.6770 - mae: 0.6513 - val_loss: 0.5247 - val_mae: 0.5931\n",
      "Epoch 11/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6702 - mae: 0.6470 - val_loss: 0.5200 - val_mae: 0.5890\n",
      "Epoch 12/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.6635 - mae: 0.6427 - val_loss: 0.5154 - val_mae: 0.5850\n",
      "Epoch 13/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.6568 - mae: 0.6384 - val_loss: 0.5109 - val_mae: 0.5810\n",
      "Epoch 14/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6502 - mae: 0.6340 - val_loss: 0.5065 - val_mae: 0.5770\n",
      "Epoch 15/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6436 - mae: 0.6297 - val_loss: 0.5021 - val_mae: 0.5731\n",
      "Epoch 16/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6372 - mae: 0.6254 - val_loss: 0.4979 - val_mae: 0.5692\n",
      "Epoch 17/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6307 - mae: 0.6212 - val_loss: 0.4937 - val_mae: 0.5653\n",
      "Epoch 18/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6244 - mae: 0.6170 - val_loss: 0.4895 - val_mae: 0.5615\n",
      "Epoch 19/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6181 - mae: 0.6131 - val_loss: 0.4855 - val_mae: 0.5577\n",
      "Epoch 20/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6119 - mae: 0.6093 - val_loss: 0.4814 - val_mae: 0.5539\n",
      "Epoch 21/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6057 - mae: 0.6056 - val_loss: 0.4775 - val_mae: 0.5502\n",
      "Epoch 22/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5996 - mae: 0.6018 - val_loss: 0.4736 - val_mae: 0.5465\n",
      "Epoch 23/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5935 - mae: 0.5981 - val_loss: 0.4698 - val_mae: 0.5429\n",
      "Epoch 24/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5875 - mae: 0.5944 - val_loss: 0.4661 - val_mae: 0.5393\n",
      "Epoch 25/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5816 - mae: 0.5907 - val_loss: 0.4623 - val_mae: 0.5358\n",
      "Epoch 26/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5757 - mae: 0.5870 - val_loss: 0.4587 - val_mae: 0.5323\n",
      "Epoch 27/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5698 - mae: 0.5834 - val_loss: 0.4551 - val_mae: 0.5289\n",
      "Epoch 28/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5640 - mae: 0.5798 - val_loss: 0.4515 - val_mae: 0.5255\n",
      "Epoch 29/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5583 - mae: 0.5762 - val_loss: 0.4479 - val_mae: 0.5221\n",
      "Epoch 30/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5525 - mae: 0.5726 - val_loss: 0.4444 - val_mae: 0.5188\n",
      "Epoch 31/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5468 - mae: 0.5690 - val_loss: 0.4410 - val_mae: 0.5155\n",
      "Epoch 32/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5412 - mae: 0.5655 - val_loss: 0.4375 - val_mae: 0.5131\n",
      "Epoch 33/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5357 - mae: 0.5625 - val_loss: 0.4341 - val_mae: 0.5108\n",
      "Epoch 34/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5301 - mae: 0.5596 - val_loss: 0.4307 - val_mae: 0.5086\n",
      "Epoch 35/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5246 - mae: 0.5567 - val_loss: 0.4274 - val_mae: 0.5063\n",
      "Epoch 36/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5191 - mae: 0.5538 - val_loss: 0.4240 - val_mae: 0.5041\n",
      "Epoch 37/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5136 - mae: 0.5509 - val_loss: 0.4207 - val_mae: 0.5019\n",
      "Epoch 38/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5081 - mae: 0.5480 - val_loss: 0.4173 - val_mae: 0.4997\n",
      "Epoch 39/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5026 - mae: 0.5451 - val_loss: 0.4140 - val_mae: 0.4974\n",
      "Epoch 40/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4971 - mae: 0.5422 - val_loss: 0.4106 - val_mae: 0.4952\n",
      "Epoch 41/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4916 - mae: 0.5393 - val_loss: 0.4073 - val_mae: 0.4930\n",
      "Epoch 42/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4861 - mae: 0.5364 - val_loss: 0.4039 - val_mae: 0.4908\n",
      "Epoch 43/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4806 - mae: 0.5335 - val_loss: 0.4006 - val_mae: 0.4885\n",
      "Epoch 44/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4750 - mae: 0.5306 - val_loss: 0.3972 - val_mae: 0.4863\n",
      "Epoch 45/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4694 - mae: 0.5277 - val_loss: 0.3938 - val_mae: 0.4840\n",
      "Epoch 46/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4638 - mae: 0.5247 - val_loss: 0.3903 - val_mae: 0.4817\n",
      "Epoch 47/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4582 - mae: 0.5217 - val_loss: 0.3869 - val_mae: 0.4794\n",
      "Epoch 48/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4526 - mae: 0.5188 - val_loss: 0.3834 - val_mae: 0.4771\n",
      "Epoch 49/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4469 - mae: 0.5158 - val_loss: 0.3798 - val_mae: 0.4747\n",
      "Epoch 50/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4412 - mae: 0.5128 - val_loss: 0.3763 - val_mae: 0.4722\n",
      "Epoch 51/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4354 - mae: 0.5097 - val_loss: 0.3727 - val_mae: 0.4697\n",
      "Epoch 52/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4296 - mae: 0.5067 - val_loss: 0.3690 - val_mae: 0.4672\n",
      "Epoch 53/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4238 - mae: 0.5036 - val_loss: 0.3653 - val_mae: 0.4647\n",
      "Epoch 54/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4179 - mae: 0.5005 - val_loss: 0.3615 - val_mae: 0.4621\n",
      "Epoch 55/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4119 - mae: 0.4973 - val_loss: 0.3577 - val_mae: 0.4594\n",
      "Epoch 56/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4060 - mae: 0.4941 - val_loss: 0.3539 - val_mae: 0.4567\n",
      "Epoch 57/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3999 - mae: 0.4909 - val_loss: 0.3500 - val_mae: 0.4540\n",
      "Epoch 58/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3938 - mae: 0.4877 - val_loss: 0.3460 - val_mae: 0.4512\n",
      "Epoch 59/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3877 - mae: 0.4844 - val_loss: 0.3420 - val_mae: 0.4483\n",
      "Epoch 60/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3815 - mae: 0.4811 - val_loss: 0.3379 - val_mae: 0.4454\n",
      "Epoch 61/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3753 - mae: 0.4777 - val_loss: 0.3337 - val_mae: 0.4424\n",
      "Epoch 62/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3690 - mae: 0.4744 - val_loss: 0.3295 - val_mae: 0.4393\n",
      "Epoch 63/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3627 - mae: 0.4710 - val_loss: 0.3252 - val_mae: 0.4362\n",
      "Epoch 64/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3564 - mae: 0.4675 - val_loss: 0.3208 - val_mae: 0.4330\n",
      "Epoch 65/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3500 - mae: 0.4640 - val_loss: 0.3164 - val_mae: 0.4297\n",
      "Epoch 66/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3436 - mae: 0.4605 - val_loss: 0.3119 - val_mae: 0.4264\n",
      "Epoch 67/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3371 - mae: 0.4570 - val_loss: 0.3074 - val_mae: 0.4231\n",
      "Epoch 68/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3307 - mae: 0.4534 - val_loss: 0.3028 - val_mae: 0.4197\n",
      "Epoch 69/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3243 - mae: 0.4498 - val_loss: 0.2981 - val_mae: 0.4162\n",
      "Epoch 70/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3176 - mae: 0.4461 - val_loss: 0.2935 - val_mae: 0.4127\n",
      "Epoch 71/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3109 - mae: 0.4423 - val_loss: 0.2887 - val_mae: 0.4091\n",
      "Epoch 72/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3042 - mae: 0.4385 - val_loss: 0.2839 - val_mae: 0.4054\n",
      "Epoch 73/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2974 - mae: 0.4347 - val_loss: 0.2791 - val_mae: 0.4016\n",
      "Epoch 74/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2907 - mae: 0.4308 - val_loss: 0.2742 - val_mae: 0.3978\n",
      "Epoch 75/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2841 - mae: 0.4269 - val_loss: 0.2694 - val_mae: 0.3939\n",
      "Epoch 76/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2774 - mae: 0.4230 - val_loss: 0.2645 - val_mae: 0.3900\n",
      "Epoch 77/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2709 - mae: 0.4191 - val_loss: 0.2596 - val_mae: 0.3860\n",
      "Epoch 78/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2645 - mae: 0.4152 - val_loss: 0.2547 - val_mae: 0.3819\n",
      "Epoch 79/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2583 - mae: 0.4114 - val_loss: 0.2498 - val_mae: 0.3779\n",
      "Epoch 80/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2522 - mae: 0.4076 - val_loss: 0.2449 - val_mae: 0.3738\n",
      "Epoch 81/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2462 - mae: 0.4038 - val_loss: 0.2401 - val_mae: 0.3696\n",
      "Epoch 82/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2403 - mae: 0.4000 - val_loss: 0.2353 - val_mae: 0.3654\n",
      "Epoch 83/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2345 - mae: 0.3962 - val_loss: 0.2305 - val_mae: 0.3613\n",
      "Epoch 84/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2289 - mae: 0.3925 - val_loss: 0.2256 - val_mae: 0.3571\n",
      "Epoch 85/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2234 - mae: 0.3888 - val_loss: 0.2207 - val_mae: 0.3540\n",
      "Epoch 86/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2180 - mae: 0.3854 - val_loss: 0.2157 - val_mae: 0.3508\n",
      "Epoch 87/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2127 - mae: 0.3820 - val_loss: 0.2106 - val_mae: 0.3475\n",
      "Epoch 88/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2076 - mae: 0.3786 - val_loss: 0.2057 - val_mae: 0.3442\n",
      "Epoch 89/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2025 - mae: 0.3752 - val_loss: 0.2007 - val_mae: 0.3408\n",
      "Epoch 90/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1977 - mae: 0.3719 - val_loss: 0.1959 - val_mae: 0.3374\n",
      "Epoch 91/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1931 - mae: 0.3686 - val_loss: 0.1913 - val_mae: 0.3340\n",
      "Epoch 92/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1885 - mae: 0.3654 - val_loss: 0.1869 - val_mae: 0.3307\n",
      "Epoch 93/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1842 - mae: 0.3621 - val_loss: 0.1826 - val_mae: 0.3274\n",
      "Epoch 94/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1799 - mae: 0.3589 - val_loss: 0.1786 - val_mae: 0.3242\n",
      "Epoch 95/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1758 - mae: 0.3556 - val_loss: 0.1747 - val_mae: 0.3211\n",
      "Epoch 96/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1719 - mae: 0.3524 - val_loss: 0.1710 - val_mae: 0.3180\n",
      "Epoch 97/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1681 - mae: 0.3492 - val_loss: 0.1675 - val_mae: 0.3150\n",
      "Epoch 98/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1644 - mae: 0.3461 - val_loss: 0.1641 - val_mae: 0.3121\n",
      "Epoch 99/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1610 - mae: 0.3430 - val_loss: 0.1608 - val_mae: 0.3091\n",
      "Epoch 100/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1577 - mae: 0.3400 - val_loss: 0.1576 - val_mae: 0.3061\n",
      "Epoch 101/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1545 - mae: 0.3371 - val_loss: 0.1544 - val_mae: 0.3031\n",
      "Epoch 102/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1514 - mae: 0.3342 - val_loss: 0.1512 - val_mae: 0.3000\n",
      "Epoch 103/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1485 - mae: 0.3314 - val_loss: 0.1482 - val_mae: 0.2970\n",
      "Epoch 104/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1458 - mae: 0.3287 - val_loss: 0.1453 - val_mae: 0.2939\n",
      "Epoch 105/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1431 - mae: 0.3260 - val_loss: 0.1424 - val_mae: 0.2908\n",
      "Epoch 106/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1405 - mae: 0.3233 - val_loss: 0.1397 - val_mae: 0.2878\n",
      "Epoch 107/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1381 - mae: 0.3207 - val_loss: 0.1372 - val_mae: 0.2849\n",
      "Epoch 108/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1358 - mae: 0.3181 - val_loss: 0.1349 - val_mae: 0.2822\n",
      "Epoch 109/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1336 - mae: 0.3155 - val_loss: 0.1327 - val_mae: 0.2796\n",
      "Epoch 110/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1314 - mae: 0.3130 - val_loss: 0.1307 - val_mae: 0.2771\n",
      "Epoch 111/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1293 - mae: 0.3104 - val_loss: 0.1289 - val_mae: 0.2747\n",
      "Epoch 112/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1273 - mae: 0.3079 - val_loss: 0.1272 - val_mae: 0.2724\n",
      "Epoch 113/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1255 - mae: 0.3055 - val_loss: 0.1254 - val_mae: 0.2701\n",
      "Epoch 114/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1237 - mae: 0.3032 - val_loss: 0.1237 - val_mae: 0.2678\n",
      "Epoch 115/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1220 - mae: 0.3010 - val_loss: 0.1221 - val_mae: 0.2655\n",
      "Epoch 116/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1204 - mae: 0.2988 - val_loss: 0.1205 - val_mae: 0.2632\n",
      "Epoch 117/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1188 - mae: 0.2966 - val_loss: 0.1189 - val_mae: 0.2610\n",
      "Epoch 118/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1173 - mae: 0.2946 - val_loss: 0.1174 - val_mae: 0.2589\n",
      "Epoch 119/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1158 - mae: 0.2925 - val_loss: 0.1159 - val_mae: 0.2567\n",
      "Epoch 120/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1144 - mae: 0.2905 - val_loss: 0.1145 - val_mae: 0.2548\n",
      "Epoch 121/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1131 - mae: 0.2886 - val_loss: 0.1133 - val_mae: 0.2529\n",
      "Epoch 122/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1118 - mae: 0.2867 - val_loss: 0.1121 - val_mae: 0.2511\n",
      "Epoch 123/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1105 - mae: 0.2849 - val_loss: 0.1109 - val_mae: 0.2493\n",
      "Epoch 124/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1093 - mae: 0.2831 - val_loss: 0.1097 - val_mae: 0.2475\n",
      "Epoch 125/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1082 - mae: 0.2813 - val_loss: 0.1085 - val_mae: 0.2458\n",
      "Epoch 126/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1070 - mae: 0.2796 - val_loss: 0.1075 - val_mae: 0.2448\n",
      "Epoch 127/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1059 - mae: 0.2783 - val_loss: 0.1065 - val_mae: 0.2440\n",
      "Epoch 128/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1049 - mae: 0.2771 - val_loss: 0.1055 - val_mae: 0.2431\n",
      "Epoch 129/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1039 - mae: 0.2760 - val_loss: 0.1045 - val_mae: 0.2423\n",
      "Epoch 130/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1030 - mae: 0.2748 - val_loss: 0.1036 - val_mae: 0.2414\n",
      "Epoch 131/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1020 - mae: 0.2736 - val_loss: 0.1027 - val_mae: 0.2406\n",
      "Epoch 132/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1011 - mae: 0.2724 - val_loss: 0.1019 - val_mae: 0.2398\n",
      "Epoch 133/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1002 - mae: 0.2712 - val_loss: 0.1012 - val_mae: 0.2390\n",
      "Epoch 134/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0993 - mae: 0.2700 - val_loss: 0.1005 - val_mae: 0.2383\n",
      "Epoch 135/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0985 - mae: 0.2688 - val_loss: 0.0998 - val_mae: 0.2375\n",
      "Epoch 136/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0976 - mae: 0.2676 - val_loss: 0.0990 - val_mae: 0.2368\n",
      "Epoch 137/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0969 - mae: 0.2665 - val_loss: 0.0984 - val_mae: 0.2360\n",
      "Epoch 138/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0961 - mae: 0.2654 - val_loss: 0.0977 - val_mae: 0.2353\n",
      "Epoch 139/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0953 - mae: 0.2643 - val_loss: 0.0970 - val_mae: 0.2346\n",
      "Epoch 140/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0946 - mae: 0.2632 - val_loss: 0.0963 - val_mae: 0.2338\n",
      "Epoch 141/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0939 - mae: 0.2621 - val_loss: 0.0957 - val_mae: 0.2331\n",
      "Epoch 142/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0932 - mae: 0.2611 - val_loss: 0.0950 - val_mae: 0.2323\n",
      "Epoch 143/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0925 - mae: 0.2600 - val_loss: 0.0943 - val_mae: 0.2315\n",
      "Epoch 144/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0918 - mae: 0.2589 - val_loss: 0.0937 - val_mae: 0.2307\n",
      "Epoch 145/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0911 - mae: 0.2578 - val_loss: 0.0930 - val_mae: 0.2299\n",
      "Epoch 146/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0904 - mae: 0.2567 - val_loss: 0.0924 - val_mae: 0.2290\n",
      "Epoch 147/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0897 - mae: 0.2556 - val_loss: 0.0918 - val_mae: 0.2282\n",
      "Epoch 148/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0891 - mae: 0.2545 - val_loss: 0.0912 - val_mae: 0.2274\n",
      "Epoch 149/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0884 - mae: 0.2534 - val_loss: 0.0906 - val_mae: 0.2266\n",
      "Epoch 150/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0878 - mae: 0.2523 - val_loss: 0.0901 - val_mae: 0.2259\n",
      "Epoch 151/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0872 - mae: 0.2512 - val_loss: 0.0897 - val_mae: 0.2251\n",
      "Epoch 152/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0865 - mae: 0.2500 - val_loss: 0.0892 - val_mae: 0.2244\n",
      "Epoch 153/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0859 - mae: 0.2489 - val_loss: 0.0887 - val_mae: 0.2237\n",
      "Epoch 154/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0853 - mae: 0.2478 - val_loss: 0.0882 - val_mae: 0.2229\n",
      "Epoch 155/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0847 - mae: 0.2467 - val_loss: 0.0878 - val_mae: 0.2222\n",
      "Epoch 156/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0842 - mae: 0.2456 - val_loss: 0.0873 - val_mae: 0.2214\n",
      "Epoch 157/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0836 - mae: 0.2446 - val_loss: 0.0869 - val_mae: 0.2207\n",
      "Epoch 158/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0830 - mae: 0.2435 - val_loss: 0.0864 - val_mae: 0.2200\n",
      "Epoch 159/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0825 - mae: 0.2425 - val_loss: 0.0860 - val_mae: 0.2193\n",
      "Epoch 160/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0819 - mae: 0.2414 - val_loss: 0.0856 - val_mae: 0.2186\n",
      "Epoch 161/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0814 - mae: 0.2404 - val_loss: 0.0852 - val_mae: 0.2179\n",
      "Epoch 162/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0809 - mae: 0.2394 - val_loss: 0.0847 - val_mae: 0.2172\n",
      "Epoch 163/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0804 - mae: 0.2384 - val_loss: 0.0843 - val_mae: 0.2165\n",
      "Epoch 164/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0799 - mae: 0.2374 - val_loss: 0.0839 - val_mae: 0.2159\n",
      "Epoch 165/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0794 - mae: 0.2365 - val_loss: 0.0835 - val_mae: 0.2152\n",
      "Epoch 166/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0789 - mae: 0.2355 - val_loss: 0.0832 - val_mae: 0.2146\n",
      "Epoch 167/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0784 - mae: 0.2346 - val_loss: 0.0828 - val_mae: 0.2139\n",
      "Epoch 168/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0779 - mae: 0.2336 - val_loss: 0.0825 - val_mae: 0.2133\n",
      "Epoch 169/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0775 - mae: 0.2327 - val_loss: 0.0821 - val_mae: 0.2127\n",
      "Epoch 170/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0770 - mae: 0.2318 - val_loss: 0.0818 - val_mae: 0.2121\n",
      "Epoch 171/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0766 - mae: 0.2309 - val_loss: 0.0815 - val_mae: 0.2115\n",
      "Epoch 172/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0761 - mae: 0.2300 - val_loss: 0.0812 - val_mae: 0.2110\n",
      "Epoch 173/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0757 - mae: 0.2291 - val_loss: 0.0810 - val_mae: 0.2105\n",
      "Epoch 174/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0753 - mae: 0.2282 - val_loss: 0.0807 - val_mae: 0.2101\n",
      "Epoch 175/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0748 - mae: 0.2274 - val_loss: 0.0805 - val_mae: 0.2098\n",
      "Epoch 176/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0744 - mae: 0.2266 - val_loss: 0.0802 - val_mae: 0.2095\n",
      "Epoch 177/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0740 - mae: 0.2259 - val_loss: 0.0800 - val_mae: 0.2091\n",
      "Epoch 178/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0736 - mae: 0.2251 - val_loss: 0.0797 - val_mae: 0.2088\n",
      "Epoch 179/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0732 - mae: 0.2244 - val_loss: 0.0795 - val_mae: 0.2085\n",
      "Epoch 180/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0729 - mae: 0.2238 - val_loss: 0.0792 - val_mae: 0.2081\n",
      "Epoch 181/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0725 - mae: 0.2231 - val_loss: 0.0791 - val_mae: 0.2079\n",
      "Epoch 182/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0721 - mae: 0.2224 - val_loss: 0.0789 - val_mae: 0.2076\n",
      "Epoch 183/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0718 - mae: 0.2217 - val_loss: 0.0788 - val_mae: 0.2073\n",
      "Epoch 184/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0714 - mae: 0.2210 - val_loss: 0.0786 - val_mae: 0.2070\n",
      "Epoch 185/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0711 - mae: 0.2203 - val_loss: 0.0784 - val_mae: 0.2067\n",
      "Epoch 186/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0707 - mae: 0.2197 - val_loss: 0.0782 - val_mae: 0.2065\n",
      "Epoch 187/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0704 - mae: 0.2190 - val_loss: 0.0781 - val_mae: 0.2062\n",
      "Epoch 188/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0700 - mae: 0.2184 - val_loss: 0.0779 - val_mae: 0.2059\n",
      "Epoch 189/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0697 - mae: 0.2177 - val_loss: 0.0777 - val_mae: 0.2056\n",
      "Epoch 190/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0694 - mae: 0.2171 - val_loss: 0.0776 - val_mae: 0.2053\n",
      "Epoch 191/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0691 - mae: 0.2165 - val_loss: 0.0774 - val_mae: 0.2050\n",
      "Epoch 192/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0687 - mae: 0.2159 - val_loss: 0.0772 - val_mae: 0.2048\n",
      "Epoch 193/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0684 - mae: 0.2153 - val_loss: 0.0771 - val_mae: 0.2045\n",
      "Epoch 194/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0681 - mae: 0.2147 - val_loss: 0.0769 - val_mae: 0.2042\n",
      "Epoch 195/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0678 - mae: 0.2141 - val_loss: 0.0768 - val_mae: 0.2040\n",
      "Epoch 196/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0675 - mae: 0.2135 - val_loss: 0.0766 - val_mae: 0.2037\n",
      "Epoch 197/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0672 - mae: 0.2129 - val_loss: 0.0765 - val_mae: 0.2035\n",
      "Epoch 198/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0669 - mae: 0.2123 - val_loss: 0.0765 - val_mae: 0.2033\n",
      "Epoch 199/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0667 - mae: 0.2117 - val_loss: 0.0764 - val_mae: 0.2031\n",
      "Epoch 200/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0664 - mae: 0.2111 - val_loss: 0.0763 - val_mae: 0.2029\n",
      "Epoch 1/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - loss: 0.8544 - mae: 0.7559 - val_loss: 0.3958 - val_mae: 0.4728\n",
      "Epoch 2/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8437 - mae: 0.7496 - val_loss: 0.3905 - val_mae: 0.4679\n",
      "Epoch 3/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8331 - mae: 0.7433 - val_loss: 0.3853 - val_mae: 0.4629\n",
      "Epoch 4/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8224 - mae: 0.7369 - val_loss: 0.3801 - val_mae: 0.4579\n",
      "Epoch 5/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.8119 - mae: 0.7303 - val_loss: 0.3750 - val_mae: 0.4529\n",
      "Epoch 6/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8013 - mae: 0.7238 - val_loss: 0.3698 - val_mae: 0.4478\n",
      "Epoch 7/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7909 - mae: 0.7171 - val_loss: 0.3647 - val_mae: 0.4427\n",
      "Epoch 8/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7805 - mae: 0.7104 - val_loss: 0.3596 - val_mae: 0.4376\n",
      "Epoch 9/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.7702 - mae: 0.7036 - val_loss: 0.3545 - val_mae: 0.4326\n",
      "Epoch 10/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.7600 - mae: 0.6967 - val_loss: 0.3494 - val_mae: 0.4287\n",
      "Epoch 11/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7499 - mae: 0.6898 - val_loss: 0.3444 - val_mae: 0.4246\n",
      "Epoch 12/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7399 - mae: 0.6828 - val_loss: 0.3393 - val_mae: 0.4206\n",
      "Epoch 13/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.7300 - mae: 0.6758 - val_loss: 0.3343 - val_mae: 0.4164\n",
      "Epoch 14/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7203 - mae: 0.6687 - val_loss: 0.3293 - val_mae: 0.4122\n",
      "Epoch 15/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7106 - mae: 0.6616 - val_loss: 0.3244 - val_mae: 0.4079\n",
      "Epoch 16/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7011 - mae: 0.6544 - val_loss: 0.3194 - val_mae: 0.4036\n",
      "Epoch 17/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 0.6917 - mae: 0.6472 - val_loss: 0.3145 - val_mae: 0.3992\n",
      "Epoch 18/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.6825 - mae: 0.6403 - val_loss: 0.3096 - val_mae: 0.3948\n",
      "Epoch 19/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.6733 - mae: 0.6341 - val_loss: 0.3048 - val_mae: 0.3903\n",
      "Epoch 20/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6644 - mae: 0.6278 - val_loss: 0.3000 - val_mae: 0.3858\n",
      "Epoch 21/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.6555 - mae: 0.6216 - val_loss: 0.2952 - val_mae: 0.3813\n",
      "Epoch 22/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6469 - mae: 0.6153 - val_loss: 0.2905 - val_mae: 0.3767\n",
      "Epoch 23/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6383 - mae: 0.6090 - val_loss: 0.2859 - val_mae: 0.3722\n",
      "Epoch 24/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6300 - mae: 0.6027 - val_loss: 0.2812 - val_mae: 0.3676\n",
      "Epoch 25/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6218 - mae: 0.5964 - val_loss: 0.2767 - val_mae: 0.3630\n",
      "Epoch 26/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.6137 - mae: 0.5913 - val_loss: 0.2721 - val_mae: 0.3584\n",
      "Epoch 27/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6058 - mae: 0.5866 - val_loss: 0.2677 - val_mae: 0.3537\n",
      "Epoch 28/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5980 - mae: 0.5820 - val_loss: 0.2632 - val_mae: 0.3491\n",
      "Epoch 29/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.5905 - mae: 0.5773 - val_loss: 0.2589 - val_mae: 0.3444\n",
      "Epoch 30/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5830 - mae: 0.5726 - val_loss: 0.2545 - val_mae: 0.3398\n",
      "Epoch 31/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5757 - mae: 0.5679 - val_loss: 0.2503 - val_mae: 0.3351\n",
      "Epoch 32/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5686 - mae: 0.5633 - val_loss: 0.2461 - val_mae: 0.3304\n",
      "Epoch 33/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5616 - mae: 0.5587 - val_loss: 0.2420 - val_mae: 0.3258\n",
      "Epoch 34/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.5548 - mae: 0.5540 - val_loss: 0.2379 - val_mae: 0.3211\n",
      "Epoch 35/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5480 - mae: 0.5495 - val_loss: 0.2339 - val_mae: 0.3165\n",
      "Epoch 36/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5415 - mae: 0.5456 - val_loss: 0.2299 - val_mae: 0.3118\n",
      "Epoch 37/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5350 - mae: 0.5418 - val_loss: 0.2260 - val_mae: 0.3072\n",
      "Epoch 38/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5287 - mae: 0.5379 - val_loss: 0.2222 - val_mae: 0.3026\n",
      "Epoch 39/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5225 - mae: 0.5341 - val_loss: 0.2184 - val_mae: 0.2980\n",
      "Epoch 40/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5164 - mae: 0.5302 - val_loss: 0.2147 - val_mae: 0.2939\n",
      "Epoch 41/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5105 - mae: 0.5264 - val_loss: 0.2111 - val_mae: 0.2901\n",
      "Epoch 42/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5046 - mae: 0.5225 - val_loss: 0.2075 - val_mae: 0.2863\n",
      "Epoch 43/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4988 - mae: 0.5186 - val_loss: 0.2040 - val_mae: 0.2826\n",
      "Epoch 44/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4931 - mae: 0.5148 - val_loss: 0.2006 - val_mae: 0.2789\n",
      "Epoch 45/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4875 - mae: 0.5109 - val_loss: 0.1972 - val_mae: 0.2757\n",
      "Epoch 46/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4820 - mae: 0.5078 - val_loss: 0.1939 - val_mae: 0.2732\n",
      "Epoch 47/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4765 - mae: 0.5057 - val_loss: 0.1907 - val_mae: 0.2708\n",
      "Epoch 48/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4711 - mae: 0.5036 - val_loss: 0.1875 - val_mae: 0.2687\n",
      "Epoch 49/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4658 - mae: 0.5015 - val_loss: 0.1845 - val_mae: 0.2669\n",
      "Epoch 50/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4605 - mae: 0.4997 - val_loss: 0.1814 - val_mae: 0.2651\n",
      "Epoch 51/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4553 - mae: 0.4978 - val_loss: 0.1785 - val_mae: 0.2640\n",
      "Epoch 52/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4501 - mae: 0.4964 - val_loss: 0.1756 - val_mae: 0.2630\n",
      "Epoch 53/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4449 - mae: 0.4950 - val_loss: 0.1728 - val_mae: 0.2619\n",
      "Epoch 54/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4398 - mae: 0.4935 - val_loss: 0.1701 - val_mae: 0.2607\n",
      "Epoch 55/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4347 - mae: 0.4919 - val_loss: 0.1674 - val_mae: 0.2596\n",
      "Epoch 56/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4297 - mae: 0.4903 - val_loss: 0.1648 - val_mae: 0.2585\n",
      "Epoch 57/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4246 - mae: 0.4886 - val_loss: 0.1623 - val_mae: 0.2573\n",
      "Epoch 58/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4196 - mae: 0.4869 - val_loss: 0.1599 - val_mae: 0.2561\n",
      "Epoch 59/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4146 - mae: 0.4852 - val_loss: 0.1575 - val_mae: 0.2549\n",
      "Epoch 60/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4096 - mae: 0.4834 - val_loss: 0.1552 - val_mae: 0.2537\n",
      "Epoch 61/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4047 - mae: 0.4815 - val_loss: 0.1529 - val_mae: 0.2525\n",
      "Epoch 62/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3997 - mae: 0.4796 - val_loss: 0.1508 - val_mae: 0.2512\n",
      "Epoch 63/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3948 - mae: 0.4777 - val_loss: 0.1487 - val_mae: 0.2500\n",
      "Epoch 64/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3898 - mae: 0.4757 - val_loss: 0.1466 - val_mae: 0.2487\n",
      "Epoch 65/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3849 - mae: 0.4737 - val_loss: 0.1447 - val_mae: 0.2475\n",
      "Epoch 66/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3800 - mae: 0.4716 - val_loss: 0.1428 - val_mae: 0.2462\n",
      "Epoch 67/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3751 - mae: 0.4695 - val_loss: 0.1409 - val_mae: 0.2449\n",
      "Epoch 68/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3702 - mae: 0.4674 - val_loss: 0.1392 - val_mae: 0.2436\n",
      "Epoch 69/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3654 - mae: 0.4652 - val_loss: 0.1375 - val_mae: 0.2423\n",
      "Epoch 70/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3605 - mae: 0.4630 - val_loss: 0.1358 - val_mae: 0.2410\n",
      "Epoch 71/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3557 - mae: 0.4608 - val_loss: 0.1343 - val_mae: 0.2398\n",
      "Epoch 72/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3509 - mae: 0.4585 - val_loss: 0.1328 - val_mae: 0.2385\n",
      "Epoch 73/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3462 - mae: 0.4562 - val_loss: 0.1313 - val_mae: 0.2371\n",
      "Epoch 74/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3415 - mae: 0.4539 - val_loss: 0.1300 - val_mae: 0.2358\n",
      "Epoch 75/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3368 - mae: 0.4515 - val_loss: 0.1286 - val_mae: 0.2345\n",
      "Epoch 76/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3321 - mae: 0.4491 - val_loss: 0.1274 - val_mae: 0.2332\n",
      "Epoch 77/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3275 - mae: 0.4467 - val_loss: 0.1262 - val_mae: 0.2319\n",
      "Epoch 78/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3230 - mae: 0.4443 - val_loss: 0.1251 - val_mae: 0.2309\n",
      "Epoch 79/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3185 - mae: 0.4420 - val_loss: 0.1240 - val_mae: 0.2305\n",
      "Epoch 80/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3140 - mae: 0.4401 - val_loss: 0.1230 - val_mae: 0.2300\n",
      "Epoch 81/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3097 - mae: 0.4381 - val_loss: 0.1220 - val_mae: 0.2295\n",
      "Epoch 82/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3053 - mae: 0.4361 - val_loss: 0.1211 - val_mae: 0.2290\n",
      "Epoch 83/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3011 - mae: 0.4341 - val_loss: 0.1203 - val_mae: 0.2285\n",
      "Epoch 84/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2969 - mae: 0.4321 - val_loss: 0.1195 - val_mae: 0.2283\n",
      "Epoch 85/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2928 - mae: 0.4301 - val_loss: 0.1187 - val_mae: 0.2281\n",
      "Epoch 86/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.2888 - mae: 0.4280 - val_loss: 0.1180 - val_mae: 0.2279\n",
      "Epoch 87/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2849 - mae: 0.4260 - val_loss: 0.1174 - val_mae: 0.2277\n",
      "Epoch 88/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2810 - mae: 0.4240 - val_loss: 0.1168 - val_mae: 0.2284\n",
      "Epoch 89/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2772 - mae: 0.4219 - val_loss: 0.1162 - val_mae: 0.2294\n",
      "Epoch 90/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2736 - mae: 0.4199 - val_loss: 0.1157 - val_mae: 0.2303\n",
      "Epoch 91/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2700 - mae: 0.4178 - val_loss: 0.1152 - val_mae: 0.2312\n",
      "Epoch 92/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2665 - mae: 0.4158 - val_loss: 0.1148 - val_mae: 0.2321\n",
      "Epoch 93/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2631 - mae: 0.4138 - val_loss: 0.1144 - val_mae: 0.2330\n",
      "Epoch 94/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2598 - mae: 0.4118 - val_loss: 0.1141 - val_mae: 0.2338\n",
      "Epoch 95/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2566 - mae: 0.4098 - val_loss: 0.1138 - val_mae: 0.2346\n",
      "Epoch 96/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2535 - mae: 0.4078 - val_loss: 0.1135 - val_mae: 0.2353\n",
      "Epoch 97/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2505 - mae: 0.4058 - val_loss: 0.1133 - val_mae: 0.2360\n",
      "Epoch 98/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2475 - mae: 0.4038 - val_loss: 0.1130 - val_mae: 0.2367\n",
      "Epoch 99/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2447 - mae: 0.4019 - val_loss: 0.1129 - val_mae: 0.2374\n",
      "Epoch 100/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2420 - mae: 0.4000 - val_loss: 0.1127 - val_mae: 0.2380\n",
      "Epoch 101/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2394 - mae: 0.3981 - val_loss: 0.1126 - val_mae: 0.2386\n",
      "Epoch 102/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2368 - mae: 0.3962 - val_loss: 0.1125 - val_mae: 0.2391\n",
      "Epoch 103/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2344 - mae: 0.3943 - val_loss: 0.1124 - val_mae: 0.2396\n",
      "Epoch 104/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2320 - mae: 0.3926 - val_loss: 0.1123 - val_mae: 0.2401\n",
      "Epoch 105/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2297 - mae: 0.3911 - val_loss: 0.1123 - val_mae: 0.2406\n",
      "Epoch 106/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2275 - mae: 0.3897 - val_loss: 0.1123 - val_mae: 0.2411\n",
      "Epoch 107/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2254 - mae: 0.3882 - val_loss: 0.1123 - val_mae: 0.2415\n",
      "Epoch 108/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2234 - mae: 0.3868 - val_loss: 0.1123 - val_mae: 0.2419\n",
      "Epoch 109/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2214 - mae: 0.3854 - val_loss: 0.1123 - val_mae: 0.2422\n",
      "Epoch 110/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.2195 - mae: 0.3840 - val_loss: 0.1124 - val_mae: 0.2426\n",
      "Epoch 111/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2177 - mae: 0.3825 - val_loss: 0.1124 - val_mae: 0.2429\n",
      "Epoch 112/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2159 - mae: 0.3812 - val_loss: 0.1125 - val_mae: 0.2432\n",
      "Epoch 113/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2142 - mae: 0.3798 - val_loss: 0.1125 - val_mae: 0.2434\n",
      "Epoch 114/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2126 - mae: 0.3784 - val_loss: 0.1126 - val_mae: 0.2437\n",
      "Epoch 115/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2110 - mae: 0.3770 - val_loss: 0.1127 - val_mae: 0.2439\n",
      "Epoch 116/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2095 - mae: 0.3757 - val_loss: 0.1128 - val_mae: 0.2441\n",
      "Epoch 117/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2080 - mae: 0.3743 - val_loss: 0.1129 - val_mae: 0.2443\n",
      "Epoch 118/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2066 - mae: 0.3730 - val_loss: 0.1130 - val_mae: 0.2444\n",
      "Epoch 119/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2052 - mae: 0.3717 - val_loss: 0.1131 - val_mae: 0.2446\n",
      "Epoch 120/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2039 - mae: 0.3704 - val_loss: 0.1131 - val_mae: 0.2447\n",
      "Epoch 121/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2026 - mae: 0.3692 - val_loss: 0.1132 - val_mae: 0.2449\n",
      "Epoch 122/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2014 - mae: 0.3680 - val_loss: 0.1133 - val_mae: 0.2451\n",
      "Epoch 123/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2002 - mae: 0.3669 - val_loss: 0.1134 - val_mae: 0.2453\n",
      "Epoch 124/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1990 - mae: 0.3657 - val_loss: 0.1135 - val_mae: 0.2455\n",
      "Epoch 125/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1979 - mae: 0.3645 - val_loss: 0.1136 - val_mae: 0.2457\n",
      "Epoch 126/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1968 - mae: 0.3634 - val_loss: 0.1137 - val_mae: 0.2458\n",
      "Epoch 127/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1957 - mae: 0.3622 - val_loss: 0.1138 - val_mae: 0.2460\n",
      "Epoch 128/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1946 - mae: 0.3611 - val_loss: 0.1139 - val_mae: 0.2461\n",
      "Epoch 129/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1936 - mae: 0.3600 - val_loss: 0.1140 - val_mae: 0.2462\n",
      "Epoch 130/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1926 - mae: 0.3588 - val_loss: 0.1140 - val_mae: 0.2463\n",
      "Epoch 131/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1917 - mae: 0.3577 - val_loss: 0.1141 - val_mae: 0.2464\n",
      "Epoch 132/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1907 - mae: 0.3566 - val_loss: 0.1141 - val_mae: 0.2464\n",
      "Epoch 133/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1898 - mae: 0.3555 - val_loss: 0.1142 - val_mae: 0.2464\n",
      "Epoch 134/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1889 - mae: 0.3544 - val_loss: 0.1142 - val_mae: 0.2465\n",
      "Epoch 135/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1880 - mae: 0.3534 - val_loss: 0.1143 - val_mae: 0.2465\n",
      "Epoch 136/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1871 - mae: 0.3523 - val_loss: 0.1143 - val_mae: 0.2465\n",
      "Epoch 137/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1862 - mae: 0.3512 - val_loss: 0.1144 - val_mae: 0.2464\n",
      "Epoch 138/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1854 - mae: 0.3502 - val_loss: 0.1144 - val_mae: 0.2464\n",
      "Epoch 139/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1846 - mae: 0.3492 - val_loss: 0.1144 - val_mae: 0.2463\n",
      "Epoch 140/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1838 - mae: 0.3481 - val_loss: 0.1144 - val_mae: 0.2463\n",
      "Epoch 141/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1830 - mae: 0.3471 - val_loss: 0.1144 - val_mae: 0.2462\n",
      "Epoch 142/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1822 - mae: 0.3461 - val_loss: 0.1144 - val_mae: 0.2461\n",
      "Epoch 143/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1814 - mae: 0.3451 - val_loss: 0.1144 - val_mae: 0.2460\n",
      "Epoch 144/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1806 - mae: 0.3440 - val_loss: 0.1143 - val_mae: 0.2458\n",
      "Epoch 145/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1799 - mae: 0.3431 - val_loss: 0.1143 - val_mae: 0.2457\n",
      "Epoch 146/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1792 - mae: 0.3421 - val_loss: 0.1142 - val_mae: 0.2455\n",
      "Epoch 147/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1784 - mae: 0.3411 - val_loss: 0.1142 - val_mae: 0.2453\n",
      "Epoch 148/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1777 - mae: 0.3401 - val_loss: 0.1141 - val_mae: 0.2452\n",
      "Epoch 149/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1770 - mae: 0.3391 - val_loss: 0.1141 - val_mae: 0.2450\n",
      "Epoch 150/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1763 - mae: 0.3382 - val_loss: 0.1140 - val_mae: 0.2448\n",
      "Epoch 151/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1756 - mae: 0.3372 - val_loss: 0.1139 - val_mae: 0.2445\n",
      "Epoch 152/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1749 - mae: 0.3363 - val_loss: 0.1138 - val_mae: 0.2443\n",
      "Epoch 153/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1742 - mae: 0.3353 - val_loss: 0.1137 - val_mae: 0.2440\n",
      "Epoch 154/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1736 - mae: 0.3344 - val_loss: 0.1136 - val_mae: 0.2438\n",
      "Epoch 155/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1729 - mae: 0.3335 - val_loss: 0.1135 - val_mae: 0.2435\n",
      "Epoch 156/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1722 - mae: 0.3325 - val_loss: 0.1134 - val_mae: 0.2432\n",
      "Epoch 157/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1716 - mae: 0.3316 - val_loss: 0.1132 - val_mae: 0.2429\n",
      "Epoch 158/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1709 - mae: 0.3307 - val_loss: 0.1131 - val_mae: 0.2427\n",
      "Epoch 159/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1703 - mae: 0.3299 - val_loss: 0.1129 - val_mae: 0.2427\n",
      "Epoch 160/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1697 - mae: 0.3291 - val_loss: 0.1128 - val_mae: 0.2426\n",
      "Epoch 161/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1691 - mae: 0.3284 - val_loss: 0.1126 - val_mae: 0.2425\n",
      "Epoch 162/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1684 - mae: 0.3277 - val_loss: 0.1125 - val_mae: 0.2424\n",
      "Epoch 163/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1678 - mae: 0.3270 - val_loss: 0.1123 - val_mae: 0.2423\n",
      "Epoch 164/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1672 - mae: 0.3263 - val_loss: 0.1121 - val_mae: 0.2422\n",
      "Epoch 165/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1666 - mae: 0.3257 - val_loss: 0.1119 - val_mae: 0.2421\n",
      "Epoch 166/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1660 - mae: 0.3252 - val_loss: 0.1117 - val_mae: 0.2419\n",
      "Epoch 167/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1654 - mae: 0.3246 - val_loss: 0.1115 - val_mae: 0.2417\n",
      "Epoch 168/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1648 - mae: 0.3241 - val_loss: 0.1113 - val_mae: 0.2416\n",
      "Epoch 169/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1643 - mae: 0.3235 - val_loss: 0.1111 - val_mae: 0.2414\n",
      "Epoch 170/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1637 - mae: 0.3230 - val_loss: 0.1108 - val_mae: 0.2412\n",
      "Epoch 171/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1631 - mae: 0.3224 - val_loss: 0.1106 - val_mae: 0.2410\n",
      "Epoch 172/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1625 - mae: 0.3219 - val_loss: 0.1104 - val_mae: 0.2409\n",
      "Epoch 173/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1620 - mae: 0.3213 - val_loss: 0.1101 - val_mae: 0.2407\n",
      "Epoch 174/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1614 - mae: 0.3208 - val_loss: 0.1099 - val_mae: 0.2405\n",
      "Epoch 175/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1609 - mae: 0.3203 - val_loss: 0.1096 - val_mae: 0.2403\n",
      "Epoch 176/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1603 - mae: 0.3197 - val_loss: 0.1094 - val_mae: 0.2401\n",
      "Epoch 177/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1598 - mae: 0.3192 - val_loss: 0.1091 - val_mae: 0.2398\n",
      "Epoch 178/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1592 - mae: 0.3187 - val_loss: 0.1088 - val_mae: 0.2396\n",
      "Epoch 179/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1587 - mae: 0.3181 - val_loss: 0.1086 - val_mae: 0.2394\n",
      "Epoch 180/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1582 - mae: 0.3176 - val_loss: 0.1083 - val_mae: 0.2391\n",
      "Epoch 181/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1577 - mae: 0.3171 - val_loss: 0.1080 - val_mae: 0.2388\n",
      "Epoch 182/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1571 - mae: 0.3166 - val_loss: 0.1077 - val_mae: 0.2386\n",
      "Epoch 183/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1566 - mae: 0.3161 - val_loss: 0.1074 - val_mae: 0.2383\n",
      "Epoch 184/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1561 - mae: 0.3155 - val_loss: 0.1071 - val_mae: 0.2380\n",
      "Epoch 185/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1556 - mae: 0.3150 - val_loss: 0.1068 - val_mae: 0.2377\n",
      "Epoch 186/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1551 - mae: 0.3145 - val_loss: 0.1065 - val_mae: 0.2374\n",
      "Epoch 187/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1546 - mae: 0.3140 - val_loss: 0.1062 - val_mae: 0.2371\n",
      "Epoch 188/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1541 - mae: 0.3135 - val_loss: 0.1059 - val_mae: 0.2368\n",
      "Epoch 189/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1536 - mae: 0.3131 - val_loss: 0.1056 - val_mae: 0.2364\n",
      "Epoch 190/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1531 - mae: 0.3126 - val_loss: 0.1053 - val_mae: 0.2361\n",
      "Epoch 191/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1526 - mae: 0.3122 - val_loss: 0.1049 - val_mae: 0.2357\n",
      "Epoch 192/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1521 - mae: 0.3117 - val_loss: 0.1046 - val_mae: 0.2354\n",
      "Epoch 193/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1516 - mae: 0.3113 - val_loss: 0.1043 - val_mae: 0.2350\n",
      "Epoch 194/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1511 - mae: 0.3108 - val_loss: 0.1040 - val_mae: 0.2347\n",
      "Epoch 195/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1507 - mae: 0.3104 - val_loss: 0.1036 - val_mae: 0.2343\n",
      "Epoch 196/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1502 - mae: 0.3099 - val_loss: 0.1033 - val_mae: 0.2339\n",
      "Epoch 197/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1497 - mae: 0.3094 - val_loss: 0.1030 - val_mae: 0.2336\n",
      "Epoch 198/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1492 - mae: 0.3090 - val_loss: 0.1026 - val_mae: 0.2332\n",
      "Epoch 199/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1488 - mae: 0.3085 - val_loss: 0.1023 - val_mae: 0.2328\n",
      "Epoch 200/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1483 - mae: 0.3081 - val_loss: 0.1019 - val_mae: 0.2324\n",
      "Epoch 1/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - loss: 0.7615 - mae: 0.7561 - val_loss: 0.4344 - val_mae: 0.6089\n",
      "Epoch 2/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7534 - mae: 0.7512 - val_loss: 0.4253 - val_mae: 0.6026\n",
      "Epoch 3/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7453 - mae: 0.7463 - val_loss: 0.4164 - val_mae: 0.5963\n",
      "Epoch 4/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7372 - mae: 0.7414 - val_loss: 0.4075 - val_mae: 0.5899\n",
      "Epoch 5/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7291 - mae: 0.7364 - val_loss: 0.3987 - val_mae: 0.5834\n",
      "Epoch 6/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.7211 - mae: 0.7314 - val_loss: 0.3900 - val_mae: 0.5769\n",
      "Epoch 7/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7131 - mae: 0.7264 - val_loss: 0.3814 - val_mae: 0.5703\n",
      "Epoch 8/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7052 - mae: 0.7213 - val_loss: 0.3729 - val_mae: 0.5637\n",
      "Epoch 9/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6973 - mae: 0.7162 - val_loss: 0.3645 - val_mae: 0.5571\n",
      "Epoch 10/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6895 - mae: 0.7111 - val_loss: 0.3562 - val_mae: 0.5504\n",
      "Epoch 11/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6817 - mae: 0.7059 - val_loss: 0.3481 - val_mae: 0.5437\n",
      "Epoch 12/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.6740 - mae: 0.7007 - val_loss: 0.3401 - val_mae: 0.5369\n",
      "Epoch 13/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6663 - mae: 0.6955 - val_loss: 0.3323 - val_mae: 0.5302\n",
      "Epoch 14/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6587 - mae: 0.6903 - val_loss: 0.3246 - val_mae: 0.5234\n",
      "Epoch 15/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6512 - mae: 0.6850 - val_loss: 0.3171 - val_mae: 0.5166\n",
      "Epoch 16/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6437 - mae: 0.6797 - val_loss: 0.3097 - val_mae: 0.5098\n",
      "Epoch 17/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6364 - mae: 0.6744 - val_loss: 0.3025 - val_mae: 0.5029\n",
      "Epoch 18/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.6291 - mae: 0.6692 - val_loss: 0.2954 - val_mae: 0.4961\n",
      "Epoch 19/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6219 - mae: 0.6639 - val_loss: 0.2886 - val_mae: 0.4893\n",
      "Epoch 20/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6148 - mae: 0.6585 - val_loss: 0.2819 - val_mae: 0.4825\n",
      "Epoch 21/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6077 - mae: 0.6532 - val_loss: 0.2754 - val_mae: 0.4757\n",
      "Epoch 22/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6008 - mae: 0.6479 - val_loss: 0.2690 - val_mae: 0.4689\n",
      "Epoch 23/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5940 - mae: 0.6426 - val_loss: 0.2629 - val_mae: 0.4621\n",
      "Epoch 24/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5872 - mae: 0.6373 - val_loss: 0.2569 - val_mae: 0.4554\n",
      "Epoch 25/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5806 - mae: 0.6321 - val_loss: 0.2512 - val_mae: 0.4487\n",
      "Epoch 26/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5741 - mae: 0.6268 - val_loss: 0.2456 - val_mae: 0.4420\n",
      "Epoch 27/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5677 - mae: 0.6215 - val_loss: 0.2402 - val_mae: 0.4354\n",
      "Epoch 28/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5614 - mae: 0.6163 - val_loss: 0.2350 - val_mae: 0.4288\n",
      "Epoch 29/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5552 - mae: 0.6111 - val_loss: 0.2300 - val_mae: 0.4222\n",
      "Epoch 30/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5492 - mae: 0.6059 - val_loss: 0.2252 - val_mae: 0.4157\n",
      "Epoch 31/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5432 - mae: 0.6008 - val_loss: 0.2206 - val_mae: 0.4092\n",
      "Epoch 32/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5374 - mae: 0.5957 - val_loss: 0.2162 - val_mae: 0.4028\n",
      "Epoch 33/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5317 - mae: 0.5907 - val_loss: 0.2119 - val_mae: 0.3965\n",
      "Epoch 34/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5261 - mae: 0.5863 - val_loss: 0.2078 - val_mae: 0.3902\n",
      "Epoch 35/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.5206 - mae: 0.5819 - val_loss: 0.2039 - val_mae: 0.3840\n",
      "Epoch 36/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5153 - mae: 0.5775 - val_loss: 0.2002 - val_mae: 0.3778\n",
      "Epoch 37/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5101 - mae: 0.5732 - val_loss: 0.1967 - val_mae: 0.3717\n",
      "Epoch 38/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5050 - mae: 0.5689 - val_loss: 0.1933 - val_mae: 0.3657\n",
      "Epoch 39/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5000 - mae: 0.5647 - val_loss: 0.1901 - val_mae: 0.3598\n",
      "Epoch 40/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4952 - mae: 0.5605 - val_loss: 0.1870 - val_mae: 0.3539\n",
      "Epoch 41/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4904 - mae: 0.5563 - val_loss: 0.1841 - val_mae: 0.3482\n",
      "Epoch 42/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4858 - mae: 0.5522 - val_loss: 0.1814 - val_mae: 0.3425\n",
      "Epoch 43/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4813 - mae: 0.5481 - val_loss: 0.1788 - val_mae: 0.3369\n",
      "Epoch 44/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4769 - mae: 0.5441 - val_loss: 0.1763 - val_mae: 0.3313\n",
      "Epoch 45/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4727 - mae: 0.5401 - val_loss: 0.1740 - val_mae: 0.3259\n",
      "Epoch 46/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4685 - mae: 0.5362 - val_loss: 0.1718 - val_mae: 0.3206\n",
      "Epoch 47/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4645 - mae: 0.5324 - val_loss: 0.1697 - val_mae: 0.3166\n",
      "Epoch 48/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4606 - mae: 0.5296 - val_loss: 0.1678 - val_mae: 0.3135\n",
      "Epoch 49/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4568 - mae: 0.5270 - val_loss: 0.1660 - val_mae: 0.3104\n",
      "Epoch 50/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4530 - mae: 0.5245 - val_loss: 0.1643 - val_mae: 0.3073\n",
      "Epoch 51/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4494 - mae: 0.5220 - val_loss: 0.1627 - val_mae: 0.3043\n",
      "Epoch 52/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4459 - mae: 0.5196 - val_loss: 0.1612 - val_mae: 0.3013\n",
      "Epoch 53/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4425 - mae: 0.5172 - val_loss: 0.1598 - val_mae: 0.2983\n",
      "Epoch 54/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4392 - mae: 0.5148 - val_loss: 0.1584 - val_mae: 0.2955\n",
      "Epoch 55/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4360 - mae: 0.5124 - val_loss: 0.1572 - val_mae: 0.2926\n",
      "Epoch 56/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4328 - mae: 0.5101 - val_loss: 0.1561 - val_mae: 0.2898\n",
      "Epoch 57/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4298 - mae: 0.5078 - val_loss: 0.1550 - val_mae: 0.2871\n",
      "Epoch 58/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.4268 - mae: 0.5056 - val_loss: 0.1540 - val_mae: 0.2844\n",
      "Epoch 59/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4239 - mae: 0.5034 - val_loss: 0.1530 - val_mae: 0.2818\n",
      "Epoch 60/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4211 - mae: 0.5013 - val_loss: 0.1521 - val_mae: 0.2798\n",
      "Epoch 61/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4183 - mae: 0.4996 - val_loss: 0.1513 - val_mae: 0.2786\n",
      "Epoch 62/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4156 - mae: 0.4982 - val_loss: 0.1505 - val_mae: 0.2773\n",
      "Epoch 63/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4130 - mae: 0.4969 - val_loss: 0.1498 - val_mae: 0.2761\n",
      "Epoch 64/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4105 - mae: 0.4957 - val_loss: 0.1491 - val_mae: 0.2748\n",
      "Epoch 65/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4080 - mae: 0.4944 - val_loss: 0.1485 - val_mae: 0.2736\n",
      "Epoch 66/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4055 - mae: 0.4932 - val_loss: 0.1479 - val_mae: 0.2725\n",
      "Epoch 67/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4031 - mae: 0.4920 - val_loss: 0.1473 - val_mae: 0.2713\n",
      "Epoch 68/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4008 - mae: 0.4908 - val_loss: 0.1467 - val_mae: 0.2702\n",
      "Epoch 69/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3985 - mae: 0.4897 - val_loss: 0.1462 - val_mae: 0.2691\n",
      "Epoch 70/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3963 - mae: 0.4886 - val_loss: 0.1457 - val_mae: 0.2681\n",
      "Epoch 71/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3941 - mae: 0.4875 - val_loss: 0.1452 - val_mae: 0.2670\n",
      "Epoch 72/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3920 - mae: 0.4864 - val_loss: 0.1448 - val_mae: 0.2660\n",
      "Epoch 73/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3899 - mae: 0.4854 - val_loss: 0.1443 - val_mae: 0.2650\n",
      "Epoch 74/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3878 - mae: 0.4843 - val_loss: 0.1439 - val_mae: 0.2640\n",
      "Epoch 75/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3858 - mae: 0.4834 - val_loss: 0.1434 - val_mae: 0.2630\n",
      "Epoch 76/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.3838 - mae: 0.4824 - val_loss: 0.1430 - val_mae: 0.2621\n",
      "Epoch 77/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3818 - mae: 0.4815 - val_loss: 0.1426 - val_mae: 0.2612\n",
      "Epoch 78/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3799 - mae: 0.4805 - val_loss: 0.1422 - val_mae: 0.2603\n",
      "Epoch 79/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3780 - mae: 0.4797 - val_loss: 0.1418 - val_mae: 0.2594\n",
      "Epoch 80/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3761 - mae: 0.4788 - val_loss: 0.1414 - val_mae: 0.2586\n",
      "Epoch 81/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3743 - mae: 0.4780 - val_loss: 0.1410 - val_mae: 0.2578\n",
      "Epoch 82/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3725 - mae: 0.4771 - val_loss: 0.1406 - val_mae: 0.2570\n",
      "Epoch 83/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3707 - mae: 0.4763 - val_loss: 0.1402 - val_mae: 0.2562\n",
      "Epoch 84/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3689 - mae: 0.4756 - val_loss: 0.1398 - val_mae: 0.2554\n",
      "Epoch 85/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3672 - mae: 0.4748 - val_loss: 0.1395 - val_mae: 0.2547\n",
      "Epoch 86/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3655 - mae: 0.4741 - val_loss: 0.1391 - val_mae: 0.2539\n",
      "Epoch 87/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3638 - mae: 0.4734 - val_loss: 0.1387 - val_mae: 0.2532\n",
      "Epoch 88/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3621 - mae: 0.4727 - val_loss: 0.1383 - val_mae: 0.2525\n",
      "Epoch 89/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3605 - mae: 0.4720 - val_loss: 0.1379 - val_mae: 0.2518\n",
      "Epoch 90/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3588 - mae: 0.4713 - val_loss: 0.1375 - val_mae: 0.2511\n",
      "Epoch 91/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3572 - mae: 0.4707 - val_loss: 0.1371 - val_mae: 0.2505\n",
      "Epoch 92/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3557 - mae: 0.4701 - val_loss: 0.1367 - val_mae: 0.2498\n",
      "Epoch 93/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3541 - mae: 0.4695 - val_loss: 0.1363 - val_mae: 0.2492\n",
      "Epoch 94/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3526 - mae: 0.4689 - val_loss: 0.1359 - val_mae: 0.2486\n",
      "Epoch 95/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3510 - mae: 0.4683 - val_loss: 0.1355 - val_mae: 0.2480\n",
      "Epoch 96/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3495 - mae: 0.4677 - val_loss: 0.1351 - val_mae: 0.2474\n",
      "Epoch 97/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3480 - mae: 0.4672 - val_loss: 0.1347 - val_mae: 0.2468\n",
      "Epoch 98/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3466 - mae: 0.4666 - val_loss: 0.1343 - val_mae: 0.2462\n",
      "Epoch 99/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3451 - mae: 0.4661 - val_loss: 0.1339 - val_mae: 0.2457\n",
      "Epoch 100/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3437 - mae: 0.4656 - val_loss: 0.1335 - val_mae: 0.2451\n",
      "Epoch 101/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3423 - mae: 0.4651 - val_loss: 0.1330 - val_mae: 0.2446\n",
      "Epoch 102/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3409 - mae: 0.4646 - val_loss: 0.1326 - val_mae: 0.2441\n",
      "Epoch 103/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3395 - mae: 0.4641 - val_loss: 0.1322 - val_mae: 0.2435\n",
      "Epoch 104/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3382 - mae: 0.4636 - val_loss: 0.1318 - val_mae: 0.2430\n",
      "Epoch 105/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3368 - mae: 0.4631 - val_loss: 0.1314 - val_mae: 0.2425\n",
      "Epoch 106/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3355 - mae: 0.4626 - val_loss: 0.1310 - val_mae: 0.2420\n",
      "Epoch 107/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3342 - mae: 0.4622 - val_loss: 0.1306 - val_mae: 0.2415\n",
      "Epoch 108/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3329 - mae: 0.4617 - val_loss: 0.1302 - val_mae: 0.2410\n",
      "Epoch 109/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3316 - mae: 0.4613 - val_loss: 0.1298 - val_mae: 0.2405\n",
      "Epoch 110/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3303 - mae: 0.4609 - val_loss: 0.1294 - val_mae: 0.2400\n",
      "Epoch 111/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3291 - mae: 0.4604 - val_loss: 0.1290 - val_mae: 0.2396\n",
      "Epoch 112/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3279 - mae: 0.4600 - val_loss: 0.1287 - val_mae: 0.2391\n",
      "Epoch 113/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3266 - mae: 0.4596 - val_loss: 0.1283 - val_mae: 0.2386\n",
      "Epoch 114/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3254 - mae: 0.4591 - val_loss: 0.1279 - val_mae: 0.2382\n",
      "Epoch 115/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3243 - mae: 0.4587 - val_loss: 0.1275 - val_mae: 0.2377\n",
      "Epoch 116/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3231 - mae: 0.4583 - val_loss: 0.1271 - val_mae: 0.2373\n",
      "Epoch 117/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3219 - mae: 0.4579 - val_loss: 0.1268 - val_mae: 0.2368\n",
      "Epoch 118/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3208 - mae: 0.4575 - val_loss: 0.1264 - val_mae: 0.2364\n",
      "Epoch 119/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3197 - mae: 0.4571 - val_loss: 0.1260 - val_mae: 0.2359\n",
      "Epoch 120/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3185 - mae: 0.4567 - val_loss: 0.1257 - val_mae: 0.2355\n",
      "Epoch 121/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3174 - mae: 0.4563 - val_loss: 0.1253 - val_mae: 0.2350\n",
      "Epoch 122/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3164 - mae: 0.4559 - val_loss: 0.1250 - val_mae: 0.2346\n",
      "Epoch 123/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3153 - mae: 0.4555 - val_loss: 0.1246 - val_mae: 0.2342\n",
      "Epoch 124/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3142 - mae: 0.4551 - val_loss: 0.1243 - val_mae: 0.2337\n",
      "Epoch 125/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3132 - mae: 0.4547 - val_loss: 0.1240 - val_mae: 0.2333\n",
      "Epoch 126/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3121 - mae: 0.4543 - val_loss: 0.1236 - val_mae: 0.2329\n",
      "Epoch 127/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3111 - mae: 0.4539 - val_loss: 0.1233 - val_mae: 0.2324\n",
      "Epoch 128/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3101 - mae: 0.4535 - val_loss: 0.1230 - val_mae: 0.2320\n",
      "Epoch 129/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3091 - mae: 0.4531 - val_loss: 0.1227 - val_mae: 0.2316\n",
      "Epoch 130/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3081 - mae: 0.4527 - val_loss: 0.1224 - val_mae: 0.2312\n",
      "Epoch 131/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3071 - mae: 0.4523 - val_loss: 0.1221 - val_mae: 0.2307\n",
      "Epoch 132/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3062 - mae: 0.4519 - val_loss: 0.1218 - val_mae: 0.2303\n",
      "Epoch 133/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3052 - mae: 0.4516 - val_loss: 0.1215 - val_mae: 0.2299\n",
      "Epoch 134/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3043 - mae: 0.4512 - val_loss: 0.1212 - val_mae: 0.2295\n",
      "Epoch 135/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3034 - mae: 0.4508 - val_loss: 0.1209 - val_mae: 0.2291\n",
      "Epoch 136/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3024 - mae: 0.4504 - val_loss: 0.1206 - val_mae: 0.2286\n",
      "Epoch 137/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3015 - mae: 0.4500 - val_loss: 0.1203 - val_mae: 0.2282\n",
      "Epoch 138/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3006 - mae: 0.4496 - val_loss: 0.1200 - val_mae: 0.2278\n",
      "Epoch 139/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2997 - mae: 0.4492 - val_loss: 0.1198 - val_mae: 0.2274\n",
      "Epoch 140/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2989 - mae: 0.4488 - val_loss: 0.1195 - val_mae: 0.2270\n",
      "Epoch 141/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2980 - mae: 0.4485 - val_loss: 0.1192 - val_mae: 0.2266\n",
      "Epoch 142/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2971 - mae: 0.4481 - val_loss: 0.1190 - val_mae: 0.2262\n",
      "Epoch 143/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2963 - mae: 0.4477 - val_loss: 0.1187 - val_mae: 0.2258\n",
      "Epoch 144/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2954 - mae: 0.4473 - val_loss: 0.1185 - val_mae: 0.2253\n",
      "Epoch 145/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2946 - mae: 0.4469 - val_loss: 0.1182 - val_mae: 0.2249\n",
      "Epoch 146/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2938 - mae: 0.4465 - val_loss: 0.1180 - val_mae: 0.2245\n",
      "Epoch 147/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2930 - mae: 0.4461 - val_loss: 0.1177 - val_mae: 0.2241\n",
      "Epoch 148/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2922 - mae: 0.4458 - val_loss: 0.1175 - val_mae: 0.2237\n",
      "Epoch 149/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2914 - mae: 0.4454 - val_loss: 0.1173 - val_mae: 0.2233\n",
      "Epoch 150/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2906 - mae: 0.4450 - val_loss: 0.1170 - val_mae: 0.2229\n",
      "Epoch 151/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2898 - mae: 0.4446 - val_loss: 0.1168 - val_mae: 0.2225\n",
      "Epoch 152/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2890 - mae: 0.4442 - val_loss: 0.1166 - val_mae: 0.2221\n",
      "Epoch 153/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2882 - mae: 0.4438 - val_loss: 0.1164 - val_mae: 0.2217\n",
      "Epoch 154/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2875 - mae: 0.4434 - val_loss: 0.1162 - val_mae: 0.2213\n",
      "Epoch 155/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2867 - mae: 0.4431 - val_loss: 0.1160 - val_mae: 0.2209\n",
      "Epoch 156/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2860 - mae: 0.4427 - val_loss: 0.1157 - val_mae: 0.2205\n",
      "Epoch 157/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2852 - mae: 0.4423 - val_loss: 0.1155 - val_mae: 0.2203\n",
      "Epoch 158/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2845 - mae: 0.4419 - val_loss: 0.1153 - val_mae: 0.2202\n",
      "Epoch 159/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2838 - mae: 0.4415 - val_loss: 0.1151 - val_mae: 0.2201\n",
      "Epoch 160/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2831 - mae: 0.4412 - val_loss: 0.1149 - val_mae: 0.2201\n",
      "Epoch 161/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2824 - mae: 0.4408 - val_loss: 0.1147 - val_mae: 0.2200\n",
      "Epoch 162/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2817 - mae: 0.4406 - val_loss: 0.1145 - val_mae: 0.2199\n",
      "Epoch 163/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2810 - mae: 0.4403 - val_loss: 0.1143 - val_mae: 0.2199\n",
      "Epoch 164/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2803 - mae: 0.4400 - val_loss: 0.1142 - val_mae: 0.2198\n",
      "Epoch 165/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2796 - mae: 0.4397 - val_loss: 0.1140 - val_mae: 0.2197\n",
      "Epoch 166/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2789 - mae: 0.4395 - val_loss: 0.1138 - val_mae: 0.2197\n",
      "Epoch 167/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2782 - mae: 0.4392 - val_loss: 0.1136 - val_mae: 0.2196\n",
      "Epoch 168/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2776 - mae: 0.4389 - val_loss: 0.1134 - val_mae: 0.2195\n",
      "Epoch 169/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2769 - mae: 0.4387 - val_loss: 0.1132 - val_mae: 0.2194\n",
      "Epoch 170/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.2763 - mae: 0.4384 - val_loss: 0.1131 - val_mae: 0.2194\n",
      "Epoch 171/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2756 - mae: 0.4381 - val_loss: 0.1129 - val_mae: 0.2193\n",
      "Epoch 172/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2750 - mae: 0.4378 - val_loss: 0.1127 - val_mae: 0.2192\n",
      "Epoch 173/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2743 - mae: 0.4375 - val_loss: 0.1125 - val_mae: 0.2191\n",
      "Epoch 174/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2737 - mae: 0.4373 - val_loss: 0.1124 - val_mae: 0.2190\n",
      "Epoch 175/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2731 - mae: 0.4370 - val_loss: 0.1122 - val_mae: 0.2189\n",
      "Epoch 176/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2724 - mae: 0.4367 - val_loss: 0.1120 - val_mae: 0.2188\n",
      "Epoch 177/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2718 - mae: 0.4364 - val_loss: 0.1119 - val_mae: 0.2187\n",
      "Epoch 178/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2712 - mae: 0.4361 - val_loss: 0.1117 - val_mae: 0.2186\n",
      "Epoch 179/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2706 - mae: 0.4359 - val_loss: 0.1115 - val_mae: 0.2185\n",
      "Epoch 180/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2700 - mae: 0.4356 - val_loss: 0.1114 - val_mae: 0.2184\n",
      "Epoch 181/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2694 - mae: 0.4353 - val_loss: 0.1112 - val_mae: 0.2183\n",
      "Epoch 182/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2688 - mae: 0.4350 - val_loss: 0.1110 - val_mae: 0.2182\n",
      "Epoch 183/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2682 - mae: 0.4347 - val_loss: 0.1109 - val_mae: 0.2181\n",
      "Epoch 184/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2676 - mae: 0.4344 - val_loss: 0.1107 - val_mae: 0.2180\n",
      "Epoch 185/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2670 - mae: 0.4341 - val_loss: 0.1106 - val_mae: 0.2179\n",
      "Epoch 186/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2664 - mae: 0.4338 - val_loss: 0.1104 - val_mae: 0.2178\n",
      "Epoch 187/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2659 - mae: 0.4335 - val_loss: 0.1103 - val_mae: 0.2177\n",
      "Epoch 188/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2653 - mae: 0.4332 - val_loss: 0.1101 - val_mae: 0.2177\n",
      "Epoch 189/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2647 - mae: 0.4330 - val_loss: 0.1100 - val_mae: 0.2177\n",
      "Epoch 190/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2642 - mae: 0.4327 - val_loss: 0.1098 - val_mae: 0.2177\n",
      "Epoch 191/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2636 - mae: 0.4324 - val_loss: 0.1097 - val_mae: 0.2177\n",
      "Epoch 192/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2630 - mae: 0.4321 - val_loss: 0.1095 - val_mae: 0.2177\n",
      "Epoch 193/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2625 - mae: 0.4318 - val_loss: 0.1094 - val_mae: 0.2177\n",
      "Epoch 194/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2619 - mae: 0.4315 - val_loss: 0.1092 - val_mae: 0.2176\n",
      "Epoch 195/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2614 - mae: 0.4312 - val_loss: 0.1091 - val_mae: 0.2176\n",
      "Epoch 196/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2609 - mae: 0.4309 - val_loss: 0.1089 - val_mae: 0.2176\n",
      "Epoch 197/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2603 - mae: 0.4306 - val_loss: 0.1088 - val_mae: 0.2175\n",
      "Epoch 198/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2598 - mae: 0.4303 - val_loss: 0.1086 - val_mae: 0.2175\n",
      "Epoch 199/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2592 - mae: 0.4300 - val_loss: 0.1085 - val_mae: 0.2174\n",
      "Epoch 200/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2587 - mae: 0.4297 - val_loss: 0.1084 - val_mae: 0.2174\n",
      "Epoch 1/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - loss: 0.9598 - mae: 0.8250 - val_loss: 0.6926 - val_mae: 0.7692\n",
      "Epoch 2/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9489 - mae: 0.8188 - val_loss: 0.6805 - val_mae: 0.7610\n",
      "Epoch 3/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.9380 - mae: 0.8125 - val_loss: 0.6684 - val_mae: 0.7527\n",
      "Epoch 4/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9271 - mae: 0.8062 - val_loss: 0.6564 - val_mae: 0.7442\n",
      "Epoch 5/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.9162 - mae: 0.7998 - val_loss: 0.6444 - val_mae: 0.7356\n",
      "Epoch 6/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.9052 - mae: 0.7932 - val_loss: 0.6324 - val_mae: 0.7269\n",
      "Epoch 7/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8943 - mae: 0.7867 - val_loss: 0.6205 - val_mae: 0.7180\n",
      "Epoch 8/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8834 - mae: 0.7800 - val_loss: 0.6086 - val_mae: 0.7090\n",
      "Epoch 9/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8724 - mae: 0.7733 - val_loss: 0.5968 - val_mae: 0.6999\n",
      "Epoch 10/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.8615 - mae: 0.7678 - val_loss: 0.5851 - val_mae: 0.6907\n",
      "Epoch 11/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.8506 - mae: 0.7622 - val_loss: 0.5735 - val_mae: 0.6813\n",
      "Epoch 12/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.8397 - mae: 0.7566 - val_loss: 0.5621 - val_mae: 0.6719\n",
      "Epoch 13/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8289 - mae: 0.7508 - val_loss: 0.5507 - val_mae: 0.6623\n",
      "Epoch 14/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8181 - mae: 0.7450 - val_loss: 0.5395 - val_mae: 0.6527\n",
      "Epoch 15/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8074 - mae: 0.7392 - val_loss: 0.5284 - val_mae: 0.6429\n",
      "Epoch 16/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7968 - mae: 0.7332 - val_loss: 0.5175 - val_mae: 0.6331\n",
      "Epoch 17/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7862 - mae: 0.7272 - val_loss: 0.5067 - val_mae: 0.6232\n",
      "Epoch 18/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7757 - mae: 0.7212 - val_loss: 0.4961 - val_mae: 0.6133\n",
      "Epoch 19/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7654 - mae: 0.7151 - val_loss: 0.4857 - val_mae: 0.6032\n",
      "Epoch 20/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7551 - mae: 0.7090 - val_loss: 0.4754 - val_mae: 0.5932\n",
      "Epoch 21/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7449 - mae: 0.7028 - val_loss: 0.4654 - val_mae: 0.5830\n",
      "Epoch 22/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.7349 - mae: 0.6966 - val_loss: 0.4556 - val_mae: 0.5729\n",
      "Epoch 23/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7250 - mae: 0.6904 - val_loss: 0.4459 - val_mae: 0.5630\n",
      "Epoch 24/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7152 - mae: 0.6841 - val_loss: 0.4365 - val_mae: 0.5542\n",
      "Epoch 25/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7056 - mae: 0.6778 - val_loss: 0.4273 - val_mae: 0.5454\n",
      "Epoch 26/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6961 - mae: 0.6716 - val_loss: 0.4183 - val_mae: 0.5366\n",
      "Epoch 27/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6868 - mae: 0.6653 - val_loss: 0.4095 - val_mae: 0.5279\n",
      "Epoch 28/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.6777 - mae: 0.6590 - val_loss: 0.4009 - val_mae: 0.5192\n",
      "Epoch 29/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.6687 - mae: 0.6528 - val_loss: 0.3925 - val_mae: 0.5105\n",
      "Epoch 30/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6599 - mae: 0.6466 - val_loss: 0.3843 - val_mae: 0.5018\n",
      "Epoch 31/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6513 - mae: 0.6404 - val_loss: 0.3763 - val_mae: 0.4932\n",
      "Epoch 32/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6428 - mae: 0.6342 - val_loss: 0.3685 - val_mae: 0.4846\n",
      "Epoch 33/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6346 - mae: 0.6281 - val_loss: 0.3609 - val_mae: 0.4761\n",
      "Epoch 34/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.6265 - mae: 0.6220 - val_loss: 0.3535 - val_mae: 0.4677\n",
      "Epoch 35/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6186 - mae: 0.6160 - val_loss: 0.3463 - val_mae: 0.4599\n",
      "Epoch 36/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6108 - mae: 0.6103 - val_loss: 0.3392 - val_mae: 0.4542\n",
      "Epoch 37/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6032 - mae: 0.6059 - val_loss: 0.3323 - val_mae: 0.4485\n",
      "Epoch 38/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5958 - mae: 0.6016 - val_loss: 0.3256 - val_mae: 0.4428\n",
      "Epoch 39/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5886 - mae: 0.5973 - val_loss: 0.3191 - val_mae: 0.4376\n",
      "Epoch 40/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5815 - mae: 0.5934 - val_loss: 0.3126 - val_mae: 0.4326\n",
      "Epoch 41/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5746 - mae: 0.5895 - val_loss: 0.3064 - val_mae: 0.4276\n",
      "Epoch 42/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5678 - mae: 0.5857 - val_loss: 0.3002 - val_mae: 0.4226\n",
      "Epoch 43/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5611 - mae: 0.5819 - val_loss: 0.2942 - val_mae: 0.4175\n",
      "Epoch 44/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5546 - mae: 0.5781 - val_loss: 0.2884 - val_mae: 0.4124\n",
      "Epoch 45/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5483 - mae: 0.5743 - val_loss: 0.2826 - val_mae: 0.4073\n",
      "Epoch 46/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5420 - mae: 0.5706 - val_loss: 0.2770 - val_mae: 0.4022\n",
      "Epoch 47/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5358 - mae: 0.5668 - val_loss: 0.2715 - val_mae: 0.3970\n",
      "Epoch 48/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5298 - mae: 0.5631 - val_loss: 0.2661 - val_mae: 0.3918\n",
      "Epoch 49/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5238 - mae: 0.5594 - val_loss: 0.2609 - val_mae: 0.3866\n",
      "Epoch 50/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5179 - mae: 0.5557 - val_loss: 0.2557 - val_mae: 0.3814\n",
      "Epoch 51/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5121 - mae: 0.5520 - val_loss: 0.2507 - val_mae: 0.3766\n",
      "Epoch 52/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5063 - mae: 0.5488 - val_loss: 0.2457 - val_mae: 0.3721\n",
      "Epoch 53/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5006 - mae: 0.5456 - val_loss: 0.2409 - val_mae: 0.3675\n",
      "Epoch 54/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4950 - mae: 0.5424 - val_loss: 0.2362 - val_mae: 0.3629\n",
      "Epoch 55/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4894 - mae: 0.5392 - val_loss: 0.2316 - val_mae: 0.3583\n",
      "Epoch 56/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4838 - mae: 0.5360 - val_loss: 0.2271 - val_mae: 0.3535\n",
      "Epoch 57/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4782 - mae: 0.5328 - val_loss: 0.2228 - val_mae: 0.3488\n",
      "Epoch 58/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4727 - mae: 0.5295 - val_loss: 0.2185 - val_mae: 0.3440\n",
      "Epoch 59/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4672 - mae: 0.5263 - val_loss: 0.2144 - val_mae: 0.3392\n",
      "Epoch 60/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4617 - mae: 0.5230 - val_loss: 0.2104 - val_mae: 0.3344\n",
      "Epoch 61/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4562 - mae: 0.5198 - val_loss: 0.2066 - val_mae: 0.3295\n",
      "Epoch 62/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4507 - mae: 0.5165 - val_loss: 0.2029 - val_mae: 0.3246\n",
      "Epoch 63/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4452 - mae: 0.5132 - val_loss: 0.1993 - val_mae: 0.3197\n",
      "Epoch 64/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4397 - mae: 0.5099 - val_loss: 0.1958 - val_mae: 0.3148\n",
      "Epoch 65/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4342 - mae: 0.5066 - val_loss: 0.1925 - val_mae: 0.3099\n",
      "Epoch 66/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4287 - mae: 0.5032 - val_loss: 0.1892 - val_mae: 0.3051\n",
      "Epoch 67/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4232 - mae: 0.4999 - val_loss: 0.1862 - val_mae: 0.3002\n",
      "Epoch 68/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4178 - mae: 0.4966 - val_loss: 0.1832 - val_mae: 0.2953\n",
      "Epoch 69/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4123 - mae: 0.4932 - val_loss: 0.1804 - val_mae: 0.2904\n",
      "Epoch 70/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4068 - mae: 0.4899 - val_loss: 0.1777 - val_mae: 0.2856\n",
      "Epoch 71/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4014 - mae: 0.4865 - val_loss: 0.1752 - val_mae: 0.2808\n",
      "Epoch 72/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3960 - mae: 0.4831 - val_loss: 0.1727 - val_mae: 0.2760\n",
      "Epoch 73/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3907 - mae: 0.4798 - val_loss: 0.1704 - val_mae: 0.2713\n",
      "Epoch 74/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3853 - mae: 0.4764 - val_loss: 0.1682 - val_mae: 0.2666\n",
      "Epoch 75/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3800 - mae: 0.4731 - val_loss: 0.1661 - val_mae: 0.2622\n",
      "Epoch 76/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3748 - mae: 0.4699 - val_loss: 0.1641 - val_mae: 0.2600\n",
      "Epoch 77/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3696 - mae: 0.4680 - val_loss: 0.1622 - val_mae: 0.2578\n",
      "Epoch 78/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3645 - mae: 0.4661 - val_loss: 0.1604 - val_mae: 0.2557\n",
      "Epoch 79/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3594 - mae: 0.4641 - val_loss: 0.1586 - val_mae: 0.2535\n",
      "Epoch 80/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3544 - mae: 0.4622 - val_loss: 0.1570 - val_mae: 0.2513\n",
      "Epoch 81/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3495 - mae: 0.4602 - val_loss: 0.1554 - val_mae: 0.2495\n",
      "Epoch 82/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3447 - mae: 0.4584 - val_loss: 0.1539 - val_mae: 0.2476\n",
      "Epoch 83/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3399 - mae: 0.4566 - val_loss: 0.1524 - val_mae: 0.2458\n",
      "Epoch 84/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3352 - mae: 0.4548 - val_loss: 0.1510 - val_mae: 0.2439\n",
      "Epoch 85/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3307 - mae: 0.4529 - val_loss: 0.1496 - val_mae: 0.2420\n",
      "Epoch 86/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3262 - mae: 0.4510 - val_loss: 0.1483 - val_mae: 0.2402\n",
      "Epoch 87/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3218 - mae: 0.4491 - val_loss: 0.1470 - val_mae: 0.2391\n",
      "Epoch 88/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3175 - mae: 0.4472 - val_loss: 0.1457 - val_mae: 0.2379\n",
      "Epoch 89/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3134 - mae: 0.4453 - val_loss: 0.1444 - val_mae: 0.2367\n",
      "Epoch 90/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3093 - mae: 0.4433 - val_loss: 0.1432 - val_mae: 0.2355\n",
      "Epoch 91/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3053 - mae: 0.4414 - val_loss: 0.1419 - val_mae: 0.2342\n",
      "Epoch 92/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3014 - mae: 0.4394 - val_loss: 0.1407 - val_mae: 0.2329\n",
      "Epoch 93/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2976 - mae: 0.4375 - val_loss: 0.1395 - val_mae: 0.2315\n",
      "Epoch 94/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2940 - mae: 0.4355 - val_loss: 0.1383 - val_mae: 0.2301\n",
      "Epoch 95/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2904 - mae: 0.4336 - val_loss: 0.1370 - val_mae: 0.2287\n",
      "Epoch 96/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2869 - mae: 0.4316 - val_loss: 0.1358 - val_mae: 0.2273\n",
      "Epoch 97/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2835 - mae: 0.4297 - val_loss: 0.1346 - val_mae: 0.2258\n",
      "Epoch 98/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2802 - mae: 0.4278 - val_loss: 0.1334 - val_mae: 0.2243\n",
      "Epoch 99/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.2770 - mae: 0.4258 - val_loss: 0.1322 - val_mae: 0.2230\n",
      "Epoch 100/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2738 - mae: 0.4239 - val_loss: 0.1309 - val_mae: 0.2218\n",
      "Epoch 101/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2708 - mae: 0.4220 - val_loss: 0.1297 - val_mae: 0.2205\n",
      "Epoch 102/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2678 - mae: 0.4203 - val_loss: 0.1285 - val_mae: 0.2193\n",
      "Epoch 103/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2650 - mae: 0.4186 - val_loss: 0.1273 - val_mae: 0.2181\n",
      "Epoch 104/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2622 - mae: 0.4169 - val_loss: 0.1261 - val_mae: 0.2168\n",
      "Epoch 105/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2594 - mae: 0.4152 - val_loss: 0.1248 - val_mae: 0.2156\n",
      "Epoch 106/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2568 - mae: 0.4135 - val_loss: 0.1236 - val_mae: 0.2143\n",
      "Epoch 107/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2542 - mae: 0.4118 - val_loss: 0.1225 - val_mae: 0.2131\n",
      "Epoch 108/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2517 - mae: 0.4102 - val_loss: 0.1213 - val_mae: 0.2118\n",
      "Epoch 109/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2493 - mae: 0.4085 - val_loss: 0.1201 - val_mae: 0.2106\n",
      "Epoch 110/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2469 - mae: 0.4069 - val_loss: 0.1189 - val_mae: 0.2101\n",
      "Epoch 111/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2446 - mae: 0.4056 - val_loss: 0.1178 - val_mae: 0.2096\n",
      "Epoch 112/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2424 - mae: 0.4045 - val_loss: 0.1167 - val_mae: 0.2092\n",
      "Epoch 113/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2402 - mae: 0.4033 - val_loss: 0.1156 - val_mae: 0.2088\n",
      "Epoch 114/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2381 - mae: 0.4022 - val_loss: 0.1145 - val_mae: 0.2083\n",
      "Epoch 115/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2360 - mae: 0.4011 - val_loss: 0.1134 - val_mae: 0.2079\n",
      "Epoch 116/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.2340 - mae: 0.4000 - val_loss: 0.1124 - val_mae: 0.2075\n",
      "Epoch 117/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2320 - mae: 0.3988 - val_loss: 0.1114 - val_mae: 0.2071\n",
      "Epoch 118/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2301 - mae: 0.3977 - val_loss: 0.1104 - val_mae: 0.2067\n",
      "Epoch 119/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2283 - mae: 0.3966 - val_loss: 0.1094 - val_mae: 0.2063\n",
      "Epoch 120/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2264 - mae: 0.3955 - val_loss: 0.1085 - val_mae: 0.2058\n",
      "Epoch 121/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2247 - mae: 0.3945 - val_loss: 0.1075 - val_mae: 0.2054\n",
      "Epoch 122/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2229 - mae: 0.3934 - val_loss: 0.1067 - val_mae: 0.2050\n",
      "Epoch 123/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2212 - mae: 0.3923 - val_loss: 0.1058 - val_mae: 0.2046\n",
      "Epoch 124/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2196 - mae: 0.3912 - val_loss: 0.1049 - val_mae: 0.2042\n",
      "Epoch 125/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2180 - mae: 0.3901 - val_loss: 0.1041 - val_mae: 0.2039\n",
      "Epoch 126/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2164 - mae: 0.3890 - val_loss: 0.1033 - val_mae: 0.2035\n",
      "Epoch 127/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2149 - mae: 0.3880 - val_loss: 0.1025 - val_mae: 0.2031\n",
      "Epoch 128/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2133 - mae: 0.3869 - val_loss: 0.1018 - val_mae: 0.2027\n",
      "Epoch 129/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2119 - mae: 0.3858 - val_loss: 0.1011 - val_mae: 0.2023\n",
      "Epoch 130/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2104 - mae: 0.3847 - val_loss: 0.1004 - val_mae: 0.2019\n",
      "Epoch 131/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2090 - mae: 0.3837 - val_loss: 0.0997 - val_mae: 0.2015\n",
      "Epoch 132/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2076 - mae: 0.3826 - val_loss: 0.0990 - val_mae: 0.2012\n",
      "Epoch 133/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2063 - mae: 0.3816 - val_loss: 0.0983 - val_mae: 0.2008\n",
      "Epoch 134/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2049 - mae: 0.3805 - val_loss: 0.0977 - val_mae: 0.2004\n",
      "Epoch 135/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2036 - mae: 0.3795 - val_loss: 0.0971 - val_mae: 0.2000\n",
      "Epoch 136/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2023 - mae: 0.3784 - val_loss: 0.0965 - val_mae: 0.1997\n",
      "Epoch 137/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2011 - mae: 0.3774 - val_loss: 0.0959 - val_mae: 0.1993\n",
      "Epoch 138/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1998 - mae: 0.3763 - val_loss: 0.0953 - val_mae: 0.1989\n",
      "Epoch 139/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1986 - mae: 0.3753 - val_loss: 0.0948 - val_mae: 0.1987\n",
      "Epoch 140/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1974 - mae: 0.3743 - val_loss: 0.0942 - val_mae: 0.1986\n",
      "Epoch 141/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1962 - mae: 0.3733 - val_loss: 0.0937 - val_mae: 0.1985\n",
      "Epoch 142/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1951 - mae: 0.3722 - val_loss: 0.0931 - val_mae: 0.1984\n",
      "Epoch 143/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1939 - mae: 0.3712 - val_loss: 0.0926 - val_mae: 0.1983\n",
      "Epoch 144/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1928 - mae: 0.3702 - val_loss: 0.0921 - val_mae: 0.1982\n",
      "Epoch 145/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1917 - mae: 0.3692 - val_loss: 0.0916 - val_mae: 0.1980\n",
      "Epoch 146/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1906 - mae: 0.3683 - val_loss: 0.0911 - val_mae: 0.1979\n",
      "Epoch 147/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1896 - mae: 0.3673 - val_loss: 0.0906 - val_mae: 0.1977\n",
      "Epoch 148/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1885 - mae: 0.3663 - val_loss: 0.0901 - val_mae: 0.1976\n",
      "Epoch 149/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1875 - mae: 0.3653 - val_loss: 0.0896 - val_mae: 0.1974\n",
      "Epoch 150/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1865 - mae: 0.3644 - val_loss: 0.0891 - val_mae: 0.1973\n",
      "Epoch 151/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1855 - mae: 0.3634 - val_loss: 0.0887 - val_mae: 0.1971\n",
      "Epoch 152/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1845 - mae: 0.3625 - val_loss: 0.0882 - val_mae: 0.1969\n",
      "Epoch 153/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1835 - mae: 0.3615 - val_loss: 0.0877 - val_mae: 0.1967\n",
      "Epoch 154/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1826 - mae: 0.3606 - val_loss: 0.0873 - val_mae: 0.1965\n",
      "Epoch 155/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1816 - mae: 0.3597 - val_loss: 0.0868 - val_mae: 0.1963\n",
      "Epoch 156/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1807 - mae: 0.3588 - val_loss: 0.0864 - val_mae: 0.1961\n",
      "Epoch 157/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1797 - mae: 0.3578 - val_loss: 0.0859 - val_mae: 0.1959\n",
      "Epoch 158/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1788 - mae: 0.3569 - val_loss: 0.0855 - val_mae: 0.1957\n",
      "Epoch 159/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1779 - mae: 0.3560 - val_loss: 0.0851 - val_mae: 0.1955\n",
      "Epoch 160/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1770 - mae: 0.3551 - val_loss: 0.0846 - val_mae: 0.1952\n",
      "Epoch 161/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1762 - mae: 0.3543 - val_loss: 0.0842 - val_mae: 0.1950\n",
      "Epoch 162/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1753 - mae: 0.3534 - val_loss: 0.0838 - val_mae: 0.1948\n",
      "Epoch 163/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1745 - mae: 0.3525 - val_loss: 0.0834 - val_mae: 0.1945\n",
      "Epoch 164/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1736 - mae: 0.3516 - val_loss: 0.0830 - val_mae: 0.1943\n",
      "Epoch 165/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1728 - mae: 0.3508 - val_loss: 0.0825 - val_mae: 0.1941\n",
      "Epoch 166/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1720 - mae: 0.3499 - val_loss: 0.0821 - val_mae: 0.1938\n",
      "Epoch 167/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1711 - mae: 0.3491 - val_loss: 0.0817 - val_mae: 0.1936\n",
      "Epoch 168/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1703 - mae: 0.3482 - val_loss: 0.0813 - val_mae: 0.1933\n",
      "Epoch 169/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1695 - mae: 0.3474 - val_loss: 0.0809 - val_mae: 0.1931\n",
      "Epoch 170/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1687 - mae: 0.3465 - val_loss: 0.0806 - val_mae: 0.1928\n",
      "Epoch 171/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1680 - mae: 0.3457 - val_loss: 0.0802 - val_mae: 0.1925\n",
      "Epoch 172/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1672 - mae: 0.3449 - val_loss: 0.0798 - val_mae: 0.1923\n",
      "Epoch 173/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1664 - mae: 0.3440 - val_loss: 0.0794 - val_mae: 0.1920\n",
      "Epoch 174/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1657 - mae: 0.3432 - val_loss: 0.0790 - val_mae: 0.1918\n",
      "Epoch 175/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1649 - mae: 0.3424 - val_loss: 0.0787 - val_mae: 0.1915\n",
      "Epoch 176/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1642 - mae: 0.3416 - val_loss: 0.0783 - val_mae: 0.1912\n",
      "Epoch 177/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1635 - mae: 0.3408 - val_loss: 0.0779 - val_mae: 0.1910\n",
      "Epoch 178/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1628 - mae: 0.3400 - val_loss: 0.0776 - val_mae: 0.1907\n",
      "Epoch 179/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1621 - mae: 0.3392 - val_loss: 0.0772 - val_mae: 0.1904\n",
      "Epoch 180/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1613 - mae: 0.3384 - val_loss: 0.0769 - val_mae: 0.1901\n",
      "Epoch 181/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1607 - mae: 0.3376 - val_loss: 0.0765 - val_mae: 0.1899\n",
      "Epoch 182/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1600 - mae: 0.3368 - val_loss: 0.0762 - val_mae: 0.1896\n",
      "Epoch 183/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1593 - mae: 0.3360 - val_loss: 0.0759 - val_mae: 0.1893\n",
      "Epoch 184/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1586 - mae: 0.3352 - val_loss: 0.0755 - val_mae: 0.1891\n",
      "Epoch 185/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1579 - mae: 0.3345 - val_loss: 0.0752 - val_mae: 0.1888\n",
      "Epoch 186/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1573 - mae: 0.3337 - val_loss: 0.0749 - val_mae: 0.1885\n",
      "Epoch 187/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1566 - mae: 0.3329 - val_loss: 0.0746 - val_mae: 0.1882\n",
      "Epoch 188/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1560 - mae: 0.3321 - val_loss: 0.0742 - val_mae: 0.1880\n",
      "Epoch 189/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1553 - mae: 0.3314 - val_loss: 0.0739 - val_mae: 0.1877\n",
      "Epoch 190/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1547 - mae: 0.3306 - val_loss: 0.0736 - val_mae: 0.1874\n",
      "Epoch 191/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1541 - mae: 0.3299 - val_loss: 0.0733 - val_mae: 0.1871\n",
      "Epoch 192/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1534 - mae: 0.3291 - val_loss: 0.0730 - val_mae: 0.1868\n",
      "Epoch 193/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1528 - mae: 0.3284 - val_loss: 0.0727 - val_mae: 0.1866\n",
      "Epoch 194/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1522 - mae: 0.3276 - val_loss: 0.0724 - val_mae: 0.1863\n",
      "Epoch 195/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1516 - mae: 0.3269 - val_loss: 0.0721 - val_mae: 0.1860\n",
      "Epoch 196/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1510 - mae: 0.3262 - val_loss: 0.0718 - val_mae: 0.1857\n",
      "Epoch 197/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1504 - mae: 0.3254 - val_loss: 0.0715 - val_mae: 0.1855\n",
      "Epoch 198/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1498 - mae: 0.3247 - val_loss: 0.0712 - val_mae: 0.1852\n",
      "Epoch 199/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1493 - mae: 0.3240 - val_loss: 0.0709 - val_mae: 0.1849\n",
      "Epoch 200/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1487 - mae: 0.3233 - val_loss: 0.0706 - val_mae: 0.1846\n"
     ]
    }
   ],
   "source": [
    "for act in activations:\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(X_train_z.shape[1],)),\n",
    "        layers.Dense(16, activation=act),\n",
    "        layers.Dense(2,  activation='tanh')     # ⬅️ zwei Ausgänge: [Mn, Mw]\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_z, y_train_s,                    # y_train_s: (n,2)\n",
    "        validation_data=(X_val_z, y_val_s),\n",
    "        epochs=200, batch_size=16, shuffle=True, verbose=1,\n",
    "        callbacks=[]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0YBfUSrKBSZN"
   },
   "outputs": [],
   "source": [
    "\n",
    "    # Vorhersage (skaliert) -> zurückskalieren\n",
    "    y_hat_train_s = model.predict(X_train_z, verbose=0)\n",
    "    y_hat_val_s   = model.predict(X_val_z,   verbose=0)\n",
    "    y_hat_test_s  = model.predict(X_test_z,  verbose=0)\n",
    "\n",
    "    y_hat_train = inv_y(y_hat_train_s)          # (n,2) in realen Einheiten\n",
    "    y_hat_val   = inv_y(y_hat_val_s)\n",
    "    y_hat_test  = inv_y(y_hat_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Q9ZIfV65BSWm",
    "outputId": "6998d8e4-f6a1-4037-c092-cbc25bf21aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020F92389C60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020F93511580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transfer_functions = {\n",
    "    'relu': 'ReLU',\n",
    "    'tanh': 'Tanh',\n",
    "    'sigmoid': 'Sigmoid',\n",
    "    'softplus': 'Softplus'\n",
    "}\n",
    "\n",
    "mse_results = []\n",
    "\n",
    "for activation, name in transfer_functions.items():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(16, activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='tanh'))   # ⬅️ zwei Outputs: [Mn, Mw]\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, batch_size=4, epochs=50, verbose=0)\n",
    "    y_pred = model.predict(X_test, verbose=0)  # Form (n,2)\n",
    "    # Durchschnitts-MSE über beide Outputs (Mn & Mw)\n",
    "    mse = mean_squared_error(y_test, y_pred)   # = uniform_average\n",
    "    mse_results.append(mse)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(list(transfer_functions.values()), mse_results, marker='o', linestyle='-')\n",
    "plt.title('Mean MSE (Mn & Mw) vs. Transfer Function')\n",
    "plt.xlabel('Transfer Function')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky2flHEEBSUj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEyyme3-BSSL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhVOphxKBSPj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM6viJ1X4oRLwr65SDqw9Ni",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
