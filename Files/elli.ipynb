{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/elhamshaerirahbar-bot/my-colab-project/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8S8VCECinI2",
    "outputId": "442f5205-7a69-49da-a8a5-1f42a4fc8e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.20.0rc0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.11.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0Syqe_mYiwTx"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, re, unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "mQM3DjQNi0he",
    "outputId": "b018038a-6aec-4a81-e135-9ae3d186ce03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Run  Factor A  Factor B  Factor C  Factor D  Response 1 (Experimental)  \\\n",
      "0    1       110         7        50        10                    1127.19   \n",
      "1    2        85        13        50        10                    1024.97   \n",
      "2    3       101         1       500        60                    1950.00   \n",
      "3    4       101         1       500        60                    2223.17   \n",
      "4    5        50        10        50        10                    1845.60   \n",
      "\n",
      "   Response 2 (Experimental)  \n",
      "0                    1321.65  \n",
      "1                    1339.35  \n",
      "2                    2878.90  \n",
      "3                    2989.00  \n",
      "4                    2690.50  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Just read the file\n",
    "df = pd.read_csv('Exp_Mn_Mw_Value.txt', sep='\\t')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Y9BwNofi4-T",
    "outputId": "92a5901e-bb2a-48a0-bd86-613b27ddaa22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (25, 4)  y: (25, 2)\n"
     ]
    }
   ],
   "source": [
    "# Use iloc to select columns by position\n",
    "\n",
    "X = df.iloc[:, 1:5].astype(float).to_numpy()  # columns 1-4 as features\n",
    "y = df.iloc[:, 5:7].astype(float).to_numpy()  # Next 2 columns as targets\n",
    "\n",
    "print(\"X:\", X.shape, \" y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2AA1C6Wi77R",
    "outputId": "187af667-98c6-49ba-857a-f7dab735a70b"
   },
   "outputs": [],
   "source": [
    "#Data splitting\n",
    "# For 20% test, 16% val, 64% train:\n",
    "SEED = 5  \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, shuffle=True, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.20, shuffle=True, random_state=SEED  # 0.20 of 0.80 = 0.16 overall\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WAeiXioBjGXg"
   },
   "outputs": [],
   "source": [
    "#Scaling\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Ensure y has correct shape (samples, 2_targets)\n",
    "assert y_train.ndim == 2 and y_train.shape[1] == 2, \"y muss (n,2) sein\"\n",
    "\n",
    "# Scale features (X) using StandardScaler \n",
    "# Fit scaler only on training data to prevent data leakage\n",
    "x_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Transform all sets using the same scaler (mean=0, std=1)\n",
    "X_train_z = x_scaler.transform(X_train)  # Standardized training features\n",
    "X_val_z   = x_scaler.transform(X_val)    # Standardized validation features  \n",
    "X_test_z  = x_scaler.transform(X_test)   # Standardized test features\n",
    "\n",
    "#  Scale targets (y) to [-1,1] range for tanh activation\n",
    "# Fit scaler only on training targets to prevent data leakage\n",
    "y_scaler  = MinMaxScaler(feature_range=(-1, 1)).fit(y_train)  # y_train: (n,2)\n",
    "\n",
    "# Transform all target sets using the same scaler\n",
    "y_train_s = y_scaler.transform(y_train)  # Scaled training targets [-1,1]\n",
    "y_val_s   = y_scaler.transform(y_val)    # Scaled validation targets [-1,1]\n",
    "y_test_s  = y_scaler.transform(y_test)   # Scaled test targets [-1,1]\n",
    "\n",
    "def inv_y(y_s):\n",
    "    \"\"\"\n",
    "    Inverse transform scaled predictions back to original units.\n",
    "    Args: y_s - scaled predictions in [-1,1] range\n",
    "    Returns: predictions in original scale (Mn, Mw units)\n",
    "    \"\"\"\n",
    "    return y_scaler.inverse_transform(y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dBaYl7yWjKR5"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otPjam8rjLqF",
    "outputId": "c6ef832c-fff8-46ad-d52a-389edaf598dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Build Neural Network: 4 inputs -> 3 hidden layers (16,8,8) -> 2 outputs\n",
    "# Architecture: fully connected feedforward network with regularization\n",
    "# Purpose: predict 2 molecular weight responses (Mn, Mw) from 4 factors\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Verify target shape (samples, 2_outputs)\n",
    "assert y_train_s.ndim == 2 and y_train_s.shape[1] == 2, \"y muss (n,2) sein!\"\n",
    "\n",
    "# Build neural network model\n",
    "model = Sequential([\n",
    "    # Input layer: 4 features -> 16 neurons\n",
    "    # ReLU activation for non-linearity\n",
    "    # L2 regularization to prevent overfitting\n",
    "    layers.Dense(16, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-5),\n",
    "                 input_shape=(X_train_z.shape[1],)),\n",
    "    \n",
    "    # Dropout to reduce overfitting (randomly disable 10% of neurons)\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    # Hidden layer: 16 -> 8 neurons\n",
    "    layers.Dense(8, activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(1e-5)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    # Hidden layer: 8 -> 8 neurons  \n",
    "    layers.Dense(8, activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(1e-5)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    # Output layer: 8 -> 2 outputs (Mn, Mw)\n",
    "    # Tanh activation outputs [-1,1] to match our scaled targets\n",
    "    layers.Dense(2, activation='tanh')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "# MSE loss for regression, MAE and MAPE as additional metrics\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse', \n",
    "              metrics=['mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SiGI9kdjLoU",
    "outputId": "a56e7194-c800-4b0d-945d-a91716792ef7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.3090 - mae: 0.4278 - mape: 110.7342 - val_loss: 0.2823 - val_mae: 0.3777 - val_mape: 119.2936\n",
      "Epoch 2/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2986 - mae: 0.4261 - mape: 129.6580 - val_loss: 0.2773 - val_mae: 0.3733 - val_mape: 117.0840\n",
      "Epoch 3/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2592 - mae: 0.4011 - mape: 127.1232 - val_loss: 0.2737 - val_mae: 0.3697 - val_mape: 114.9165\n",
      "Epoch 4/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2847 - mae: 0.4077 - mape: 109.7059 - val_loss: 0.2693 - val_mae: 0.3657 - val_mape: 112.8975\n",
      "Epoch 5/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2792 - mae: 0.4114 - mape: 110.9016 - val_loss: 0.2658 - val_mae: 0.3621 - val_mape: 110.8175\n",
      "Epoch 6/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2420 - mae: 0.3817 - mape: 109.7000 - val_loss: 0.2607 - val_mae: 0.3576 - val_mape: 108.8064\n",
      "Epoch 7/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.2958 - mae: 0.4115 - mape: 112.2363 - val_loss: 0.2564 - val_mae: 0.3538 - val_mape: 107.0117\n",
      "Epoch 8/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2767 - mae: 0.4051 - mape: 117.1405 - val_loss: 0.2544 - val_mae: 0.3511 - val_mape: 105.3409\n",
      "Epoch 9/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2610 - mae: 0.3939 - mape: 113.7125 - val_loss: 0.2532 - val_mae: 0.3487 - val_mape: 103.5863\n",
      "Epoch 10/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2692 - mae: 0.4052 - mape: 111.2495 - val_loss: 0.2521 - val_mae: 0.3465 - val_mape: 101.8534\n",
      "Epoch 11/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2413 - mae: 0.3827 - mape: 108.7339 - val_loss: 0.2511 - val_mae: 0.3453 - val_mape: 100.7095\n",
      "Epoch 12/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2596 - mae: 0.4031 - mape: 115.3090 - val_loss: 0.2502 - val_mae: 0.3445 - val_mape: 99.6933\n",
      "Epoch 13/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2658 - mae: 0.4057 - mape: 107.3882 - val_loss: 0.2496 - val_mae: 0.3440 - val_mape: 98.8484\n",
      "Epoch 14/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2515 - mae: 0.3875 - mape: 95.0821 - val_loss: 0.2491 - val_mae: 0.3436 - val_mape: 98.0153\n",
      "Epoch 15/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2640 - mae: 0.3942 - mape: 104.9003 - val_loss: 0.2485 - val_mae: 0.3431 - val_mape: 97.1366\n",
      "Epoch 16/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2550 - mae: 0.3914 - mape: 105.5615 - val_loss: 0.2480 - val_mae: 0.3426 - val_mape: 96.2450\n",
      "Epoch 17/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2441 - mae: 0.3739 - mape: 89.4262 - val_loss: 0.2476 - val_mae: 0.3423 - val_mape: 95.4063\n",
      "Epoch 18/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2277 - mae: 0.3697 - mape: 107.2800 - val_loss: 0.2472 - val_mae: 0.3418 - val_mape: 94.5312\n",
      "Epoch 19/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2489 - mae: 0.3996 - mape: 111.6504 - val_loss: 0.2467 - val_mae: 0.3412 - val_mape: 93.6416\n",
      "Epoch 20/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2591 - mae: 0.4039 - mape: 113.6298 - val_loss: 0.2461 - val_mae: 0.3406 - val_mape: 92.8266\n",
      "Epoch 21/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2620 - mae: 0.3941 - mape: 113.3231 - val_loss: 0.2454 - val_mae: 0.3398 - val_mape: 91.9559\n",
      "Epoch 22/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2341 - mae: 0.3916 - mape: 122.3905 - val_loss: 0.2444 - val_mae: 0.3390 - val_mape: 91.2394\n",
      "Epoch 23/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2258 - mae: 0.3792 - mape: 90.3700 - val_loss: 0.2435 - val_mae: 0.3382 - val_mape: 90.6193\n",
      "Epoch 24/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2061 - mae: 0.3625 - mape: 103.7125 - val_loss: 0.2424 - val_mae: 0.3373 - val_mape: 90.0309\n",
      "Epoch 25/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2086 - mae: 0.3631 - mape: 98.6744 - val_loss: 0.2413 - val_mae: 0.3365 - val_mape: 89.4786\n",
      "Epoch 26/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2421 - mae: 0.3908 - mape: 104.0327 - val_loss: 0.2399 - val_mae: 0.3355 - val_mape: 89.0488\n",
      "Epoch 27/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2165 - mae: 0.3630 - mape: 94.9540 - val_loss: 0.2387 - val_mae: 0.3346 - val_mape: 88.6214\n",
      "Epoch 28/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2080 - mae: 0.3673 - mape: 105.2270 - val_loss: 0.2374 - val_mae: 0.3337 - val_mape: 88.2339\n",
      "Epoch 29/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2133 - mae: 0.3739 - mape: 113.0138 - val_loss: 0.2362 - val_mae: 0.3328 - val_mape: 87.8126\n",
      "Epoch 30/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1940 - mae: 0.3452 - mape: 85.8867 - val_loss: 0.2350 - val_mae: 0.3320 - val_mape: 87.4251\n",
      "Epoch 31/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2197 - mae: 0.3826 - mape: 105.9125 - val_loss: 0.2338 - val_mae: 0.3311 - val_mape: 87.1016\n",
      "Epoch 32/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2546 - mae: 0.3873 - mape: 119.9416 - val_loss: 0.2326 - val_mae: 0.3301 - val_mape: 86.6621\n",
      "Epoch 33/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2075 - mae: 0.3699 - mape: 94.6561 - val_loss: 0.2315 - val_mae: 0.3292 - val_mape: 86.2366\n",
      "Epoch 34/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2243 - mae: 0.3711 - mape: 111.6934 - val_loss: 0.2303 - val_mae: 0.3283 - val_mape: 85.8518\n",
      "Epoch 35/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2304 - mae: 0.3703 - mape: 98.1171 - val_loss: 0.2293 - val_mae: 0.3274 - val_mape: 85.3338\n",
      "Epoch 36/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1749 - mae: 0.3336 - mape: 94.3803 - val_loss: 0.2282 - val_mae: 0.3264 - val_mape: 84.8487\n",
      "Epoch 37/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2414 - mae: 0.3914 - mape: 120.6787 - val_loss: 0.2270 - val_mae: 0.3254 - val_mape: 84.3540\n",
      "Epoch 38/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1899 - mae: 0.3488 - mape: 107.6173 - val_loss: 0.2259 - val_mae: 0.3244 - val_mape: 83.8047\n",
      "Epoch 39/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2889 - mae: 0.4159 - mape: 127.4269 - val_loss: 0.2247 - val_mae: 0.3232 - val_mape: 83.1873\n",
      "Epoch 40/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2139 - mae: 0.3820 - mape: 120.2135 - val_loss: 0.2235 - val_mae: 0.3221 - val_mape: 82.5691\n",
      "Epoch 41/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2131 - mae: 0.3703 - mape: 117.4409 - val_loss: 0.2221 - val_mae: 0.3209 - val_mape: 82.0307\n",
      "Epoch 42/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2454 - mae: 0.3916 - mape: 111.2587 - val_loss: 0.2206 - val_mae: 0.3197 - val_mape: 81.6968\n",
      "Epoch 43/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1972 - mae: 0.3603 - mape: 106.9502 - val_loss: 0.2191 - val_mae: 0.3185 - val_mape: 81.4325\n",
      "Epoch 44/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2060 - mae: 0.3662 - mape: 113.3218 - val_loss: 0.2179 - val_mae: 0.3175 - val_mape: 81.1536\n",
      "Epoch 45/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2761 - mae: 0.4197 - mape: 128.7738 - val_loss: 0.2166 - val_mae: 0.3163 - val_mape: 80.7640\n",
      "Epoch 46/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2664 - mae: 0.4075 - mape: 132.0923 - val_loss: 0.2155 - val_mae: 0.3152 - val_mape: 80.2433\n",
      "Epoch 47/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1757 - mae: 0.3236 - mape: 84.4147 - val_loss: 0.2144 - val_mae: 0.3144 - val_mape: 80.3087\n",
      "Epoch 48/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1793 - mae: 0.3443 - mape: 115.0147 - val_loss: 0.2132 - val_mae: 0.3135 - val_mape: 80.5268\n",
      "Epoch 49/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2193 - mae: 0.3745 - mape: 122.0535 - val_loss: 0.2121 - val_mae: 0.3127 - val_mape: 80.7065\n",
      "Epoch 50/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1761 - mae: 0.3232 - mape: 109.0387 - val_loss: 0.2110 - val_mae: 0.3119 - val_mape: 80.8457\n",
      "Epoch 51/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2188 - mae: 0.3787 - mape: 120.3128 - val_loss: 0.2101 - val_mae: 0.3111 - val_mape: 80.9538\n",
      "Epoch 52/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2024 - mae: 0.3672 - mape: 126.0729 - val_loss: 0.2090 - val_mae: 0.3103 - val_mape: 81.1240\n",
      "Epoch 53/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1999 - mae: 0.3619 - mape: 129.3898 - val_loss: 0.2079 - val_mae: 0.3094 - val_mape: 81.2856\n",
      "Epoch 54/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1853 - mae: 0.3534 - mape: 117.8756 - val_loss: 0.2066 - val_mae: 0.3084 - val_mape: 81.4687\n",
      "Epoch 55/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1886 - mae: 0.3542 - mape: 106.2357 - val_loss: 0.2053 - val_mae: 0.3074 - val_mape: 81.6314\n",
      "Epoch 56/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2137 - mae: 0.3357 - mape: 92.3134 - val_loss: 0.2041 - val_mae: 0.3065 - val_mape: 81.7560\n",
      "Epoch 57/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1844 - mae: 0.3436 - mape: 107.3898 - val_loss: 0.2030 - val_mae: 0.3056 - val_mape: 81.9003\n",
      "Epoch 58/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2412 - mae: 0.3895 - mape: 120.8868 - val_loss: 0.2018 - val_mae: 0.3047 - val_mape: 82.0959\n",
      "Epoch 59/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2010 - mae: 0.3519 - mape: 122.5048 - val_loss: 0.2008 - val_mae: 0.3039 - val_mape: 82.2298\n",
      "Epoch 60/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2098 - mae: 0.3679 - mape: 123.9550 - val_loss: 0.1998 - val_mae: 0.3031 - val_mape: 82.3942\n",
      "Epoch 61/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2250 - mae: 0.3746 - mape: 125.3984 - val_loss: 0.1987 - val_mae: 0.3022 - val_mape: 82.5459\n",
      "Epoch 62/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2231 - mae: 0.3700 - mape: 126.2098 - val_loss: 0.1976 - val_mae: 0.3014 - val_mape: 82.6763\n",
      "Epoch 63/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2457 - mae: 0.3969 - mape: 124.3759 - val_loss: 0.1966 - val_mae: 0.3006 - val_mape: 82.9028\n",
      "Epoch 64/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2145 - mae: 0.3575 - mape: 123.7365 - val_loss: 0.1956 - val_mae: 0.2998 - val_mape: 83.0013\n",
      "Epoch 65/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1576 - mae: 0.3166 - mape: 108.4621 - val_loss: 0.1947 - val_mae: 0.2991 - val_mape: 83.1074\n",
      "Epoch 66/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1730 - mae: 0.3317 - mape: 128.9543 - val_loss: 0.1939 - val_mae: 0.2984 - val_mape: 83.1707\n",
      "Epoch 67/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2310 - mae: 0.3754 - mape: 139.3086 - val_loss: 0.1931 - val_mae: 0.2977 - val_mape: 83.1050\n",
      "Epoch 68/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.2239 - mae: 0.3749 - mape: 123.0402 - val_loss: 0.1923 - val_mae: 0.2970 - val_mape: 83.0434\n",
      "Epoch 69/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1588 - mae: 0.3238 - mape: 123.8086 - val_loss: 0.1915 - val_mae: 0.2962 - val_mape: 83.0130\n",
      "Epoch 70/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1894 - mae: 0.3487 - mape: 126.7041 - val_loss: 0.1905 - val_mae: 0.2954 - val_mape: 83.0212\n",
      "Epoch 71/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1861 - mae: 0.3465 - mape: 127.6989 - val_loss: 0.1895 - val_mae: 0.2946 - val_mape: 83.0584\n",
      "Epoch 72/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1746 - mae: 0.3258 - mape: 118.2067 - val_loss: 0.1886 - val_mae: 0.2939 - val_mape: 83.0305\n",
      "Epoch 73/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1564 - mae: 0.3047 - mape: 105.8163 - val_loss: 0.1877 - val_mae: 0.2931 - val_mape: 82.9542\n",
      "Epoch 74/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2326 - mae: 0.3710 - mape: 129.3370 - val_loss: 0.1869 - val_mae: 0.2923 - val_mape: 82.8356\n",
      "Epoch 75/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1652 - mae: 0.3324 - mape: 133.8296 - val_loss: 0.1860 - val_mae: 0.2915 - val_mape: 82.7587\n",
      "Epoch 76/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1656 - mae: 0.3291 - mape: 127.1481 - val_loss: 0.1851 - val_mae: 0.2907 - val_mape: 82.6292\n",
      "Epoch 77/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2215 - mae: 0.3648 - mape: 139.7685 - val_loss: 0.1842 - val_mae: 0.2898 - val_mape: 82.4402\n",
      "Epoch 78/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2017 - mae: 0.3627 - mape: 132.3396 - val_loss: 0.1834 - val_mae: 0.2890 - val_mape: 82.2925\n",
      "Epoch 79/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2072 - mae: 0.3438 - mape: 125.4409 - val_loss: 0.1826 - val_mae: 0.2883 - val_mape: 82.0748\n",
      "Epoch 80/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1316 - mae: 0.2770 - mape: 96.0432 - val_loss: 0.1817 - val_mae: 0.2875 - val_mape: 81.8105\n",
      "Epoch 81/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1503 - mae: 0.2942 - mape: 104.5241 - val_loss: 0.1809 - val_mae: 0.2867 - val_mape: 81.4554\n",
      "Epoch 82/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2469 - mae: 0.3868 - mape: 143.4957 - val_loss: 0.1800 - val_mae: 0.2858 - val_mape: 81.1055\n",
      "Epoch 83/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2129 - mae: 0.3546 - mape: 121.7399 - val_loss: 0.1792 - val_mae: 0.2849 - val_mape: 80.7544\n",
      "Epoch 84/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1451 - mae: 0.3008 - mape: 106.7430 - val_loss: 0.1784 - val_mae: 0.2841 - val_mape: 80.4099\n",
      "Epoch 85/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1682 - mae: 0.3213 - mape: 125.4660 - val_loss: 0.1776 - val_mae: 0.2832 - val_mape: 80.1116\n",
      "Epoch 86/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1526 - mae: 0.3196 - mape: 127.2141 - val_loss: 0.1767 - val_mae: 0.2823 - val_mape: 79.8909\n",
      "Epoch 87/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1686 - mae: 0.3302 - mape: 127.7100 - val_loss: 0.1759 - val_mae: 0.2814 - val_mape: 79.6568\n",
      "Epoch 88/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2035 - mae: 0.3412 - mape: 118.7515 - val_loss: 0.1750 - val_mae: 0.2805 - val_mape: 79.3285\n",
      "Epoch 89/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1857 - mae: 0.3394 - mape: 120.8306 - val_loss: 0.1742 - val_mae: 0.2797 - val_mape: 79.2733\n",
      "Epoch 90/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1855 - mae: 0.3442 - mape: 144.1666 - val_loss: 0.1733 - val_mae: 0.2789 - val_mape: 79.2062\n",
      "Epoch 91/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1746 - mae: 0.3420 - mape: 136.3870 - val_loss: 0.1725 - val_mae: 0.2781 - val_mape: 79.1765\n",
      "Epoch 92/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2202 - mae: 0.3606 - mape: 136.3821 - val_loss: 0.1716 - val_mae: 0.2772 - val_mape: 79.0578\n",
      "Epoch 93/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1349 - mae: 0.2936 - mape: 112.0114 - val_loss: 0.1708 - val_mae: 0.2763 - val_mape: 78.9654\n",
      "Epoch 94/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1419 - mae: 0.2934 - mape: 114.5432 - val_loss: 0.1699 - val_mae: 0.2754 - val_mape: 78.8880\n",
      "Epoch 95/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1708 - mae: 0.3330 - mape: 137.8003 - val_loss: 0.1690 - val_mae: 0.2745 - val_mape: 78.8441\n",
      "Epoch 96/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1295 - mae: 0.2753 - mape: 110.6212 - val_loss: 0.1681 - val_mae: 0.2737 - val_mape: 78.7675\n",
      "Epoch 97/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1717 - mae: 0.3374 - mape: 137.9941 - val_loss: 0.1673 - val_mae: 0.2728 - val_mape: 78.7333\n",
      "Epoch 98/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1758 - mae: 0.3356 - mape: 144.7672 - val_loss: 0.1665 - val_mae: 0.2720 - val_mape: 78.7061\n",
      "Epoch 99/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1779 - mae: 0.3400 - mape: 146.8882 - val_loss: 0.1657 - val_mae: 0.2712 - val_mape: 78.6862\n",
      "Epoch 100/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2058 - mae: 0.3594 - mape: 145.9759 - val_loss: 0.1650 - val_mae: 0.2705 - val_mape: 78.7335\n",
      "Epoch 101/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1341 - mae: 0.2891 - mape: 115.7573 - val_loss: 0.1643 - val_mae: 0.2698 - val_mape: 78.7559\n",
      "Epoch 102/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1505 - mae: 0.3142 - mape: 132.1378 - val_loss: 0.1635 - val_mae: 0.2691 - val_mape: 78.8200\n",
      "Epoch 103/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1612 - mae: 0.3163 - mape: 135.1461 - val_loss: 0.1628 - val_mae: 0.2684 - val_mape: 78.8439\n",
      "Epoch 104/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1711 - mae: 0.3452 - mape: 147.0493 - val_loss: 0.1620 - val_mae: 0.2676 - val_mape: 78.9667\n",
      "Epoch 105/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1261 - mae: 0.2793 - mape: 115.3637 - val_loss: 0.1612 - val_mae: 0.2668 - val_mape: 79.0555\n",
      "Epoch 106/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2149 - mae: 0.3544 - mape: 144.5630 - val_loss: 0.1604 - val_mae: 0.2662 - val_mape: 79.2073\n",
      "Epoch 107/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2272 - mae: 0.3575 - mape: 129.2044 - val_loss: 0.1596 - val_mae: 0.2658 - val_mape: 79.4074\n",
      "Epoch 108/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1207 - mae: 0.2700 - mape: 107.0440 - val_loss: 0.1589 - val_mae: 0.2652 - val_mape: 79.4797\n",
      "Epoch 109/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1531 - mae: 0.3132 - mape: 141.3454 - val_loss: 0.1581 - val_mae: 0.2647 - val_mape: 79.6367\n",
      "Epoch 110/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1525 - mae: 0.3062 - mape: 146.7139 - val_loss: 0.1574 - val_mae: 0.2642 - val_mape: 79.8144\n",
      "Epoch 111/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1579 - mae: 0.3212 - mape: 138.9202 - val_loss: 0.1567 - val_mae: 0.2639 - val_mape: 80.0842\n",
      "Epoch 112/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1684 - mae: 0.3305 - mape: 142.5486 - val_loss: 0.1559 - val_mae: 0.2636 - val_mape: 80.4168\n",
      "Epoch 113/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1346 - mae: 0.2848 - mape: 116.7907 - val_loss: 0.1552 - val_mae: 0.2632 - val_mape: 80.7822\n",
      "Epoch 114/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1268 - mae: 0.2704 - mape: 109.9562 - val_loss: 0.1544 - val_mae: 0.2628 - val_mape: 81.0650\n",
      "Epoch 115/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1337 - mae: 0.2821 - mape: 128.8710 - val_loss: 0.1537 - val_mae: 0.2624 - val_mape: 81.2717\n",
      "Epoch 116/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1216 - mae: 0.2706 - mape: 120.0419 - val_loss: 0.1530 - val_mae: 0.2619 - val_mape: 81.3644\n",
      "Epoch 117/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1442 - mae: 0.2892 - mape: 118.8389 - val_loss: 0.1524 - val_mae: 0.2615 - val_mape: 81.4525\n",
      "Epoch 118/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1251 - mae: 0.2803 - mape: 123.1496 - val_loss: 0.1518 - val_mae: 0.2611 - val_mape: 81.5174\n",
      "Epoch 119/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1974 - mae: 0.3332 - mape: 144.8130 - val_loss: 0.1513 - val_mae: 0.2606 - val_mape: 81.4689\n",
      "Epoch 120/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1465 - mae: 0.3061 - mape: 146.4609 - val_loss: 0.1508 - val_mae: 0.2602 - val_mape: 81.4363\n",
      "Epoch 121/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1454 - mae: 0.3079 - mape: 145.0770 - val_loss: 0.1504 - val_mae: 0.2598 - val_mape: 81.3926\n",
      "Epoch 122/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1416 - mae: 0.2813 - mape: 120.9739 - val_loss: 0.1499 - val_mae: 0.2593 - val_mape: 81.2602\n",
      "Epoch 123/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1312 - mae: 0.2837 - mape: 131.9844 - val_loss: 0.1494 - val_mae: 0.2587 - val_mape: 81.1046\n",
      "Epoch 124/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2320 - mae: 0.3668 - mape: 151.7036 - val_loss: 0.1489 - val_mae: 0.2583 - val_mape: 80.9948\n",
      "Epoch 125/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1450 - mae: 0.3126 - mape: 139.1667 - val_loss: 0.1484 - val_mae: 0.2578 - val_mape: 80.9846\n",
      "Epoch 126/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1637 - mae: 0.3243 - mape: 140.2200 - val_loss: 0.1477 - val_mae: 0.2573 - val_mape: 81.0952\n",
      "Epoch 127/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1477 - mae: 0.3098 - mape: 128.2462 - val_loss: 0.1466 - val_mae: 0.2566 - val_mape: 81.4057\n",
      "Epoch 128/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1660 - mae: 0.3045 - mape: 123.2200 - val_loss: 0.1456 - val_mae: 0.2560 - val_mape: 81.6579\n",
      "Epoch 129/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1849 - mae: 0.3454 - mape: 146.5125 - val_loss: 0.1446 - val_mae: 0.2551 - val_mape: 81.7510\n",
      "Epoch 130/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1518 - mae: 0.3025 - mape: 135.6944 - val_loss: 0.1437 - val_mae: 0.2544 - val_mape: 81.8866\n",
      "Epoch 131/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1930 - mae: 0.3502 - mape: 146.8722 - val_loss: 0.1428 - val_mae: 0.2538 - val_mape: 82.1066\n",
      "Epoch 132/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2748 - mae: 0.3865 - mape: 143.6038 - val_loss: 0.1421 - val_mae: 0.2535 - val_mape: 82.3917\n",
      "Epoch 133/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1747 - mae: 0.3074 - mape: 124.0989 - val_loss: 0.1413 - val_mae: 0.2530 - val_mape: 82.6632\n",
      "Epoch 134/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2041 - mae: 0.3438 - mape: 141.8741 - val_loss: 0.1405 - val_mae: 0.2524 - val_mape: 82.7854\n",
      "Epoch 135/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1316 - mae: 0.2876 - mape: 119.0655 - val_loss: 0.1397 - val_mae: 0.2517 - val_mape: 82.8262\n",
      "Epoch 136/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1378 - mae: 0.2979 - mape: 141.7374 - val_loss: 0.1389 - val_mae: 0.2510 - val_mape: 82.8446\n",
      "Epoch 137/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1718 - mae: 0.3070 - mape: 128.3058 - val_loss: 0.1381 - val_mae: 0.2503 - val_mape: 82.8056\n",
      "Epoch 138/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2086 - mae: 0.3303 - mape: 126.6882 - val_loss: 0.1375 - val_mae: 0.2497 - val_mape: 82.6712\n",
      "Epoch 139/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1824 - mae: 0.3095 - mape: 120.2877 - val_loss: 0.1369 - val_mae: 0.2489 - val_mape: 82.4283\n",
      "Epoch 140/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1559 - mae: 0.2951 - mape: 123.0305 - val_loss: 0.1363 - val_mae: 0.2482 - val_mape: 82.2443\n",
      "Epoch 141/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1824 - mae: 0.3239 - mape: 143.4971 - val_loss: 0.1357 - val_mae: 0.2476 - val_mape: 82.1378\n",
      "Epoch 142/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1200 - mae: 0.2738 - mape: 135.7360 - val_loss: 0.1351 - val_mae: 0.2470 - val_mape: 82.0586\n",
      "Epoch 143/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1846 - mae: 0.3227 - mape: 139.8518 - val_loss: 0.1344 - val_mae: 0.2464 - val_mape: 81.9697\n",
      "Epoch 144/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1773 - mae: 0.3111 - mape: 131.1437 - val_loss: 0.1339 - val_mae: 0.2457 - val_mape: 81.6581\n",
      "Epoch 145/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1650 - mae: 0.3220 - mape: 142.0391 - val_loss: 0.1333 - val_mae: 0.2449 - val_mape: 81.4332\n",
      "Epoch 146/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1633 - mae: 0.3008 - mape: 129.0756 - val_loss: 0.1327 - val_mae: 0.2441 - val_mape: 81.0634\n",
      "Epoch 147/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1301 - mae: 0.2827 - mape: 141.8438 - val_loss: 0.1321 - val_mae: 0.2432 - val_mape: 80.7213\n",
      "Epoch 148/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1329 - mae: 0.2904 - mape: 127.9483 - val_loss: 0.1314 - val_mae: 0.2425 - val_mape: 80.6391\n",
      "Epoch 149/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1844 - mae: 0.3190 - mape: 136.5306 - val_loss: 0.1306 - val_mae: 0.2418 - val_mape: 80.6404\n",
      "Epoch 150/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1425 - mae: 0.2907 - mape: 151.2326 - val_loss: 0.1298 - val_mae: 0.2412 - val_mape: 80.6682\n",
      "Epoch 151/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1600 - mae: 0.2957 - mape: 127.4978 - val_loss: 0.1290 - val_mae: 0.2406 - val_mape: 80.8041\n",
      "Epoch 152/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1198 - mae: 0.2781 - mape: 132.3208 - val_loss: 0.1282 - val_mae: 0.2400 - val_mape: 81.0126\n",
      "Epoch 153/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1399 - mae: 0.2967 - mape: 150.6961 - val_loss: 0.1274 - val_mae: 0.2396 - val_mape: 81.3971\n",
      "Epoch 154/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1679 - mae: 0.3049 - mape: 137.2005 - val_loss: 0.1266 - val_mae: 0.2393 - val_mape: 81.7205\n",
      "Epoch 155/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1990 - mae: 0.3159 - mape: 134.6035 - val_loss: 0.1258 - val_mae: 0.2387 - val_mape: 81.7965\n",
      "Epoch 156/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1587 - mae: 0.3134 - mape: 139.5551 - val_loss: 0.1251 - val_mae: 0.2382 - val_mape: 81.9510\n",
      "Epoch 157/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1519 - mae: 0.3030 - mape: 132.6246 - val_loss: 0.1243 - val_mae: 0.2378 - val_mape: 82.3063\n",
      "Epoch 158/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1579 - mae: 0.3054 - mape: 126.7557 - val_loss: 0.1236 - val_mae: 0.2375 - val_mape: 82.6651\n",
      "Epoch 159/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1488 - mae: 0.3061 - mape: 142.0328 - val_loss: 0.1229 - val_mae: 0.2371 - val_mape: 83.0296\n",
      "Epoch 160/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1779 - mae: 0.3251 - mape: 147.4188 - val_loss: 0.1222 - val_mae: 0.2367 - val_mape: 83.3413\n",
      "Epoch 161/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1955 - mae: 0.3070 - mape: 124.3306 - val_loss: 0.1215 - val_mae: 0.2361 - val_mape: 83.4204\n",
      "Epoch 162/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1388 - mae: 0.2812 - mape: 126.4377 - val_loss: 0.1209 - val_mae: 0.2355 - val_mape: 83.4626\n",
      "Epoch 163/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1693 - mae: 0.3043 - mape: 130.3787 - val_loss: 0.1202 - val_mae: 0.2348 - val_mape: 83.4607\n",
      "Epoch 164/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1563 - mae: 0.2910 - mape: 125.6840 - val_loss: 0.1196 - val_mae: 0.2341 - val_mape: 83.3573\n",
      "Epoch 165/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1118 - mae: 0.2614 - mape: 128.0247 - val_loss: 0.1189 - val_mae: 0.2334 - val_mape: 83.2687\n",
      "Epoch 166/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1286 - mae: 0.2783 - mape: 131.0762 - val_loss: 0.1182 - val_mae: 0.2326 - val_mape: 83.0610\n",
      "Epoch 167/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2054 - mae: 0.3416 - mape: 143.7333 - val_loss: 0.1176 - val_mae: 0.2320 - val_mape: 83.0361\n",
      "Epoch 168/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1502 - mae: 0.2844 - mape: 118.9305 - val_loss: 0.1171 - val_mae: 0.2313 - val_mape: 82.9977\n",
      "Epoch 169/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1288 - mae: 0.2926 - mape: 136.2225 - val_loss: 0.1165 - val_mae: 0.2309 - val_mape: 83.1199\n",
      "Epoch 170/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2418 - mae: 0.3642 - mape: 135.2769 - val_loss: 0.1160 - val_mae: 0.2306 - val_mape: 83.4015\n",
      "Epoch 171/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1193 - mae: 0.2802 - mape: 134.0629 - val_loss: 0.1155 - val_mae: 0.2306 - val_mape: 83.8865\n",
      "Epoch 172/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1153 - mae: 0.2703 - mape: 134.0020 - val_loss: 0.1150 - val_mae: 0.2306 - val_mape: 84.4309\n",
      "Epoch 173/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1605 - mae: 0.3192 - mape: 148.8157 - val_loss: 0.1144 - val_mae: 0.2304 - val_mape: 84.8407\n",
      "Epoch 174/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1074 - mae: 0.2593 - mape: 130.2922 - val_loss: 0.1139 - val_mae: 0.2304 - val_mape: 85.2839\n",
      "Epoch 175/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2379 - mae: 0.3610 - mape: 133.5786 - val_loss: 0.1134 - val_mae: 0.2303 - val_mape: 85.6956\n",
      "Epoch 176/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1106 - mae: 0.2640 - mape: 141.2495 - val_loss: 0.1129 - val_mae: 0.2300 - val_mape: 85.8600\n",
      "Epoch 177/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1262 - mae: 0.2740 - mape: 127.0249 - val_loss: 0.1124 - val_mae: 0.2296 - val_mape: 86.0498\n",
      "Epoch 178/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1472 - mae: 0.2918 - mape: 151.9787 - val_loss: 0.1118 - val_mae: 0.2293 - val_mape: 86.2035\n",
      "Epoch 179/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2016 - mae: 0.3322 - mape: 136.0139 - val_loss: 0.1113 - val_mae: 0.2291 - val_mape: 86.3531\n",
      "Epoch 180/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1068 - mae: 0.2687 - mape: 139.4684 - val_loss: 0.1108 - val_mae: 0.2289 - val_mape: 86.6379\n",
      "Epoch 181/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1074 - mae: 0.2608 - mape: 142.5004 - val_loss: 0.1103 - val_mae: 0.2288 - val_mape: 86.9148\n",
      "Epoch 182/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1246 - mae: 0.2866 - mape: 145.9417 - val_loss: 0.1098 - val_mae: 0.2287 - val_mape: 87.2467\n",
      "Epoch 183/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1333 - mae: 0.2793 - mape: 121.1362 - val_loss: 0.1092 - val_mae: 0.2284 - val_mape: 87.4824\n",
      "Epoch 184/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1077 - mae: 0.2525 - mape: 120.1949 - val_loss: 0.1086 - val_mae: 0.2278 - val_mape: 87.5343\n",
      "Epoch 185/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1317 - mae: 0.2706 - mape: 128.7799 - val_loss: 0.1081 - val_mae: 0.2270 - val_mape: 87.3166\n",
      "Epoch 186/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1125 - mae: 0.2639 - mape: 129.8443 - val_loss: 0.1075 - val_mae: 0.2263 - val_mape: 87.1582\n",
      "Epoch 187/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1661 - mae: 0.2998 - mape: 152.2889 - val_loss: 0.1068 - val_mae: 0.2254 - val_mape: 86.8509\n",
      "Epoch 188/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1457 - mae: 0.2832 - mape: 142.8595 - val_loss: 0.1062 - val_mae: 0.2246 - val_mape: 86.5448\n",
      "Epoch 189/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1580 - mae: 0.3077 - mape: 142.2439 - val_loss: 0.1055 - val_mae: 0.2238 - val_mape: 86.3146\n",
      "Epoch 190/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0913 - mae: 0.2442 - mape: 125.0210 - val_loss: 0.1049 - val_mae: 0.2228 - val_mape: 85.9510\n",
      "Epoch 191/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1613 - mae: 0.2908 - mape: 132.5320 - val_loss: 0.1042 - val_mae: 0.2219 - val_mape: 85.5349\n",
      "Epoch 192/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1219 - mae: 0.2376 - mape: 107.3499 - val_loss: 0.1035 - val_mae: 0.2208 - val_mape: 84.9767\n",
      "Epoch 193/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1994 - mae: 0.3349 - mape: 143.6853 - val_loss: 0.1029 - val_mae: 0.2197 - val_mape: 84.3652\n",
      "Epoch 194/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1196 - mae: 0.2777 - mape: 133.2438 - val_loss: 0.1022 - val_mae: 0.2185 - val_mape: 83.6737\n",
      "Epoch 195/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1697 - mae: 0.3211 - mape: 157.6903 - val_loss: 0.1016 - val_mae: 0.2174 - val_mape: 83.1255\n",
      "Epoch 196/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1506 - mae: 0.2851 - mape: 141.2007 - val_loss: 0.1009 - val_mae: 0.2164 - val_mape: 82.6903\n",
      "Epoch 197/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1280 - mae: 0.2779 - mape: 119.8395 - val_loss: 0.1003 - val_mae: 0.2156 - val_mape: 82.3740\n",
      "Epoch 198/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1487 - mae: 0.2941 - mape: 131.0952 - val_loss: 0.0997 - val_mae: 0.2148 - val_mape: 82.1574\n",
      "Epoch 199/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1429 - mae: 0.2816 - mape: 141.7716 - val_loss: 0.0991 - val_mae: 0.2141 - val_mape: 82.0392\n",
      "Epoch 200/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2145 - mae: 0.3531 - mape: 154.6229 - val_loss: 0.0986 - val_mae: 0.2139 - val_mape: 82.1023\n",
      "Epoch 201/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0979 - mae: 0.2498 - mape: 129.6481 - val_loss: 0.0982 - val_mae: 0.2137 - val_mape: 82.3054\n",
      "Epoch 202/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1498 - mae: 0.2991 - mape: 127.8626 - val_loss: 0.0978 - val_mae: 0.2137 - val_mape: 82.5077\n",
      "Epoch 203/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1323 - mae: 0.2909 - mape: 151.0774 - val_loss: 0.0974 - val_mae: 0.2136 - val_mape: 82.8135\n",
      "Epoch 204/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1444 - mae: 0.3032 - mape: 140.7568 - val_loss: 0.0970 - val_mae: 0.2138 - val_mape: 83.4322\n",
      "Epoch 205/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0989 - mae: 0.2496 - mape: 123.8190 - val_loss: 0.0965 - val_mae: 0.2137 - val_mape: 83.9904\n",
      "Epoch 206/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1555 - mae: 0.2970 - mape: 140.3402 - val_loss: 0.0959 - val_mae: 0.2135 - val_mape: 84.4013\n",
      "Epoch 207/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0992 - mae: 0.2451 - mape: 123.7723 - val_loss: 0.0953 - val_mae: 0.2131 - val_mape: 84.6813\n",
      "Epoch 208/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1080 - mae: 0.2586 - mape: 121.0979 - val_loss: 0.0947 - val_mae: 0.2127 - val_mape: 84.9414\n",
      "Epoch 209/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1465 - mae: 0.2868 - mape: 142.2985 - val_loss: 0.0940 - val_mae: 0.2121 - val_mape: 84.9936\n",
      "Epoch 210/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1345 - mae: 0.2660 - mape: 122.1847 - val_loss: 0.0933 - val_mae: 0.2112 - val_mape: 84.8466\n",
      "Epoch 211/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1623 - mae: 0.2949 - mape: 129.0590 - val_loss: 0.0926 - val_mae: 0.2103 - val_mape: 84.5467\n",
      "Epoch 212/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1417 - mae: 0.2822 - mape: 140.5461 - val_loss: 0.0919 - val_mae: 0.2094 - val_mape: 84.2319\n",
      "Epoch 213/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1055 - mae: 0.2570 - mape: 119.5292 - val_loss: 0.0912 - val_mae: 0.2085 - val_mape: 83.9557\n",
      "Epoch 214/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1447 - mae: 0.2738 - mape: 125.2199 - val_loss: 0.0905 - val_mae: 0.2076 - val_mape: 83.6814\n",
      "Epoch 215/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0798 - mae: 0.2197 - mape: 115.0183 - val_loss: 0.0899 - val_mae: 0.2069 - val_mape: 83.5710\n",
      "Epoch 216/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0917 - mae: 0.2422 - mape: 107.1515 - val_loss: 0.0892 - val_mae: 0.2062 - val_mape: 83.6548\n",
      "Epoch 217/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1509 - mae: 0.2930 - mape: 137.9742 - val_loss: 0.0885 - val_mae: 0.2056 - val_mape: 83.9053\n",
      "Epoch 218/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1141 - mae: 0.2560 - mape: 122.5815 - val_loss: 0.0877 - val_mae: 0.2049 - val_mape: 84.0644\n",
      "Epoch 219/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1143 - mae: 0.2714 - mape: 130.0547 - val_loss: 0.0870 - val_mae: 0.2041 - val_mape: 84.2921\n",
      "Epoch 220/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1016 - mae: 0.2561 - mape: 133.0811 - val_loss: 0.0862 - val_mae: 0.2034 - val_mape: 84.4431\n",
      "Epoch 221/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1009 - mae: 0.2548 - mape: 127.5294 - val_loss: 0.0855 - val_mae: 0.2027 - val_mape: 84.5590\n",
      "Epoch 222/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1676 - mae: 0.2941 - mape: 116.1541 - val_loss: 0.0849 - val_mae: 0.2022 - val_mape: 84.6454\n",
      "Epoch 223/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1183 - mae: 0.2765 - mape: 135.8103 - val_loss: 0.0842 - val_mae: 0.2017 - val_mape: 84.8589\n",
      "Epoch 224/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0861 - mae: 0.2324 - mape: 128.7212 - val_loss: 0.0836 - val_mae: 0.2011 - val_mape: 84.9544\n",
      "Epoch 225/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0894 - mae: 0.2477 - mape: 146.5642 - val_loss: 0.0829 - val_mae: 0.2006 - val_mape: 85.2382\n",
      "Epoch 226/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1388 - mae: 0.2676 - mape: 122.4743 - val_loss: 0.0823 - val_mae: 0.2001 - val_mape: 85.4678\n",
      "Epoch 227/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0793 - mae: 0.2288 - mape: 131.7322 - val_loss: 0.0817 - val_mae: 0.1995 - val_mape: 85.5640\n",
      "Epoch 228/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0827 - mae: 0.2282 - mape: 114.0556 - val_loss: 0.0810 - val_mae: 0.1989 - val_mape: 85.6605\n",
      "Epoch 229/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1725 - mae: 0.2976 - mape: 136.7427 - val_loss: 0.0804 - val_mae: 0.1982 - val_mape: 85.5332\n",
      "Epoch 230/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0860 - mae: 0.2357 - mape: 121.1995 - val_loss: 0.0797 - val_mae: 0.1973 - val_mape: 85.2616\n",
      "Epoch 231/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0946 - mae: 0.2436 - mape: 124.6418 - val_loss: 0.0791 - val_mae: 0.1965 - val_mape: 85.1183\n",
      "Epoch 232/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1161 - mae: 0.2633 - mape: 153.5005 - val_loss: 0.0784 - val_mae: 0.1957 - val_mape: 85.2487\n",
      "Epoch 233/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1199 - mae: 0.2700 - mape: 124.2208 - val_loss: 0.0777 - val_mae: 0.1950 - val_mape: 85.5415\n",
      "Epoch 234/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1792 - mae: 0.3227 - mape: 123.8079 - val_loss: 0.0770 - val_mae: 0.1943 - val_mape: 85.7095\n",
      "Epoch 235/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2022 - mae: 0.3176 - mape: 136.0393 - val_loss: 0.0764 - val_mae: 0.1939 - val_mape: 86.2045\n",
      "Epoch 236/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1020 - mae: 0.2420 - mape: 124.5186 - val_loss: 0.0758 - val_mae: 0.1933 - val_mape: 86.4921\n",
      "Epoch 237/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1310 - mae: 0.2755 - mape: 140.4003 - val_loss: 0.0752 - val_mae: 0.1925 - val_mape: 86.5826\n",
      "Epoch 238/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0992 - mae: 0.2375 - mape: 121.4545 - val_loss: 0.0746 - val_mae: 0.1918 - val_mape: 86.7071\n",
      "Epoch 239/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1411 - mae: 0.2756 - mape: 145.3108 - val_loss: 0.0739 - val_mae: 0.1909 - val_mape: 86.7343\n",
      "Epoch 240/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0878 - mae: 0.2384 - mape: 154.9072 - val_loss: 0.0733 - val_mae: 0.1900 - val_mape: 86.8020\n",
      "Epoch 241/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1475 - mae: 0.2770 - mape: 126.9121 - val_loss: 0.0728 - val_mae: 0.1894 - val_mape: 86.6644\n",
      "Epoch 242/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0822 - mae: 0.2193 - mape: 136.0910 - val_loss: 0.0723 - val_mae: 0.1886 - val_mape: 86.3331\n",
      "Epoch 243/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1218 - mae: 0.2672 - mape: 136.2221 - val_loss: 0.0718 - val_mae: 0.1878 - val_mape: 85.8229\n",
      "Epoch 244/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1224 - mae: 0.2623 - mape: 121.5730 - val_loss: 0.0713 - val_mae: 0.1868 - val_mape: 84.9692\n",
      "Epoch 245/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1340 - mae: 0.2687 - mape: 137.8498 - val_loss: 0.0709 - val_mae: 0.1859 - val_mape: 84.2521\n",
      "Epoch 246/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1018 - mae: 0.2425 - mape: 140.4231 - val_loss: 0.0704 - val_mae: 0.1849 - val_mape: 83.4558\n",
      "Epoch 247/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1236 - mae: 0.2770 - mape: 152.7009 - val_loss: 0.0699 - val_mae: 0.1842 - val_mape: 82.7347\n",
      "Epoch 248/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0927 - mae: 0.2436 - mape: 124.2271 - val_loss: 0.0695 - val_mae: 0.1836 - val_mape: 82.1169\n",
      "Epoch 249/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1306 - mae: 0.2657 - mape: 123.5394 - val_loss: 0.0691 - val_mae: 0.1831 - val_mape: 81.5433\n",
      "Epoch 250/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0730 - mae: 0.2106 - mape: 111.1076 - val_loss: 0.0688 - val_mae: 0.1830 - val_mape: 81.5751\n",
      "Epoch 251/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0966 - mae: 0.2484 - mape: 150.8853 - val_loss: 0.0686 - val_mae: 0.1832 - val_mape: 82.0990\n",
      "Epoch 252/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0931 - mae: 0.2261 - mape: 109.7492 - val_loss: 0.0682 - val_mae: 0.1832 - val_mape: 82.5501\n",
      "Epoch 253/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0911 - mae: 0.2338 - mape: 132.9199 - val_loss: 0.0678 - val_mae: 0.1831 - val_mape: 82.8684\n",
      "Epoch 254/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.1469 - mae: 0.2978 - mape: 142.4163 - val_loss: 0.0673 - val_mae: 0.1828 - val_mape: 83.1752\n",
      "Epoch 255/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1008 - mae: 0.2595 - mape: 137.6792 - val_loss: 0.0668 - val_mae: 0.1826 - val_mape: 83.7414\n",
      "Epoch 256/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0826 - mae: 0.2253 - mape: 109.2538 - val_loss: 0.0664 - val_mae: 0.1825 - val_mape: 84.3007\n",
      "Epoch 257/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1407 - mae: 0.2830 - mape: 115.6514 - val_loss: 0.0659 - val_mae: 0.1825 - val_mape: 85.0715\n",
      "Epoch 258/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0516 - mae: 0.1886 - mape: 115.6984 - val_loss: 0.0655 - val_mae: 0.1824 - val_mape: 85.7291\n",
      "Epoch 259/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0853 - mae: 0.2364 - mape: 124.1102 - val_loss: 0.0651 - val_mae: 0.1824 - val_mape: 86.4112\n",
      "Epoch 260/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0637 - mae: 0.2015 - mape: 122.9974 - val_loss: 0.0647 - val_mae: 0.1824 - val_mape: 87.1980\n",
      "Epoch 261/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1094 - mae: 0.2434 - mape: 119.1894 - val_loss: 0.0642 - val_mae: 0.1823 - val_mape: 87.9056\n",
      "Epoch 262/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1094 - mae: 0.2575 - mape: 129.6210 - val_loss: 0.0637 - val_mae: 0.1823 - val_mape: 89.0352\n",
      "Epoch 263/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0921 - mae: 0.2377 - mape: 138.6048 - val_loss: 0.0632 - val_mae: 0.1824 - val_mape: 89.9829\n",
      "Epoch 264/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1601 - mae: 0.2905 - mape: 133.5020 - val_loss: 0.0630 - val_mae: 0.1827 - val_mape: 90.7763\n",
      "Epoch 265/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0908 - mae: 0.2397 - mape: 147.2731 - val_loss: 0.0629 - val_mae: 0.1830 - val_mape: 91.3687\n",
      "Epoch 266/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0605 - mae: 0.2040 - mape: 136.4984 - val_loss: 0.0627 - val_mae: 0.1833 - val_mape: 91.8940\n",
      "Epoch 267/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1257 - mae: 0.2921 - mape: 148.2719 - val_loss: 0.0625 - val_mae: 0.1838 - val_mape: 92.9889\n",
      "Epoch 268/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1260 - mae: 0.2483 - mape: 124.2320 - val_loss: 0.0624 - val_mae: 0.1842 - val_mape: 93.9122\n",
      "Epoch 269/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1762 - mae: 0.3057 - mape: 131.4937 - val_loss: 0.0623 - val_mae: 0.1847 - val_mape: 94.7515\n",
      "Epoch 270/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0865 - mae: 0.2340 - mape: 149.4231 - val_loss: 0.0622 - val_mae: 0.1849 - val_mape: 95.3543\n",
      "Epoch 271/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1158 - mae: 0.2500 - mape: 142.9477 - val_loss: 0.0620 - val_mae: 0.1851 - val_mape: 95.7725\n",
      "Epoch 272/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1943 - mae: 0.3224 - mape: 148.5182 - val_loss: 0.0619 - val_mae: 0.1852 - val_mape: 95.9759\n",
      "Epoch 273/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0589 - mae: 0.1970 - mape: 100.8755 - val_loss: 0.0617 - val_mae: 0.1852 - val_mape: 96.2051\n",
      "Epoch 274/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1306 - mae: 0.2570 - mape: 110.4729 - val_loss: 0.0616 - val_mae: 0.1853 - val_mape: 96.3219\n",
      "Epoch 275/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0621 - mae: 0.2092 - mape: 126.6433 - val_loss: 0.0615 - val_mae: 0.1854 - val_mape: 96.5044\n",
      "Epoch 276/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1219 - mae: 0.2494 - mape: 113.3002 - val_loss: 0.0615 - val_mae: 0.1855 - val_mape: 96.5812\n",
      "Epoch 277/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1273 - mae: 0.2609 - mape: 144.0207 - val_loss: 0.0613 - val_mae: 0.1852 - val_mape: 96.3451\n",
      "Epoch 278/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1623 - mae: 0.2926 - mape: 118.5405 - val_loss: 0.0613 - val_mae: 0.1851 - val_mape: 95.9650\n",
      "Epoch 279/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1064 - mae: 0.2365 - mape: 123.6317 - val_loss: 0.0612 - val_mae: 0.1847 - val_mape: 95.2931\n",
      "Epoch 280/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0646 - mae: 0.2051 - mape: 121.7857 - val_loss: 0.0610 - val_mae: 0.1843 - val_mape: 94.5754\n",
      "Epoch 281/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0649 - mae: 0.2007 - mape: 121.6558 - val_loss: 0.0608 - val_mae: 0.1838 - val_mape: 94.1087\n",
      "Epoch 282/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0811 - mae: 0.2153 - mape: 121.8769 - val_loss: 0.0606 - val_mae: 0.1833 - val_mape: 93.5202\n",
      "Epoch 283/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0593 - mae: 0.1883 - mape: 112.1885 - val_loss: 0.0603 - val_mae: 0.1827 - val_mape: 92.8253\n",
      "Epoch 284/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0655 - mae: 0.2069 - mape: 124.9540 - val_loss: 0.0601 - val_mae: 0.1822 - val_mape: 92.1889\n",
      "Epoch 285/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0739 - mae: 0.2120 - mape: 130.9923 - val_loss: 0.0599 - val_mae: 0.1817 - val_mape: 91.3874\n",
      "Epoch 286/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0912 - mae: 0.2296 - mape: 125.2395 - val_loss: 0.0597 - val_mae: 0.1812 - val_mape: 90.7947\n",
      "Epoch 287/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1076 - mae: 0.2443 - mape: 141.0804 - val_loss: 0.0595 - val_mae: 0.1805 - val_mape: 89.8343\n",
      "Epoch 288/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0744 - mae: 0.2056 - mape: 112.7020 - val_loss: 0.0591 - val_mae: 0.1794 - val_mape: 88.3994\n",
      "Epoch 289/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1247 - mae: 0.2541 - mape: 124.5936 - val_loss: 0.0588 - val_mae: 0.1784 - val_mape: 86.9168\n",
      "Epoch 290/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0715 - mae: 0.2158 - mape: 136.5361 - val_loss: 0.0585 - val_mae: 0.1775 - val_mape: 85.5195\n",
      "Epoch 291/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0737 - mae: 0.2115 - mape: 147.0929 - val_loss: 0.0582 - val_mae: 0.1764 - val_mape: 83.8173\n",
      "Epoch 292/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1081 - mae: 0.2337 - mape: 111.4758 - val_loss: 0.0580 - val_mae: 0.1754 - val_mape: 81.7637\n",
      "Epoch 293/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0782 - mae: 0.2297 - mape: 125.5628 - val_loss: 0.0578 - val_mae: 0.1741 - val_mape: 79.3763\n",
      "Epoch 294/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0672 - mae: 0.2055 - mape: 127.3199 - val_loss: 0.0575 - val_mae: 0.1726 - val_mape: 76.8273\n",
      "Epoch 295/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0774 - mae: 0.2200 - mape: 113.0958 - val_loss: 0.0572 - val_mae: 0.1710 - val_mape: 74.3899\n",
      "Epoch 296/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1316 - mae: 0.2771 - mape: 130.3591 - val_loss: 0.0569 - val_mae: 0.1702 - val_mape: 73.2821\n",
      "Epoch 297/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0620 - mae: 0.2072 - mape: 106.5419 - val_loss: 0.0566 - val_mae: 0.1701 - val_mape: 73.4692\n",
      "Epoch 298/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0667 - mae: 0.2067 - mape: 112.8908 - val_loss: 0.0563 - val_mae: 0.1698 - val_mape: 73.4354\n",
      "Epoch 299/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1002 - mae: 0.2304 - mape: 111.4943 - val_loss: 0.0560 - val_mae: 0.1696 - val_mape: 73.3804\n",
      "Epoch 300/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0922 - mae: 0.2427 - mape: 131.9532 - val_loss: 0.0557 - val_mae: 0.1694 - val_mape: 73.3913\n",
      "Epoch 301/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0664 - mae: 0.1978 - mape: 105.9433 - val_loss: 0.0554 - val_mae: 0.1693 - val_mape: 73.3686\n",
      "Epoch 302/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1338 - mae: 0.2553 - mape: 128.1186 - val_loss: 0.0551 - val_mae: 0.1691 - val_mape: 73.3587\n",
      "Epoch 303/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1249 - mae: 0.2484 - mape: 123.0570 - val_loss: 0.0548 - val_mae: 0.1689 - val_mape: 73.3114\n",
      "Epoch 304/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1129 - mae: 0.2401 - mape: 141.0820 - val_loss: 0.0544 - val_mae: 0.1687 - val_mape: 73.1517\n",
      "Epoch 305/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1124 - mae: 0.2484 - mape: 120.9866 - val_loss: 0.0541 - val_mae: 0.1684 - val_mape: 73.0313\n",
      "Epoch 306/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1061 - mae: 0.2319 - mape: 125.1997 - val_loss: 0.0537 - val_mae: 0.1679 - val_mape: 72.7933\n",
      "Epoch 307/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1083 - mae: 0.2544 - mape: 160.2960 - val_loss: 0.0533 - val_mae: 0.1673 - val_mape: 72.5446\n",
      "Epoch 308/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0999 - mae: 0.2306 - mape: 132.0995 - val_loss: 0.0529 - val_mae: 0.1667 - val_mape: 72.3033\n",
      "Epoch 309/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1326 - mae: 0.2599 - mape: 135.5846 - val_loss: 0.0524 - val_mae: 0.1658 - val_mape: 71.9786\n",
      "Epoch 310/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0822 - mae: 0.2257 - mape: 117.9582 - val_loss: 0.0520 - val_mae: 0.1649 - val_mape: 71.6368\n",
      "Epoch 311/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0957 - mae: 0.2342 - mape: 127.5103 - val_loss: 0.0514 - val_mae: 0.1638 - val_mape: 71.2043\n",
      "Epoch 312/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1470 - mae: 0.2688 - mape: 114.6155 - val_loss: 0.0509 - val_mae: 0.1628 - val_mape: 70.7361\n",
      "Epoch 313/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0508 - mae: 0.1796 - mape: 100.5650 - val_loss: 0.0504 - val_mae: 0.1618 - val_mape: 70.1667\n",
      "Epoch 314/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0856 - mae: 0.2066 - mape: 116.3978 - val_loss: 0.0499 - val_mae: 0.1609 - val_mape: 69.6636\n",
      "Epoch 315/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0858 - mae: 0.2114 - mape: 103.1925 - val_loss: 0.0494 - val_mae: 0.1599 - val_mape: 69.1213\n",
      "Epoch 316/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0706 - mae: 0.2085 - mape: 119.8774 - val_loss: 0.0490 - val_mae: 0.1592 - val_mape: 68.7888\n",
      "Epoch 317/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0625 - mae: 0.2015 - mape: 110.6258 - val_loss: 0.0487 - val_mae: 0.1586 - val_mape: 68.5162\n",
      "Epoch 318/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1191 - mae: 0.2459 - mape: 125.8216 - val_loss: 0.0485 - val_mae: 0.1582 - val_mape: 68.3036\n",
      "Epoch 319/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0540 - mae: 0.1715 - mape: 105.9364 - val_loss: 0.0482 - val_mae: 0.1577 - val_mape: 68.1213\n",
      "Epoch 320/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0911 - mae: 0.2242 - mape: 114.6369 - val_loss: 0.0480 - val_mae: 0.1574 - val_mape: 67.9439\n",
      "Epoch 321/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0558 - mae: 0.1841 - mape: 100.0828 - val_loss: 0.0478 - val_mae: 0.1570 - val_mape: 67.7528\n",
      "Epoch 322/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0977 - mae: 0.2311 - mape: 127.4423 - val_loss: 0.0476 - val_mae: 0.1566 - val_mape: 67.5878\n",
      "Epoch 323/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0835 - mae: 0.2038 - mape: 103.4148 - val_loss: 0.0474 - val_mae: 0.1561 - val_mape: 67.3045\n",
      "Epoch 324/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0881 - mae: 0.2385 - mape: 140.1172 - val_loss: 0.0471 - val_mae: 0.1556 - val_mape: 67.1025\n",
      "Epoch 325/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0553 - mae: 0.1935 - mape: 117.3954 - val_loss: 0.0469 - val_mae: 0.1553 - val_mape: 66.9520\n",
      "Epoch 326/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0959 - mae: 0.2064 - mape: 93.1052 - val_loss: 0.0468 - val_mae: 0.1553 - val_mape: 66.9729\n",
      "Epoch 327/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1603 - mae: 0.2749 - mape: 114.5922 - val_loss: 0.0468 - val_mae: 0.1555 - val_mape: 67.1103\n",
      "Epoch 328/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0718 - mae: 0.2006 - mape: 140.6407 - val_loss: 0.0467 - val_mae: 0.1555 - val_mape: 67.1591\n",
      "Epoch 329/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0760 - mae: 0.2206 - mape: 116.4086 - val_loss: 0.0466 - val_mae: 0.1556 - val_mape: 67.2528\n",
      "Epoch 330/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0878 - mae: 0.2063 - mape: 96.0258 - val_loss: 0.0465 - val_mae: 0.1557 - val_mape: 67.3155\n",
      "Epoch 331/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1620 - mae: 0.2931 - mape: 128.2102 - val_loss: 0.0466 - val_mae: 0.1559 - val_mape: 67.4849\n",
      "Epoch 332/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0464 - mae: 0.1662 - mape: 91.4324 - val_loss: 0.0467 - val_mae: 0.1561 - val_mape: 67.6059\n",
      "Epoch 333/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0893 - mae: 0.2190 - mape: 119.6496 - val_loss: 0.0467 - val_mae: 0.1562 - val_mape: 67.7213\n",
      "Epoch 334/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0525 - mae: 0.1848 - mape: 108.5858 - val_loss: 0.0468 - val_mae: 0.1564 - val_mape: 67.8786\n",
      "Epoch 335/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1003 - mae: 0.2346 - mape: 105.2163 - val_loss: 0.0468 - val_mae: 0.1568 - val_mape: 68.1081\n",
      "Epoch 336/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1027 - mae: 0.2327 - mape: 151.8624 - val_loss: 0.0469 - val_mae: 0.1573 - val_mape: 68.4577\n",
      "Epoch 337/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0667 - mae: 0.1998 - mape: 111.1178 - val_loss: 0.0470 - val_mae: 0.1574 - val_mape: 68.7044\n",
      "Epoch 338/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0831 - mae: 0.1963 - mape: 106.5450 - val_loss: 0.0470 - val_mae: 0.1576 - val_mape: 68.9158\n",
      "Epoch 339/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0924 - mae: 0.2459 - mape: 166.2417 - val_loss: 0.0469 - val_mae: 0.1575 - val_mape: 69.0337\n",
      "Epoch 340/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0638 - mae: 0.2043 - mape: 140.7853 - val_loss: 0.0468 - val_mae: 0.1575 - val_mape: 69.1748\n",
      "Epoch 341/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0539 - mae: 0.1844 - mape: 114.5938 - val_loss: 0.0467 - val_mae: 0.1577 - val_mape: 69.4330\n",
      "Epoch 342/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1023 - mae: 0.2151 - mape: 129.3345 - val_loss: 0.0466 - val_mae: 0.1579 - val_mape: 69.7286\n",
      "Epoch 343/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0563 - mae: 0.1950 - mape: 146.6012 - val_loss: 0.0465 - val_mae: 0.1582 - val_mape: 70.0820\n",
      "Epoch 344/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0508 - mae: 0.1774 - mape: 118.7785 - val_loss: 0.0463 - val_mae: 0.1583 - val_mape: 70.3069\n",
      "Epoch 345/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0918 - mae: 0.2070 - mape: 135.2395 - val_loss: 0.0461 - val_mae: 0.1584 - val_mape: 70.4694\n",
      "Epoch 346/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1437 - mae: 0.2745 - mape: 152.7297 - val_loss: 0.0459 - val_mae: 0.1584 - val_mape: 70.5610\n",
      "Epoch 347/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1083 - mae: 0.2317 - mape: 107.7861 - val_loss: 0.0457 - val_mae: 0.1581 - val_mape: 70.5731\n",
      "Epoch 348/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0892 - mae: 0.2109 - mape: 119.1412 - val_loss: 0.0454 - val_mae: 0.1577 - val_mape: 70.4734\n",
      "Epoch 349/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0901 - mae: 0.2063 - mape: 102.2548 - val_loss: 0.0450 - val_mae: 0.1573 - val_mape: 70.2990\n",
      "Epoch 350/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0661 - mae: 0.1930 - mape: 140.7194 - val_loss: 0.0448 - val_mae: 0.1567 - val_mape: 70.0639\n",
      "Epoch 351/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0842 - mae: 0.2117 - mape: 132.2057 - val_loss: 0.0445 - val_mae: 0.1562 - val_mape: 69.7761\n",
      "Epoch 352/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0714 - mae: 0.1838 - mape: 81.4662 - val_loss: 0.0442 - val_mae: 0.1554 - val_mape: 69.3352\n",
      "Epoch 353/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1784 - mae: 0.2832 - mape: 153.6949 - val_loss: 0.0438 - val_mae: 0.1547 - val_mape: 68.9265\n",
      "Epoch 354/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0584 - mae: 0.1766 - mape: 110.9724 - val_loss: 0.0434 - val_mae: 0.1539 - val_mape: 68.4814\n",
      "Epoch 355/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0675 - mae: 0.1901 - mape: 113.8661 - val_loss: 0.0430 - val_mae: 0.1532 - val_mape: 68.0229\n",
      "Epoch 356/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0455 - mae: 0.1702 - mape: 136.3060 - val_loss: 0.0427 - val_mae: 0.1526 - val_mape: 67.6199\n",
      "Epoch 357/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0581 - mae: 0.1850 - mape: 115.4530 - val_loss: 0.0424 - val_mae: 0.1520 - val_mape: 67.3027\n",
      "Epoch 358/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0487 - mae: 0.1727 - mape: 117.6433 - val_loss: 0.0421 - val_mae: 0.1515 - val_mape: 67.0285\n",
      "Epoch 359/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1637 - mae: 0.2737 - mape: 142.9598 - val_loss: 0.0418 - val_mae: 0.1510 - val_mape: 66.7851\n",
      "Epoch 360/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0979 - mae: 0.2261 - mape: 114.7818 - val_loss: 0.0414 - val_mae: 0.1504 - val_mape: 66.4749\n",
      "Epoch 361/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1032 - mae: 0.2233 - mape: 87.0826 - val_loss: 0.0411 - val_mae: 0.1498 - val_mape: 66.1358\n",
      "Epoch 362/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1437 - mae: 0.2593 - mape: 134.0598 - val_loss: 0.0410 - val_mae: 0.1494 - val_mape: 66.0679\n",
      "Epoch 363/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0540 - mae: 0.1808 - mape: 136.0067 - val_loss: 0.0408 - val_mae: 0.1492 - val_mape: 66.0786\n",
      "Epoch 364/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0613 - mae: 0.1794 - mape: 110.9167 - val_loss: 0.0408 - val_mae: 0.1490 - val_mape: 66.1708\n",
      "Epoch 365/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1172 - mae: 0.2356 - mape: 125.0586 - val_loss: 0.0407 - val_mae: 0.1488 - val_mape: 66.2276\n",
      "Epoch 366/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0519 - mae: 0.1785 - mape: 104.4273 - val_loss: 0.0406 - val_mae: 0.1487 - val_mape: 66.2643\n",
      "Epoch 367/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0928 - mae: 0.2131 - mape: 138.6229 - val_loss: 0.0406 - val_mae: 0.1488 - val_mape: 66.4866\n",
      "Epoch 368/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1273 - mae: 0.2467 - mape: 142.4154 - val_loss: 0.0406 - val_mae: 0.1489 - val_mape: 66.6464\n",
      "Epoch 369/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1158 - mae: 0.2263 - mape: 103.5651 - val_loss: 0.0406 - val_mae: 0.1489 - val_mape: 66.7526\n",
      "Epoch 370/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0326 - mae: 0.1425 - mape: 121.8311 - val_loss: 0.0405 - val_mae: 0.1488 - val_mape: 66.8232\n",
      "Epoch 371/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0912 - mae: 0.2006 - mape: 100.5481 - val_loss: 0.0404 - val_mae: 0.1487 - val_mape: 66.8663\n",
      "Epoch 372/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0921 - mae: 0.2164 - mape: 118.5428 - val_loss: 0.0403 - val_mae: 0.1488 - val_mape: 66.9611\n",
      "Epoch 373/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0638 - mae: 0.1900 - mape: 108.8986 - val_loss: 0.0403 - val_mae: 0.1489 - val_mape: 67.0261\n",
      "Epoch 374/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0532 - mae: 0.1844 - mape: 99.9743 - val_loss: 0.0402 - val_mae: 0.1486 - val_mape: 66.8959\n",
      "Epoch 375/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0749 - mae: 0.2150 - mape: 139.8524 - val_loss: 0.0400 - val_mae: 0.1481 - val_mape: 66.7486\n",
      "Epoch 376/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0452 - mae: 0.1734 - mape: 127.9251 - val_loss: 0.0399 - val_mae: 0.1476 - val_mape: 66.5755\n",
      "Epoch 377/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0585 - mae: 0.1892 - mape: 127.2173 - val_loss: 0.0398 - val_mae: 0.1474 - val_mape: 66.7532\n",
      "Epoch 378/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1166 - mae: 0.2562 - mape: 123.9014 - val_loss: 0.0397 - val_mae: 0.1473 - val_mape: 66.9023\n",
      "Epoch 379/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0731 - mae: 0.1963 - mape: 119.4034 - val_loss: 0.0396 - val_mae: 0.1474 - val_mape: 67.1207\n",
      "Epoch 380/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0343 - mae: 0.1508 - mape: 103.7580 - val_loss: 0.0396 - val_mae: 0.1475 - val_mape: 67.3601\n",
      "Epoch 381/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0780 - mae: 0.1800 - mape: 91.2329 - val_loss: 0.0394 - val_mae: 0.1475 - val_mape: 67.4203\n",
      "Epoch 382/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0999 - mae: 0.2072 - mape: 85.7009 - val_loss: 0.0393 - val_mae: 0.1473 - val_mape: 67.0205\n",
      "Epoch 383/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0554 - mae: 0.1720 - mape: 112.1411 - val_loss: 0.0391 - val_mae: 0.1470 - val_mape: 66.8322\n",
      "Epoch 384/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0383 - mae: 0.1518 - mape: 107.5761 - val_loss: 0.0389 - val_mae: 0.1466 - val_mape: 66.6555\n",
      "Epoch 385/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1093 - mae: 0.2268 - mape: 129.1131 - val_loss: 0.0387 - val_mae: 0.1461 - val_mape: 66.5048\n",
      "Epoch 386/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0733 - mae: 0.1981 - mape: 107.4585 - val_loss: 0.0385 - val_mae: 0.1459 - val_mape: 66.5406\n",
      "Epoch 387/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0632 - mae: 0.1873 - mape: 108.4061 - val_loss: 0.0384 - val_mae: 0.1456 - val_mape: 66.4714\n",
      "Epoch 388/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0490 - mae: 0.1669 - mape: 130.1052 - val_loss: 0.0383 - val_mae: 0.1453 - val_mape: 66.1532\n",
      "Epoch 389/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0537 - mae: 0.1817 - mape: 127.2003 - val_loss: 0.0381 - val_mae: 0.1452 - val_mape: 66.2997\n",
      "Epoch 390/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0920 - mae: 0.2136 - mape: 104.2168 - val_loss: 0.0380 - val_mae: 0.1450 - val_mape: 66.3795\n",
      "Epoch 391/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0668 - mae: 0.2071 - mape: 145.4966 - val_loss: 0.0379 - val_mae: 0.1447 - val_mape: 66.4433\n",
      "Epoch 392/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0629 - mae: 0.1691 - mape: 89.4360 - val_loss: 0.0377 - val_mae: 0.1442 - val_mape: 66.0582\n",
      "Epoch 393/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1060 - mae: 0.2206 - mape: 135.4308 - val_loss: 0.0374 - val_mae: 0.1436 - val_mape: 65.6166\n",
      "Epoch 394/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0885 - mae: 0.2110 - mape: 124.2803 - val_loss: 0.0373 - val_mae: 0.1433 - val_mape: 65.3987\n",
      "Epoch 395/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0812 - mae: 0.1916 - mape: 80.5527 - val_loss: 0.0371 - val_mae: 0.1429 - val_mape: 65.0939\n",
      "Epoch 396/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0484 - mae: 0.1796 - mape: 105.6024 - val_loss: 0.0370 - val_mae: 0.1425 - val_mape: 64.7767\n",
      "Epoch 397/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0424 - mae: 0.1672 - mape: 149.1366 - val_loss: 0.0369 - val_mae: 0.1421 - val_mape: 64.5699\n",
      "Epoch 398/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0686 - mae: 0.1907 - mape: 124.8717 - val_loss: 0.0368 - val_mae: 0.1416 - val_mape: 64.2299\n",
      "Epoch 399/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0416 - mae: 0.1527 - mape: 96.4408 - val_loss: 0.0366 - val_mae: 0.1409 - val_mape: 63.8431\n",
      "Epoch 400/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0376 - mae: 0.1393 - mape: 83.0884 - val_loss: 0.0365 - val_mae: 0.1403 - val_mape: 63.5071\n",
      "Epoch 401/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0496 - mae: 0.1733 - mape: 105.8564 - val_loss: 0.0364 - val_mae: 0.1396 - val_mape: 63.0818\n",
      "Epoch 402/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0537 - mae: 0.1768 - mape: 106.5296 - val_loss: 0.0363 - val_mae: 0.1391 - val_mape: 62.7488\n",
      "Epoch 403/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0634 - mae: 0.1750 - mape: 138.9161 - val_loss: 0.0361 - val_mae: 0.1386 - val_mape: 62.4326\n",
      "Epoch 404/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0886 - mae: 0.2186 - mape: 119.6267 - val_loss: 0.0360 - val_mae: 0.1382 - val_mape: 62.2103\n",
      "Epoch 405/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0981 - mae: 0.2199 - mape: 130.8214 - val_loss: 0.0358 - val_mae: 0.1375 - val_mape: 61.7603\n",
      "Epoch 406/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0681 - mae: 0.1903 - mape: 115.5509 - val_loss: 0.0357 - val_mae: 0.1373 - val_mape: 62.2408\n",
      "Epoch 407/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1022 - mae: 0.2166 - mape: 137.4881 - val_loss: 0.0356 - val_mae: 0.1385 - val_mape: 65.1144\n",
      "Epoch 408/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0391 - mae: 0.1524 - mape: 96.4598 - val_loss: 0.0355 - val_mae: 0.1392 - val_mape: 66.9347\n",
      "Epoch 409/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0436 - mae: 0.1685 - mape: 115.9066 - val_loss: 0.0354 - val_mae: 0.1398 - val_mape: 68.5695\n",
      "Epoch 410/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0460 - mae: 0.1724 - mape: 157.1317 - val_loss: 0.0354 - val_mae: 0.1410 - val_mape: 71.3877\n",
      "Epoch 411/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0939 - mae: 0.2213 - mape: 138.7575 - val_loss: 0.0354 - val_mae: 0.1416 - val_mape: 72.7923\n",
      "Epoch 412/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0791 - mae: 0.1846 - mape: 102.4936 - val_loss: 0.0353 - val_mae: 0.1414 - val_mape: 72.9225\n",
      "Epoch 413/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0436 - mae: 0.1640 - mape: 95.5216 - val_loss: 0.0351 - val_mae: 0.1411 - val_mape: 72.5647\n",
      "Epoch 414/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0347 - mae: 0.1493 - mape: 81.4285 - val_loss: 0.0351 - val_mae: 0.1409 - val_mape: 72.3737\n",
      "Epoch 415/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0397 - mae: 0.1550 - mape: 109.5033 - val_loss: 0.0351 - val_mae: 0.1402 - val_mape: 70.9848\n",
      "Epoch 416/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0847 - mae: 0.2080 - mape: 149.3376 - val_loss: 0.0350 - val_mae: 0.1391 - val_mape: 68.9114\n",
      "Epoch 417/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0711 - mae: 0.1966 - mape: 144.1839 - val_loss: 0.0349 - val_mae: 0.1383 - val_mape: 67.5841\n",
      "Epoch 418/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0839 - mae: 0.1762 - mape: 92.4408 - val_loss: 0.0348 - val_mae: 0.1375 - val_mape: 66.1618\n",
      "Epoch 419/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0606 - mae: 0.1773 - mape: 124.5066 - val_loss: 0.0347 - val_mae: 0.1360 - val_mape: 63.4995\n",
      "Epoch 420/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0417 - mae: 0.1522 - mape: 109.3370 - val_loss: 0.0346 - val_mae: 0.1345 - val_mape: 60.8064\n",
      "Epoch 421/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0469 - mae: 0.1729 - mape: 93.3328 - val_loss: 0.0344 - val_mae: 0.1345 - val_mape: 60.8650\n",
      "Epoch 422/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0620 - mae: 0.1800 - mape: 95.4633 - val_loss: 0.0343 - val_mae: 0.1346 - val_mape: 60.9767\n",
      "Epoch 423/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0655 - mae: 0.1729 - mape: 123.3158 - val_loss: 0.0342 - val_mae: 0.1349 - val_mape: 61.1337\n",
      "Epoch 424/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0484 - mae: 0.1512 - mape: 86.6410 - val_loss: 0.0341 - val_mae: 0.1352 - val_mape: 61.3325\n",
      "Epoch 425/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0729 - mae: 0.1774 - mape: 91.3465 - val_loss: 0.0341 - val_mae: 0.1356 - val_mape: 61.5392\n",
      "Epoch 426/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1055 - mae: 0.2213 - mape: 130.9158 - val_loss: 0.0340 - val_mae: 0.1358 - val_mape: 61.6612\n",
      "Epoch 427/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0532 - mae: 0.1576 - mape: 91.3348 - val_loss: 0.0340 - val_mae: 0.1360 - val_mape: 61.7743\n",
      "Epoch 428/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0575 - mae: 0.1831 - mape: 148.2419 - val_loss: 0.0340 - val_mae: 0.1362 - val_mape: 61.8033\n",
      "Epoch 429/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0449 - mae: 0.1605 - mape: 99.0789 - val_loss: 0.0340 - val_mae: 0.1363 - val_mape: 61.8835\n",
      "Epoch 430/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0432 - mae: 0.1493 - mape: 113.1729 - val_loss: 0.0341 - val_mae: 0.1366 - val_mape: 62.1655\n",
      "Epoch 431/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1062 - mae: 0.2208 - mape: 128.5131 - val_loss: 0.0342 - val_mae: 0.1369 - val_mape: 62.4093\n",
      "Epoch 432/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0635 - mae: 0.1806 - mape: 93.4807 - val_loss: 0.0343 - val_mae: 0.1372 - val_mape: 62.5906\n",
      "Epoch 433/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0379 - mae: 0.1365 - mape: 100.1730 - val_loss: 0.0344 - val_mae: 0.1376 - val_mape: 62.8969\n",
      "Epoch 434/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0261 - mae: 0.1279 - mape: 104.7421 - val_loss: 0.0346 - val_mae: 0.1379 - val_mape: 63.2623\n",
      "Epoch 435/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0326 - mae: 0.1406 - mape: 88.0349 - val_loss: 0.0347 - val_mae: 0.1382 - val_mape: 63.6190\n",
      "Epoch 436/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1069 - mae: 0.2274 - mape: 145.7800 - val_loss: 0.0348 - val_mae: 0.1383 - val_mape: 63.8791\n",
      "Epoch 437/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0269 - mae: 0.1313 - mape: 89.2256 - val_loss: 0.0347 - val_mae: 0.1381 - val_mape: 63.9947\n",
      "Epoch 438/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0738 - mae: 0.2071 - mape: 131.6948 - val_loss: 0.0346 - val_mae: 0.1379 - val_mape: 64.0785\n",
      "Epoch 439/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0345 - mae: 0.1489 - mape: 79.8143 - val_loss: 0.0346 - val_mae: 0.1378 - val_mape: 64.1858\n",
      "Epoch 440/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0365 - mae: 0.1362 - mape: 90.4015 - val_loss: 0.0345 - val_mae: 0.1376 - val_mape: 64.2049\n",
      "Epoch 441/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0877 - mae: 0.2073 - mape: 144.9611 - val_loss: 0.0345 - val_mae: 0.1374 - val_mape: 64.3609\n",
      "Epoch 442/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0443 - mae: 0.1602 - mape: 97.0562 - val_loss: 0.0344 - val_mae: 0.1371 - val_mape: 64.4726\n",
      "Epoch 443/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1491 - mae: 0.2616 - mape: 120.5413 - val_loss: 0.0342 - val_mae: 0.1365 - val_mape: 64.3740\n",
      "Epoch 444/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0478 - mae: 0.1538 - mape: 126.1303 - val_loss: 0.0340 - val_mae: 0.1359 - val_mape: 64.3164\n",
      "Epoch 445/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0375 - mae: 0.1653 - mape: 130.3685 - val_loss: 0.0339 - val_mae: 0.1355 - val_mape: 64.4333\n",
      "Epoch 446/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0500 - mae: 0.1593 - mape: 113.5121 - val_loss: 0.0337 - val_mae: 0.1351 - val_mape: 64.5529\n",
      "Epoch 447/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0818 - mae: 0.1925 - mape: 109.7064 - val_loss: 0.0336 - val_mae: 0.1349 - val_mape: 64.6901\n",
      "Epoch 448/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0353 - mae: 0.1421 - mape: 93.4028 - val_loss: 0.0335 - val_mae: 0.1344 - val_mape: 64.6973\n",
      "Epoch 449/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0375 - mae: 0.1527 - mape: 106.0239 - val_loss: 0.0333 - val_mae: 0.1340 - val_mape: 64.6925\n",
      "Epoch 450/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0402 - mae: 0.1608 - mape: 119.7445 - val_loss: 0.0332 - val_mae: 0.1338 - val_mape: 64.8143\n",
      "Epoch 451/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0851 - mae: 0.2049 - mape: 113.6321 - val_loss: 0.0332 - val_mae: 0.1337 - val_mape: 65.1488\n",
      "Epoch 452/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0288 - mae: 0.1321 - mape: 77.9780 - val_loss: 0.0333 - val_mae: 0.1337 - val_mape: 65.4910\n",
      "Epoch 453/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0596 - mae: 0.1881 - mape: 147.3268 - val_loss: 0.0334 - val_mae: 0.1341 - val_mape: 66.0724\n",
      "Epoch 454/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0697 - mae: 0.1748 - mape: 98.7039 - val_loss: 0.0336 - val_mae: 0.1343 - val_mape: 66.5388\n",
      "Epoch 455/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0477 - mae: 0.1661 - mape: 134.9680 - val_loss: 0.0336 - val_mae: 0.1345 - val_mape: 66.9444\n",
      "Epoch 456/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0286 - mae: 0.1289 - mape: 107.0027 - val_loss: 0.0336 - val_mae: 0.1348 - val_mape: 67.3314\n",
      "Epoch 457/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0789 - mae: 0.2061 - mape: 126.0260 - val_loss: 0.0338 - val_mae: 0.1347 - val_mape: 67.5981\n",
      "Epoch 458/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1006 - mae: 0.2281 - mape: 158.9800 - val_loss: 0.0339 - val_mae: 0.1344 - val_mape: 67.7143\n",
      "Epoch 459/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0391 - mae: 0.1373 - mape: 98.8369 - val_loss: 0.0341 - val_mae: 0.1360 - val_mape: 70.8518\n",
      "Epoch 460/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0235 - mae: 0.1224 - mape: 110.1547 - val_loss: 0.0342 - val_mae: 0.1369 - val_mape: 72.6189\n",
      "Epoch 461/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0607 - mae: 0.1857 - mape: 127.1570 - val_loss: 0.0341 - val_mae: 0.1376 - val_mape: 74.5231\n",
      "Epoch 462/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0345 - mae: 0.1437 - mape: 112.3143 - val_loss: 0.0340 - val_mae: 0.1382 - val_mape: 76.3299\n",
      "Epoch 463/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0377 - mae: 0.1470 - mape: 117.9396 - val_loss: 0.0340 - val_mae: 0.1388 - val_mape: 77.9195\n",
      "Epoch 464/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0329 - mae: 0.1414 - mape: 138.3257 - val_loss: 0.0339 - val_mae: 0.1391 - val_mape: 78.9979\n",
      "Epoch 465/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1157 - mae: 0.2498 - mape: 151.1532 - val_loss: 0.0337 - val_mae: 0.1390 - val_mape: 79.3876\n",
      "Epoch 466/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0525 - mae: 0.1713 - mape: 147.8531 - val_loss: 0.0335 - val_mae: 0.1386 - val_mape: 79.4027\n",
      "Epoch 467/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0518 - mae: 0.1685 - mape: 120.4722 - val_loss: 0.0331 - val_mae: 0.1380 - val_mape: 79.5579\n",
      "Epoch 468/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0662 - mae: 0.1776 - mape: 114.3759 - val_loss: 0.0326 - val_mae: 0.1371 - val_mape: 79.3479\n",
      "Epoch 469/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0624 - mae: 0.1815 - mape: 125.7699 - val_loss: 0.0323 - val_mae: 0.1366 - val_mape: 79.5126\n",
      "Epoch 470/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0620 - mae: 0.1873 - mape: 156.7912 - val_loss: 0.0320 - val_mae: 0.1361 - val_mape: 79.5820\n",
      "Epoch 471/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0590 - mae: 0.1693 - mape: 92.3440 - val_loss: 0.0315 - val_mae: 0.1353 - val_mape: 79.1323\n",
      "Epoch 472/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0272 - mae: 0.1315 - mape: 103.2427 - val_loss: 0.0311 - val_mae: 0.1343 - val_mape: 78.6749\n",
      "Epoch 473/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0296 - mae: 0.1477 - mape: 107.6889 - val_loss: 0.0307 - val_mae: 0.1335 - val_mape: 78.2105\n",
      "Epoch 474/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0297 - mae: 0.1369 - mape: 117.2660 - val_loss: 0.0303 - val_mae: 0.1330 - val_mape: 78.2822\n",
      "Epoch 475/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0616 - mae: 0.1789 - mape: 122.9603 - val_loss: 0.0302 - val_mae: 0.1327 - val_mape: 78.4690\n",
      "Epoch 476/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0364 - mae: 0.1370 - mape: 105.1610 - val_loss: 0.0299 - val_mae: 0.1320 - val_mape: 77.9846\n",
      "Epoch 477/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0423 - mae: 0.1624 - mape: 116.4046 - val_loss: 0.0296 - val_mae: 0.1310 - val_mape: 76.9725\n",
      "Epoch 478/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0538 - mae: 0.1653 - mape: 103.3280 - val_loss: 0.0292 - val_mae: 0.1298 - val_mape: 75.4407\n",
      "Epoch 479/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0247 - mae: 0.1363 - mape: 123.3990 - val_loss: 0.0289 - val_mae: 0.1283 - val_mape: 73.3668\n",
      "Epoch 480/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0978 - mae: 0.1979 - mape: 128.3452 - val_loss: 0.0287 - val_mae: 0.1272 - val_mape: 71.6168\n",
      "Epoch 481/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0411 - mae: 0.1615 - mape: 118.4350 - val_loss: 0.0287 - val_mae: 0.1266 - val_mape: 70.2648\n",
      "Epoch 482/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0658 - mae: 0.1634 - mape: 105.9845 - val_loss: 0.0286 - val_mae: 0.1258 - val_mape: 68.8491\n",
      "Epoch 483/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0362 - mae: 0.1443 - mape: 132.7573 - val_loss: 0.0286 - val_mae: 0.1251 - val_mape: 67.5296\n",
      "Epoch 484/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0540 - mae: 0.1547 - mape: 115.8690 - val_loss: 0.0285 - val_mae: 0.1245 - val_mape: 66.5000\n",
      "Epoch 485/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0240 - mae: 0.1277 - mape: 97.6752 - val_loss: 0.0285 - val_mae: 0.1241 - val_mape: 65.7861\n",
      "Epoch 486/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0310 - mae: 0.1409 - mape: 105.6208 - val_loss: 0.0285 - val_mae: 0.1236 - val_mape: 64.9136\n",
      "Epoch 487/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0330 - mae: 0.1432 - mape: 99.0054 - val_loss: 0.0285 - val_mae: 0.1230 - val_mape: 63.7654\n",
      "Epoch 488/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0774 - mae: 0.1715 - mape: 114.6576 - val_loss: 0.0285 - val_mae: 0.1224 - val_mape: 62.3305\n",
      "Epoch 489/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0377 - mae: 0.1473 - mape: 117.7683 - val_loss: 0.0286 - val_mae: 0.1219 - val_mape: 60.9746\n",
      "Epoch 490/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1012 - mae: 0.2285 - mape: 133.8442 - val_loss: 0.0287 - val_mae: 0.1216 - val_mape: 60.0241\n",
      "Epoch 491/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0821 - mae: 0.2026 - mape: 111.7973 - val_loss: 0.0288 - val_mae: 0.1211 - val_mape: 59.0647\n",
      "Epoch 492/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0345 - mae: 0.1540 - mape: 136.0769 - val_loss: 0.0288 - val_mae: 0.1205 - val_mape: 58.2033\n",
      "Epoch 493/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0550 - mae: 0.1654 - mape: 118.1137 - val_loss: 0.0287 - val_mae: 0.1202 - val_mape: 57.7420\n",
      "Epoch 494/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0251 - mae: 0.1175 - mape: 101.4407 - val_loss: 0.0287 - val_mae: 0.1202 - val_mape: 57.7323\n",
      "Epoch 495/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1253 - mae: 0.2312 - mape: 163.4319 - val_loss: 0.0285 - val_mae: 0.1199 - val_mape: 57.5846\n",
      "Epoch 496/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0514 - mae: 0.1634 - mape: 128.4669 - val_loss: 0.0283 - val_mae: 0.1195 - val_mape: 57.4918\n",
      "Epoch 497/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0244 - mae: 0.1222 - mape: 106.4431 - val_loss: 0.0281 - val_mae: 0.1192 - val_mape: 57.4704\n",
      "Epoch 498/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0187 - mae: 0.1142 - mape: 110.2786 - val_loss: 0.0279 - val_mae: 0.1191 - val_mape: 57.5498\n",
      "Epoch 499/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0387 - mae: 0.1503 - mape: 102.8569 - val_loss: 0.0278 - val_mae: 0.1191 - val_mape: 57.6515\n",
      "Epoch 500/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0907 - mae: 0.2143 - mape: 110.9587 - val_loss: 0.0278 - val_mae: 0.1191 - val_mape: 57.6797\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Compile model with optimizer and loss function\n",
    "model.compile(optimizer='adam',    # Adaptive learning rate optimizer\n",
    "              loss='mse',          # Mean Squared Error for regression\n",
    "              metrics=['mae', 'mape'])  # Track Mean Absolute Error and Mean Absolute Percentage Error\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "# Stops training when validation loss doesn't improve for 25 epochs\n",
    "# Restores the best weights found during training\n",
    "early = EarlyStopping(monitor='val_loss',        # Watch validation loss\n",
    "                     patience=25,                # Wait 25 epochs without improvement\n",
    "                     restore_best_weights=True)  # Keep best model weights\n",
    "\n",
    "# Train the model\n",
    "# Uses scaled features (X_train_z) and scaled targets (y_train_s) in [-1,1] range\n",
    "# Validates on separate validation set to monitor overfitting\n",
    "history = model.fit(\n",
    "    X_train_z, y_train_s,                    # Training data (scaled)\n",
    "    validation_data=(X_val_z, y_val_s),     # Validation data (scaled)\n",
    "    epochs=500,                              # Maximum 500 epochs\n",
    "    batch_size=16,                           # Process 16 samples at a time\n",
    "    verbose=1,                               # Print progress during training\n",
    "    callbacks=[early]                        # Apply early stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLV4VDdDjLmG",
    "outputId": "e06804a3-2b4d-4bc0-ad9d-206f2ab4cdb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on all sets\n",
    "y_hat_train_s = model.predict(X_train_z)\n",
    "y_hat_val_s   = model.predict(X_val_z)\n",
    "y_hat_test_s  = model.predict(X_test_z)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_hat_train = inv_y(y_hat_train_s)\n",
    "y_hat_val   = inv_y(y_hat_val_s)\n",
    "y_hat_test  = inv_y(y_hat_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xeWwgdE0jLkG"
   },
   "outputs": [],
   "source": [
    "#Evaluate code performance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def report_2out(name, y_true, y_pred, labels=(\"Mn\", \"Mw\")):\n",
    "    \"\"\"\n",
    "    Calculate and print regression metrics for 2-output model\n",
    "    Args: name - dataset name, y_true/y_pred - shape (n,2), labels - output names\n",
    "    \"\"\"\n",
    "    for i, label in enumerate(labels):\n",
    "        # Extract single output column\n",
    "        yt = y_true[:, i]\n",
    "        yp = y_pred[:, i]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae  = mean_absolute_error(yt, yp)\n",
    "        mse  = mean_squared_error(yt, yp)\n",
    "        r2   = r2_score(yt, yp)\n",
    "        mape = mean_absolute_percentage_error(yt, yp)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"[{name}] {label}: MAE={mae:.6f}  MSE={mse:.6f}  R²={r2:.4f}  MAPE={mape:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptHevHX-jLh_",
    "outputId": "ca2a17b0-6b4b-4e41-8e90-50bde0ab8b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Mn: MAE=160.151855  MSE=38833.078926  R²=0.9249  MAPE=0.064455\n",
      "[Train] Mw: MAE=279.137066  MSE=117677.247310  R²=0.9087  MAPE=0.098560\n",
      "[Val  ] Mn: MAE=136.180398  MSE=26586.174508  R²=0.9401  MAPE=0.083220\n",
      "[Val  ] Mw: MAE=298.984687  MSE=195193.671561  R²=0.7071  MAPE=0.184854\n",
      "[Test ] Mn: MAE=968.564535  MSE=2104017.658424  R²=-0.0418  MAPE=0.228543\n",
      "[Test ] Mw: MAE=1232.024797  MSE=3175572.242193  R²=0.0070  MAPE=0.253384\n"
     ]
    }
   ],
   "source": [
    "#print metrics\n",
    "report_2out(\"Train\", y_train, y_hat_train)\n",
    "report_2out(\"Val  \", y_val,   y_hat_val)\n",
    "report_2out(\"Test \", y_test,  y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGS2LHAAjLfx",
    "outputId": "c5ef78f4-c870-4658-9a4c-388ffdd530b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZovIuGAXjLd4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-ZWVSsjjLby",
    "outputId": "224eda97-b2d7-4034-eb93-9c2c243abade"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split target   actual   predicted    residual   abs_error  pct_error\n",
      "Train     Mn 1845.600 1945.874634 -100.274634  100.274634   5.433173\n",
      "Train     Mn 2590.790 2575.164062   15.625937   15.625937   0.603134\n",
      "Train     Mn 2074.517 2165.433105  -90.916105   90.916105   4.382519\n",
      "Train     Mn 2955.830 2675.055908  280.774092  280.774092   9.498993\n",
      "Train     Mn 2298.620 2629.554443 -330.934443  330.934443  14.397092\n",
      "Train     Mn 2525.270 2552.159912  -26.889912   26.889912   1.064833\n",
      "Train     Mn 2752.840 2674.102783   78.737217   78.737217   2.860218\n",
      "Train     Mn 1846.180 1945.874634  -99.694634   99.694634   5.400049\n",
      "Train     Mn 1127.190 1133.361816   -6.171816    6.171816   0.547540\n",
      "Train     Mn 2322.830 2440.811523 -117.981523  117.981523   5.079215\n",
      "Train     Mn 3764.530 3469.653076  294.876924  294.876924   7.833034\n",
      "Train     Mn 2073.900 2165.433105  -91.533105   91.533105   4.413574\n",
      "Train     Mn 1264.440 1137.396118  127.043882  127.043882  10.047442\n",
      "Train     Mn 3762.880 3469.653076  293.226924  293.226924   7.792620\n",
      "Train     Mn 2298.650 2629.554443 -330.904443  330.904443  14.395599\n",
      "Train     Mn 2951.900 2675.055908  276.844092  276.844092   9.378505\n",
      "Train     Mw 2690.500 2765.109619  -74.609619   74.609619   2.773076\n",
      "Train     Mw 3517.860 3205.412598  312.447402  312.447402   8.881746\n",
      "Train     Mw 2970.820 2887.820801   82.999199   82.999199   2.793814\n",
      "Train     Mw 2966.910 3283.862793 -316.952793  316.952793  10.682926\n",
      "Train     Mw 2972.980 3250.059082 -277.079082  277.079082   9.319911\n",
      "Train     Mw 3441.190 3248.616211  192.573789  192.573789   5.596139\n",
      "Train     Mw 3129.570 3279.947510 -150.377510  150.377510   4.805053\n",
      "Train     Mw 2689.910 2765.109619  -75.199619   75.199619   2.795618\n",
      "Train     Mw 1321.650 1776.908447 -455.258447  455.258447  34.446219\n",
      "Train     Mw 2987.310 3046.357422  -59.047422   59.047422   1.976608\n",
      "Train     Mw 5752.150 5049.625977  702.524023  702.524023  12.213242\n",
      "Train     Mw 2974.510 2887.820801   86.689199   86.689199   2.914403\n",
      "Train     Mw 1456.220 1838.029053 -381.809053  381.809053  26.219188\n",
      "Train     Mw 5752.810 5049.625977  703.184023  703.184023  12.223314\n",
      "Train     Mw 2972.940 3250.059082 -277.119082  277.119082   9.321382\n",
      "Train     Mw 2965.540 3283.862793 -318.322793  318.322793  10.734058\n",
      "  Val     Mn 2752.800 2674.102783   78.697217   78.697217   2.858806\n",
      "  Val     Mn 1024.970 1207.698120 -182.728120  182.728120  17.827655\n",
      "  Val     Mn 2525.910 2552.159912  -26.249912   26.249912   1.039226\n",
      "  Val     Mn 2223.170 1966.123657  257.046343  257.046343  11.562154\n",
      "  Val     Mw 3129.610 3279.947510 -150.337510  150.337510   4.803714\n",
      "  Val     Mw 1339.350 2188.679688 -849.329688  849.329688  63.413573\n",
      "  Val     Mw 3440.430 3248.616211  191.813789  191.813789   5.575285\n",
      "  Val     Mw 2989.000 2993.457764   -4.457764    4.457764   0.149139\n",
      " Test     Mn 4663.770 2373.273193 2290.496807 2290.496807  49.112559\n",
      " Test     Mn 4663.040 2373.273193 2289.766807 2289.766807  49.104593\n",
      " Test     Mn 1950.000 1966.123657  -16.123657   16.123657   0.826854\n",
      " Test     Mn 2322.860 2440.811523 -117.951523  117.951523   5.077858\n",
      " Test     Mn 1265.880 1137.396118  128.483882  128.483882  10.149768\n",
      " Test     Mw 5921.610 3118.255127 2803.354873 2803.354873  47.341093\n",
      " Test     Mw 5921.490 3118.255127 2803.234873 2803.234873  47.340025\n",
      " Test     Mw 2878.900 2993.457764 -114.557764  114.557764   3.979220\n",
      " Test     Mw 2987.280 3046.357422  -59.077422   59.077422   1.977633\n",
      " Test     Mw 1458.130 1838.029053 -379.899053  379.899053  26.053853\n"
     ]
    }
   ],
   "source": [
    "# Create detailed comparison table showing actual vs predicted values\n",
    "# Shows sample-by-sample performance for both outputs (Mn, Mw) across all datasets\n",
    "# Includes error metrics: residual, absolute error, and percentage error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_table_multi(split, y_true, y_pred, target_names=(\"Mn\",\"Mw\"), n=None):\n",
    "    \"\"\"Create comparison table for actual vs predicted values\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    parts = []\n",
    "    for j, name in enumerate(target_names):\n",
    "        df = pd.DataFrame({\n",
    "            \"split\":     split,\n",
    "            \"target\":    name,\n",
    "            \"actual\":    y_true[:, j],\n",
    "            \"predicted\": y_pred[:, j],\n",
    "        })\n",
    "        # Calculate error metrics\n",
    "        df[\"residual\"]  = df[\"actual\"] - df[\"predicted\"]\n",
    "        df[\"abs_error\"] = df[\"residual\"].abs()\n",
    "        df[\"pct_error\"] = 100 * df[\"abs_error\"] / df[\"actual\"].abs().clip(lower=1e-8)\n",
    "        \n",
    "        parts.append(df if n is None else df.head(n))\n",
    "    \n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "# Create comparison tables for all datasets\n",
    "tbl_train = make_table_multi(\"Train\", y_train, y_hat_train)\n",
    "tbl_val   = make_table_multi(\"Val\",   y_val,   y_hat_val)\n",
    "tbl_test  = make_table_multi(\"Test\",  y_test,  y_hat_test)\n",
    "\n",
    "# Combine all tables\n",
    "tbl_all = pd.concat([tbl_train, tbl_val, tbl_test], ignore_index=True)\n",
    "print(tbl_all.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "t9miTBP8jLXi"
   },
   "outputs": [],
   "source": [
    "#testing other activation function from ANN\n",
    "import random, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers\n",
    "\n",
    "activations = ['relu', 'tanh', 'sigmoid', 'softplus']\n",
    "labels      = ['ReLU', 'Tanh', 'Sigmoid', 'Softplus']\n",
    "\n",
    "val_mse_real  = []\n",
    "test_mse_real = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000013F275276A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000013F275276A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 5  # for reproducibility\n",
    "\n",
    "for act in activations:\n",
    "    # Reset state\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "    # Build model\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(X_train_z.shape[1],)),\n",
    "        layers.Dense(16, activation=act),\n",
    "        layers.Dense(2, activation='tanh')  # 2 outputs: [Mn, Mw]\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train_z, y_train_s,\n",
    "        validation_data=(X_val_z, y_val_s),\n",
    "        epochs=200, batch_size=16, shuffle=True, verbose=0\n",
    "    )\n",
    "\n",
    "    # Predict (scaled)\n",
    "    y_hat_val_s  = model.predict(X_val_z, verbose=0)\n",
    "    y_hat_test_s = model.predict(X_test_z, verbose=0)\n",
    "\n",
    "    # Inverse transform to real units\n",
    "    y_hat_val  = inv_y(y_hat_val_s)\n",
    "    y_hat_test = inv_y(y_hat_test_s)\n",
    "\n",
    "    # Compute MSE in real units\n",
    "    val_mse_real.append(mean_squared_error(y_val, y_hat_val))\n",
    "    test_mse_real.append(mean_squared_error(y_test, y_hat_test))\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(labels, val_mse_real, marker='o', label='Validation MSE')\n",
    "plt.plot(labels, test_mse_real, marker='s', label='Test MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE for Different Activation Functions')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhVOphxKBSPj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM6viJ1X4oRLwr65SDqw9Ni",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
