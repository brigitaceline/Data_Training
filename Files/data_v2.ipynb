{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3db735-f20b-4ac0-a485-5d0e2b0f8e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.20.0rc0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.11.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d649c7-d51d-4c75-8282-1a113bfabdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bf0a48-b2f9-47f6-a743-c188fccc0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Exp_Mn_Mw_Value.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94da57c8-927e-42c3-949a-25eadb812aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:5].values   # columns 1–4: Factor A–D\n",
    "y = dataset.iloc[:, 5:7].values   # columns 5–6: Responses Mn, Mw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "317fe654-af6d-4f21-b8c1-92c88c945ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Factor A</th>\n",
       "      <th>Factor B</th>\n",
       "      <th>Factor C</th>\n",
       "      <th>Factor D</th>\n",
       "      <th>Response 1 (Experimental)</th>\n",
       "      <th>Response 2 (Experimental)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1127.19</td>\n",
       "      <td>1321.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1024.97</td>\n",
       "      <td>1339.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>60</td>\n",
       "      <td>1950.00</td>\n",
       "      <td>2878.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>60</td>\n",
       "      <td>2223.17</td>\n",
       "      <td>2989.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1845.60</td>\n",
       "      <td>2690.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run  Factor A  Factor B  Factor C  Factor D  Response 1 (Experimental)  \\\n",
       "0    1       110         7        50        10                    1127.19   \n",
       "1    2        85        13        50        10                    1024.97   \n",
       "2    3       101         1       500        60                    1950.00   \n",
       "3    4       101         1       500        60                    2223.17   \n",
       "4    5        50        10        50        10                    1845.60   \n",
       "\n",
       "   Response 2 (Experimental)  \n",
       "0                    1321.65  \n",
       "1                    1339.35  \n",
       "2                    2878.90  \n",
       "3                    2989.00  \n",
       "4                    2690.50  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be38a326-b711-4d25-87f6-1864401e1041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bdbbca1-d98b-4861-96ae-618fca1323fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1111, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d7ff439-be10-4f8c-9e6b-a3e5648010bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0621d54e-fe24-4ac8-8964-ef33a8e228cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))  # define the input shape here\n",
    "model.add(Dense(18, activation='tanh',\n",
    "                kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dense(2))  # 2 outputs: Mn, Mw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abceeaaf-acc6-4f74-9082-d408c0083652",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e90cb557-8d03-416c-91f5-693a8ec51e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 8700730.0000 - mae: 2734.7178 - val_loss: 13696344.0000 - val_mae: 3553.8567\n",
      "Epoch 2/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8700595.0000 - mae: 2734.6990 - val_loss: 13696108.0000 - val_mae: 3553.8250\n",
      "Epoch 3/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8700465.0000 - mae: 2734.6809 - val_loss: 13695856.0000 - val_mae: 3553.7908\n",
      "Epoch 4/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8700347.0000 - mae: 2734.6641 - val_loss: 13695587.0000 - val_mae: 3553.7546\n",
      "Epoch 5/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8700229.0000 - mae: 2734.6458 - val_loss: 13695320.0000 - val_mae: 3553.7188\n",
      "Epoch 6/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8700089.0000 - mae: 2734.6279 - val_loss: 13695068.0000 - val_mae: 3553.6846\n",
      "Epoch 7/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8699972.0000 - mae: 2734.6106 - val_loss: 13694797.0000 - val_mae: 3553.6477\n",
      "Epoch 8/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8699849.0000 - mae: 2734.5935 - val_loss: 13694520.0000 - val_mae: 3553.6106\n",
      "Epoch 9/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8699703.0000 - mae: 2734.5715 - val_loss: 13694271.0000 - val_mae: 3553.5771\n",
      "Epoch 10/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8699576.0000 - mae: 2734.5542 - val_loss: 13694015.0000 - val_mae: 3553.5430\n",
      "Epoch 11/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8699447.0000 - mae: 2734.5364 - val_loss: 13693733.0000 - val_mae: 3553.5051\n",
      "Epoch 12/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8699312.0000 - mae: 2734.5164 - val_loss: 13693453.0000 - val_mae: 3553.4668\n",
      "Epoch 13/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8699179.0000 - mae: 2734.4983 - val_loss: 13693167.0000 - val_mae: 3553.4280\n",
      "Epoch 14/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8699030.0000 - mae: 2734.4773 - val_loss: 13692880.0000 - val_mae: 3553.3889\n",
      "Epoch 15/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8698880.0000 - mae: 2734.4556 - val_loss: 13692600.0000 - val_mae: 3553.3516\n",
      "Epoch 16/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8698735.0000 - mae: 2734.4346 - val_loss: 13692311.0000 - val_mae: 3553.3125\n",
      "Epoch 17/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8698580.0000 - mae: 2734.4141 - val_loss: 13692015.0000 - val_mae: 3553.2722\n",
      "Epoch 18/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8698435.0000 - mae: 2734.3911 - val_loss: 13691685.0000 - val_mae: 3553.2278\n",
      "Epoch 19/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8698257.0000 - mae: 2734.3662 - val_loss: 13691381.0000 - val_mae: 3553.1865\n",
      "Epoch 20/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8698112.0000 - mae: 2734.3433 - val_loss: 13691041.0000 - val_mae: 3553.1404\n",
      "Epoch 21/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8697944.0000 - mae: 2734.3208 - val_loss: 13690699.0000 - val_mae: 3553.0938\n",
      "Epoch 22/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8697764.0000 - mae: 2734.2925 - val_loss: 13690380.0000 - val_mae: 3553.0505\n",
      "Epoch 23/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8697587.0000 - mae: 2734.2668 - val_loss: 13690040.0000 - val_mae: 3553.0042\n",
      "Epoch 24/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8697405.0000 - mae: 2734.2410 - val_loss: 13689700.0000 - val_mae: 3552.9580\n",
      "Epoch 25/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8697224.0000 - mae: 2734.2146 - val_loss: 13689340.0000 - val_mae: 3552.9089\n",
      "Epoch 26/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8697039.0000 - mae: 2734.1892 - val_loss: 13688967.0000 - val_mae: 3552.8582\n",
      "Epoch 27/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8696847.0000 - mae: 2734.1584 - val_loss: 13688581.0000 - val_mae: 3552.8059\n",
      "Epoch 28/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8696636.0000 - mae: 2734.1287 - val_loss: 13688193.0000 - val_mae: 3552.7532\n",
      "Epoch 29/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8696443.0000 - mae: 2734.0989 - val_loss: 13687771.0000 - val_mae: 3552.6960\n",
      "Epoch 30/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8696229.0000 - mae: 2734.0676 - val_loss: 13687347.0000 - val_mae: 3552.6379\n",
      "Epoch 31/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8695985.0000 - mae: 2734.0332 - val_loss: 13686973.0000 - val_mae: 3552.5872\n",
      "Epoch 32/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8695765.0000 - mae: 2734.0007 - val_loss: 13686547.0000 - val_mae: 3552.5293\n",
      "Epoch 33/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8695540.0000 - mae: 2733.9651 - val_loss: 13686099.0000 - val_mae: 3552.4680\n",
      "Epoch 34/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8695293.0000 - mae: 2733.9268 - val_loss: 13685621.0000 - val_mae: 3552.4033\n",
      "Epoch 35/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8695089.0000 - mae: 2733.8979 - val_loss: 13685101.0000 - val_mae: 3552.3330\n",
      "Epoch 36/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8694795.0000 - mae: 2733.8557 - val_loss: 13684645.0000 - val_mae: 3552.2708\n",
      "Epoch 37/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8694537.0000 - mae: 2733.8137 - val_loss: 13684192.0000 - val_mae: 3552.2090\n",
      "Epoch 38/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8694284.0000 - mae: 2733.7766 - val_loss: 13683723.0000 - val_mae: 3552.1453\n",
      "Epoch 39/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8694018.0000 - mae: 2733.7349 - val_loss: 13683247.0000 - val_mae: 3552.0808\n",
      "Epoch 40/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8693755.0000 - mae: 2733.6946 - val_loss: 13682732.0000 - val_mae: 3552.0105\n",
      "Epoch 41/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8693460.0000 - mae: 2733.6504 - val_loss: 13682231.0000 - val_mae: 3551.9417\n",
      "Epoch 42/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8693174.0000 - mae: 2733.6077 - val_loss: 13681736.0000 - val_mae: 3551.8738\n",
      "Epoch 43/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8692901.0000 - mae: 2733.5637 - val_loss: 13681196.0000 - val_mae: 3551.8000\n",
      "Epoch 44/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8692594.0000 - mae: 2733.5178 - val_loss: 13680679.0000 - val_mae: 3551.7295\n",
      "Epoch 45/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8692284.0000 - mae: 2733.4700 - val_loss: 13680141.0000 - val_mae: 3551.6560\n",
      "Epoch 46/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8691970.0000 - mae: 2733.4211 - val_loss: 13679615.0000 - val_mae: 3551.5837\n",
      "Epoch 47/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8691676.0000 - mae: 2733.3726 - val_loss: 13679057.0000 - val_mae: 3551.5076\n",
      "Epoch 48/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8691328.0000 - mae: 2733.3198 - val_loss: 13678509.0000 - val_mae: 3551.4324\n",
      "Epoch 49/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8690988.0000 - mae: 2733.2673 - val_loss: 13677969.0000 - val_mae: 3551.3582\n",
      "Epoch 50/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8690670.0000 - mae: 2733.2170 - val_loss: 13677349.0000 - val_mae: 3551.2732\n",
      "Epoch 51/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8690334.0000 - mae: 2733.1628 - val_loss: 13676711.0000 - val_mae: 3551.1855\n",
      "Epoch 52/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8689953.0000 - mae: 2733.1040 - val_loss: 13676099.0000 - val_mae: 3551.1013\n",
      "Epoch 53/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8689600.0000 - mae: 2733.0488 - val_loss: 13675481.0000 - val_mae: 3551.0168\n",
      "Epoch 54/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8689224.0000 - mae: 2732.9883 - val_loss: 13674888.0000 - val_mae: 3550.9355\n",
      "Epoch 55/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8688841.0000 - mae: 2732.9290 - val_loss: 13674307.0000 - val_mae: 3550.8552\n",
      "Epoch 56/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8688483.0000 - mae: 2732.8704 - val_loss: 13673659.0000 - val_mae: 3550.7664\n",
      "Epoch 57/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8688068.0000 - mae: 2732.8054 - val_loss: 13673013.0000 - val_mae: 3550.6775\n",
      "Epoch 58/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8687692.0000 - mae: 2732.7463 - val_loss: 13672307.0000 - val_mae: 3550.5801\n",
      "Epoch 59/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8687288.0000 - mae: 2732.6785 - val_loss: 13671603.0000 - val_mae: 3550.4834\n",
      "Epoch 60/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8686882.0000 - mae: 2732.6140 - val_loss: 13670892.0000 - val_mae: 3550.3855\n",
      "Epoch 61/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8686458.0000 - mae: 2732.5439 - val_loss: 13670208.0000 - val_mae: 3550.2910\n",
      "Epoch 62/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8686029.0000 - mae: 2732.4744 - val_loss: 13669512.0000 - val_mae: 3550.1953\n",
      "Epoch 63/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8685573.0000 - mae: 2732.4031 - val_loss: 13668877.0000 - val_mae: 3550.1074\n",
      "Epoch 64/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8685118.0000 - mae: 2732.3298 - val_loss: 13668200.0000 - val_mae: 3550.0139\n",
      "Epoch 65/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8684728.0000 - mae: 2732.2646 - val_loss: 13667409.0000 - val_mae: 3549.9050\n",
      "Epoch 66/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8684229.0000 - mae: 2732.1865 - val_loss: 13666711.0000 - val_mae: 3549.8076\n",
      "Epoch 67/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8683796.0000 - mae: 2732.1162 - val_loss: 13665935.0000 - val_mae: 3549.7002\n",
      "Epoch 68/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8683318.0000 - mae: 2732.0344 - val_loss: 13665179.0000 - val_mae: 3549.5957\n",
      "Epoch 69/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8682845.0000 - mae: 2731.9558 - val_loss: 13664419.0000 - val_mae: 3549.4902\n",
      "Epoch 70/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8682370.0000 - mae: 2731.8777 - val_loss: 13663643.0000 - val_mae: 3549.3828\n",
      "Epoch 71/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8681898.0000 - mae: 2731.7976 - val_loss: 13662880.0000 - val_mae: 3549.2771\n",
      "Epoch 72/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8681366.0000 - mae: 2731.7129 - val_loss: 13662204.0000 - val_mae: 3549.1833\n",
      "Epoch 73/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8680867.0000 - mae: 2731.6265 - val_loss: 13661456.0000 - val_mae: 3549.0793\n",
      "Epoch 74/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8680365.0000 - mae: 2731.5422 - val_loss: 13660645.0000 - val_mae: 3548.9668\n",
      "Epoch 75/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8679835.0000 - mae: 2731.4548 - val_loss: 13659916.0000 - val_mae: 3548.8652\n",
      "Epoch 76/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8679301.0000 - mae: 2731.3623 - val_loss: 13659112.0000 - val_mae: 3548.7532\n",
      "Epoch 77/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8678779.0000 - mae: 2731.2751 - val_loss: 13658267.0000 - val_mae: 3548.6355\n",
      "Epoch 78/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8678246.0000 - mae: 2731.1855 - val_loss: 13657416.0000 - val_mae: 3548.5173\n",
      "Epoch 79/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8677677.0000 - mae: 2731.0913 - val_loss: 13656597.0000 - val_mae: 3548.4031\n",
      "Epoch 80/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8677159.0000 - mae: 2730.9980 - val_loss: 13655759.0000 - val_mae: 3548.2864\n",
      "Epoch 81/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8676581.0000 - mae: 2730.9004 - val_loss: 13654943.0000 - val_mae: 3548.1726\n",
      "Epoch 82/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8676013.0000 - mae: 2730.8040 - val_loss: 13654112.0000 - val_mae: 3548.0574\n",
      "Epoch 83/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8675411.0000 - mae: 2730.7051 - val_loss: 13653344.0000 - val_mae: 3547.9500\n",
      "Epoch 84/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8674885.0000 - mae: 2730.6104 - val_loss: 13652427.0000 - val_mae: 3547.8215\n",
      "Epoch 85/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8674250.0000 - mae: 2730.5071 - val_loss: 13651581.0000 - val_mae: 3547.7039\n",
      "Epoch 86/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8673650.0000 - mae: 2730.4021 - val_loss: 13650745.0000 - val_mae: 3547.5872\n",
      "Epoch 87/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8673070.0000 - mae: 2730.3008 - val_loss: 13649863.0000 - val_mae: 3547.4636\n",
      "Epoch 88/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8672472.0000 - mae: 2730.1943 - val_loss: 13648989.0000 - val_mae: 3547.3411\n",
      "Epoch 89/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8671821.0000 - mae: 2730.0872 - val_loss: 13648157.0000 - val_mae: 3547.2244\n",
      "Epoch 90/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8671237.0000 - mae: 2729.9839 - val_loss: 13647380.0000 - val_mae: 3547.1155\n",
      "Epoch 91/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8670603.0000 - mae: 2729.8679 - val_loss: 13646519.0000 - val_mae: 3546.9949\n",
      "Epoch 92/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8670004.0000 - mae: 2729.7625 - val_loss: 13645605.0000 - val_mae: 3546.8672\n",
      "Epoch 93/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8669383.0000 - mae: 2729.6523 - val_loss: 13644669.0000 - val_mae: 3546.7356\n",
      "Epoch 94/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8668687.0000 - mae: 2729.5361 - val_loss: 13643869.0000 - val_mae: 3546.6233\n",
      "Epoch 95/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8668071.0000 - mae: 2729.4216 - val_loss: 13642987.0000 - val_mae: 3546.5000\n",
      "Epoch 96/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8667395.0000 - mae: 2729.3064 - val_loss: 13642091.0000 - val_mae: 3546.3738\n",
      "Epoch 97/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8666747.0000 - mae: 2729.1895 - val_loss: 13641208.0000 - val_mae: 3546.2500\n",
      "Epoch 98/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8666059.0000 - mae: 2729.0708 - val_loss: 13640301.0000 - val_mae: 3546.1228\n",
      "Epoch 99/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8665405.0000 - mae: 2728.9539 - val_loss: 13639432.0000 - val_mae: 3546.0007\n",
      "Epoch 100/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8664756.0000 - mae: 2728.8333 - val_loss: 13638472.0000 - val_mae: 3545.8665\n",
      "Epoch 101/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8664045.0000 - mae: 2728.7095 - val_loss: 13637551.0000 - val_mae: 3545.7366\n",
      "Epoch 102/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8663339.0000 - mae: 2728.5889 - val_loss: 13636656.0000 - val_mae: 3545.6106\n",
      "Epoch 103/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8662679.0000 - mae: 2728.4653 - val_loss: 13635744.0000 - val_mae: 3545.4832\n",
      "Epoch 104/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8661971.0000 - mae: 2728.3401 - val_loss: 13634861.0000 - val_mae: 3545.3586\n",
      "Epoch 105/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8661280.0000 - mae: 2728.2134 - val_loss: 13633884.0000 - val_mae: 3545.2209\n",
      "Epoch 106/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8660551.0000 - mae: 2728.0859 - val_loss: 13632955.0000 - val_mae: 3545.0906\n",
      "Epoch 107/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8659822.0000 - mae: 2727.9592 - val_loss: 13632013.0000 - val_mae: 3544.9578\n",
      "Epoch 108/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8659111.0000 - mae: 2727.8313 - val_loss: 13631084.0000 - val_mae: 3544.8269\n",
      "Epoch 109/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8658430.0000 - mae: 2727.7026 - val_loss: 13630096.0000 - val_mae: 3544.6882\n",
      "Epoch 110/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8657666.0000 - mae: 2727.5706 - val_loss: 13629205.0000 - val_mae: 3544.5625\n",
      "Epoch 111/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8656915.0000 - mae: 2727.4358 - val_loss: 13628288.0000 - val_mae: 3544.4336\n",
      "Epoch 112/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8656180.0000 - mae: 2727.3040 - val_loss: 13627359.0000 - val_mae: 3544.3025\n",
      "Epoch 113/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8655492.0000 - mae: 2727.1694 - val_loss: 13626393.0000 - val_mae: 3544.1672\n",
      "Epoch 114/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8654683.0000 - mae: 2727.0312 - val_loss: 13625457.0000 - val_mae: 3544.0349\n",
      "Epoch 115/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8653939.0000 - mae: 2726.8958 - val_loss: 13624517.0000 - val_mae: 3543.9023\n",
      "Epoch 116/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8653216.0000 - mae: 2726.7622 - val_loss: 13623579.0000 - val_mae: 3543.7703\n",
      "Epoch 117/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8652463.0000 - mae: 2726.6230 - val_loss: 13622617.0000 - val_mae: 3543.6348\n",
      "Epoch 118/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8651693.0000 - mae: 2726.4868 - val_loss: 13621692.0000 - val_mae: 3543.5039\n",
      "Epoch 119/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8650951.0000 - mae: 2726.3474 - val_loss: 13620720.0000 - val_mae: 3543.3669\n",
      "Epoch 120/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8650193.0000 - mae: 2726.2095 - val_loss: 13619727.0000 - val_mae: 3543.2268\n",
      "Epoch 121/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8649459.0000 - mae: 2726.0737 - val_loss: 13618728.0000 - val_mae: 3543.0859\n",
      "Epoch 122/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8648668.0000 - mae: 2725.9316 - val_loss: 13617808.0000 - val_mae: 3542.9558\n",
      "Epoch 123/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8647878.0000 - mae: 2725.7908 - val_loss: 13616868.0000 - val_mae: 3542.8225\n",
      "Epoch 124/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8647139.0000 - mae: 2725.6506 - val_loss: 13615893.0000 - val_mae: 3542.6848\n",
      "Epoch 125/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8646407.0000 - mae: 2725.5125 - val_loss: 13614960.0000 - val_mae: 3542.5537\n",
      "Epoch 126/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8645580.0000 - mae: 2725.3672 - val_loss: 13614056.0000 - val_mae: 3542.4258\n",
      "Epoch 127/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8644813.0000 - mae: 2725.2236 - val_loss: 13613083.0000 - val_mae: 3542.2891\n",
      "Epoch 128/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8644062.0000 - mae: 2725.0808 - val_loss: 13612075.0000 - val_mae: 3542.1465\n",
      "Epoch 129/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8643277.0000 - mae: 2724.9399 - val_loss: 13611140.0000 - val_mae: 3542.0144\n",
      "Epoch 130/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8642484.0000 - mae: 2724.7927 - val_loss: 13610161.0000 - val_mae: 3541.8762\n",
      "Epoch 131/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8641707.0000 - mae: 2724.6511 - val_loss: 13609128.0000 - val_mae: 3541.7305\n",
      "Epoch 132/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8640934.0000 - mae: 2724.5073 - val_loss: 13608165.0000 - val_mae: 3541.5950\n",
      "Epoch 133/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8640152.0000 - mae: 2724.3638 - val_loss: 13607155.0000 - val_mae: 3541.4519\n",
      "Epoch 134/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8639386.0000 - mae: 2724.2195 - val_loss: 13606191.0000 - val_mae: 3541.3157\n",
      "Epoch 135/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8638570.0000 - mae: 2724.0718 - val_loss: 13605192.0000 - val_mae: 3541.1746\n",
      "Epoch 136/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8637775.0000 - mae: 2723.9290 - val_loss: 13604229.0000 - val_mae: 3541.0388\n",
      "Epoch 137/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8637018.0000 - mae: 2723.7844 - val_loss: 13603205.0000 - val_mae: 3540.8936\n",
      "Epoch 138/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8636227.0000 - mae: 2723.6421 - val_loss: 13602257.0000 - val_mae: 3540.7595\n",
      "Epoch 139/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8635451.0000 - mae: 2723.4944 - val_loss: 13601255.0000 - val_mae: 3540.6182\n",
      "Epoch 140/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8634646.0000 - mae: 2723.3484 - val_loss: 13600249.0000 - val_mae: 3540.4758\n",
      "Epoch 141/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8633875.0000 - mae: 2723.2041 - val_loss: 13599217.0000 - val_mae: 3540.3293\n",
      "Epoch 142/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8633107.0000 - mae: 2723.0601 - val_loss: 13598232.0000 - val_mae: 3540.1904\n",
      "Epoch 143/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8632290.0000 - mae: 2722.9143 - val_loss: 13597225.0000 - val_mae: 3540.0476\n",
      "Epoch 144/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8631501.0000 - mae: 2722.7727 - val_loss: 13596280.0000 - val_mae: 3539.9141\n",
      "Epoch 145/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8630699.0000 - mae: 2722.6270 - val_loss: 13595303.0000 - val_mae: 3539.7756\n",
      "Epoch 146/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8629955.0000 - mae: 2722.4810 - val_loss: 13594225.0000 - val_mae: 3539.6238\n",
      "Epoch 147/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8629159.0000 - mae: 2722.3342 - val_loss: 13593213.0000 - val_mae: 3539.4807\n",
      "Epoch 148/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8628346.0000 - mae: 2722.1885 - val_loss: 13592187.0000 - val_mae: 3539.3352\n",
      "Epoch 149/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8627545.0000 - mae: 2722.0422 - val_loss: 13591204.0000 - val_mae: 3539.1960\n",
      "Epoch 150/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8626799.0000 - mae: 2721.8950 - val_loss: 13590200.0000 - val_mae: 3539.0537\n",
      "Epoch 151/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8625986.0000 - mae: 2721.7485 - val_loss: 13589196.0000 - val_mae: 3538.9114\n",
      "Epoch 152/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8625210.0000 - mae: 2721.6018 - val_loss: 13588199.0000 - val_mae: 3538.7703\n",
      "Epoch 153/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8624408.0000 - mae: 2721.4548 - val_loss: 13587209.0000 - val_mae: 3538.6301\n",
      "Epoch 154/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8623631.0000 - mae: 2721.3086 - val_loss: 13586216.0000 - val_mae: 3538.4895\n",
      "Epoch 155/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8622821.0000 - mae: 2721.1638 - val_loss: 13585240.0000 - val_mae: 3538.3513\n",
      "Epoch 156/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8622041.0000 - mae: 2721.0188 - val_loss: 13584284.0000 - val_mae: 3538.2158\n",
      "Epoch 157/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8621285.0000 - mae: 2720.8718 - val_loss: 13583265.0000 - val_mae: 3538.0715\n",
      "Epoch 158/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8620514.0000 - mae: 2720.7246 - val_loss: 13582280.0000 - val_mae: 3537.9329\n",
      "Epoch 159/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8619725.0000 - mae: 2720.5757 - val_loss: 13581291.0000 - val_mae: 3537.7927\n",
      "Epoch 160/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8618899.0000 - mae: 2720.4285 - val_loss: 13580336.0000 - val_mae: 3537.6575\n",
      "Epoch 161/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8618142.0000 - mae: 2720.2849 - val_loss: 13579357.0000 - val_mae: 3537.5188\n",
      "Epoch 162/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8617375.0000 - mae: 2720.1379 - val_loss: 13578336.0000 - val_mae: 3537.3748\n",
      "Epoch 163/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8616581.0000 - mae: 2719.9924 - val_loss: 13577325.0000 - val_mae: 3537.2312\n",
      "Epoch 164/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8615767.0000 - mae: 2719.8477 - val_loss: 13576371.0000 - val_mae: 3537.0959\n",
      "Epoch 165/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8615015.0000 - mae: 2719.7026 - val_loss: 13575395.0000 - val_mae: 3536.9578\n",
      "Epoch 166/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8614232.0000 - mae: 2719.5569 - val_loss: 13574377.0000 - val_mae: 3536.8137\n",
      "Epoch 167/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8613442.0000 - mae: 2719.4121 - val_loss: 13573411.0000 - val_mae: 3536.6768\n",
      "Epoch 168/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8612682.0000 - mae: 2719.2622 - val_loss: 13572416.0000 - val_mae: 3536.5359\n",
      "Epoch 169/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8611881.0000 - mae: 2719.1165 - val_loss: 13571444.0000 - val_mae: 3536.3977\n",
      "Epoch 170/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8611105.0000 - mae: 2718.9707 - val_loss: 13570488.0000 - val_mae: 3536.2625\n",
      "Epoch 171/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8610357.0000 - mae: 2718.8254 - val_loss: 13569491.0000 - val_mae: 3536.1213\n",
      "Epoch 172/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8609547.0000 - mae: 2718.6792 - val_loss: 13568528.0000 - val_mae: 3535.9851\n",
      "Epoch 173/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8608817.0000 - mae: 2718.5386 - val_loss: 13567495.0000 - val_mae: 3535.8386\n",
      "Epoch 174/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8608001.0000 - mae: 2718.3914 - val_loss: 13566548.0000 - val_mae: 3535.7039\n",
      "Epoch 175/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8607236.0000 - mae: 2718.2476 - val_loss: 13565581.0000 - val_mae: 3535.5671\n",
      "Epoch 176/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8606457.0000 - mae: 2718.1008 - val_loss: 13564621.0000 - val_mae: 3535.4307\n",
      "Epoch 177/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8605684.0000 - mae: 2717.9609 - val_loss: 13563707.0000 - val_mae: 3535.3010\n",
      "Epoch 178/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8604904.0000 - mae: 2717.8145 - val_loss: 13562736.0000 - val_mae: 3535.1633\n",
      "Epoch 179/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8604173.0000 - mae: 2717.6699 - val_loss: 13561757.0000 - val_mae: 3535.0251\n",
      "Epoch 180/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8603373.0000 - mae: 2717.5264 - val_loss: 13560807.0000 - val_mae: 3534.8899\n",
      "Epoch 181/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8602648.0000 - mae: 2717.3833 - val_loss: 13559829.0000 - val_mae: 3534.7512\n",
      "Epoch 182/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8601845.0000 - mae: 2717.2388 - val_loss: 13558865.0000 - val_mae: 3534.6145\n",
      "Epoch 183/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8601077.0000 - mae: 2717.0959 - val_loss: 13557901.0000 - val_mae: 3534.4778\n",
      "Epoch 184/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8600327.0000 - mae: 2716.9541 - val_loss: 13556935.0000 - val_mae: 3534.3406\n",
      "Epoch 185/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8599581.0000 - mae: 2716.8132 - val_loss: 13555944.0000 - val_mae: 3534.2000\n",
      "Epoch 186/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8598792.0000 - mae: 2716.6738 - val_loss: 13555012.0000 - val_mae: 3534.0684\n",
      "Epoch 187/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8598074.0000 - mae: 2716.5312 - val_loss: 13554020.0000 - val_mae: 3533.9270\n",
      "Epoch 188/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8597334.0000 - mae: 2716.3875 - val_loss: 13553044.0000 - val_mae: 3533.7891\n",
      "Epoch 189/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8596547.0000 - mae: 2716.2515 - val_loss: 13552177.0000 - val_mae: 3533.6660\n",
      "Epoch 190/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8595809.0000 - mae: 2716.1011 - val_loss: 13551191.0000 - val_mae: 3533.5261\n",
      "Epoch 191/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8595022.0000 - mae: 2715.9609 - val_loss: 13550251.0000 - val_mae: 3533.3926\n",
      "Epoch 192/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8594295.0000 - mae: 2715.8208 - val_loss: 13549297.0000 - val_mae: 3533.2571\n",
      "Epoch 193/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8593527.0000 - mae: 2715.6821 - val_loss: 13548379.0000 - val_mae: 3533.1270\n",
      "Epoch 194/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8592805.0000 - mae: 2715.5403 - val_loss: 13547453.0000 - val_mae: 3532.9954\n",
      "Epoch 195/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8592049.0000 - mae: 2715.3992 - val_loss: 13546543.0000 - val_mae: 3532.8660\n",
      "Epoch 196/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8591332.0000 - mae: 2715.2593 - val_loss: 13545581.0000 - val_mae: 3532.7292\n",
      "Epoch 197/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8590543.0000 - mae: 2715.1182 - val_loss: 13544692.0000 - val_mae: 3532.6028\n",
      "Epoch 198/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8589836.0000 - mae: 2714.9780 - val_loss: 13543756.0000 - val_mae: 3532.4700\n",
      "Epoch 199/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8589073.0000 - mae: 2714.8376 - val_loss: 13542841.0000 - val_mae: 3532.3401\n",
      "Epoch 200/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8588327.0000 - mae: 2714.6990 - val_loss: 13541904.0000 - val_mae: 3532.2073\n",
      "Epoch 201/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8587608.0000 - mae: 2714.5603 - val_loss: 13540973.0000 - val_mae: 3532.0750\n",
      "Epoch 202/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8586873.0000 - mae: 2714.4199 - val_loss: 13540013.0000 - val_mae: 3531.9387\n",
      "Epoch 203/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8586090.0000 - mae: 2714.2825 - val_loss: 13539107.0000 - val_mae: 3531.8103\n",
      "Epoch 204/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8585375.0000 - mae: 2714.1440 - val_loss: 13538148.0000 - val_mae: 3531.6738\n",
      "Epoch 205/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8584611.0000 - mae: 2714.0059 - val_loss: 13537229.0000 - val_mae: 3531.5439\n",
      "Epoch 206/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8583871.0000 - mae: 2713.8691 - val_loss: 13536332.0000 - val_mae: 3531.4163\n",
      "Epoch 207/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8583166.0000 - mae: 2713.7266 - val_loss: 13535376.0000 - val_mae: 3531.2812\n",
      "Epoch 208/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8582443.0000 - mae: 2713.5879 - val_loss: 13534413.0000 - val_mae: 3531.1445\n",
      "Epoch 209/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8581659.0000 - mae: 2713.4519 - val_loss: 13533521.0000 - val_mae: 3531.0178\n",
      "Epoch 210/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8580939.0000 - mae: 2713.3118 - val_loss: 13532589.0000 - val_mae: 3530.8855\n",
      "Epoch 211/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8580217.0000 - mae: 2713.1750 - val_loss: 13531648.0000 - val_mae: 3530.7517\n",
      "Epoch 212/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8579472.0000 - mae: 2713.0386 - val_loss: 13530735.0000 - val_mae: 3530.6218\n",
      "Epoch 213/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8578741.0000 - mae: 2712.9048 - val_loss: 13529840.0000 - val_mae: 3530.4949\n",
      "Epoch 214/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8578034.0000 - mae: 2712.7664 - val_loss: 13528925.0000 - val_mae: 3530.3650\n",
      "Epoch 215/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8577316.0000 - mae: 2712.6304 - val_loss: 13527995.0000 - val_mae: 3530.2324\n",
      "Epoch 216/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8576592.0000 - mae: 2712.4939 - val_loss: 13527081.0000 - val_mae: 3530.1028\n",
      "Epoch 217/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8575864.0000 - mae: 2712.3589 - val_loss: 13526211.0000 - val_mae: 3529.9792\n",
      "Epoch 218/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8575142.0000 - mae: 2712.2207 - val_loss: 13525303.0000 - val_mae: 3529.8499\n",
      "Epoch 219/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8574403.0000 - mae: 2712.0879 - val_loss: 13524427.0000 - val_mae: 3529.7256\n",
      "Epoch 220/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8573720.0000 - mae: 2711.9524 - val_loss: 13523511.0000 - val_mae: 3529.5957\n",
      "Epoch 221/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8573009.0000 - mae: 2711.8157 - val_loss: 13522608.0000 - val_mae: 3529.4675\n",
      "Epoch 222/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8572244.0000 - mae: 2711.6826 - val_loss: 13521748.0000 - val_mae: 3529.3457\n",
      "Epoch 223/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8571564.0000 - mae: 2711.5488 - val_loss: 13520832.0000 - val_mae: 3529.2151\n",
      "Epoch 224/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8570846.0000 - mae: 2711.4141 - val_loss: 13519947.0000 - val_mae: 3529.0891\n",
      "Epoch 225/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8570125.0000 - mae: 2711.2805 - val_loss: 13519045.0000 - val_mae: 3528.9609\n",
      "Epoch 226/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8569400.0000 - mae: 2711.1484 - val_loss: 13518187.0000 - val_mae: 3528.8389\n",
      "Epoch 227/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8568726.0000 - mae: 2711.0127 - val_loss: 13517263.0000 - val_mae: 3528.7078\n",
      "Epoch 228/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8567979.0000 - mae: 2710.8796 - val_loss: 13516384.0000 - val_mae: 3528.5828\n",
      "Epoch 229/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8567261.0000 - mae: 2710.7480 - val_loss: 13515491.0000 - val_mae: 3528.4558\n",
      "Epoch 230/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8566575.0000 - mae: 2710.6150 - val_loss: 13514547.0000 - val_mae: 3528.3215\n",
      "Epoch 231/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8565853.0000 - mae: 2710.4812 - val_loss: 13513629.0000 - val_mae: 3528.1914\n",
      "Epoch 232/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8565140.0000 - mae: 2710.3496 - val_loss: 13512717.0000 - val_mae: 3528.0615\n",
      "Epoch 233/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8564430.0000 - mae: 2710.2156 - val_loss: 13511807.0000 - val_mae: 3527.9324\n",
      "Epoch 234/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8563712.0000 - mae: 2710.0867 - val_loss: 13510939.0000 - val_mae: 3527.8086\n",
      "Epoch 235/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8563016.0000 - mae: 2709.9526 - val_loss: 13510027.0000 - val_mae: 3527.6790\n",
      "Epoch 236/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8562317.0000 - mae: 2709.8215 - val_loss: 13509133.0000 - val_mae: 3527.5518\n",
      "Epoch 237/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8561592.0000 - mae: 2709.6880 - val_loss: 13508227.0000 - val_mae: 3527.4231\n",
      "Epoch 238/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8560914.0000 - mae: 2709.5583 - val_loss: 13507303.0000 - val_mae: 3527.2920\n",
      "Epoch 239/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8560203.0000 - mae: 2709.4260 - val_loss: 13506405.0000 - val_mae: 3527.1643\n",
      "Epoch 240/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8559499.0000 - mae: 2709.2969 - val_loss: 13505520.0000 - val_mae: 3527.0383\n",
      "Epoch 241/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8558804.0000 - mae: 2709.1646 - val_loss: 13504636.0000 - val_mae: 3526.9128\n",
      "Epoch 242/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8558085.0000 - mae: 2709.0354 - val_loss: 13503801.0000 - val_mae: 3526.7939\n",
      "Epoch 243/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8557415.0000 - mae: 2708.9031 - val_loss: 13502907.0000 - val_mae: 3526.6667\n",
      "Epoch 244/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8556706.0000 - mae: 2708.7729 - val_loss: 13502035.0000 - val_mae: 3526.5430\n",
      "Epoch 245/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8556012.0000 - mae: 2708.6416 - val_loss: 13501149.0000 - val_mae: 3526.4172\n",
      "Epoch 246/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8555330.0000 - mae: 2708.5122 - val_loss: 13500245.0000 - val_mae: 3526.2891\n",
      "Epoch 247/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8554611.0000 - mae: 2708.3831 - val_loss: 13499363.0000 - val_mae: 3526.1633\n",
      "Epoch 248/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8553955.0000 - mae: 2708.2507 - val_loss: 13498469.0000 - val_mae: 3526.0364\n",
      "Epoch 249/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8553205.0000 - mae: 2708.1211 - val_loss: 13497621.0000 - val_mae: 3525.9160\n",
      "Epoch 250/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8552534.0000 - mae: 2707.9941 - val_loss: 13496760.0000 - val_mae: 3525.7930\n",
      "Epoch 251/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8551843.0000 - mae: 2707.8628 - val_loss: 13495877.0000 - val_mae: 3525.6677\n",
      "Epoch 252/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8551174.0000 - mae: 2707.7334 - val_loss: 13494988.0000 - val_mae: 3525.5410\n",
      "Epoch 253/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8550466.0000 - mae: 2707.6040 - val_loss: 13494132.0000 - val_mae: 3525.4197\n",
      "Epoch 254/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8549795.0000 - mae: 2707.4736 - val_loss: 13493256.0000 - val_mae: 3525.2949\n",
      "Epoch 255/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8549112.0000 - mae: 2707.3445 - val_loss: 13492373.0000 - val_mae: 3525.1699\n",
      "Epoch 256/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8548418.0000 - mae: 2707.2170 - val_loss: 13491507.0000 - val_mae: 3525.0461\n",
      "Epoch 257/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8547707.0000 - mae: 2707.0920 - val_loss: 13490668.0000 - val_mae: 3524.9270\n",
      "Epoch 258/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8547070.0000 - mae: 2706.9634 - val_loss: 13489796.0000 - val_mae: 3524.8035\n",
      "Epoch 259/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8546366.0000 - mae: 2706.8354 - val_loss: 13488957.0000 - val_mae: 3524.6836\n",
      "Epoch 260/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8545676.0000 - mae: 2706.7104 - val_loss: 13488107.0000 - val_mae: 3524.5625\n",
      "Epoch 261/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8545022.0000 - mae: 2706.5830 - val_loss: 13487253.0000 - val_mae: 3524.4414\n",
      "Epoch 262/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8544354.0000 - mae: 2706.4541 - val_loss: 13486388.0000 - val_mae: 3524.3184\n",
      "Epoch 263/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8543652.0000 - mae: 2706.3271 - val_loss: 13485527.0000 - val_mae: 3524.1960\n",
      "Epoch 264/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8542975.0000 - mae: 2706.2021 - val_loss: 13484661.0000 - val_mae: 3524.0730\n",
      "Epoch 265/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8542324.0000 - mae: 2706.0750 - val_loss: 13483789.0000 - val_mae: 3523.9490\n",
      "Epoch 266/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8541619.0000 - mae: 2705.9490 - val_loss: 13482933.0000 - val_mae: 3523.8269\n",
      "Epoch 267/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8541000.0000 - mae: 2705.8223 - val_loss: 13482048.0000 - val_mae: 3523.7012\n",
      "Epoch 268/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8540284.0000 - mae: 2705.6965 - val_loss: 13481212.0000 - val_mae: 3523.5820\n",
      "Epoch 269/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8539624.0000 - mae: 2705.5718 - val_loss: 13480365.0000 - val_mae: 3523.4617\n",
      "Epoch 270/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8538942.0000 - mae: 2705.4473 - val_loss: 13479532.0000 - val_mae: 3523.3430\n",
      "Epoch 271/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8538333.0000 - mae: 2705.3235 - val_loss: 13478645.0000 - val_mae: 3523.2170\n",
      "Epoch 272/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8537613.0000 - mae: 2705.1965 - val_loss: 13477832.0000 - val_mae: 3523.1013\n",
      "Epoch 273/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8536936.0000 - mae: 2705.0752 - val_loss: 13477020.0000 - val_mae: 3522.9856\n",
      "Epoch 274/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8536308.0000 - mae: 2704.9482 - val_loss: 13476165.0000 - val_mae: 3522.8640\n",
      "Epoch 275/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8535619.0000 - mae: 2704.8237 - val_loss: 13475311.0000 - val_mae: 3522.7422\n",
      "Epoch 276/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8534977.0000 - mae: 2704.6995 - val_loss: 13474453.0000 - val_mae: 3522.6204\n",
      "Epoch 277/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8534304.0000 - mae: 2704.5752 - val_loss: 13473624.0000 - val_mae: 3522.5027\n",
      "Epoch 278/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8533649.0000 - mae: 2704.4519 - val_loss: 13472768.0000 - val_mae: 3522.3809\n",
      "Epoch 279/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8532986.0000 - mae: 2704.3279 - val_loss: 13471931.0000 - val_mae: 3522.2617\n",
      "Epoch 280/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8532321.0000 - mae: 2704.2039 - val_loss: 13471101.0000 - val_mae: 3522.1436\n",
      "Epoch 281/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8531640.0000 - mae: 2704.0830 - val_loss: 13470293.0000 - val_mae: 3522.0286\n",
      "Epoch 282/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8531001.0000 - mae: 2703.9604 - val_loss: 13469469.0000 - val_mae: 3521.9114\n",
      "Epoch 283/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8530346.0000 - mae: 2703.8369 - val_loss: 13468627.0000 - val_mae: 3521.7913\n",
      "Epoch 284/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8529706.0000 - mae: 2703.7126 - val_loss: 13467773.0000 - val_mae: 3521.6699\n",
      "Epoch 285/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8529020.0000 - mae: 2703.5894 - val_loss: 13466936.0000 - val_mae: 3521.5508\n",
      "Epoch 286/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8528395.0000 - mae: 2703.4690 - val_loss: 13466067.0000 - val_mae: 3521.4270\n",
      "Epoch 287/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8527715.0000 - mae: 2703.3452 - val_loss: 13465240.0000 - val_mae: 3521.3093\n",
      "Epoch 288/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8527079.0000 - mae: 2703.2217 - val_loss: 13464409.0000 - val_mae: 3521.1912\n",
      "Epoch 289/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8526413.0000 - mae: 2703.0996 - val_loss: 13463580.0000 - val_mae: 3521.0732\n",
      "Epoch 290/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8525752.0000 - mae: 2702.9785 - val_loss: 13462765.0000 - val_mae: 3520.9573\n",
      "Epoch 291/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8525110.0000 - mae: 2702.8577 - val_loss: 13461944.0000 - val_mae: 3520.8406\n",
      "Epoch 292/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8524456.0000 - mae: 2702.7363 - val_loss: 13461128.0000 - val_mae: 3520.7246\n",
      "Epoch 293/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8523807.0000 - mae: 2702.6145 - val_loss: 13460312.0000 - val_mae: 3520.6084\n",
      "Epoch 294/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8523199.0000 - mae: 2702.4954 - val_loss: 13459453.0000 - val_mae: 3520.4863\n",
      "Epoch 295/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8522494.0000 - mae: 2702.3730 - val_loss: 13458661.0000 - val_mae: 3520.3730\n",
      "Epoch 296/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8521897.0000 - mae: 2702.2512 - val_loss: 13457824.0000 - val_mae: 3520.2546\n",
      "Epoch 297/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8521235.0000 - mae: 2702.1294 - val_loss: 13457008.0000 - val_mae: 3520.1379\n",
      "Epoch 298/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8520571.0000 - mae: 2702.0095 - val_loss: 13456209.0000 - val_mae: 3520.0242\n",
      "Epoch 299/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8519934.0000 - mae: 2701.8909 - val_loss: 13455396.0000 - val_mae: 3519.9082\n",
      "Epoch 300/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8519315.0000 - mae: 2701.7693 - val_loss: 13454563.0000 - val_mae: 3519.7898\n",
      "Epoch 301/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8518666.0000 - mae: 2701.6487 - val_loss: 13453752.0000 - val_mae: 3519.6746\n",
      "Epoch 302/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8518027.0000 - mae: 2701.5288 - val_loss: 13452928.0000 - val_mae: 3519.5574\n",
      "Epoch 303/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8517401.0000 - mae: 2701.4099 - val_loss: 13452103.0000 - val_mae: 3519.4395\n",
      "Epoch 304/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8516733.0000 - mae: 2701.2925 - val_loss: 13451327.0000 - val_mae: 3519.3289\n",
      "Epoch 305/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8516098.0000 - mae: 2701.1750 - val_loss: 13450536.0000 - val_mae: 3519.2166\n",
      "Epoch 306/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8515496.0000 - mae: 2701.0566 - val_loss: 13449713.0000 - val_mae: 3519.0996\n",
      "Epoch 307/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8514845.0000 - mae: 2700.9370 - val_loss: 13448912.0000 - val_mae: 3518.9851\n",
      "Epoch 308/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8514215.0000 - mae: 2700.8191 - val_loss: 13448115.0000 - val_mae: 3518.8718\n",
      "Epoch 309/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8513567.0000 - mae: 2700.7000 - val_loss: 13447285.0000 - val_mae: 3518.7539\n",
      "Epoch 310/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8512954.0000 - mae: 2700.5815 - val_loss: 13446445.0000 - val_mae: 3518.6340\n",
      "Epoch 311/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8512299.0000 - mae: 2700.4622 - val_loss: 13445652.0000 - val_mae: 3518.5212\n",
      "Epoch 312/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8511680.0000 - mae: 2700.3411 - val_loss: 13444825.0000 - val_mae: 3518.4036\n",
      "Epoch 313/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8510996.0000 - mae: 2700.2236 - val_loss: 13444048.0000 - val_mae: 3518.2932\n",
      "Epoch 314/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8510405.0000 - mae: 2700.1045 - val_loss: 13443227.0000 - val_mae: 3518.1765\n",
      "Epoch 315/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8509775.0000 - mae: 2699.9832 - val_loss: 13442385.0000 - val_mae: 3518.0564\n",
      "Epoch 316/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8509081.0000 - mae: 2699.8667 - val_loss: 13441600.0000 - val_mae: 3517.9443\n",
      "Epoch 317/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8508488.0000 - mae: 2699.7478 - val_loss: 13440769.0000 - val_mae: 3517.8262\n",
      "Epoch 318/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8507848.0000 - mae: 2699.6292 - val_loss: 13439959.0000 - val_mae: 3517.7109\n",
      "Epoch 319/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8507217.0000 - mae: 2699.5110 - val_loss: 13439145.0000 - val_mae: 3517.5945\n",
      "Epoch 320/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8506578.0000 - mae: 2699.3953 - val_loss: 13438352.0000 - val_mae: 3517.4817\n",
      "Epoch 321/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8505965.0000 - mae: 2699.2778 - val_loss: 13437560.0000 - val_mae: 3517.3691\n",
      "Epoch 322/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8505325.0000 - mae: 2699.1628 - val_loss: 13436772.0000 - val_mae: 3517.2566\n",
      "Epoch 323/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8504725.0000 - mae: 2699.0459 - val_loss: 13435964.0000 - val_mae: 3517.1414\n",
      "Epoch 324/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8504111.0000 - mae: 2698.9277 - val_loss: 13435152.0000 - val_mae: 3517.0261\n",
      "Epoch 325/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8503489.0000 - mae: 2698.8101 - val_loss: 13434344.0000 - val_mae: 3516.9109\n",
      "Epoch 326/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8502837.0000 - mae: 2698.6948 - val_loss: 13433576.0000 - val_mae: 3516.8015\n",
      "Epoch 327/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8502232.0000 - mae: 2698.5786 - val_loss: 13432791.0000 - val_mae: 3516.6897\n",
      "Epoch 328/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8501622.0000 - mae: 2698.4624 - val_loss: 13431984.0000 - val_mae: 3516.5745\n",
      "Epoch 329/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8500972.0000 - mae: 2698.3469 - val_loss: 13431205.0000 - val_mae: 3516.4636\n",
      "Epoch 330/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8500377.0000 - mae: 2698.2317 - val_loss: 13430404.0000 - val_mae: 3516.3494\n",
      "Epoch 331/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8499746.0000 - mae: 2698.1165 - val_loss: 13429611.0000 - val_mae: 3516.2363\n",
      "Epoch 332/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8499140.0000 - mae: 2698.0005 - val_loss: 13428816.0000 - val_mae: 3516.1230\n",
      "Epoch 333/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8498509.0000 - mae: 2697.8848 - val_loss: 13428029.0000 - val_mae: 3516.0115\n",
      "Epoch 334/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8497891.0000 - mae: 2697.7690 - val_loss: 13427251.0000 - val_mae: 3515.9004\n",
      "Epoch 335/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8497272.0000 - mae: 2697.6545 - val_loss: 13426472.0000 - val_mae: 3515.7891\n",
      "Epoch 336/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8496677.0000 - mae: 2697.5393 - val_loss: 13425675.0000 - val_mae: 3515.6750\n",
      "Epoch 337/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8496027.0000 - mae: 2697.4248 - val_loss: 13424903.0000 - val_mae: 3515.5657\n",
      "Epoch 338/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8495426.0000 - mae: 2697.3105 - val_loss: 13424107.0000 - val_mae: 3515.4524\n",
      "Epoch 339/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8494835.0000 - mae: 2697.1934 - val_loss: 13423285.0000 - val_mae: 3515.3352\n",
      "Epoch 340/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8494193.0000 - mae: 2697.0774 - val_loss: 13422491.0000 - val_mae: 3515.2219\n",
      "Epoch 341/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8493579.0000 - mae: 2696.9617 - val_loss: 13421704.0000 - val_mae: 3515.1101\n",
      "Epoch 342/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8492968.0000 - mae: 2696.8474 - val_loss: 13420924.0000 - val_mae: 3514.9988\n",
      "Epoch 343/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8492343.0000 - mae: 2696.7334 - val_loss: 13420153.0000 - val_mae: 3514.8889\n",
      "Epoch 344/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8491751.0000 - mae: 2696.6191 - val_loss: 13419357.0000 - val_mae: 3514.7754\n",
      "Epoch 345/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8491116.0000 - mae: 2696.5054 - val_loss: 13418587.0000 - val_mae: 3514.6653\n",
      "Epoch 346/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8490515.0000 - mae: 2696.3918 - val_loss: 13417821.0000 - val_mae: 3514.5566\n",
      "Epoch 347/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8489921.0000 - mae: 2696.2766 - val_loss: 13417041.0000 - val_mae: 3514.4456\n",
      "Epoch 348/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8489279.0000 - mae: 2696.1633 - val_loss: 13416280.0000 - val_mae: 3514.3372\n",
      "Epoch 349/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8488711.0000 - mae: 2696.0488 - val_loss: 13415483.0000 - val_mae: 3514.2234\n",
      "Epoch 350/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8488090.0000 - mae: 2695.9343 - val_loss: 13414704.0000 - val_mae: 3514.1123\n",
      "Epoch 351/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8487487.0000 - mae: 2695.8206 - val_loss: 13413924.0000 - val_mae: 3514.0012\n",
      "Epoch 352/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8486888.0000 - mae: 2695.7075 - val_loss: 13413139.0000 - val_mae: 3513.8889\n",
      "Epoch 353/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8486264.0000 - mae: 2695.5938 - val_loss: 13412379.0000 - val_mae: 3513.7810\n",
      "Epoch 354/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8485663.0000 - mae: 2695.4814 - val_loss: 13411611.0000 - val_mae: 3513.6711\n",
      "Epoch 355/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8485059.0000 - mae: 2695.3687 - val_loss: 13410840.0000 - val_mae: 3513.5613\n",
      "Epoch 356/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8484439.0000 - mae: 2695.2571 - val_loss: 13410080.0000 - val_mae: 3513.4531\n",
      "Epoch 357/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8483838.0000 - mae: 2695.1453 - val_loss: 13409317.0000 - val_mae: 3513.3447\n",
      "Epoch 358/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8483269.0000 - mae: 2695.0308 - val_loss: 13408520.0000 - val_mae: 3513.2312\n",
      "Epoch 359/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8482635.0000 - mae: 2694.9165 - val_loss: 13407749.0000 - val_mae: 3513.1211\n",
      "Epoch 360/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8482029.0000 - mae: 2694.8040 - val_loss: 13406969.0000 - val_mae: 3513.0098\n",
      "Epoch 361/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8481426.0000 - mae: 2694.6909 - val_loss: 13406184.0000 - val_mae: 3512.8977\n",
      "Epoch 362/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8480825.0000 - mae: 2694.5774 - val_loss: 13405401.0000 - val_mae: 3512.7864\n",
      "Epoch 363/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8480222.0000 - mae: 2694.4648 - val_loss: 13404609.0000 - val_mae: 3512.6736\n",
      "Epoch 364/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8479591.0000 - mae: 2694.3528 - val_loss: 13403849.0000 - val_mae: 3512.5652\n",
      "Epoch 365/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8479000.0000 - mae: 2694.2410 - val_loss: 13403079.0000 - val_mae: 3512.4551\n",
      "Epoch 366/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8478420.0000 - mae: 2694.1282 - val_loss: 13402296.0000 - val_mae: 3512.3435\n",
      "Epoch 367/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8477802.0000 - mae: 2694.0151 - val_loss: 13401523.0000 - val_mae: 3512.2334\n",
      "Epoch 368/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8477219.0000 - mae: 2693.9028 - val_loss: 13400737.0000 - val_mae: 3512.1211\n",
      "Epoch 369/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8476581.0000 - mae: 2693.7915 - val_loss: 13399983.0000 - val_mae: 3512.0137\n",
      "Epoch 370/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8476010.0000 - mae: 2693.6797 - val_loss: 13399208.0000 - val_mae: 3511.9031\n",
      "Epoch 371/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8475405.0000 - mae: 2693.5674 - val_loss: 13398435.0000 - val_mae: 3511.7930\n",
      "Epoch 372/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8474825.0000 - mae: 2693.4546 - val_loss: 13397656.0000 - val_mae: 3511.6819\n",
      "Epoch 373/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8474196.0000 - mae: 2693.3430 - val_loss: 13396904.0000 - val_mae: 3511.5750\n",
      "Epoch 374/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8473620.0000 - mae: 2693.2317 - val_loss: 13396123.0000 - val_mae: 3511.4631\n",
      "Epoch 375/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8473037.0000 - mae: 2693.1182 - val_loss: 13395347.0000 - val_mae: 3511.3525\n",
      "Epoch 376/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8472395.0000 - mae: 2693.0081 - val_loss: 13394607.0000 - val_mae: 3511.2471\n",
      "Epoch 377/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8471823.0000 - mae: 2692.8979 - val_loss: 13393845.0000 - val_mae: 3511.1384\n",
      "Epoch 378/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8471245.0000 - mae: 2692.7861 - val_loss: 13393073.0000 - val_mae: 3511.0281\n",
      "Epoch 379/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8470643.0000 - mae: 2692.6750 - val_loss: 13392312.0000 - val_mae: 3510.9199\n",
      "Epoch 380/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8470041.0000 - mae: 2692.5640 - val_loss: 13391555.0000 - val_mae: 3510.8115\n",
      "Epoch 381/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8469436.0000 - mae: 2692.4546 - val_loss: 13390801.0000 - val_mae: 3510.7041\n",
      "Epoch 382/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8468854.0000 - mae: 2692.3438 - val_loss: 13390032.0000 - val_mae: 3510.5945\n",
      "Epoch 383/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8468255.0000 - mae: 2692.2327 - val_loss: 13389265.0000 - val_mae: 3510.4851\n",
      "Epoch 384/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8467679.0000 - mae: 2692.1213 - val_loss: 13388501.0000 - val_mae: 3510.3760\n",
      "Epoch 385/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8467069.0000 - mae: 2692.0095 - val_loss: 13387736.0000 - val_mae: 3510.2668\n",
      "Epoch 386/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8466501.0000 - mae: 2691.8982 - val_loss: 13386971.0000 - val_mae: 3510.1575\n",
      "Epoch 387/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8465879.0000 - mae: 2691.7886 - val_loss: 13386229.0000 - val_mae: 3510.0520\n",
      "Epoch 388/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8465304.0000 - mae: 2691.6794 - val_loss: 13385480.0000 - val_mae: 3509.9446\n",
      "Epoch 389/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8464711.0000 - mae: 2691.5703 - val_loss: 13384744.0000 - val_mae: 3509.8398\n",
      "Epoch 390/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8464149.0000 - mae: 2691.4597 - val_loss: 13383972.0000 - val_mae: 3509.7297\n",
      "Epoch 391/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8463540.0000 - mae: 2691.3496 - val_loss: 13383225.0000 - val_mae: 3509.6233\n",
      "Epoch 392/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8462969.0000 - mae: 2691.2390 - val_loss: 13382464.0000 - val_mae: 3509.5149\n",
      "Epoch 393/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8462370.0000 - mae: 2691.1287 - val_loss: 13381712.0000 - val_mae: 3509.4075\n",
      "Epoch 394/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8461762.0000 - mae: 2691.0203 - val_loss: 13380979.0000 - val_mae: 3509.3035\n",
      "Epoch 395/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8461217.0000 - mae: 2690.9104 - val_loss: 13380215.0000 - val_mae: 3509.1941\n",
      "Epoch 396/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8460632.0000 - mae: 2690.7988 - val_loss: 13379449.0000 - val_mae: 3509.0847\n",
      "Epoch 397/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8460017.0000 - mae: 2690.6897 - val_loss: 13378712.0000 - val_mae: 3508.9797\n",
      "Epoch 398/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8459439.0000 - mae: 2690.5820 - val_loss: 13377976.0000 - val_mae: 3508.8743\n",
      "Epoch 399/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8458882.0000 - mae: 2690.4724 - val_loss: 13377219.0000 - val_mae: 3508.7664\n",
      "Epoch 400/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8458282.0000 - mae: 2690.3638 - val_loss: 13376476.0000 - val_mae: 3508.6602\n",
      "Epoch 401/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8457704.0000 - mae: 2690.2554 - val_loss: 13375727.0000 - val_mae: 3508.5535\n",
      "Epoch 402/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8457121.0000 - mae: 2690.1470 - val_loss: 13374984.0000 - val_mae: 3508.4473\n",
      "Epoch 403/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8456559.0000 - mae: 2690.0383 - val_loss: 13374224.0000 - val_mae: 3508.3391\n",
      "Epoch 404/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8455958.0000 - mae: 2689.9304 - val_loss: 13373483.0000 - val_mae: 3508.2332\n",
      "Epoch 405/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8455379.0000 - mae: 2689.8225 - val_loss: 13372745.0000 - val_mae: 3508.1277\n",
      "Epoch 406/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8454790.0000 - mae: 2689.7158 - val_loss: 13372017.0000 - val_mae: 3508.0242\n",
      "Epoch 407/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8454224.0000 - mae: 2689.6069 - val_loss: 13371264.0000 - val_mae: 3507.9167\n",
      "Epoch 408/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8453632.0000 - mae: 2689.4983 - val_loss: 13370528.0000 - val_mae: 3507.8113\n",
      "Epoch 409/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8453054.0000 - mae: 2689.3889 - val_loss: 13369781.0000 - val_mae: 3507.7051\n",
      "Epoch 410/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8452457.0000 - mae: 2689.2795 - val_loss: 13369035.0000 - val_mae: 3507.5984\n",
      "Epoch 411/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8451883.0000 - mae: 2689.1702 - val_loss: 13368272.0000 - val_mae: 3507.4893\n",
      "Epoch 412/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8451296.0000 - mae: 2689.0603 - val_loss: 13367511.0000 - val_mae: 3507.3809\n",
      "Epoch 413/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8450717.0000 - mae: 2688.9502 - val_loss: 13366760.0000 - val_mae: 3507.2734\n",
      "Epoch 414/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8450129.0000 - mae: 2688.8413 - val_loss: 13366000.0000 - val_mae: 3507.1650\n",
      "Epoch 415/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8449559.0000 - mae: 2688.7319 - val_loss: 13365243.0000 - val_mae: 3507.0569\n",
      "Epoch 416/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8448975.0000 - mae: 2688.6226 - val_loss: 13364499.0000 - val_mae: 3506.9504\n",
      "Epoch 417/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8448387.0000 - mae: 2688.5144 - val_loss: 13363763.0000 - val_mae: 3506.8457\n",
      "Epoch 418/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8447810.0000 - mae: 2688.4070 - val_loss: 13363031.0000 - val_mae: 3506.7412\n",
      "Epoch 419/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8447243.0000 - mae: 2688.2998 - val_loss: 13362285.0000 - val_mae: 3506.6348\n",
      "Epoch 420/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8446653.0000 - mae: 2688.1921 - val_loss: 13361552.0000 - val_mae: 3506.5300\n",
      "Epoch 421/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8446084.0000 - mae: 2688.0854 - val_loss: 13360820.0000 - val_mae: 3506.4255\n",
      "Epoch 422/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8445526.0000 - mae: 2687.9783 - val_loss: 13360067.0000 - val_mae: 3506.3184\n",
      "Epoch 423/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8444952.0000 - mae: 2687.8696 - val_loss: 13359317.0000 - val_mae: 3506.2109\n",
      "Epoch 424/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8444362.0000 - mae: 2687.7625 - val_loss: 13358589.0000 - val_mae: 3506.1072\n",
      "Epoch 425/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8443806.0000 - mae: 2687.6553 - val_loss: 13357849.0000 - val_mae: 3506.0012\n",
      "Epoch 426/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8443222.0000 - mae: 2687.5479 - val_loss: 13357120.0000 - val_mae: 3505.8972\n",
      "Epoch 427/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8442638.0000 - mae: 2687.4421 - val_loss: 13356392.0000 - val_mae: 3505.7932\n",
      "Epoch 428/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8442074.0000 - mae: 2687.3352 - val_loss: 13355651.0000 - val_mae: 3505.6875\n",
      "Epoch 429/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8441514.0000 - mae: 2687.2273 - val_loss: 13354899.0000 - val_mae: 3505.5801\n",
      "Epoch 430/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8440918.0000 - mae: 2687.1201 - val_loss: 13354172.0000 - val_mae: 3505.4763\n",
      "Epoch 431/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8440354.0000 - mae: 2687.0127 - val_loss: 13353440.0000 - val_mae: 3505.3718\n",
      "Epoch 432/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8439790.0000 - mae: 2686.9060 - val_loss: 13352701.0000 - val_mae: 3505.2664\n",
      "Epoch 433/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8439224.0000 - mae: 2686.7991 - val_loss: 13351960.0000 - val_mae: 3505.1604\n",
      "Epoch 434/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8438659.0000 - mae: 2686.6921 - val_loss: 13351219.0000 - val_mae: 3505.0544\n",
      "Epoch 435/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8438055.0000 - mae: 2686.5859 - val_loss: 13350507.0000 - val_mae: 3504.9529\n",
      "Epoch 436/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8437514.0000 - mae: 2686.4807 - val_loss: 13349773.0000 - val_mae: 3504.8484\n",
      "Epoch 437/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8436935.0000 - mae: 2686.3730 - val_loss: 13349040.0000 - val_mae: 3504.7434\n",
      "Epoch 438/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8436365.0000 - mae: 2686.2668 - val_loss: 13348304.0000 - val_mae: 3504.6379\n",
      "Epoch 439/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8435804.0000 - mae: 2686.1599 - val_loss: 13347571.0000 - val_mae: 3504.5334\n",
      "Epoch 440/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8435227.0000 - mae: 2686.0527 - val_loss: 13346839.0000 - val_mae: 3504.4290\n",
      "Epoch 441/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8434668.0000 - mae: 2685.9460 - val_loss: 13346097.0000 - val_mae: 3504.3230\n",
      "Epoch 442/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8434091.0000 - mae: 2685.8398 - val_loss: 13345372.0000 - val_mae: 3504.2195\n",
      "Epoch 443/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8433511.0000 - mae: 2685.7344 - val_loss: 13344660.0000 - val_mae: 3504.1179\n",
      "Epoch 444/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8432955.0000 - mae: 2685.6292 - val_loss: 13343928.0000 - val_mae: 3504.0137\n",
      "Epoch 445/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8432406.0000 - mae: 2685.5220 - val_loss: 13343187.0000 - val_mae: 3503.9075\n",
      "Epoch 446/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8431826.0000 - mae: 2685.4150 - val_loss: 13342451.0000 - val_mae: 3503.8020\n",
      "Epoch 447/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8431251.0000 - mae: 2685.3091 - val_loss: 13341727.0000 - val_mae: 3503.6985\n",
      "Epoch 448/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8430664.0000 - mae: 2685.2048 - val_loss: 13341012.0000 - val_mae: 3503.5967\n",
      "Epoch 449/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8430152.0000 - mae: 2685.0979 - val_loss: 13340253.0000 - val_mae: 3503.4883\n",
      "Epoch 450/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8429540.0000 - mae: 2684.9910 - val_loss: 13339531.0000 - val_mae: 3503.3848\n",
      "Epoch 451/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8428982.0000 - mae: 2684.8850 - val_loss: 13338796.0000 - val_mae: 3503.2800\n",
      "Epoch 452/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8428413.0000 - mae: 2684.7786 - val_loss: 13338071.0000 - val_mae: 3503.1765\n",
      "Epoch 453/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8427842.0000 - mae: 2684.6738 - val_loss: 13337357.0000 - val_mae: 3503.0742\n",
      "Epoch 454/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8427298.0000 - mae: 2684.5674 - val_loss: 13336619.0000 - val_mae: 3502.9688\n",
      "Epoch 455/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8426732.0000 - mae: 2684.4612 - val_loss: 13335883.0000 - val_mae: 3502.8640\n",
      "Epoch 456/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8426156.0000 - mae: 2684.3547 - val_loss: 13335156.0000 - val_mae: 3502.7598\n",
      "Epoch 457/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8425585.0000 - mae: 2684.2500 - val_loss: 13334432.0000 - val_mae: 3502.6562\n",
      "Epoch 458/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8425026.0000 - mae: 2684.1440 - val_loss: 13333701.0000 - val_mae: 3502.5518\n",
      "Epoch 459/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8424451.0000 - mae: 2684.0391 - val_loss: 13332976.0000 - val_mae: 3502.4485\n",
      "Epoch 460/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8423914.0000 - mae: 2683.9329 - val_loss: 13332235.0000 - val_mae: 3502.3420\n",
      "Epoch 461/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8423331.0000 - mae: 2683.8281 - val_loss: 13331519.0000 - val_mae: 3502.2402\n",
      "Epoch 462/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8422792.0000 - mae: 2683.7227 - val_loss: 13330785.0000 - val_mae: 3502.1350\n",
      "Epoch 463/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8422223.0000 - mae: 2683.6172 - val_loss: 13330064.0000 - val_mae: 3502.0320\n",
      "Epoch 464/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8421668.0000 - mae: 2683.5125 - val_loss: 13329345.0000 - val_mae: 3501.9290\n",
      "Epoch 465/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8421098.0000 - mae: 2683.4087 - val_loss: 13328635.0000 - val_mae: 3501.8279\n",
      "Epoch 466/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8420540.0000 - mae: 2683.3057 - val_loss: 13327929.0000 - val_mae: 3501.7268\n",
      "Epoch 467/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8420005.0000 - mae: 2683.2012 - val_loss: 13327209.0000 - val_mae: 3501.6240\n",
      "Epoch 468/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8419412.0000 - mae: 2683.0974 - val_loss: 13326511.0000 - val_mae: 3501.5242\n",
      "Epoch 469/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8418884.0000 - mae: 2682.9929 - val_loss: 13325775.0000 - val_mae: 3501.4189\n",
      "Epoch 470/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8418309.0000 - mae: 2682.8875 - val_loss: 13325049.0000 - val_mae: 3501.3152\n",
      "Epoch 471/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8417770.0000 - mae: 2682.7827 - val_loss: 13324315.0000 - val_mae: 3501.2100\n",
      "Epoch 472/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8417200.0000 - mae: 2682.6775 - val_loss: 13323599.0000 - val_mae: 3501.1082\n",
      "Epoch 473/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8416640.0000 - mae: 2682.5735 - val_loss: 13322889.0000 - val_mae: 3501.0066\n",
      "Epoch 474/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8416079.0000 - mae: 2682.4700 - val_loss: 13322183.0000 - val_mae: 3500.9053\n",
      "Epoch 475/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8415544.0000 - mae: 2682.3655 - val_loss: 13321461.0000 - val_mae: 3500.8020\n",
      "Epoch 476/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8414973.0000 - mae: 2682.2610 - val_loss: 13320745.0000 - val_mae: 3500.7000\n",
      "Epoch 477/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8414416.0000 - mae: 2682.1570 - val_loss: 13320029.0000 - val_mae: 3500.5977\n",
      "Epoch 478/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8413864.0000 - mae: 2682.0525 - val_loss: 13319307.0000 - val_mae: 3500.4941\n",
      "Epoch 479/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8413315.0000 - mae: 2681.9473 - val_loss: 13318577.0000 - val_mae: 3500.3899\n",
      "Epoch 480/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8412759.0000 - mae: 2681.8418 - val_loss: 13317857.0000 - val_mae: 3500.2871\n",
      "Epoch 481/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8412184.0000 - mae: 2681.7385 - val_loss: 13317157.0000 - val_mae: 3500.1868\n",
      "Epoch 482/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8411625.0000 - mae: 2681.6375 - val_loss: 13316460.0000 - val_mae: 3500.0872\n",
      "Epoch 483/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8411085.0000 - mae: 2681.5337 - val_loss: 13315741.0000 - val_mae: 3499.9844\n",
      "Epoch 484/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8410547.0000 - mae: 2681.4287 - val_loss: 13315012.0000 - val_mae: 3499.8801\n",
      "Epoch 485/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8409975.0000 - mae: 2681.3250 - val_loss: 13314301.0000 - val_mae: 3499.7786\n",
      "Epoch 486/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8409443.0000 - mae: 2681.2200 - val_loss: 13313577.0000 - val_mae: 3499.6750\n",
      "Epoch 487/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8408856.0000 - mae: 2681.1172 - val_loss: 13312876.0000 - val_mae: 3499.5745\n",
      "Epoch 488/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8408321.0000 - mae: 2681.0142 - val_loss: 13312161.0000 - val_mae: 3499.4724\n",
      "Epoch 489/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8407755.0000 - mae: 2680.9116 - val_loss: 13311451.0000 - val_mae: 3499.3711\n",
      "Epoch 490/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8407203.0000 - mae: 2680.8088 - val_loss: 13310741.0000 - val_mae: 3499.2695\n",
      "Epoch 491/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8406679.0000 - mae: 2680.7036 - val_loss: 13310011.0000 - val_mae: 3499.1648\n",
      "Epoch 492/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8406097.0000 - mae: 2680.5994 - val_loss: 13309300.0000 - val_mae: 3499.0632\n",
      "Epoch 493/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8405560.0000 - mae: 2680.4954 - val_loss: 13308572.0000 - val_mae: 3498.9592\n",
      "Epoch 494/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8405009.0000 - mae: 2680.3906 - val_loss: 13307845.0000 - val_mae: 3498.8555\n",
      "Epoch 495/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8404440.0000 - mae: 2680.2871 - val_loss: 13307137.0000 - val_mae: 3498.7542\n",
      "Epoch 496/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8403870.0000 - mae: 2680.1858 - val_loss: 13306441.0000 - val_mae: 3498.6543\n",
      "Epoch 497/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8403345.0000 - mae: 2680.0825 - val_loss: 13305721.0000 - val_mae: 3498.5515\n",
      "Epoch 498/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8402777.0000 - mae: 2679.9795 - val_loss: 13305016.0000 - val_mae: 3498.4504\n",
      "Epoch 499/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8402218.0000 - mae: 2679.8774 - val_loss: 13304315.0000 - val_mae: 3498.3499\n",
      "Epoch 500/500\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8401704.0000 - mae: 2679.7742 - val_loss: 13303583.0000 - val_mae: 3498.2454\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=4,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stop], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394721da-173b-47b2-9fa8-7ab6e8018bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"R2 :\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d4f6c26-e078-4548-8b3c-f6190ba16d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Mn, Actual Mw, Predicted Mn, Predicted Mw:\n",
      "[[2298.62       2972.98         54.69046783   56.43782806]\n",
      " [3762.88       5752.81         54.70809937   56.45594406]\n",
      " [1127.19       1321.65         53.65939713   55.3809166 ]]\n"
     ]
    }
   ],
   "source": [
    "comparison = np.hstack((y_test, y_pred))\n",
    "print(\"Actual Mn, Actual Mw, Predicted Mn, Predicted Mw:\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d2914ca-de41-4347-99d9-9e30fddd6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec6a097a-2fce-411f-b304-6f0af5b51566",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=4, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7072968-0e42-46dd-98c6-49620c4d6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c433a695-725e-49dd-85c0-d6514583adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f752766c-633f-409e-a5c8-3068bb465be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['MeanSquaredLogarithmicError'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a60e89a-0a88-4a5f-879c-7fb6cd5ce032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db02b169-28c7-4417-8aa0-69da64e6465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa3dd4-f88c-4077-a4c5-9afdd0bd3c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
