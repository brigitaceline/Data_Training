{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/elhamshaerirahbar-bot/my-colab-project/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8S8VCECinI2",
    "outputId": "442f5205-7a69-49da-a8a5-1f42a4fc8e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.20.0rc0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.11.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0Syqe_mYiwTx"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, re, unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "mQM3DjQNi0he",
    "outputId": "b018038a-6aec-4a81-e135-9ae3d186ce03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Run  Factor A  Factor B  Factor C  Factor D  Response 1 (Experimental)  \\\n",
      "0    1       110         7        50        10                    1127.19   \n",
      "1    2        85        13        50        10                    1024.97   \n",
      "2    3       101         1       500        60                    1950.00   \n",
      "3    4       101         1       500        60                    2223.17   \n",
      "4    5        50        10        50        10                    1845.60   \n",
      "\n",
      "   Response 2 (Experimental)  \n",
      "0                    1321.65  \n",
      "1                    1339.35  \n",
      "2                    2878.90  \n",
      "3                    2989.00  \n",
      "4                    2690.50  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Just read the file\n",
    "df = pd.read_csv('Exp_Mn_Mw_Value.txt', sep='\\t')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Y9BwNofi4-T",
    "outputId": "92a5901e-bb2a-48a0-bd86-613b27ddaa22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (25, 4)  y: (25, 2)\n"
     ]
    }
   ],
   "source": [
    "#select columns by position\n",
    "X = df.iloc[:, 1:5].astype(float).to_numpy()  # First 4 columns as features\n",
    "y = df.iloc[:, 5:7].astype(float).to_numpy()  # Next 2 columns as targets\n",
    "\n",
    "print(\"X:\", X.shape, \" y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2AA1C6Wi77R",
    "outputId": "187af667-98c6-49ba-857a-f7dab735a70b"
   },
   "outputs": [],
   "source": [
    "SEED = 5\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Simple train/test/val split\n",
    "# For 20% test, 16% val, 64% train:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, shuffle=True, random_state=SEED\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.20, shuffle=True, random_state=SEED  # 0.20 of 0.80 = 0.16 overall\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WAeiXioBjGXg"
   },
   "outputs": [],
   "source": [
    "#scaling\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Ensure y has correct shape (samples, 2_targets)\n",
    "assert y_train.ndim == 2 and y_train.shape[1] == 2, \"y muss (n,2) sein\"\n",
    "\n",
    "# --- Scale features (X) using StandardScaler ---\n",
    "# Fit scaler only on training data to prevent data leakage\n",
    "x_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Transform all sets using the same scaler (mean=0, std=1)\n",
    "X_train_z = x_scaler.transform(X_train)  # Standardized training features\n",
    "X_val_z   = x_scaler.transform(X_val)    # Standardized validation features  \n",
    "X_test_z  = x_scaler.transform(X_test)   # Standardized test features\n",
    "\n",
    "# --- Scale targets (y) to [-1,1] range for tanh activation ---\n",
    "# Fit scaler only on training targets to prevent data leakage\n",
    "y_scaler  = MinMaxScaler(feature_range=(-1, 1)).fit(y_train)  # y_train: (n,2)\n",
    "\n",
    "# Transform all target sets using the same scaler\n",
    "y_train_s = y_scaler.transform(y_train)  # Scaled training targets [-1,1]\n",
    "y_val_s   = y_scaler.transform(y_val)    # Scaled validation targets [-1,1]\n",
    "y_test_s  = y_scaler.transform(y_test)   # Scaled test targets [-1,1]\n",
    "\n",
    "def inv_y(y_s):\n",
    "    \"\"\"\n",
    "    Inverse transform scaled predictions back to original units.\n",
    "    Args: y_s - scaled predictions in [-1,1] range\n",
    "    Returns: predictions in original scale (Mn, Mw units)\n",
    "    \"\"\"\n",
    "    return y_scaler.inverse_transform(y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dBaYl7yWjKR5"
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otPjam8rjLqF",
    "outputId": "c6ef832c-fff8-46ad-d52a-389edaf598dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#build ann\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Verify target shape (samples, 2_outputs)\n",
    "assert y_train_s.ndim == 2 and y_train_s.shape[1] == 2, \"y muss (n,2) sein!\"\n",
    "\n",
    "# Build Neural Network: 4 inputs -> 3 hidden layers (16,8,8) -> 2 outputs\n",
    "# Architecture: fully connected feedforward network with regularization\n",
    "# Purpose: predict 2 molecular weight responses (Mn, Mw) from 4 factors\n",
    "model = Sequential([\n",
    "    # Input layer: 4 features -> 16 neurons\n",
    "    # ReLU activation for non-linearity\n",
    "    # L2 regularization to prevent overfitting\n",
    "    layers.Dense(16, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-5),\n",
    "                 input_shape=(X_train_z.shape[1],)),\n",
    "    \n",
    "    # Dropout to reduce overfitting (randomly disable 10% of neurons)\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    # Hidden layer: 16 -> 8 neurons\n",
    "    layers.Dense(8, activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(1e-5)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    # Hidden layer: 8 -> 8 neurons  \n",
    "    layers.Dense(8, activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(1e-5)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    # Output layer: 8 -> 2 outputs (Mn, Mw)\n",
    "    # Tanh activation outputs [-1,1] to match our scaled targets\n",
    "    layers.Dense(2, activation='tanh')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "# MSE loss for regression, MAE and MAPE as additional metrics\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse', \n",
    "              metrics=['mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SiGI9kdjLoU",
    "outputId": "a56e7194-c800-4b0d-945d-a91716792ef7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.3274 - mae: 0.4274 - mape: 150.0093 - val_loss: 0.3114 - val_mae: 0.3439 - val_mape: 76.1992\n",
      "Epoch 2/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3389 - mae: 0.4401 - mape: 149.1714 - val_loss: 0.3082 - val_mae: 0.3425 - val_mape: 76.0202\n",
      "Epoch 3/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3155 - mae: 0.4222 - mape: 118.0924 - val_loss: 0.3050 - val_mae: 0.3412 - val_mape: 76.0242\n",
      "Epoch 4/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3328 - mae: 0.4257 - mape: 93.5885 - val_loss: 0.3022 - val_mae: 0.3399 - val_mape: 75.5715\n",
      "Epoch 5/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3255 - mae: 0.4347 - mape: 106.3482 - val_loss: 0.2993 - val_mae: 0.3386 - val_mape: 75.0381\n",
      "Epoch 6/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3166 - mae: 0.4149 - mape: 100.0335 - val_loss: 0.2962 - val_mae: 0.3370 - val_mape: 74.3747\n",
      "Epoch 7/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3031 - mae: 0.4188 - mape: 106.2824 - val_loss: 0.2933 - val_mae: 0.3355 - val_mape: 73.6875\n",
      "Epoch 8/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3050 - mae: 0.4107 - mape: 93.3991 - val_loss: 0.2906 - val_mae: 0.3341 - val_mape: 73.0299\n",
      "Epoch 9/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3049 - mae: 0.4160 - mape: 103.5783 - val_loss: 0.2882 - val_mae: 0.3328 - val_mape: 72.2571\n",
      "Epoch 10/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3051 - mae: 0.4118 - mape: 95.3466 - val_loss: 0.2856 - val_mae: 0.3314 - val_mape: 71.5196\n",
      "Epoch 11/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2814 - mae: 0.3969 - mape: 90.4377 - val_loss: 0.2833 - val_mae: 0.3300 - val_mape: 70.6701\n",
      "Epoch 12/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2962 - mae: 0.4053 - mape: 90.0079 - val_loss: 0.2811 - val_mae: 0.3287 - val_mape: 69.8755\n",
      "Epoch 13/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2958 - mae: 0.4094 - mape: 89.7670 - val_loss: 0.2791 - val_mae: 0.3274 - val_mape: 69.1286\n",
      "Epoch 14/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2827 - mae: 0.3924 - mape: 87.1180 - val_loss: 0.2773 - val_mae: 0.3263 - val_mape: 68.4465\n",
      "Epoch 15/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2822 - mae: 0.3954 - mape: 94.5517 - val_loss: 0.2755 - val_mae: 0.3251 - val_mape: 67.7967\n",
      "Epoch 16/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2979 - mae: 0.4094 - mape: 102.2409 - val_loss: 0.2737 - val_mae: 0.3241 - val_mape: 67.2640\n",
      "Epoch 17/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2828 - mae: 0.3963 - mape: 89.3265 - val_loss: 0.2720 - val_mae: 0.3234 - val_mape: 66.9429\n",
      "Epoch 18/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3200 - mae: 0.4229 - mape: 167.4070 - val_loss: 0.2703 - val_mae: 0.3228 - val_mape: 66.7029\n",
      "Epoch 19/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2863 - mae: 0.3964 - mape: 84.9676 - val_loss: 0.2687 - val_mae: 0.3222 - val_mape: 66.4424\n",
      "Epoch 20/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2816 - mae: 0.3966 - mape: 88.5125 - val_loss: 0.2672 - val_mae: 0.3220 - val_mape: 67.1725\n",
      "Epoch 21/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2865 - mae: 0.3986 - mape: 93.9587 - val_loss: 0.2661 - val_mae: 0.3222 - val_mape: 68.2736\n",
      "Epoch 22/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2930 - mae: 0.4079 - mape: 93.9746 - val_loss: 0.2654 - val_mae: 0.3225 - val_mape: 69.3923\n",
      "Epoch 23/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2845 - mae: 0.3999 - mape: 108.3722 - val_loss: 0.2647 - val_mae: 0.3229 - val_mape: 70.4386\n",
      "Epoch 24/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2841 - mae: 0.3916 - mape: 97.2792 - val_loss: 0.2640 - val_mae: 0.3232 - val_mape: 71.5321\n",
      "Epoch 25/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2842 - mae: 0.4014 - mape: 96.4444 - val_loss: 0.2633 - val_mae: 0.3234 - val_mape: 72.5656\n",
      "Epoch 26/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2922 - mae: 0.3957 - mape: 89.3008 - val_loss: 0.2626 - val_mae: 0.3238 - val_mape: 73.6435\n",
      "Epoch 27/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2784 - mae: 0.3996 - mape: 96.2053 - val_loss: 0.2620 - val_mae: 0.3244 - val_mape: 74.9824\n",
      "Epoch 28/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2881 - mae: 0.3948 - mape: 90.9664 - val_loss: 0.2613 - val_mae: 0.3249 - val_mape: 76.4701\n",
      "Epoch 29/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2811 - mae: 0.3970 - mape: 99.4489 - val_loss: 0.2607 - val_mae: 0.3256 - val_mape: 78.0284\n",
      "Epoch 30/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2924 - mae: 0.4073 - mape: 114.3707 - val_loss: 0.2601 - val_mae: 0.3261 - val_mape: 79.5210\n",
      "Epoch 31/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2714 - mae: 0.3954 - mape: 98.5156 - val_loss: 0.2595 - val_mae: 0.3267 - val_mape: 81.1336\n",
      "Epoch 32/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2956 - mae: 0.4129 - mape: 137.8897 - val_loss: 0.2590 - val_mae: 0.3273 - val_mape: 82.7848\n",
      "Epoch 33/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.2837 - mae: 0.3869 - mape: 90.0791 - val_loss: 0.2584 - val_mae: 0.3280 - val_mape: 84.4397\n",
      "Epoch 34/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2606 - mae: 0.3769 - mape: 114.6208 - val_loss: 0.2578 - val_mae: 0.3285 - val_mape: 85.9505\n",
      "Epoch 35/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2694 - mae: 0.3923 - mape: 167.9156 - val_loss: 0.2575 - val_mae: 0.3302 - val_mape: 88.0170\n",
      "Epoch 36/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2844 - mae: 0.3898 - mape: 93.1464 - val_loss: 0.2572 - val_mae: 0.3322 - val_mape: 90.2462\n",
      "Epoch 37/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2563 - mae: 0.3727 - mape: 97.7248 - val_loss: 0.2569 - val_mae: 0.3342 - val_mape: 92.5617\n",
      "Epoch 38/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2635 - mae: 0.3918 - mape: 160.0348 - val_loss: 0.2567 - val_mae: 0.3362 - val_mape: 94.8183\n",
      "Epoch 39/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2516 - mae: 0.3791 - mape: 91.7726 - val_loss: 0.2564 - val_mae: 0.3381 - val_mape: 97.0538\n",
      "Epoch 40/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2445 - mae: 0.3684 - mape: 97.6458 - val_loss: 0.2560 - val_mae: 0.3397 - val_mape: 99.0367\n",
      "Epoch 41/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2769 - mae: 0.4098 - mape: 111.4487 - val_loss: 0.2556 - val_mae: 0.3411 - val_mape: 100.6354\n",
      "Epoch 42/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2716 - mae: 0.3990 - mape: 113.9818 - val_loss: 0.2552 - val_mae: 0.3425 - val_mape: 102.3301\n",
      "Epoch 43/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2766 - mae: 0.3839 - mape: 90.6142 - val_loss: 0.2549 - val_mae: 0.3437 - val_mape: 104.0049\n",
      "Epoch 44/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2573 - mae: 0.3751 - mape: 126.2998 - val_loss: 0.2546 - val_mae: 0.3452 - val_mape: 105.7791\n",
      "Epoch 45/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2690 - mae: 0.3927 - mape: 114.5040 - val_loss: 0.2542 - val_mae: 0.3461 - val_mape: 107.2008\n",
      "Epoch 46/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2624 - mae: 0.3755 - mape: 93.6247 - val_loss: 0.2539 - val_mae: 0.3471 - val_mape: 108.6521\n",
      "Epoch 47/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2721 - mae: 0.3898 - mape: 101.9151 - val_loss: 0.2536 - val_mae: 0.3480 - val_mape: 110.0553\n",
      "Epoch 48/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2807 - mae: 0.3823 - mape: 90.9563 - val_loss: 0.2534 - val_mae: 0.3488 - val_mape: 111.3584\n",
      "Epoch 49/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2859 - mae: 0.4115 - mape: 113.2430 - val_loss: 0.2531 - val_mae: 0.3494 - val_mape: 112.5026\n",
      "Epoch 50/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2463 - mae: 0.3713 - mape: 151.0733 - val_loss: 0.2527 - val_mae: 0.3501 - val_mape: 113.7052\n",
      "Epoch 51/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.2454 - mae: 0.3800 - mape: 115.3708 - val_loss: 0.2520 - val_mae: 0.3506 - val_mape: 114.8438\n",
      "Epoch 52/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2704 - mae: 0.3989 - mape: 106.2747 - val_loss: 0.2514 - val_mae: 0.3510 - val_mape: 115.8389\n",
      "Epoch 53/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2303 - mae: 0.3596 - mape: 102.1514 - val_loss: 0.2509 - val_mae: 0.3514 - val_mape: 116.8261\n",
      "Epoch 54/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2652 - mae: 0.3795 - mape: 113.2361 - val_loss: 0.2503 - val_mae: 0.3518 - val_mape: 117.7455\n",
      "Epoch 55/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2496 - mae: 0.3758 - mape: 111.5080 - val_loss: 0.2496 - val_mae: 0.3521 - val_mape: 118.7289\n",
      "Epoch 56/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2238 - mae: 0.3543 - mape: 99.1999 - val_loss: 0.2491 - val_mae: 0.3526 - val_mape: 120.0391\n",
      "Epoch 57/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2435 - mae: 0.3606 - mape: 86.9043 - val_loss: 0.2486 - val_mae: 0.3531 - val_mape: 121.4355\n",
      "Epoch 58/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2354 - mae: 0.3486 - mape: 97.5652 - val_loss: 0.2481 - val_mae: 0.3536 - val_mape: 122.8494\n",
      "Epoch 59/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2300 - mae: 0.3681 - mape: 119.6612 - val_loss: 0.2475 - val_mae: 0.3542 - val_mape: 124.3513\n",
      "Epoch 60/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2435 - mae: 0.3662 - mape: 123.0036 - val_loss: 0.2469 - val_mae: 0.3550 - val_mape: 126.0960\n",
      "Epoch 61/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2233 - mae: 0.3520 - mape: 116.2999 - val_loss: 0.2464 - val_mae: 0.3558 - val_mape: 127.8352\n",
      "Epoch 62/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2451 - mae: 0.3476 - mape: 96.5740 - val_loss: 0.2459 - val_mae: 0.3565 - val_mape: 129.4558\n",
      "Epoch 63/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2533 - mae: 0.3757 - mape: 113.6427 - val_loss: 0.2454 - val_mae: 0.3571 - val_mape: 131.0516\n",
      "Epoch 64/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2334 - mae: 0.3468 - mape: 130.4312 - val_loss: 0.2449 - val_mae: 0.3578 - val_mape: 132.6786\n",
      "Epoch 65/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2248 - mae: 0.3478 - mape: 109.8397 - val_loss: 0.2446 - val_mae: 0.3586 - val_mape: 134.3816\n",
      "Epoch 66/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2690 - mae: 0.3761 - mape: 104.6647 - val_loss: 0.2443 - val_mae: 0.3595 - val_mape: 136.1652\n",
      "Epoch 67/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.2386 - mae: 0.3397 - mape: 100.9874 - val_loss: 0.2441 - val_mae: 0.3604 - val_mape: 137.9745\n",
      "Epoch 68/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.2361 - mae: 0.3622 - mape: 111.6499 - val_loss: 0.2436 - val_mae: 0.3610 - val_mape: 139.6206\n",
      "Epoch 69/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2150 - mae: 0.3541 - mape: 124.3906 - val_loss: 0.2430 - val_mae: 0.3616 - val_mape: 141.2769\n",
      "Epoch 70/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2266 - mae: 0.3396 - mape: 105.1454 - val_loss: 0.2424 - val_mae: 0.3622 - val_mape: 142.9557\n",
      "Epoch 71/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2074 - mae: 0.3355 - mape: 107.7901 - val_loss: 0.2418 - val_mae: 0.3628 - val_mape: 144.7041\n",
      "Epoch 72/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2290 - mae: 0.3641 - mape: 158.2969 - val_loss: 0.2411 - val_mae: 0.3633 - val_mape: 146.3452\n",
      "Epoch 73/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2368 - mae: 0.3556 - mape: 143.6334 - val_loss: 0.2405 - val_mae: 0.3638 - val_mape: 148.0327\n",
      "Epoch 74/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2626 - mae: 0.3766 - mape: 134.8995 - val_loss: 0.2397 - val_mae: 0.3642 - val_mape: 149.4553\n",
      "Epoch 75/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2093 - mae: 0.3573 - mape: 153.4763 - val_loss: 0.2390 - val_mae: 0.3647 - val_mape: 150.8765\n",
      "Epoch 76/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.2252 - mae: 0.3461 - mape: 118.2310 - val_loss: 0.2382 - val_mae: 0.3651 - val_mape: 152.3657\n",
      "Epoch 77/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1994 - mae: 0.3326 - mape: 119.6849 - val_loss: 0.2373 - val_mae: 0.3656 - val_mape: 153.8389\n",
      "Epoch 78/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2171 - mae: 0.3475 - mape: 109.3309 - val_loss: 0.2366 - val_mae: 0.3661 - val_mape: 155.2834\n",
      "Epoch 79/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2039 - mae: 0.3297 - mape: 114.2863 - val_loss: 0.2358 - val_mae: 0.3666 - val_mape: 156.7527\n",
      "Epoch 80/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2064 - mae: 0.3359 - mape: 106.7991 - val_loss: 0.2350 - val_mae: 0.3671 - val_mape: 158.3084\n",
      "Epoch 81/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2044 - mae: 0.3323 - mape: 112.3636 - val_loss: 0.2343 - val_mae: 0.3676 - val_mape: 159.8730\n",
      "Epoch 82/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2160 - mae: 0.3591 - mape: 122.9103 - val_loss: 0.2333 - val_mae: 0.3679 - val_mape: 161.2753\n",
      "Epoch 83/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1925 - mae: 0.3232 - mape: 117.2285 - val_loss: 0.2324 - val_mae: 0.3683 - val_mape: 162.6846\n",
      "Epoch 84/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2308 - mae: 0.3359 - mape: 106.7647 - val_loss: 0.2315 - val_mae: 0.3687 - val_mape: 164.2486\n",
      "Epoch 85/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2132 - mae: 0.3281 - mape: 110.7724 - val_loss: 0.2308 - val_mae: 0.3692 - val_mape: 165.8680\n",
      "Epoch 86/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.2483 - mae: 0.3628 - mape: 108.5561 - val_loss: 0.2300 - val_mae: 0.3696 - val_mape: 167.2766\n",
      "Epoch 87/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1990 - mae: 0.3203 - mape: 127.5695 - val_loss: 0.2293 - val_mae: 0.3700 - val_mape: 168.8387\n",
      "Epoch 88/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2098 - mae: 0.3373 - mape: 121.3076 - val_loss: 0.2286 - val_mae: 0.3704 - val_mape: 170.3378\n",
      "Epoch 89/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2106 - mae: 0.3292 - mape: 97.1084 - val_loss: 0.2281 - val_mae: 0.3710 - val_mape: 171.9831\n",
      "Epoch 90/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1969 - mae: 0.3182 - mape: 113.2222 - val_loss: 0.2276 - val_mae: 0.3715 - val_mape: 173.6467\n",
      "Epoch 91/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1866 - mae: 0.3075 - mape: 111.8058 - val_loss: 0.2273 - val_mae: 0.3721 - val_mape: 175.2754\n",
      "Epoch 92/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1790 - mae: 0.3100 - mape: 155.5897 - val_loss: 0.2269 - val_mae: 0.3726 - val_mape: 176.9522\n",
      "Epoch 93/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1895 - mae: 0.3263 - mape: 125.6307 - val_loss: 0.2266 - val_mae: 0.3733 - val_mape: 178.6465\n",
      "Epoch 94/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2147 - mae: 0.3451 - mape: 196.8144 - val_loss: 0.2259 - val_mae: 0.3738 - val_mape: 180.2874\n",
      "Epoch 95/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2331 - mae: 0.3503 - mape: 165.1227 - val_loss: 0.2251 - val_mae: 0.3741 - val_mape: 181.7708\n",
      "Epoch 96/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1781 - mae: 0.2862 - mape: 88.1694 - val_loss: 0.2244 - val_mae: 0.3744 - val_mape: 183.2052\n",
      "Epoch 97/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1894 - mae: 0.3110 - mape: 102.0617 - val_loss: 0.2238 - val_mae: 0.3748 - val_mape: 184.5715\n",
      "Epoch 98/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1925 - mae: 0.3320 - mape: 122.4594 - val_loss: 0.2231 - val_mae: 0.3750 - val_mape: 185.8398\n",
      "Epoch 99/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2112 - mae: 0.3505 - mape: 141.0889 - val_loss: 0.2222 - val_mae: 0.3751 - val_mape: 186.9392\n",
      "Epoch 100/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2222 - mae: 0.3260 - mape: 113.5900 - val_loss: 0.2213 - val_mae: 0.3750 - val_mape: 187.8501\n",
      "Epoch 101/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2023 - mae: 0.3253 - mape: 96.9277 - val_loss: 0.2202 - val_mae: 0.3747 - val_mape: 188.6636\n",
      "Epoch 102/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2087 - mae: 0.3464 - mape: 122.5848 - val_loss: 0.2189 - val_mae: 0.3745 - val_mape: 189.6478\n",
      "Epoch 103/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2104 - mae: 0.3192 - mape: 111.2525 - val_loss: 0.2178 - val_mae: 0.3743 - val_mape: 190.9104\n",
      "Epoch 104/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1647 - mae: 0.2919 - mape: 96.8645 - val_loss: 0.2167 - val_mae: 0.3741 - val_mape: 192.1297\n",
      "Epoch 105/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1995 - mae: 0.3187 - mape: 100.7146 - val_loss: 0.2153 - val_mae: 0.3737 - val_mape: 193.3209\n",
      "Epoch 106/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1848 - mae: 0.3056 - mape: 101.5714 - val_loss: 0.2139 - val_mae: 0.3732 - val_mape: 194.4290\n",
      "Epoch 107/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2016 - mae: 0.3245 - mape: 110.8645 - val_loss: 0.2126 - val_mae: 0.3727 - val_mape: 195.3433\n",
      "Epoch 108/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1910 - mae: 0.3245 - mape: 141.8785 - val_loss: 0.2111 - val_mae: 0.3722 - val_mape: 196.4244\n",
      "Epoch 109/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1881 - mae: 0.3007 - mape: 106.6012 - val_loss: 0.2097 - val_mae: 0.3717 - val_mape: 197.4250\n",
      "Epoch 110/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1911 - mae: 0.3232 - mape: 150.0828 - val_loss: 0.2083 - val_mae: 0.3711 - val_mape: 198.1790\n",
      "Epoch 111/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1580 - mae: 0.2974 - mape: 137.5336 - val_loss: 0.2070 - val_mae: 0.3705 - val_mape: 198.9097\n",
      "Epoch 112/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2473 - mae: 0.3530 - mape: 189.9020 - val_loss: 0.2059 - val_mae: 0.3701 - val_mape: 199.5014\n",
      "Epoch 113/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.1650 - mae: 0.2892 - mape: 110.1392 - val_loss: 0.2048 - val_mae: 0.3697 - val_mape: 200.0292\n",
      "Epoch 114/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1653 - mae: 0.2924 - mape: 117.3623 - val_loss: 0.2038 - val_mae: 0.3693 - val_mape: 200.6650\n",
      "Epoch 115/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1841 - mae: 0.3182 - mape: 113.3917 - val_loss: 0.2028 - val_mae: 0.3691 - val_mape: 201.4388\n",
      "Epoch 116/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.2019 - mae: 0.3223 - mape: 112.5139 - val_loss: 0.2020 - val_mae: 0.3689 - val_mape: 202.3157\n",
      "Epoch 117/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1618 - mae: 0.3171 - mape: 118.8392 - val_loss: 0.2011 - val_mae: 0.3687 - val_mape: 203.1310\n",
      "Epoch 118/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2635 - mae: 0.3817 - mape: 181.7154 - val_loss: 0.2004 - val_mae: 0.3686 - val_mape: 203.7722\n",
      "Epoch 119/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1790 - mae: 0.3073 - mape: 132.1437 - val_loss: 0.1995 - val_mae: 0.3683 - val_mape: 204.3956\n",
      "Epoch 120/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2009 - mae: 0.3132 - mape: 97.5213 - val_loss: 0.1985 - val_mae: 0.3678 - val_mape: 204.9703\n",
      "Epoch 121/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1802 - mae: 0.3126 - mape: 149.7229 - val_loss: 0.1977 - val_mae: 0.3674 - val_mape: 205.4231\n",
      "Epoch 122/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1767 - mae: 0.2920 - mape: 102.3491 - val_loss: 0.1972 - val_mae: 0.3671 - val_mape: 205.8991\n",
      "Epoch 123/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1699 - mae: 0.2980 - mape: 211.7662 - val_loss: 0.1964 - val_mae: 0.3668 - val_mape: 206.3592\n",
      "Epoch 124/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2177 - mae: 0.3205 - mape: 134.9194 - val_loss: 0.1956 - val_mae: 0.3664 - val_mape: 206.7046\n",
      "Epoch 125/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1599 - mae: 0.3139 - mape: 168.8836 - val_loss: 0.1948 - val_mae: 0.3661 - val_mape: 206.9878\n",
      "Epoch 126/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1641 - mae: 0.3064 - mape: 121.1647 - val_loss: 0.1938 - val_mae: 0.3656 - val_mape: 207.2279\n",
      "Epoch 127/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2010 - mae: 0.3464 - mape: 153.6250 - val_loss: 0.1927 - val_mae: 0.3650 - val_mape: 207.2920\n",
      "Epoch 128/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1986 - mae: 0.3424 - mape: 170.3751 - val_loss: 0.1915 - val_mae: 0.3642 - val_mape: 207.1649\n",
      "Epoch 129/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2071 - mae: 0.3410 - mape: 147.4356 - val_loss: 0.1902 - val_mae: 0.3633 - val_mape: 206.9007\n",
      "Epoch 130/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1744 - mae: 0.2805 - mape: 147.2811 - val_loss: 0.1891 - val_mae: 0.3625 - val_mape: 206.5855\n",
      "Epoch 131/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.2329 - mae: 0.3484 - mape: 130.1217 - val_loss: 0.1882 - val_mae: 0.3619 - val_mape: 206.1898\n",
      "Epoch 132/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1380 - mae: 0.2638 - mape: 101.0894 - val_loss: 0.1878 - val_mae: 0.3616 - val_mape: 205.9120\n",
      "Epoch 133/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2133 - mae: 0.3240 - mape: 112.6915 - val_loss: 0.1867 - val_mae: 0.3611 - val_mape: 206.0731\n",
      "Epoch 134/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1469 - mae: 0.2689 - mape: 97.6061 - val_loss: 0.1859 - val_mae: 0.3607 - val_mape: 206.2465\n",
      "Epoch 135/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1776 - mae: 0.3110 - mape: 135.3491 - val_loss: 0.1849 - val_mae: 0.3600 - val_mape: 206.2016\n",
      "Epoch 136/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2407 - mae: 0.3534 - mape: 124.7396 - val_loss: 0.1839 - val_mae: 0.3593 - val_mape: 206.1918\n",
      "Epoch 137/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1416 - mae: 0.2763 - mape: 114.0054 - val_loss: 0.1830 - val_mae: 0.3586 - val_mape: 206.2381\n",
      "Epoch 138/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1872 - mae: 0.3086 - mape: 120.6417 - val_loss: 0.1816 - val_mae: 0.3577 - val_mape: 206.3073\n",
      "Epoch 139/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1280 - mae: 0.2641 - mape: 114.9632 - val_loss: 0.1804 - val_mae: 0.3568 - val_mape: 206.2898\n",
      "Epoch 140/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1535 - mae: 0.2828 - mape: 135.0113 - val_loss: 0.1793 - val_mae: 0.3559 - val_mape: 206.1992\n",
      "Epoch 141/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1193 - mae: 0.2497 - mape: 89.4408 - val_loss: 0.1785 - val_mae: 0.3554 - val_mape: 206.3661\n",
      "Epoch 142/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1420 - mae: 0.2956 - mape: 135.6614 - val_loss: 0.1775 - val_mae: 0.3547 - val_mape: 206.4440\n",
      "Epoch 143/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1399 - mae: 0.2633 - mape: 114.0647 - val_loss: 0.1766 - val_mae: 0.3541 - val_mape: 206.5174\n",
      "Epoch 144/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1660 - mae: 0.3068 - mape: 166.0328 - val_loss: 0.1754 - val_mae: 0.3534 - val_mape: 206.4692\n",
      "Epoch 145/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1996 - mae: 0.3025 - mape: 112.7005 - val_loss: 0.1739 - val_mae: 0.3525 - val_mape: 206.3880\n",
      "Epoch 146/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.1263 - mae: 0.2701 - mape: 140.5483 - val_loss: 0.1725 - val_mae: 0.3517 - val_mape: 206.3467\n",
      "Epoch 147/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1659 - mae: 0.2990 - mape: 141.7885 - val_loss: 0.1713 - val_mae: 0.3512 - val_mape: 206.3305\n",
      "Epoch 148/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.2125 - mae: 0.3258 - mape: 107.9076 - val_loss: 0.1703 - val_mae: 0.3506 - val_mape: 206.1487\n",
      "Epoch 149/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1779 - mae: 0.3001 - mape: 158.4834 - val_loss: 0.1689 - val_mae: 0.3497 - val_mape: 205.6887\n",
      "Epoch 150/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1453 - mae: 0.3015 - mape: 128.8428 - val_loss: 0.1675 - val_mae: 0.3487 - val_mape: 205.2203\n",
      "Epoch 151/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1912 - mae: 0.3370 - mape: 204.2083 - val_loss: 0.1660 - val_mae: 0.3477 - val_mape: 204.7684\n",
      "Epoch 152/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1568 - mae: 0.3039 - mape: 159.7195 - val_loss: 0.1646 - val_mae: 0.3466 - val_mape: 204.4061\n",
      "Epoch 153/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.2101 - mae: 0.3408 - mape: 160.3179 - val_loss: 0.1633 - val_mae: 0.3457 - val_mape: 203.9955\n",
      "Epoch 154/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1646 - mae: 0.2898 - mape: 120.4684 - val_loss: 0.1619 - val_mae: 0.3447 - val_mape: 203.4922\n",
      "Epoch 155/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1309 - mae: 0.2606 - mape: 102.3870 - val_loss: 0.1606 - val_mae: 0.3438 - val_mape: 203.0142\n",
      "Epoch 156/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1292 - mae: 0.2688 - mape: 108.1446 - val_loss: 0.1594 - val_mae: 0.3430 - val_mape: 202.7670\n",
      "Epoch 157/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2033 - mae: 0.3149 - mape: 132.8735 - val_loss: 0.1580 - val_mae: 0.3419 - val_mape: 202.2281\n",
      "Epoch 158/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1723 - mae: 0.2851 - mape: 135.7071 - val_loss: 0.1565 - val_mae: 0.3405 - val_mape: 201.6759\n",
      "Epoch 159/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1305 - mae: 0.2855 - mape: 149.4948 - val_loss: 0.1551 - val_mae: 0.3391 - val_mape: 201.2705\n",
      "Epoch 160/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.1497 - mae: 0.2849 - mape: 127.3495 - val_loss: 0.1535 - val_mae: 0.3376 - val_mape: 200.8188\n",
      "Epoch 161/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1756 - mae: 0.3138 - mape: 117.3573 - val_loss: 0.1520 - val_mae: 0.3363 - val_mape: 200.4654\n",
      "Epoch 162/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2012 - mae: 0.3119 - mape: 117.5435 - val_loss: 0.1502 - val_mae: 0.3345 - val_mape: 199.9496\n",
      "Epoch 163/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1829 - mae: 0.2988 - mape: 116.6447 - val_loss: 0.1489 - val_mae: 0.3332 - val_mape: 199.6388\n",
      "Epoch 164/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1454 - mae: 0.2874 - mape: 132.7794 - val_loss: 0.1476 - val_mae: 0.3318 - val_mape: 199.1956\n",
      "Epoch 165/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1266 - mae: 0.2718 - mape: 134.4265 - val_loss: 0.1462 - val_mae: 0.3302 - val_mape: 198.6945\n",
      "Epoch 166/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1942 - mae: 0.3395 - mape: 176.0101 - val_loss: 0.1448 - val_mae: 0.3288 - val_mape: 198.1410\n",
      "Epoch 167/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2049 - mae: 0.3152 - mape: 107.8161 - val_loss: 0.1432 - val_mae: 0.3271 - val_mape: 197.4627\n",
      "Epoch 168/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1253 - mae: 0.2495 - mape: 95.4543 - val_loss: 0.1415 - val_mae: 0.3252 - val_mape: 196.7450\n",
      "Epoch 169/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0967 - mae: 0.2393 - mape: 98.1901 - val_loss: 0.1399 - val_mae: 0.3234 - val_mape: 196.0477\n",
      "Epoch 170/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1650 - mae: 0.3106 - mape: 128.3035 - val_loss: 0.1383 - val_mae: 0.3216 - val_mape: 195.3386\n",
      "Epoch 171/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1450 - mae: 0.2733 - mape: 95.3168 - val_loss: 0.1367 - val_mae: 0.3198 - val_mape: 194.7260\n",
      "Epoch 172/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.2599 - mae: 0.3876 - mape: 139.1574 - val_loss: 0.1351 - val_mae: 0.3179 - val_mape: 193.9340\n",
      "Epoch 173/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1276 - mae: 0.2684 - mape: 94.7889 - val_loss: 0.1335 - val_mae: 0.3160 - val_mape: 193.3492\n",
      "Epoch 174/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1716 - mae: 0.3021 - mape: 153.7759 - val_loss: 0.1320 - val_mae: 0.3143 - val_mape: 192.7811\n",
      "Epoch 175/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1775 - mae: 0.2979 - mape: 135.8393 - val_loss: 0.1308 - val_mae: 0.3129 - val_mape: 192.2407\n",
      "Epoch 176/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1301 - mae: 0.2804 - mape: 140.6175 - val_loss: 0.1297 - val_mae: 0.3116 - val_mape: 191.8283\n",
      "Epoch 177/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1030 - mae: 0.2511 - mape: 146.7922 - val_loss: 0.1287 - val_mae: 0.3105 - val_mape: 191.4822\n",
      "Epoch 178/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1526 - mae: 0.2882 - mape: 126.1582 - val_loss: 0.1275 - val_mae: 0.3091 - val_mape: 190.9098\n",
      "Epoch 179/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1454 - mae: 0.2815 - mape: 123.9838 - val_loss: 0.1262 - val_mae: 0.3075 - val_mape: 190.1739\n",
      "Epoch 180/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2029 - mae: 0.3429 - mape: 181.6237 - val_loss: 0.1250 - val_mae: 0.3062 - val_mape: 189.6197\n",
      "Epoch 181/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1410 - mae: 0.2948 - mape: 145.0859 - val_loss: 0.1238 - val_mae: 0.3048 - val_mape: 189.0198\n",
      "Epoch 182/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1086 - mae: 0.2364 - mape: 105.6295 - val_loss: 0.1229 - val_mae: 0.3037 - val_mape: 188.3995\n",
      "Epoch 183/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1268 - mae: 0.2724 - mape: 101.7000 - val_loss: 0.1219 - val_mae: 0.3025 - val_mape: 187.9667\n",
      "Epoch 184/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0983 - mae: 0.2381 - mape: 162.3440 - val_loss: 0.1214 - val_mae: 0.3018 - val_mape: 187.6843\n",
      "Epoch 185/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1131 - mae: 0.2405 - mape: 97.3522 - val_loss: 0.1209 - val_mae: 0.3011 - val_mape: 187.3825\n",
      "Epoch 186/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1233 - mae: 0.2769 - mape: 134.6881 - val_loss: 0.1204 - val_mae: 0.3003 - val_mape: 187.1489\n",
      "Epoch 187/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1217 - mae: 0.2621 - mape: 118.9462 - val_loss: 0.1195 - val_mae: 0.2992 - val_mape: 186.8524\n",
      "Epoch 188/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1423 - mae: 0.2740 - mape: 149.3759 - val_loss: 0.1189 - val_mae: 0.2985 - val_mape: 186.6693\n",
      "Epoch 189/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1950 - mae: 0.3285 - mape: 176.8578 - val_loss: 0.1183 - val_mae: 0.2976 - val_mape: 186.2383\n",
      "Epoch 190/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1016 - mae: 0.2446 - mape: 150.8640 - val_loss: 0.1176 - val_mae: 0.2967 - val_mape: 185.8977\n",
      "Epoch 191/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1492 - mae: 0.2731 - mape: 123.0729 - val_loss: 0.1169 - val_mae: 0.2958 - val_mape: 185.5529\n",
      "Epoch 192/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1204 - mae: 0.2475 - mape: 110.6746 - val_loss: 0.1161 - val_mae: 0.2946 - val_mape: 185.1143\n",
      "Epoch 193/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1880 - mae: 0.3088 - mape: 140.2883 - val_loss: 0.1153 - val_mae: 0.2933 - val_mape: 184.4082\n",
      "Epoch 194/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1039 - mae: 0.2271 - mape: 99.1529 - val_loss: 0.1144 - val_mae: 0.2919 - val_mape: 183.6991\n",
      "Epoch 195/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1203 - mae: 0.2637 - mape: 144.1328 - val_loss: 0.1137 - val_mae: 0.2906 - val_mape: 182.9246\n",
      "Epoch 196/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1216 - mae: 0.2642 - mape: 169.0196 - val_loss: 0.1130 - val_mae: 0.2893 - val_mape: 182.1956\n",
      "Epoch 197/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1529 - mae: 0.2888 - mape: 183.9610 - val_loss: 0.1123 - val_mae: 0.2881 - val_mape: 181.2657\n",
      "Epoch 198/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1383 - mae: 0.2860 - mape: 124.2579 - val_loss: 0.1117 - val_mae: 0.2870 - val_mape: 180.6000\n",
      "Epoch 199/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1806 - mae: 0.3068 - mape: 165.1133 - val_loss: 0.1109 - val_mae: 0.2856 - val_mape: 179.7343\n",
      "Epoch 200/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1064 - mae: 0.2542 - mape: 145.2216 - val_loss: 0.1102 - val_mae: 0.2844 - val_mape: 178.8666\n",
      "Epoch 201/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1055 - mae: 0.2341 - mape: 141.9277 - val_loss: 0.1098 - val_mae: 0.2838 - val_mape: 178.2648\n",
      "Epoch 202/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2222 - mae: 0.3462 - mape: 154.3934 - val_loss: 0.1092 - val_mae: 0.2829 - val_mape: 177.5548\n",
      "Epoch 203/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1164 - mae: 0.2645 - mape: 107.9060 - val_loss: 0.1085 - val_mae: 0.2818 - val_mape: 176.8543\n",
      "Epoch 204/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1259 - mae: 0.2367 - mape: 102.2989 - val_loss: 0.1078 - val_mae: 0.2808 - val_mape: 176.1390\n",
      "Epoch 205/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1250 - mae: 0.2474 - mape: 122.1317 - val_loss: 0.1070 - val_mae: 0.2797 - val_mape: 175.2995\n",
      "Epoch 206/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1780 - mae: 0.2975 - mape: 165.1830 - val_loss: 0.1064 - val_mae: 0.2788 - val_mape: 174.5228\n",
      "Epoch 207/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1973 - mae: 0.3068 - mape: 131.8515 - val_loss: 0.1056 - val_mae: 0.2776 - val_mape: 173.8008\n",
      "Epoch 208/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1581 - mae: 0.2961 - mape: 121.5264 - val_loss: 0.1046 - val_mae: 0.2764 - val_mape: 173.3186\n",
      "Epoch 209/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1298 - mae: 0.2579 - mape: 129.6844 - val_loss: 0.1038 - val_mae: 0.2753 - val_mape: 172.8848\n",
      "Epoch 210/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1576 - mae: 0.2821 - mape: 158.4488 - val_loss: 0.1029 - val_mae: 0.2742 - val_mape: 172.2674\n",
      "Epoch 211/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1622 - mae: 0.3043 - mape: 168.5154 - val_loss: 0.1016 - val_mae: 0.2724 - val_mape: 171.3617\n",
      "Epoch 212/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1218 - mae: 0.2653 - mape: 182.4081 - val_loss: 0.1004 - val_mae: 0.2709 - val_mape: 170.5416\n",
      "Epoch 213/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1142 - mae: 0.2541 - mape: 158.4022 - val_loss: 0.0992 - val_mae: 0.2694 - val_mape: 169.6517\n",
      "Epoch 214/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1157 - mae: 0.2480 - mape: 142.2885 - val_loss: 0.0985 - val_mae: 0.2685 - val_mape: 169.1583\n",
      "Epoch 215/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1488 - mae: 0.2794 - mape: 154.0692 - val_loss: 0.0980 - val_mae: 0.2681 - val_mape: 168.7701\n",
      "Epoch 216/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1742 - mae: 0.2872 - mape: 132.1159 - val_loss: 0.0974 - val_mae: 0.2676 - val_mape: 168.2864\n",
      "Epoch 217/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1475 - mae: 0.2773 - mape: 145.8607 - val_loss: 0.0969 - val_mae: 0.2670 - val_mape: 167.7487\n",
      "Epoch 218/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1592 - mae: 0.2830 - mape: 131.4941 - val_loss: 0.0962 - val_mae: 0.2661 - val_mape: 166.9321\n",
      "Epoch 219/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1674 - mae: 0.2847 - mape: 112.6857 - val_loss: 0.0954 - val_mae: 0.2650 - val_mape: 166.0728\n",
      "Epoch 220/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1974 - mae: 0.3243 - mape: 162.6659 - val_loss: 0.0945 - val_mae: 0.2638 - val_mape: 164.8651\n",
      "Epoch 221/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1703 - mae: 0.2738 - mape: 133.1986 - val_loss: 0.0936 - val_mae: 0.2625 - val_mape: 163.5592\n",
      "Epoch 222/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1281 - mae: 0.2754 - mape: 176.4529 - val_loss: 0.0927 - val_mae: 0.2612 - val_mape: 162.4083\n",
      "Epoch 223/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1736 - mae: 0.2812 - mape: 135.2198 - val_loss: 0.0916 - val_mae: 0.2597 - val_mape: 161.0143\n",
      "Epoch 224/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1304 - mae: 0.2723 - mape: 149.9520 - val_loss: 0.0906 - val_mae: 0.2582 - val_mape: 159.7798\n",
      "Epoch 225/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1228 - mae: 0.2643 - mape: 153.3444 - val_loss: 0.0898 - val_mae: 0.2572 - val_mape: 158.6514\n",
      "Epoch 226/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1185 - mae: 0.2266 - mape: 103.3143 - val_loss: 0.0891 - val_mae: 0.2561 - val_mape: 157.6281\n",
      "Epoch 227/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1171 - mae: 0.2468 - mape: 144.0162 - val_loss: 0.0884 - val_mae: 0.2551 - val_mape: 156.7455\n",
      "Epoch 228/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1830 - mae: 0.3224 - mape: 146.7317 - val_loss: 0.0875 - val_mae: 0.2540 - val_mape: 156.1865\n",
      "Epoch 229/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1027 - mae: 0.2391 - mape: 143.5698 - val_loss: 0.0870 - val_mae: 0.2533 - val_mape: 155.7311\n",
      "Epoch 230/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1386 - mae: 0.2764 - mape: 145.2274 - val_loss: 0.0863 - val_mae: 0.2523 - val_mape: 155.0222\n",
      "Epoch 231/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1209 - mae: 0.2523 - mape: 147.7351 - val_loss: 0.0857 - val_mae: 0.2515 - val_mape: 154.3032\n",
      "Epoch 232/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1257 - mae: 0.2454 - mape: 114.9938 - val_loss: 0.0851 - val_mae: 0.2504 - val_mape: 153.5139\n",
      "Epoch 233/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1142 - mae: 0.2445 - mape: 107.2405 - val_loss: 0.0847 - val_mae: 0.2497 - val_mape: 152.8587\n",
      "Epoch 234/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1575 - mae: 0.2958 - mape: 137.0301 - val_loss: 0.0843 - val_mae: 0.2490 - val_mape: 152.1864\n",
      "Epoch 235/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.1175 - mae: 0.2802 - mape: 181.9410 - val_loss: 0.0840 - val_mae: 0.2484 - val_mape: 151.5923\n",
      "Epoch 236/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1516 - mae: 0.2837 - mape: 149.8295 - val_loss: 0.0835 - val_mae: 0.2476 - val_mape: 150.8666\n",
      "Epoch 237/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1316 - mae: 0.2709 - mape: 165.9389 - val_loss: 0.0832 - val_mae: 0.2471 - val_mape: 150.3187\n",
      "Epoch 238/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1966 - mae: 0.3086 - mape: 156.8901 - val_loss: 0.0831 - val_mae: 0.2470 - val_mape: 149.8060\n",
      "Epoch 239/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1129 - mae: 0.2566 - mape: 169.3043 - val_loss: 0.0829 - val_mae: 0.2468 - val_mape: 149.3822\n",
      "Epoch 240/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1282 - mae: 0.2842 - mape: 156.3537 - val_loss: 0.0825 - val_mae: 0.2463 - val_mape: 149.0575\n",
      "Epoch 241/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0810 - mae: 0.2203 - mape: 139.5888 - val_loss: 0.0823 - val_mae: 0.2460 - val_mape: 148.7840\n",
      "Epoch 242/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1636 - mae: 0.2757 - mape: 114.1252 - val_loss: 0.0823 - val_mae: 0.2461 - val_mape: 148.6574\n",
      "Epoch 243/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1134 - mae: 0.2427 - mape: 113.9031 - val_loss: 0.0822 - val_mae: 0.2460 - val_mape: 148.4899\n",
      "Epoch 244/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1544 - mae: 0.2708 - mape: 156.2798 - val_loss: 0.0817 - val_mae: 0.2451 - val_mape: 147.9882\n",
      "Epoch 245/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1564 - mae: 0.2762 - mape: 136.8270 - val_loss: 0.0810 - val_mae: 0.2440 - val_mape: 147.3504\n",
      "Epoch 246/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1084 - mae: 0.2350 - mape: 128.0069 - val_loss: 0.0805 - val_mae: 0.2432 - val_mape: 146.7682\n",
      "Epoch 247/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1434 - mae: 0.2731 - mape: 126.5098 - val_loss: 0.0799 - val_mae: 0.2422 - val_mape: 146.1820\n",
      "Epoch 248/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1279 - mae: 0.2536 - mape: 104.5346 - val_loss: 0.0793 - val_mae: 0.2412 - val_mape: 145.6779\n",
      "Epoch 249/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1465 - mae: 0.2687 - mape: 146.3169 - val_loss: 0.0787 - val_mae: 0.2401 - val_mape: 145.1360\n",
      "Epoch 250/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1538 - mae: 0.2521 - mape: 123.1323 - val_loss: 0.0780 - val_mae: 0.2390 - val_mape: 144.5362\n",
      "Epoch 251/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1559 - mae: 0.2710 - mape: 166.9491 - val_loss: 0.0772 - val_mae: 0.2376 - val_mape: 143.7617\n",
      "Epoch 252/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1639 - mae: 0.2864 - mape: 137.8884 - val_loss: 0.0764 - val_mae: 0.2360 - val_mape: 142.7500\n",
      "Epoch 253/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1875 - mae: 0.3215 - mape: 212.3055 - val_loss: 0.0756 - val_mae: 0.2345 - val_mape: 141.7249\n",
      "Epoch 254/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1574 - mae: 0.2804 - mape: 169.3299 - val_loss: 0.0748 - val_mae: 0.2328 - val_mape: 140.5899\n",
      "Epoch 255/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1867 - mae: 0.3012 - mape: 115.4656 - val_loss: 0.0740 - val_mae: 0.2312 - val_mape: 139.4544\n",
      "Epoch 256/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1216 - mae: 0.2404 - mape: 151.9205 - val_loss: 0.0734 - val_mae: 0.2300 - val_mape: 138.4509\n",
      "Epoch 257/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0902 - mae: 0.2211 - mape: 105.4489 - val_loss: 0.0729 - val_mae: 0.2288 - val_mape: 137.4012\n",
      "Epoch 258/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1697 - mae: 0.2792 - mape: 119.2670 - val_loss: 0.0722 - val_mae: 0.2273 - val_mape: 136.0705\n",
      "Epoch 259/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0872 - mae: 0.2158 - mape: 134.9785 - val_loss: 0.0715 - val_mae: 0.2257 - val_mape: 134.7271\n",
      "Epoch 260/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1366 - mae: 0.2719 - mape: 169.2588 - val_loss: 0.0709 - val_mae: 0.2242 - val_mape: 133.4441\n",
      "Epoch 261/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1151 - mae: 0.2349 - mape: 158.5363 - val_loss: 0.0702 - val_mae: 0.2228 - val_mape: 132.4438\n",
      "Epoch 262/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1169 - mae: 0.2599 - mape: 145.4532 - val_loss: 0.0695 - val_mae: 0.2212 - val_mape: 131.3675\n",
      "Epoch 263/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1138 - mae: 0.2579 - mape: 168.1197 - val_loss: 0.0688 - val_mae: 0.2197 - val_mape: 130.4166\n",
      "Epoch 264/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1278 - mae: 0.2458 - mape: 104.5536 - val_loss: 0.0683 - val_mae: 0.2185 - val_mape: 129.5651\n",
      "Epoch 265/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1240 - mae: 0.2397 - mape: 143.7663 - val_loss: 0.0677 - val_mae: 0.2174 - val_mape: 128.6925\n",
      "Epoch 266/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.1345 - mae: 0.2441 - mape: 107.6333 - val_loss: 0.0671 - val_mae: 0.2161 - val_mape: 127.6225\n",
      "Epoch 267/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1576 - mae: 0.2908 - mape: 155.4814 - val_loss: 0.0664 - val_mae: 0.2146 - val_mape: 126.5354\n",
      "Epoch 268/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1140 - mae: 0.2321 - mape: 172.7049 - val_loss: 0.0659 - val_mae: 0.2137 - val_mape: 125.8054\n",
      "Epoch 269/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1253 - mae: 0.2522 - mape: 88.4638 - val_loss: 0.0653 - val_mae: 0.2127 - val_mape: 125.1355\n",
      "Epoch 270/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0994 - mae: 0.2331 - mape: 152.8986 - val_loss: 0.0649 - val_mae: 0.2121 - val_mape: 124.6183\n",
      "Epoch 271/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1201 - mae: 0.2531 - mape: 148.7790 - val_loss: 0.0645 - val_mae: 0.2115 - val_mape: 124.1527\n",
      "Epoch 272/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1037 - mae: 0.2315 - mape: 195.5236 - val_loss: 0.0641 - val_mae: 0.2108 - val_mape: 123.7398\n",
      "Epoch 273/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1652 - mae: 0.2816 - mape: 153.4767 - val_loss: 0.0638 - val_mae: 0.2106 - val_mape: 123.4749\n",
      "Epoch 274/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1572 - mae: 0.2517 - mape: 162.7780 - val_loss: 0.0636 - val_mae: 0.2103 - val_mape: 123.0831\n",
      "Epoch 275/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1394 - mae: 0.2802 - mape: 195.5317 - val_loss: 0.0636 - val_mae: 0.2107 - val_mape: 123.0060\n",
      "Epoch 276/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0612 - mae: 0.1807 - mape: 81.0119 - val_loss: 0.0636 - val_mae: 0.2111 - val_mape: 122.9636\n",
      "Epoch 277/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1189 - mae: 0.2324 - mape: 132.9384 - val_loss: 0.0634 - val_mae: 0.2109 - val_mape: 122.7590\n",
      "Epoch 278/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1737 - mae: 0.2782 - mape: 200.5703 - val_loss: 0.0631 - val_mae: 0.2104 - val_mape: 122.2877\n",
      "Epoch 279/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1435 - mae: 0.2490 - mape: 117.8684 - val_loss: 0.0627 - val_mae: 0.2096 - val_mape: 121.7891\n",
      "Epoch 280/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0861 - mae: 0.2062 - mape: 127.7440 - val_loss: 0.0624 - val_mae: 0.2090 - val_mape: 121.2999\n",
      "Epoch 281/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1189 - mae: 0.2320 - mape: 125.4143 - val_loss: 0.0621 - val_mae: 0.2084 - val_mape: 120.8524\n",
      "Epoch 282/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0953 - mae: 0.2294 - mape: 103.2105 - val_loss: 0.0616 - val_mae: 0.2074 - val_mape: 120.3320\n",
      "Epoch 283/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1069 - mae: 0.2420 - mape: 211.7085 - val_loss: 0.0611 - val_mae: 0.2062 - val_mape: 119.7456\n",
      "Epoch 284/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1548 - mae: 0.2763 - mape: 150.6962 - val_loss: 0.0605 - val_mae: 0.2048 - val_mape: 119.0277\n",
      "Epoch 285/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1296 - mae: 0.2526 - mape: 140.8451 - val_loss: 0.0599 - val_mae: 0.2035 - val_mape: 118.3167\n",
      "Epoch 286/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1371 - mae: 0.2577 - mape: 165.8384 - val_loss: 0.0595 - val_mae: 0.2024 - val_mape: 117.6915\n",
      "Epoch 287/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.1821 - mae: 0.2947 - mape: 186.5882 - val_loss: 0.0591 - val_mae: 0.2016 - val_mape: 117.1716\n",
      "Epoch 288/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1801 - mae: 0.2939 - mape: 163.3866 - val_loss: 0.0586 - val_mae: 0.2004 - val_mape: 116.4704\n",
      "Epoch 289/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1130 - mae: 0.2414 - mape: 118.4040 - val_loss: 0.0582 - val_mae: 0.1991 - val_mape: 115.6719\n",
      "Epoch 290/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1237 - mae: 0.2309 - mape: 112.3949 - val_loss: 0.0579 - val_mae: 0.1984 - val_mape: 115.0473\n",
      "Epoch 291/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0854 - mae: 0.2049 - mape: 110.1203 - val_loss: 0.0577 - val_mae: 0.1977 - val_mape: 114.4355\n",
      "Epoch 292/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.1502 - mae: 0.2431 - mape: 148.9353 - val_loss: 0.0575 - val_mae: 0.1972 - val_mape: 113.9038\n",
      "Epoch 293/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1835 - mae: 0.2958 - mape: 152.6064 - val_loss: 0.0571 - val_mae: 0.1961 - val_mape: 113.1453\n",
      "Epoch 294/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1948 - mae: 0.2812 - mape: 131.6948 - val_loss: 0.0566 - val_mae: 0.1950 - val_mape: 112.4355\n",
      "Epoch 295/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1558 - mae: 0.2842 - mape: 126.8281 - val_loss: 0.0559 - val_mae: 0.1933 - val_mape: 111.6377\n",
      "Epoch 296/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1040 - mae: 0.2252 - mape: 150.2678 - val_loss: 0.0553 - val_mae: 0.1918 - val_mape: 110.8527\n",
      "Epoch 297/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1639 - mae: 0.2755 - mape: 141.5989 - val_loss: 0.0546 - val_mae: 0.1899 - val_mape: 109.8399\n",
      "Epoch 298/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0852 - mae: 0.2120 - mape: 154.6845 - val_loss: 0.0539 - val_mae: 0.1882 - val_mape: 108.8700\n",
      "Epoch 299/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0815 - mae: 0.1989 - mape: 87.1233 - val_loss: 0.0534 - val_mae: 0.1872 - val_mape: 108.3489\n",
      "Epoch 300/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1067 - mae: 0.2211 - mape: 138.1308 - val_loss: 0.0529 - val_mae: 0.1865 - val_mape: 107.9989\n",
      "Epoch 301/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1645 - mae: 0.2980 - mape: 132.4450 - val_loss: 0.0523 - val_mae: 0.1853 - val_mape: 107.5005\n",
      "Epoch 302/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0730 - mae: 0.1858 - mape: 108.1609 - val_loss: 0.0516 - val_mae: 0.1841 - val_mape: 107.1112\n",
      "Epoch 303/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1420 - mae: 0.2444 - mape: 161.4444 - val_loss: 0.0510 - val_mae: 0.1827 - val_mape: 106.4824\n",
      "Epoch 304/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1195 - mae: 0.2531 - mape: 166.4503 - val_loss: 0.0504 - val_mae: 0.1815 - val_mape: 106.0835\n",
      "Epoch 305/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1862 - mae: 0.2713 - mape: 182.3704 - val_loss: 0.0500 - val_mae: 0.1806 - val_mape: 105.5572\n",
      "Epoch 306/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1132 - mae: 0.2522 - mape: 137.9203 - val_loss: 0.0496 - val_mae: 0.1799 - val_mape: 105.4922\n",
      "Epoch 307/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0976 - mae: 0.2251 - mape: 112.5856 - val_loss: 0.0492 - val_mae: 0.1790 - val_mape: 105.3125\n",
      "Epoch 308/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0842 - mae: 0.2106 - mape: 94.3234 - val_loss: 0.0487 - val_mae: 0.1781 - val_mape: 104.9829\n",
      "Epoch 309/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1710 - mae: 0.2914 - mape: 201.3247 - val_loss: 0.0484 - val_mae: 0.1773 - val_mape: 104.5669\n",
      "Epoch 310/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1507 - mae: 0.2707 - mape: 114.6653 - val_loss: 0.0482 - val_mae: 0.1772 - val_mape: 104.3226\n",
      "Epoch 311/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1071 - mae: 0.2353 - mape: 181.3538 - val_loss: 0.0480 - val_mae: 0.1771 - val_mape: 103.8719\n",
      "Epoch 312/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1089 - mae: 0.2395 - mape: 124.1068 - val_loss: 0.0478 - val_mae: 0.1767 - val_mape: 103.2836\n",
      "Epoch 313/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1471 - mae: 0.2839 - mape: 164.1172 - val_loss: 0.0475 - val_mae: 0.1762 - val_mape: 102.6901\n",
      "Epoch 314/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1370 - mae: 0.2487 - mape: 124.5734 - val_loss: 0.0471 - val_mae: 0.1753 - val_mape: 101.8383\n",
      "Epoch 315/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1136 - mae: 0.2473 - mape: 120.1973 - val_loss: 0.0467 - val_mae: 0.1741 - val_mape: 100.9358\n",
      "Epoch 316/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1368 - mae: 0.2565 - mape: 164.4833 - val_loss: 0.0464 - val_mae: 0.1731 - val_mape: 100.0008\n",
      "Epoch 317/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1368 - mae: 0.2701 - mape: 171.4525 - val_loss: 0.0459 - val_mae: 0.1717 - val_mape: 99.0030\n",
      "Epoch 318/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1584 - mae: 0.2995 - mape: 136.5243 - val_loss: 0.0453 - val_mae: 0.1700 - val_mape: 98.3159\n",
      "Epoch 319/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1504 - mae: 0.2490 - mape: 99.8911 - val_loss: 0.0449 - val_mae: 0.1691 - val_mape: 98.0932\n",
      "Epoch 320/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0987 - mae: 0.2275 - mape: 157.7747 - val_loss: 0.0445 - val_mae: 0.1683 - val_mape: 97.8315\n",
      "Epoch 321/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0917 - mae: 0.2331 - mape: 193.6367 - val_loss: 0.0441 - val_mae: 0.1677 - val_mape: 97.5790\n",
      "Epoch 322/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1643 - mae: 0.2871 - mape: 158.8826 - val_loss: 0.0437 - val_mae: 0.1669 - val_mape: 97.1714\n",
      "Epoch 323/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1588 - mae: 0.2472 - mape: 132.3139 - val_loss: 0.0433 - val_mae: 0.1662 - val_mape: 96.9155\n",
      "Epoch 324/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1188 - mae: 0.2344 - mape: 169.0766 - val_loss: 0.0429 - val_mae: 0.1654 - val_mape: 96.6723\n",
      "Epoch 325/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0916 - mae: 0.1907 - mape: 152.4441 - val_loss: 0.0425 - val_mae: 0.1649 - val_mape: 96.3743\n",
      "Epoch 326/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1005 - mae: 0.2337 - mape: 104.3526 - val_loss: 0.0421 - val_mae: 0.1644 - val_mape: 96.0630\n",
      "Epoch 327/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1246 - mae: 0.2453 - mape: 182.0240 - val_loss: 0.0418 - val_mae: 0.1637 - val_mape: 95.8143\n",
      "Epoch 328/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1400 - mae: 0.2483 - mape: 127.9342 - val_loss: 0.0415 - val_mae: 0.1630 - val_mape: 95.6199\n",
      "Epoch 329/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0926 - mae: 0.2166 - mape: 162.6891 - val_loss: 0.0411 - val_mae: 0.1623 - val_mape: 95.1671\n",
      "Epoch 330/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1437 - mae: 0.2512 - mape: 149.7797 - val_loss: 0.0408 - val_mae: 0.1616 - val_mape: 94.8252\n",
      "Epoch 331/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0835 - mae: 0.1956 - mape: 152.7823 - val_loss: 0.0404 - val_mae: 0.1610 - val_mape: 94.2395\n",
      "Epoch 332/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1304 - mae: 0.2544 - mape: 156.4512 - val_loss: 0.0401 - val_mae: 0.1604 - val_mape: 93.6675\n",
      "Epoch 333/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1047 - mae: 0.2501 - mape: 192.7870 - val_loss: 0.0398 - val_mae: 0.1601 - val_mape: 93.2558\n",
      "Epoch 334/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1563 - mae: 0.2806 - mape: 209.9313 - val_loss: 0.0396 - val_mae: 0.1600 - val_mape: 92.7719\n",
      "Epoch 335/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0964 - mae: 0.2281 - mape: 101.0450 - val_loss: 0.0393 - val_mae: 0.1597 - val_mape: 92.5124\n",
      "Epoch 336/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1578 - mae: 0.2664 - mape: 97.9559 - val_loss: 0.0390 - val_mae: 0.1593 - val_mape: 92.5854\n",
      "Epoch 337/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1146 - mae: 0.2500 - mape: 159.2989 - val_loss: 0.0387 - val_mae: 0.1590 - val_mape: 92.5614\n",
      "Epoch 338/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1370 - mae: 0.2412 - mape: 120.5746 - val_loss: 0.0384 - val_mae: 0.1587 - val_mape: 92.4234\n",
      "Epoch 339/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0784 - mae: 0.2009 - mape: 155.9682 - val_loss: 0.0381 - val_mae: 0.1584 - val_mape: 92.1487\n",
      "Epoch 340/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1302 - mae: 0.2586 - mape: 115.4153 - val_loss: 0.0377 - val_mae: 0.1578 - val_mape: 91.8491\n",
      "Epoch 341/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1019 - mae: 0.2338 - mape: 180.9668 - val_loss: 0.0374 - val_mae: 0.1576 - val_mape: 91.7940\n",
      "Epoch 342/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0953 - mae: 0.2088 - mape: 165.5213 - val_loss: 0.0371 - val_mae: 0.1574 - val_mape: 91.5528\n",
      "Epoch 343/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1204 - mae: 0.2481 - mape: 190.9347 - val_loss: 0.0369 - val_mae: 0.1571 - val_mape: 91.3234\n",
      "Epoch 344/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1326 - mae: 0.2615 - mape: 157.5133 - val_loss: 0.0365 - val_mae: 0.1567 - val_mape: 90.8826\n",
      "Epoch 345/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1352 - mae: 0.2613 - mape: 180.4572 - val_loss: 0.0363 - val_mae: 0.1565 - val_mape: 90.6924\n",
      "Epoch 346/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0991 - mae: 0.2356 - mape: 173.3211 - val_loss: 0.0361 - val_mae: 0.1562 - val_mape: 90.3290\n",
      "Epoch 347/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1053 - mae: 0.2156 - mape: 109.3116 - val_loss: 0.0359 - val_mae: 0.1557 - val_mape: 89.7876\n",
      "Epoch 348/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1106 - mae: 0.2438 - mape: 115.3437 - val_loss: 0.0356 - val_mae: 0.1551 - val_mape: 89.2619\n",
      "Epoch 349/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1350 - mae: 0.2811 - mape: 202.6027 - val_loss: 0.0353 - val_mae: 0.1545 - val_mape: 88.7085\n",
      "Epoch 350/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1622 - mae: 0.3079 - mape: 176.9135 - val_loss: 0.0350 - val_mae: 0.1540 - val_mape: 88.4335\n",
      "Epoch 351/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1093 - mae: 0.2437 - mape: 160.8767 - val_loss: 0.0349 - val_mae: 0.1539 - val_mape: 88.5231\n",
      "Epoch 352/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0987 - mae: 0.2327 - mape: 170.5443 - val_loss: 0.0347 - val_mae: 0.1538 - val_mape: 88.3923\n",
      "Epoch 353/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1166 - mae: 0.2401 - mape: 161.7893 - val_loss: 0.0345 - val_mae: 0.1534 - val_mape: 88.2737\n",
      "Epoch 354/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2005 - mae: 0.2783 - mape: 89.9329 - val_loss: 0.0344 - val_mae: 0.1533 - val_mape: 88.2580\n",
      "Epoch 355/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1294 - mae: 0.2324 - mape: 152.6088 - val_loss: 0.0342 - val_mae: 0.1531 - val_mape: 88.3228\n",
      "Epoch 356/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1051 - mae: 0.2184 - mape: 181.0124 - val_loss: 0.0342 - val_mae: 0.1532 - val_mape: 88.4419\n",
      "Epoch 357/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1393 - mae: 0.2919 - mape: 215.7373 - val_loss: 0.0342 - val_mae: 0.1533 - val_mape: 88.5697\n",
      "Epoch 358/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1126 - mae: 0.2533 - mape: 215.0423 - val_loss: 0.0342 - val_mae: 0.1533 - val_mape: 88.5982\n",
      "Epoch 359/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1261 - mae: 0.2579 - mape: 166.8222 - val_loss: 0.0340 - val_mae: 0.1532 - val_mape: 88.7544\n",
      "Epoch 360/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1725 - mae: 0.2981 - mape: 110.9769 - val_loss: 0.0338 - val_mae: 0.1528 - val_mape: 88.8530\n",
      "Epoch 361/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0676 - mae: 0.1863 - mape: 157.4467 - val_loss: 0.0337 - val_mae: 0.1525 - val_mape: 88.7285\n",
      "Epoch 362/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0788 - mae: 0.1934 - mape: 91.1399 - val_loss: 0.0334 - val_mae: 0.1519 - val_mape: 88.3227\n",
      "Epoch 363/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1271 - mae: 0.2621 - mape: 126.9935 - val_loss: 0.0333 - val_mae: 0.1514 - val_mape: 87.8742\n",
      "Epoch 364/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.2249 - mae: 0.3246 - mape: 178.1158 - val_loss: 0.0331 - val_mae: 0.1510 - val_mape: 87.5047\n",
      "Epoch 365/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1353 - mae: 0.2333 - mape: 85.4245 - val_loss: 0.0331 - val_mae: 0.1507 - val_mape: 86.8513\n",
      "Epoch 366/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1660 - mae: 0.2959 - mape: 206.6242 - val_loss: 0.0329 - val_mae: 0.1505 - val_mape: 86.5665\n",
      "Epoch 367/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0994 - mae: 0.2370 - mape: 94.8946 - val_loss: 0.0328 - val_mae: 0.1503 - val_mape: 86.4187\n",
      "Epoch 368/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1272 - mae: 0.2500 - mape: 185.1957 - val_loss: 0.0326 - val_mae: 0.1499 - val_mape: 86.0733\n",
      "Epoch 369/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0953 - mae: 0.2029 - mape: 105.4908 - val_loss: 0.0324 - val_mae: 0.1497 - val_mape: 85.6986\n",
      "Epoch 370/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0905 - mae: 0.2088 - mape: 146.9955 - val_loss: 0.0322 - val_mae: 0.1494 - val_mape: 85.2299\n",
      "Epoch 371/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1107 - mae: 0.2564 - mape: 199.1170 - val_loss: 0.0320 - val_mae: 0.1488 - val_mape: 84.4666\n",
      "Epoch 372/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1050 - mae: 0.2335 - mape: 140.2228 - val_loss: 0.0318 - val_mae: 0.1482 - val_mape: 83.6919\n",
      "Epoch 373/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1747 - mae: 0.2806 - mape: 147.1846 - val_loss: 0.0315 - val_mae: 0.1473 - val_mape: 82.7640\n",
      "Epoch 374/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1815 - mae: 0.2841 - mape: 180.4151 - val_loss: 0.0312 - val_mae: 0.1466 - val_mape: 81.9184\n",
      "Epoch 375/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1260 - mae: 0.2779 - mape: 118.0653 - val_loss: 0.0307 - val_mae: 0.1456 - val_mape: 81.1549\n",
      "Epoch 376/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1164 - mae: 0.2514 - mape: 120.8929 - val_loss: 0.0301 - val_mae: 0.1444 - val_mape: 80.4517\n",
      "Epoch 377/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1213 - mae: 0.2400 - mape: 114.7477 - val_loss: 0.0296 - val_mae: 0.1431 - val_mape: 79.7747\n",
      "Epoch 378/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0754 - mae: 0.2051 - mape: 135.2105 - val_loss: 0.0290 - val_mae: 0.1420 - val_mape: 79.1757\n",
      "Epoch 379/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1271 - mae: 0.2471 - mape: 151.2110 - val_loss: 0.0285 - val_mae: 0.1409 - val_mape: 78.7205\n",
      "Epoch 380/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1455 - mae: 0.2701 - mape: 163.1852 - val_loss: 0.0281 - val_mae: 0.1400 - val_mape: 78.0564\n",
      "Epoch 381/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1581 - mae: 0.2820 - mape: 188.1213 - val_loss: 0.0278 - val_mae: 0.1393 - val_mape: 77.3481\n",
      "Epoch 382/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1978 - mae: 0.2770 - mape: 156.7848 - val_loss: 0.0275 - val_mae: 0.1387 - val_mape: 76.6721\n",
      "Epoch 383/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1216 - mae: 0.2449 - mape: 188.5922 - val_loss: 0.0272 - val_mae: 0.1380 - val_mape: 76.1313\n",
      "Epoch 384/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.1233 - mae: 0.2506 - mape: 145.4123 - val_loss: 0.0269 - val_mae: 0.1373 - val_mape: 75.7409\n",
      "Epoch 385/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0921 - mae: 0.2155 - mape: 139.2472 - val_loss: 0.0267 - val_mae: 0.1367 - val_mape: 75.0996\n",
      "Epoch 386/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1560 - mae: 0.3071 - mape: 197.3794 - val_loss: 0.0264 - val_mae: 0.1361 - val_mape: 74.8747\n",
      "Epoch 387/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1625 - mae: 0.2636 - mape: 142.0024 - val_loss: 0.0262 - val_mae: 0.1355 - val_mape: 74.4314\n",
      "Epoch 388/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1218 - mae: 0.2263 - mape: 154.6122 - val_loss: 0.0261 - val_mae: 0.1352 - val_mape: 73.9128\n",
      "Epoch 389/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1311 - mae: 0.2631 - mape: 164.4532 - val_loss: 0.0261 - val_mae: 0.1352 - val_mape: 73.6793\n",
      "Epoch 390/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0826 - mae: 0.2062 - mape: 174.9865 - val_loss: 0.0260 - val_mae: 0.1351 - val_mape: 73.3192\n",
      "Epoch 391/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0986 - mae: 0.2231 - mape: 106.4781 - val_loss: 0.0260 - val_mae: 0.1351 - val_mape: 72.8077\n",
      "Epoch 392/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0924 - mae: 0.2177 - mape: 168.5328 - val_loss: 0.0259 - val_mae: 0.1351 - val_mape: 72.2635\n",
      "Epoch 393/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0808 - mae: 0.1947 - mape: 88.3060 - val_loss: 0.0259 - val_mae: 0.1351 - val_mape: 71.6522\n",
      "Epoch 394/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1233 - mae: 0.2551 - mape: 202.8393 - val_loss: 0.0259 - val_mae: 0.1350 - val_mape: 70.9944\n",
      "Epoch 395/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1372 - mae: 0.2713 - mape: 125.6556 - val_loss: 0.0258 - val_mae: 0.1349 - val_mape: 70.4020\n",
      "Epoch 396/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1277 - mae: 0.2348 - mape: 154.3796 - val_loss: 0.0258 - val_mae: 0.1349 - val_mape: 69.9633\n",
      "Epoch 397/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0865 - mae: 0.2131 - mape: 169.3997 - val_loss: 0.0258 - val_mae: 0.1349 - val_mape: 69.4453\n",
      "Epoch 398/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1401 - mae: 0.2774 - mape: 203.5404 - val_loss: 0.0259 - val_mae: 0.1350 - val_mape: 69.0575\n",
      "Epoch 399/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1146 - mae: 0.2308 - mape: 183.8629 - val_loss: 0.0258 - val_mae: 0.1349 - val_mape: 68.5070\n",
      "Epoch 400/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1596 - mae: 0.3003 - mape: 244.9435 - val_loss: 0.0257 - val_mae: 0.1346 - val_mape: 68.0623\n",
      "Epoch 401/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1195 - mae: 0.2406 - mape: 99.0780 - val_loss: 0.0256 - val_mae: 0.1342 - val_mape: 67.7857\n",
      "Epoch 402/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1116 - mae: 0.2255 - mape: 210.6310 - val_loss: 0.0255 - val_mae: 0.1339 - val_mape: 67.4523\n",
      "Epoch 403/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0776 - mae: 0.2036 - mape: 165.7952 - val_loss: 0.0253 - val_mae: 0.1334 - val_mape: 67.1231\n",
      "Epoch 404/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0864 - mae: 0.2221 - mape: 175.3611 - val_loss: 0.0252 - val_mae: 0.1330 - val_mape: 66.8203\n",
      "Epoch 405/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1546 - mae: 0.2559 - mape: 163.5439 - val_loss: 0.0251 - val_mae: 0.1326 - val_mape: 66.6332\n",
      "Epoch 406/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0845 - mae: 0.2045 - mape: 139.4177 - val_loss: 0.0250 - val_mae: 0.1323 - val_mape: 66.4493\n",
      "Epoch 407/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0935 - mae: 0.2268 - mape: 97.0909 - val_loss: 0.0248 - val_mae: 0.1317 - val_mape: 66.3038\n",
      "Epoch 408/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0983 - mae: 0.2251 - mape: 207.7742 - val_loss: 0.0246 - val_mae: 0.1313 - val_mape: 66.0669\n",
      "Epoch 409/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1119 - mae: 0.2445 - mape: 109.3460 - val_loss: 0.0245 - val_mae: 0.1311 - val_mape: 65.9019\n",
      "Epoch 410/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1003 - mae: 0.2344 - mape: 97.7118 - val_loss: 0.0245 - val_mae: 0.1310 - val_mape: 65.7403\n",
      "Epoch 411/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0879 - mae: 0.2002 - mape: 153.7793 - val_loss: 0.0245 - val_mae: 0.1309 - val_mape: 65.5942\n",
      "Epoch 412/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1443 - mae: 0.2690 - mape: 213.8789 - val_loss: 0.0243 - val_mae: 0.1305 - val_mape: 65.3703\n",
      "Epoch 413/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0901 - mae: 0.2168 - mape: 136.2476 - val_loss: 0.0241 - val_mae: 0.1299 - val_mape: 65.1668\n",
      "Epoch 414/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0868 - mae: 0.1822 - mape: 68.9020 - val_loss: 0.0240 - val_mae: 0.1294 - val_mape: 64.8913\n",
      "Epoch 415/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1377 - mae: 0.2588 - mape: 162.5008 - val_loss: 0.0239 - val_mae: 0.1290 - val_mape: 64.5401\n",
      "Epoch 416/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0936 - mae: 0.2116 - mape: 158.9183 - val_loss: 0.0238 - val_mae: 0.1286 - val_mape: 64.1724\n",
      "Epoch 417/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.1350 - mae: 0.2621 - mape: 139.1430 - val_loss: 0.0237 - val_mae: 0.1282 - val_mape: 63.8654\n",
      "Epoch 418/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0878 - mae: 0.2332 - mape: 154.3652 - val_loss: 0.0236 - val_mae: 0.1278 - val_mape: 63.6593\n",
      "Epoch 419/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0615 - mae: 0.1733 - mape: 133.3819 - val_loss: 0.0235 - val_mae: 0.1274 - val_mape: 63.4755\n",
      "Epoch 420/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1268 - mae: 0.2665 - mape: 161.7482 - val_loss: 0.0233 - val_mae: 0.1269 - val_mape: 63.3574\n",
      "Epoch 421/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0739 - mae: 0.2040 - mape: 140.6843 - val_loss: 0.0231 - val_mae: 0.1263 - val_mape: 63.2698\n",
      "Epoch 422/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0972 - mae: 0.2215 - mape: 95.7411 - val_loss: 0.0229 - val_mae: 0.1256 - val_mape: 63.2170\n",
      "Epoch 423/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1147 - mae: 0.2247 - mape: 163.7446 - val_loss: 0.0226 - val_mae: 0.1250 - val_mape: 63.0633\n",
      "Epoch 424/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1191 - mae: 0.2242 - mape: 145.6268 - val_loss: 0.0225 - val_mae: 0.1246 - val_mape: 63.0631\n",
      "Epoch 425/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0940 - mae: 0.2244 - mape: 137.6661 - val_loss: 0.0222 - val_mae: 0.1240 - val_mape: 63.1535\n",
      "Epoch 426/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1418 - mae: 0.2666 - mape: 219.6187 - val_loss: 0.0219 - val_mae: 0.1233 - val_mape: 63.1495\n",
      "Epoch 427/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1026 - mae: 0.2235 - mape: 110.3554 - val_loss: 0.0217 - val_mae: 0.1227 - val_mape: 63.1434\n",
      "Epoch 428/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1421 - mae: 0.2584 - mape: 187.9539 - val_loss: 0.0213 - val_mae: 0.1219 - val_mape: 63.2762\n",
      "Epoch 429/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1000 - mae: 0.2305 - mape: 182.8377 - val_loss: 0.0210 - val_mae: 0.1212 - val_mape: 63.2623\n",
      "Epoch 430/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1052 - mae: 0.2154 - mape: 83.1217 - val_loss: 0.0207 - val_mae: 0.1203 - val_mape: 63.3904\n",
      "Epoch 431/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1556 - mae: 0.2880 - mape: 125.2710 - val_loss: 0.0203 - val_mae: 0.1195 - val_mape: 63.5032\n",
      "Epoch 432/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1218 - mae: 0.2355 - mape: 107.4018 - val_loss: 0.0199 - val_mae: 0.1184 - val_mape: 63.5011\n",
      "Epoch 433/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1237 - mae: 0.2547 - mape: 183.6038 - val_loss: 0.0194 - val_mae: 0.1174 - val_mape: 63.4309\n",
      "Epoch 434/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0895 - mae: 0.2203 - mape: 128.0797 - val_loss: 0.0190 - val_mae: 0.1162 - val_mape: 63.2406\n",
      "Epoch 435/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0988 - mae: 0.2227 - mape: 169.1001 - val_loss: 0.0187 - val_mae: 0.1151 - val_mape: 63.0107\n",
      "Epoch 436/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0676 - mae: 0.1949 - mape: 144.8954 - val_loss: 0.0184 - val_mae: 0.1143 - val_mape: 62.6814\n",
      "Epoch 437/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0564 - mae: 0.1872 - mape: 168.2459 - val_loss: 0.0182 - val_mae: 0.1137 - val_mape: 62.4719\n",
      "Epoch 438/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0731 - mae: 0.2140 - mape: 150.6921 - val_loss: 0.0181 - val_mae: 0.1132 - val_mape: 62.2661\n",
      "Epoch 439/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1084 - mae: 0.2377 - mape: 193.0135 - val_loss: 0.0179 - val_mae: 0.1126 - val_mape: 62.0184\n",
      "Epoch 440/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0864 - mae: 0.2133 - mape: 177.8412 - val_loss: 0.0176 - val_mae: 0.1116 - val_mape: 61.7320\n",
      "Epoch 441/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0855 - mae: 0.2087 - mape: 147.4717 - val_loss: 0.0173 - val_mae: 0.1107 - val_mape: 61.4433\n",
      "Epoch 442/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1390 - mae: 0.2670 - mape: 189.5805 - val_loss: 0.0170 - val_mae: 0.1098 - val_mape: 61.2215\n",
      "Epoch 443/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1411 - mae: 0.2727 - mape: 171.4337 - val_loss: 0.0168 - val_mae: 0.1090 - val_mape: 61.0480\n",
      "Epoch 444/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1103 - mae: 0.2206 - mape: 141.4064 - val_loss: 0.0166 - val_mae: 0.1083 - val_mape: 60.7741\n",
      "Epoch 445/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1263 - mae: 0.2487 - mape: 166.0453 - val_loss: 0.0164 - val_mae: 0.1076 - val_mape: 60.5440\n",
      "Epoch 446/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1025 - mae: 0.2353 - mape: 112.2027 - val_loss: 0.0161 - val_mae: 0.1069 - val_mape: 60.4181\n",
      "Epoch 447/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1760 - mae: 0.2930 - mape: 171.6019 - val_loss: 0.0160 - val_mae: 0.1063 - val_mape: 60.3563\n",
      "Epoch 448/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1150 - mae: 0.2375 - mape: 170.8535 - val_loss: 0.0157 - val_mae: 0.1057 - val_mape: 60.2791\n",
      "Epoch 449/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1470 - mae: 0.2542 - mape: 156.1780 - val_loss: 0.0155 - val_mae: 0.1051 - val_mape: 60.1895\n",
      "Epoch 450/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0932 - mae: 0.2118 - mape: 116.9994 - val_loss: 0.0153 - val_mae: 0.1046 - val_mape: 60.0514\n",
      "Epoch 451/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1187 - mae: 0.2572 - mape: 198.5006 - val_loss: 0.0151 - val_mae: 0.1040 - val_mape: 59.9652\n",
      "Epoch 452/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0976 - mae: 0.2162 - mape: 152.1163 - val_loss: 0.0149 - val_mae: 0.1032 - val_mape: 59.6900\n",
      "Epoch 453/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1560 - mae: 0.2865 - mape: 174.1954 - val_loss: 0.0147 - val_mae: 0.1024 - val_mape: 59.6171\n",
      "Epoch 454/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0812 - mae: 0.2208 - mape: 157.7608 - val_loss: 0.0144 - val_mae: 0.1017 - val_mape: 59.6348\n",
      "Epoch 455/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1120 - mae: 0.2222 - mape: 172.2825 - val_loss: 0.0142 - val_mae: 0.1010 - val_mape: 59.4002\n",
      "Epoch 456/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0855 - mae: 0.2077 - mape: 101.4845 - val_loss: 0.0139 - val_mae: 0.1000 - val_mape: 59.2433\n",
      "Epoch 457/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1300 - mae: 0.2497 - mape: 184.7512 - val_loss: 0.0136 - val_mae: 0.0989 - val_mape: 59.0343\n",
      "Epoch 458/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0969 - mae: 0.2281 - mape: 164.7574 - val_loss: 0.0133 - val_mae: 0.0979 - val_mape: 58.8228\n",
      "Epoch 459/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0774 - mae: 0.1995 - mape: 152.0063 - val_loss: 0.0131 - val_mae: 0.0970 - val_mape: 58.7391\n",
      "Epoch 460/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0891 - mae: 0.2139 - mape: 146.3565 - val_loss: 0.0128 - val_mae: 0.0960 - val_mape: 58.7665\n",
      "Epoch 461/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1363 - mae: 0.2674 - mape: 188.9835 - val_loss: 0.0125 - val_mae: 0.0951 - val_mape: 58.6281\n",
      "Epoch 462/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1464 - mae: 0.2670 - mape: 172.3135 - val_loss: 0.0122 - val_mae: 0.0942 - val_mape: 58.6645\n",
      "Epoch 463/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0816 - mae: 0.2084 - mape: 163.8408 - val_loss: 0.0119 - val_mae: 0.0936 - val_mape: 58.7341\n",
      "Epoch 464/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1173 - mae: 0.2413 - mape: 176.0330 - val_loss: 0.0117 - val_mae: 0.0929 - val_mape: 58.5912\n",
      "Epoch 465/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1225 - mae: 0.2479 - mape: 174.3372 - val_loss: 0.0116 - val_mae: 0.0924 - val_mape: 58.4430\n",
      "Epoch 466/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1087 - mae: 0.2360 - mape: 186.1695 - val_loss: 0.0114 - val_mae: 0.0917 - val_mape: 58.1661\n",
      "Epoch 467/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0820 - mae: 0.2013 - mape: 180.6211 - val_loss: 0.0113 - val_mae: 0.0913 - val_mape: 57.6734\n",
      "Epoch 468/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0829 - mae: 0.2149 - mape: 196.6686 - val_loss: 0.0112 - val_mae: 0.0909 - val_mape: 57.0740\n",
      "Epoch 469/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1009 - mae: 0.2317 - mape: 117.5848 - val_loss: 0.0111 - val_mae: 0.0907 - val_mape: 56.3952\n",
      "Epoch 470/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1503 - mae: 0.2721 - mape: 165.8282 - val_loss: 0.0111 - val_mae: 0.0909 - val_mape: 56.4978\n",
      "Epoch 471/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0879 - mae: 0.2088 - mape: 147.9417 - val_loss: 0.0111 - val_mae: 0.0909 - val_mape: 56.4695\n",
      "Epoch 472/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1116 - mae: 0.2478 - mape: 156.1928 - val_loss: 0.0111 - val_mae: 0.0908 - val_mape: 56.4319\n",
      "Epoch 473/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0952 - mae: 0.2215 - mape: 172.5480 - val_loss: 0.0111 - val_mae: 0.0907 - val_mape: 56.1615\n",
      "Epoch 474/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0953 - mae: 0.2252 - mape: 113.7529 - val_loss: 0.0111 - val_mae: 0.0907 - val_mape: 55.9198\n",
      "Epoch 475/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0744 - mae: 0.2031 - mape: 155.5108 - val_loss: 0.0111 - val_mae: 0.0906 - val_mape: 55.7553\n",
      "Epoch 476/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0866 - mae: 0.2100 - mape: 172.8110 - val_loss: 0.0111 - val_mae: 0.0906 - val_mape: 55.5010\n",
      "Epoch 477/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1408 - mae: 0.2673 - mape: 179.6439 - val_loss: 0.0111 - val_mae: 0.0904 - val_mape: 54.8964\n",
      "Epoch 478/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1069 - mae: 0.2266 - mape: 164.9753 - val_loss: 0.0112 - val_mae: 0.0901 - val_mape: 54.2018\n",
      "Epoch 479/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1470 - mae: 0.2663 - mape: 122.9242 - val_loss: 0.0112 - val_mae: 0.0900 - val_mape: 53.5636\n",
      "Epoch 480/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1118 - mae: 0.2450 - mape: 175.6875 - val_loss: 0.0112 - val_mae: 0.0899 - val_mape: 52.9536\n",
      "Epoch 481/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0502 - mae: 0.1558 - mape: 75.5056 - val_loss: 0.0113 - val_mae: 0.0898 - val_mape: 52.4385\n",
      "Epoch 482/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1476 - mae: 0.2566 - mape: 152.3482 - val_loss: 0.0113 - val_mae: 0.0896 - val_mape: 51.9860\n",
      "Epoch 483/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1245 - mae: 0.2360 - mape: 183.2906 - val_loss: 0.0113 - val_mae: 0.0894 - val_mape: 51.3352\n",
      "Epoch 484/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0920 - mae: 0.2049 - mape: 151.4470 - val_loss: 0.0114 - val_mae: 0.0897 - val_mape: 50.8838\n",
      "Epoch 485/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1058 - mae: 0.2251 - mape: 179.9099 - val_loss: 0.0115 - val_mae: 0.0900 - val_mape: 50.3640\n",
      "Epoch 486/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0860 - mae: 0.2001 - mape: 111.1544 - val_loss: 0.0117 - val_mae: 0.0904 - val_mape: 49.8242\n",
      "Epoch 487/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0677 - mae: 0.1814 - mape: 173.1571 - val_loss: 0.0119 - val_mae: 0.0908 - val_mape: 49.2677\n",
      "Epoch 488/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1033 - mae: 0.2174 - mape: 153.7712 - val_loss: 0.0120 - val_mae: 0.0910 - val_mape: 48.7353\n",
      "Epoch 489/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0927 - mae: 0.2176 - mape: 164.9009 - val_loss: 0.0121 - val_mae: 0.0910 - val_mape: 48.2979\n",
      "Epoch 490/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1197 - mae: 0.2551 - mape: 186.8580 - val_loss: 0.0120 - val_mae: 0.0909 - val_mape: 47.9917\n",
      "Epoch 491/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1582 - mae: 0.2833 - mape: 156.5740 - val_loss: 0.0119 - val_mae: 0.0907 - val_mape: 47.7849\n",
      "Epoch 492/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0881 - mae: 0.1968 - mape: 154.4076 - val_loss: 0.0118 - val_mae: 0.0904 - val_mape: 47.4176\n",
      "Epoch 493/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1124 - mae: 0.2473 - mape: 187.6451 - val_loss: 0.0116 - val_mae: 0.0898 - val_mape: 47.1526\n",
      "Epoch 494/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0905 - mae: 0.2191 - mape: 130.7560 - val_loss: 0.0113 - val_mae: 0.0890 - val_mape: 46.9732\n",
      "Epoch 495/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0827 - mae: 0.2010 - mape: 165.1320 - val_loss: 0.0112 - val_mae: 0.0884 - val_mape: 46.8191\n",
      "Epoch 496/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1660 - mae: 0.2659 - mape: 133.4964 - val_loss: 0.0110 - val_mae: 0.0882 - val_mape: 46.8397\n",
      "Epoch 497/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1104 - mae: 0.2200 - mape: 185.4700 - val_loss: 0.0109 - val_mae: 0.0880 - val_mape: 46.9078\n",
      "Epoch 498/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1319 - mae: 0.2428 - mape: 167.1026 - val_loss: 0.0109 - val_mae: 0.0879 - val_mape: 46.9380\n",
      "Epoch 499/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0444 - mae: 0.1512 - mape: 135.4330 - val_loss: 0.0108 - val_mae: 0.0878 - val_mape: 46.7536\n",
      "Epoch 500/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1197 - mae: 0.2237 - mape: 97.1403 - val_loss: 0.0108 - val_mae: 0.0875 - val_mape: 46.6239\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Compile model with optimizer and loss function\n",
    "model.compile(optimizer='adam',    # Adaptive learning rate optimizer\n",
    "              loss='mse',          # Mean Squared Error for regression\n",
    "              metrics=['mae', 'mape'])  # Track Mean Absolute Error and Mean Absolute Percentage Error\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early = EarlyStopping(monitor='val_loss',        # Watch validation loss\n",
    "                     patience=25,                # Wait 25 epochs without improvement\n",
    "                     restore_best_weights=True)  # Keep best model weights\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_z, y_train_s,                    # Training data (scaled)\n",
    "    validation_data=(X_val_z, y_val_s),     # Validation data (scaled)\n",
    "    epochs=500,                              # Maximum 500 epochs\n",
    "    batch_size=16,                           # Process 16 samples at a time\n",
    "    verbose=1,                               # Print progress during training\n",
    "    callbacks=[early]                        # Apply early stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLV4VDdDjLmG",
    "outputId": "e06804a3-2b4d-4bc0-ad9d-206f2ab4cdb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Prediction shapes:\n",
      "Train: (16, 2)\n",
      "Val:   (4, 2)\n",
      "Test:  (5, 2)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on all sets\n",
    "y_hat_train_s = model.predict(X_train_z)\n",
    "y_hat_val_s   = model.predict(X_val_z)\n",
    "y_hat_test_s  = model.predict(X_test_z)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "y_hat_train = inv_y(y_hat_train_s)\n",
    "y_hat_val   = inv_y(y_hat_val_s)\n",
    "y_hat_test  = inv_y(y_hat_test_s)\n",
    "\n",
    "# Print prediction shapes\n",
    "print(\"Prediction shapes:\")\n",
    "print(f\"Train: {y_hat_train.shape}\")\n",
    "print(f\"Val:   {y_hat_val.shape}\")\n",
    "print(f\"Test:  {y_hat_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xeWwgdE0jLkG"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def report_2out(name, y_true, y_pred, labels=(\"Mn\", \"Mw\")):\n",
    "    for i, label in enumerate(labels):\n",
    "        # Extract single output column\n",
    "        yt = y_true[:, i]\n",
    "        yp = y_pred[:, i]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae  = mean_absolute_error(yt, yp)\n",
    "        mse  = mean_squared_error(yt, yp)\n",
    "        r2   = r2_score(yt, yp)\n",
    "        mape = mean_absolute_percentage_error(yt, yp)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"[{name}] {label}: MAE={mae:.6f}  MSE={mse:.6f}  R²={r2:.4f}  MAPE={mape:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptHevHX-jLh_",
    "outputId": "ca2a17b0-6b4b-4e41-8e90-50bde0ab8b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Mn: MAE=255.885074  MSE=130725.142833  R²=0.7471  MAPE=0.098168\n",
      "[Train] Mw: MAE=413.647201  MSE=425014.070609  R²=0.6702  MAPE=0.113628\n",
      "[Val  ] Mn: MAE=116.962660  MSE=19778.821548  R²=0.9554  MAPE=0.082835\n",
      "[Val  ] Mw: MAE=191.428291  MSE=47396.411898  R²=0.9289  MAPE=0.099584\n",
      "[Test ] Mn: MAE=734.176650  MSE=1081054.258134  R²=0.4647  MAPE=0.185666\n",
      "[Test ] Mw: MAE=887.070158  MSE=1620414.644440  R²=0.4933  MAPE=0.171938\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation results for all datasets\n",
    "report_2out(\"Train\", y_train, y_hat_train)\n",
    "report_2out(\"Val  \", y_val,   y_hat_val)\n",
    "report_2out(\"Test \", y_test,  y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGS2LHAAjLfx",
    "outputId": "c5ef78f4-c870-4658-9a4c-388ffdd530b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZovIuGAXjLd4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-ZWVSsjjLby",
    "outputId": "224eda97-b2d7-4034-eb93-9c2c243abade"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split target   actual   predicted     residual   abs_error  pct_error\n",
      "Train     Mn 1845.600 1949.013550  -103.413550  103.413550   5.603248\n",
      "Train     Mn 2590.790 2428.120361   162.669639  162.669639   6.278766\n",
      "Train     Mn 2074.517 2218.637695  -144.120695  144.120695   6.947193\n",
      "Train     Mn 2955.830 2717.085205   238.744795  238.744795   8.077081\n",
      "Train     Mn 2298.620 2997.490723  -698.870723  698.870723  30.403926\n",
      "Train     Mn 2525.270 2484.681396    40.588604   40.588604   1.607298\n",
      "Train     Mn 2752.840 2674.921631    77.918369   77.918369   2.830472\n",
      "Train     Mn 1846.180 1949.013550  -102.833550  102.833550   5.570072\n",
      "Train     Mn 1127.190 1181.712524   -54.522524   54.522524   4.837031\n",
      "Train     Mn 2322.830 2321.365723     1.464277    1.464277   0.063039\n",
      "Train     Mn 3764.530 3092.835449   671.694551  671.694551  17.842720\n",
      "Train     Mn 2073.900 2218.637695  -144.737695  144.737695   6.979010\n",
      "Train     Mn 1264.440 1215.557861    48.882139   48.882139   3.865912\n",
      "Train     Mn 3762.880 3092.835449   670.044551  670.044551  17.806695\n",
      "Train     Mn 2298.650 2997.490723  -698.840723  698.840723  30.402224\n",
      "Train     Mn 2951.900 2717.085205   234.814795  234.814795   7.954700\n",
      "Train     Mw 2690.500 2689.806152     0.693848    0.693848   0.025789\n",
      "Train     Mw 3517.860 3056.827881   461.032119  461.032119  13.105471\n",
      "Train     Mw 2970.820 2963.614258     7.205742    7.205742   0.242551\n",
      "Train     Mw 2966.910 3215.564453  -248.654453  248.654453   8.380923\n",
      "Train     Mw 2972.980 3985.544434 -1012.564434 1012.564434  34.058905\n",
      "Train     Mw 3441.190 3282.087158   159.102842  159.102842   4.623483\n",
      "Train     Mw 3129.570 3271.265625  -141.695625  141.695625   4.527639\n",
      "Train     Mw 2689.910 2689.806152     0.103848    0.103848   0.003861\n",
      "Train     Mw 1321.650 1476.631714  -154.981714  154.981714  11.726381\n",
      "Train     Mw 2987.310 3099.016357  -111.706357  111.706357   3.739363\n",
      "Train     Mw 5752.150 4282.966309  1469.183691 1469.183691  25.541470\n",
      "Train     Mw 2974.510 2963.614258    10.895742   10.895742   0.366304\n",
      "Train     Mw 1456.220 1564.282227  -108.062227  108.062227   7.420735\n",
      "Train     Mw 5752.810 4282.966309  1469.843691 1469.843691  25.550013\n",
      "Train     Mw 2972.940 3985.544434 -1012.604434 1012.604434  34.060709\n",
      "Train     Mw 2965.540 3215.564453  -250.024453  250.024453   8.430992\n",
      "  Val     Mn 2752.800 2674.921631    77.878369   77.878369   2.829060\n",
      "  Val     Mn 1024.970 1271.934448  -246.964448  246.964448  24.094798\n",
      "  Val     Mn 2525.910 2484.681396    41.228604   41.228604   1.632228\n",
      "  Val     Mn 2223.170 2324.949219  -101.779219  101.779219   4.578112\n",
      "  Val     Mw 3129.610 3271.265625  -141.655625  141.655625   4.526303\n",
      "  Val     Mw 1339.350 1706.374756  -367.024756  367.024756  27.403200\n",
      "  Val     Mw 3440.430 3282.087158   158.342842  158.342842   4.602414\n",
      "  Val     Mw 2989.000 3087.689941   -98.689941   98.689941   3.301771\n",
      " Test     Mn 4663.770 3041.346191  1622.423809 1622.423809  34.787818\n",
      " Test     Mn 4663.040 3041.346191  1621.693809 1621.693809  34.777609\n",
      " Test     Mn 1950.000 2324.949219  -374.949219  374.949219  19.228165\n",
      " Test     Mn 2322.860 2321.365723     1.494277    1.494277   0.064329\n",
      " Test     Mn 1265.880 1215.557861    50.322139   50.322139   3.975269\n",
      " Test     Mw 5921.610 3917.213867  2004.396133 2004.396133  33.848837\n",
      " Test     Mw 5921.490 3917.213867  2004.276133 2004.276133  33.847497\n",
      " Test     Mw 2878.900 3087.689941  -208.789941  208.789941   7.252421\n",
      " Test     Mw 2987.280 3099.016357  -111.736357  111.736357   3.740405\n",
      " Test     Mw 1458.130 1564.282227  -106.152227  106.152227   7.280025\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_table_multi(split, y_true, y_pred, target_names=(\"Mn\",\"Mw\"), n=None):\n",
    "    \"\"\"Create comparison table for actual vs predicted values\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    parts = []\n",
    "    for j, name in enumerate(target_names):\n",
    "        df = pd.DataFrame({\n",
    "            \"split\":     split,\n",
    "            \"target\":    name,\n",
    "            \"actual\":    y_true[:, j],\n",
    "            \"predicted\": y_pred[:, j],\n",
    "        })\n",
    "        # Calculate error metrics\n",
    "        df[\"residual\"]  = df[\"actual\"] - df[\"predicted\"]\n",
    "        df[\"abs_error\"] = df[\"residual\"].abs()\n",
    "        df[\"pct_error\"] = 100 * df[\"abs_error\"] / df[\"actual\"].abs().clip(lower=1e-8)\n",
    "        \n",
    "        parts.append(df if n is None else df.head(n))\n",
    "    \n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "# Create comparison tables for all datasets\n",
    "tbl_train = make_table_multi(\"Train\", y_train, y_hat_train)\n",
    "tbl_val   = make_table_multi(\"Val\",   y_val,   y_hat_val)\n",
    "tbl_test  = make_table_multi(\"Test\",  y_test,  y_hat_test)\n",
    "\n",
    "# Combine all tables\n",
    "tbl_all = pd.concat([tbl_train, tbl_val, tbl_test], ignore_index=True)\n",
    "print(tbl_all.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Q9ZIfV65BSWm",
    "outputId": "6998d8e4-f6a1-4037-c092-cbc25bf21aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001DD2ED893A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001DD31085BC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAHWCAYAAABkNgFvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdQdJREFUeJzt3Qd0VFXXBuA3vZFCgBB6L6FKF5DeQQSxIIpUGyCgYqGIfEgVRUURFOkCFqRY6EjvvUNogdBCCIEU0pP51z4w+dPJhMzcKe+z1qzc6Xsmd+7sOWefc+x0Op0OREREREQWyF7rAIiIiIiI8orJLBERERFZLCazRERERGSxmMwSERERkcViMktEREREFovJLBERERFZLCazRERERGSxmMwSERERkcViMktEREREFovJLBFpYtq0aahatSpSUlK0DsViPf300/j444+1DsOqJCUlqfe0VKlSsLe3R/fu3bUOyewsXLgQdnZ2uHLlitahEClMZonSHJzltGvXrkzXy6rP8uUm1z/77LMwZ2XLllVxtm3bNsvrf/7559TXeujQoXTXyWvv1KkTSpQoAVdXV5QuXRpdu3bFsmXL0t1Of/+sTu+8885jY4yMjMQXX3yBTz75RCUMGR/3jTfeyPJ+Y8aMSb1NWFgY8tO9e/dU7PLaPTw8ULt2bXz55ZcGPUbLli1VbJUqVcry+k2bNqXG/+effz5xzPL+/fDDDwgJCYG5+d///pfjfqI/yXtmTubPn6/+7y+++CIWLVqE999/36jP169fv2zfm/Xr10NLkydPxurVqzWNgSg3HHN1KyIbIQmcJG7PPPNMusu3b9+O69evw8XFBZbyOrZu3aqSHH9//3TXLV26VF0fFxeX7vLly5ejZ8+eeOqppzB8+HAULFgQQUFB2LFjh0qAX3311XS3b9euHfr06ZPpuStXrpyrhEFawHr16pVl7CtWrMCsWbPg7Oyc7rpff/01y9jzK6lYu3Yt3n33XdVifPz4cfVeffTRRwY9jsR38eJFHDhwAA0bNszVe59X3bp1g5eXl3qvPv/8c5iTHj16oGLFiqnno6OjMWjQIDz//PPqOr2iRYvCnGzZskX9oPnmm29M9pxyXJk7d26my+UHldbJrCT1GVunX3/9dbzyyisWczwkG6AjIt2CBQt08nHo0aOHrnDhwrrExMR017/55pu6evXq6cqUKaPr0qWLzpxJjG3atNF5eXnpvv3223TXXbt2TWdvb6974YUX1Os9ePBg6nXVqlXTVa9eXRcfH5/pMW/fvp3uvNx3yJAheY6xVq1aut69e2e6XB63e/fuKsbVq1enu2737t3qen3sd+7c0eWX6Oho9ZyDBw9Od3lcXJxBj9OiRQv1HlapUkX33nvvpbsuNjZW/U/08S9fvjxfYn/33XfV/zwlJUVnzuT/Ja973LhxOd5O3qfk5GSdVlq1aqX+h/lF/i8xMTHZXt+3b1+dh4eHzhxJXBIfkbljmQFRGtJSePfuXdUdrJeQkKC6hDO2TOpJzee3336L6tWrq1Y3aWl6++23Vbd1Wn/99Re6dOmC4sWLqxaNChUqYMKECUhOTk53O+l2rVGjBs6cOYNWrVrB3d1dtRRJjWluSRzS+pWxPEBaNqXFtUOHDpnuc+nSJTRo0CBTa6jw8/NDfpHW3hMnTmRbBiGvtXnz5plil1bNmjVrqvcmoyd9z/Tdug/z6f+X15Yn2Y9+//33dPXA//zzD2JiYvDyyy+nu628F/Lcf//9d+plhw8fVpfVrVs33W2lBKRRo0aZWsivXr2KY8eOZRtPYmIifH190b9//yxLPmR/+fDDD1Mv+/7779X+LO+j7C/169fP9P/ID9u2bVOv87fffsOnn36q/mfynBJTeHi4ikn+5wUKFFAt0PL6pcU8q8f4448/MGnSJJQsWVK9njZt2qgW8rQuXLiAF154QfVWyG3kttLCGBERoeo/5XGkR+P06dOp+4Q8viGfcynzkVKkDRs2qPfNzc0NP/300xO/R/o49PTxSolU2t4Fea9u3LihWlNlu0iRIup9zHickdczY8YM9f7K65HbdezYMbX0SB77wYMHqtRC/17I4+dUMys9BPL+yOdGjnNDhgzB/fv38/34RpQRk1miDF9EjRs3Vkmf3rp169SXnXzpZUW+0KQrumnTpurLQRIGSbwkYZQkQk++AOTL5YMPPlC3q1evHj777DOMHDky02PKF6R8sUg34/Tp01W3t9RHSiy5Jcm3dHVLkqonCYl0Gzo5OWW6fZkyZfDff/+pcorckK5yqVvNeJLkPyd79uxRfzMmahljl+RPuqaFlCRIGUR2Pyie9D2TL1RJMuV/dPToUTwpifPWrVvpEhB57yXByvjDQL7YfXx8VDmH3s6dO1UtsSRuktjpkw957yTRT0v2I7F79+5s45H/t3TvS/1jxv+PXBYfH5+6f0tJybBhw1CtWjWVvI0fP16Vnuzfvx/GIj/q1qxZo5Iu6dqWH1SXL19WsUli+PXXX6vP2MmTJ9GiRQvcvHkz02NMnToVq1atUo8xatQo7Nu3D6+99lrq9fK65TMplw8dOlTVGr/11lvqeSThkmTul19+UfuNJLmyLaeAgACDPuciMDBQ/aCRHxpyW3n/Hifj50iOOXkhSavEVKhQIXz11Vfq/ZLPw5w5c9LdbuDAgXjvvffUWACpX5fjkCS18v4Iee2SlDZr1iz1vZD3IKcaaUleJYmV55MfDZLEt2/fPtP7kx/HN6J0tG4aJjKnMgPpdp85c6bO09MztWvwpZdeUl2PImOZwc6dO9X9li5dmu7x1q9fn+nyrLoa3377bZ27u3u67mzpqpb7Ll68OPUy6fr39/dXXdSPo48xKSlJ3WfChAnq8jNnzqjH3b59e7rXqzdv3jx1mbOzs3q9Y8eOVa8vqy5fuV12p19//TXH+D799FN1u6ioqCwfV8oXwsPDVRy//PKLunzNmjU6Ozs73ZUrV1Q3dcYygyd9zySWtm3bqucsWrSo7vz587q80JcZiPr16+sGDhyotu/du6cee9GiRbqtW7dmKjOQ/1fDhg1Tz0u5i5wcHBx069atU5cdOXJE3e+vv/7K9Lzy2IMGDcoxtg0bNqj7//PPP+ku79y5s658+fKp57t165av3ew5lRno3wt5/oyfD/lMZNz3goKCdC4uLrrPP/8802MEBASkK5GZMWOGuvzkyZPq/NGjR3NV3pH2f5iXz7l8/uQyuS43pBs/q8+RxJH29cnfjO+FXC6f5YyPlfb9EXXq1FFlUnpbtmxRtxs2bFimeNKWq2RXZqA/fkgMIjQ0VO2D7du3T/c/k2Op3G7+/Pn59lklygpbZokykBa62NhY/Pvvv4iKilJ/s2sRlNZCb29v1QKTtlVFWsukFVa6LPWku1FPHlduJ60e0vV87ty5dI8r9+3du3fqeWmpksFE0oqUWw4ODuq16FuZpRVJWmHkObMyYMAANXpaugFlVgNpLZPbysh8fWtqxsFHUo6R8SRdhzmRMg5HR0f1GrMjXdvScqOPXVo1mzRpolqPs/Mk75kMZJMuU/k/SAudlEAEBwenXr93717VrSot17kl+8zKlStTy1Tk/yGto1mR9/nIkSOqW1fI+9+5c2fVoiettEL+SgwZByfq36/Hze7QunVrFC5cWJU/pG0hk/+ZDPzTk1ZiaZ0/ePAgTKVv377pPh9CWgX1M11Ia6PsN/I/rlKlinqvMpKW0rQlMvr9XP//l8+pkO5/+cwZwpDPuShXrlyWpTzZkRbRjJ8jabHMq4wzish7kfZzIAMsZV8aN25cpvvK5YbavHmz2s+lpTft7CRvvvmmKg+RVvf8Pr4RpWXTyax068m0Q9ItIh/gvExBIo1J0pUjI7jl4Cu1P1K3RZZLn8xIAiXJiHyRStd8VqQGT7oDpetY7pf2JF3koaGhqbeVOjxJZuRLUQ7wchv9AT1jl6J0c2b8UpGEJWN9Xm4SKqlNk+5qeT3SlZzTl5V8AcuXvXS7yudDug2lHlO6etO+Fn2M8j5lPOXX6HSJXb7UJamUz2ZOJQZP8p5Jt6p0T0v3tiQh+umQ5LXcvn1bbZ86dUol4Pou/dzQ12JK16n8kJD30NPTM8vbSrIhpRSSNEsXtbzXcpmUFKRNZqXrX2pfszoOPS4Jkfil61dqt6WsQMj+LV3AaZNZ6e6VZEOSC/khI/tATiUM+UHe94ykrEJmFJAY5Ngqibh8ZqTGOKsueJlGLuP/Xuj///IcUuIjswbIY8m+LqUGuenON+Rznt3ryYn80Mn4OTJkX0tLX/+a0+dASo/key+rfSkv5Bgh5IdGWpKkli9fPvX6/D6+EenZ9NRc0goiNTvSIpV2qhhDyBRGGzduVAmtFNLLoAU5kWWTxElaFWRqKxl0Iq1VWZEvXPmCk2QlK/ovFUkOpXZNkliZQkkGf8mXjrQwSfKQceEA+XLLSsYBSo8jg4XkuaTFRAZePS4hTFtDKsmUnOSLX+omJSmTFrQnJbV8krhJ63R2yZ147rnnVBIjzynJV8aBUxnl9T3TtzrLAgRCfpBKQi8toNISJ3WvUm8oLaXZ7QdZKVasmGrllhY2SQalNSw7MlBI9gf5ASFJmexT8gNZ3n8ZVCOvX5LZ7Fp2Zf+S/1NuEmypY5T/pQwQkkFTUq+YdgooqRGVhFp6JCSx10+TJvXdsh8YQ8ZWWSE/LsaOHauOz9JLIImXtPrJvpzVQhu5+f/L/0IGMUlCL8dtqQ2eMmWK+kEjCVZ2cvs5z+n15FV2P1IyDuh63PtgTvLr+EakZ9PJrCQpcsqOfIHIJO3S1SlfFjJQQwrl9ZN8nz17FrNnz1atNvpfpIb+IifzJEmDDHaQL7m03bIZSaIoXWwyKCSnLzBJiKSbVFrC0g7gkQTT2GQgysSJE1WSkpuBKFklWkIGNOUHSZ70r71WrVrZ3k7eT0m4lixZoj6nuUnWniRZuHbtmirD0McoXaMyYEtayKR1OC8j0uXHgywAIUmwJMPZ0XezSsIqyay+i1z+ynFIkihpJc44+EvIyHXp4tUPVMqJ3F+SbNmnJVmXOVXlGJeRLBohrbVykseWH/vS4yQDqyTpNgUpzZCSlXnz5uUpcc+ONDrISWZPkB8y8tn98ccf1WfkST/nxqBvYc44K0DG1k5DyOuRH2zS8JJT62xuSw705T/yI0haYvVk35HPeXYzlxDlF5suM3gcmTxduv1k2hjp2nrppZdUHZ90OQkZbS0fXGnBkCRWRsLLFxdbZi2fdLPKDxUZoSulKNmR1kJpIZGWo4yk9VH/BaRviUjb8iAHemnxMjbZJ6U27nE1eNnVg8pCAll1IeaVzBYhMq4+lhUZmS6xSwudsUjCKqTFXP5naVu1JeGRWlrp6s5qSrDHkfIUiT+rBSAyksRVZgyQ+kt9MitJmySp8iNaf5uMZBovITXFjyMtmxKTHLtkdLq83rQlBkJ+dKUlcUt5g+y7+lHp+jrv/F6FLS35zGRsqZPaVUne80JmhUj7/xWS1Mp7oi+7eNLPuTFIoijvRdrZLsSTHDuk3ETe26xa2tO+5/KjJjevTZJV2U++++67dPeXHyJSniFTEhIZk023zOZEWmIWLFig/kptkf6LVbrd5HLpApNidfl1LAfYxYsXq4OdLH0oXxbS4kGWLTdd6lI6IC240lUp83zKNDQyDZL84JH9Qqblkf1BEg1pYZHHlK5NafGQZMIU3WryZShJ+ePIgC75USbJu7TcSBmOtEZJ4iPzz2ZM6s+fP69aTTOSmlnpns+O/ACUxFAeW7qQcyLd38ZeBUlah+V/Il/E8jqlJVtaUqWVVH7ISgIpA7Kk7ETm3DSE1Efn5r0X8jzS+iktxGmTVmlNlVZh+bGcVVe41BVLa26dOnVy9TySvMo8spJkSzKXsUVX9mGZh1VaIeV/KT1QM2fOVAmJvixEpnyTVlN5jNy+PkNJjbH8wJCBXfL5kWm5pIU6bcufIeSYLA0U0ighJRyShMpnUBJFSe7y43NuDLIPSczyP5Pjhnw2pQElY52uIeR/J6t4yT4vr0EaaaSUQvZ5uU7eJyG9EvI5lanR5HtQjg8Z5znWl1lIq70kx/JYUiIkrbSScMtnKu1gLyJjYDKbDTlwSnKacWlO+QUvNX9CPvxyXhJZ/e3kl6gcAOSDnF8tWWTepItS/ueScIwePVoNtJHEQw7gkhAI2WfkC2jEiBGqtU8SW7leWgUNGfVsTDIwRmoJpY5S5vGURFsSB+mGlrpeeV1p6UddZ/XFn1MyKySJlRpMmTXC1N22WZFkRJJm+fKVBE1eqySHkqxL8ifvgfyAlURC4jYGSdgksZJ65bQJvCS2sm9l1SorxyCpaZU5Q3PbJSzPI+UUkjRnbJUVkrRJ0igJjAxukgRakn3Zb01JPkvyg0oGLkpZhMxLLKUfWc3LnBvynspnTX6cSeuu/n2W+mF9vfSTfs6NRRJZaRWXGKSOXFqKv/zyyzz1FuhJo4z8kJPvLJk/V5JmKSlK28Iv+4DMxSv/e/msyo/xrJJZIT9qJKmVHz7SqCPlC3Jf+dxkNa81UX6yk/m58vURLZR8EciIZv0a1HLwlAm3ZQR6xmJ16YKWlgv50pMPatoJoeUDLwdJGVzwuC90IlslXY+SKMuqP5KIUd7oZ3mQ0elSC0tEZItYM5sNaZWRllnpyqlYsWK6kySyQn6NS1dV2hWWpOtV5DQfJpGtk1agjz/+WLUuZTUynXJHammlS5iJLBHZMptumZUuNP3a3ZK8SpeK1AtJ94jUoEn3kUypIwNn5Po7d+6oQTLSNSP1Y/IlLPVA0lIryz7KeZmTUaZfkpZZIiIiIjIum05mZbqkrFYrkrogWaNdygdkuhapiZUaKxlZLLVVUuQuAyeE1BbKOt+SvMrIT5lCSJLf/JqMmoiIiIiyZ9PJLBERERFZNk1rZmWaE+mml+leZHUVGXwlswDkRCadlxGXMnWOtITKJPAyvQoRERER2R5Nk9nt27erGlNZZUmm+JFufZm/T6ZjyY5038s0ObKYgSxkIHMQyklWMyEiIiIi22JWZQYywEpaaCXJzWrZxuzI/IMyICur1VkykkFaUucqrcG5nZeRiIiIiExH0tOoqCi1YIes1GcxiybI3JMit4On5IXKqi5SmqBf7jEjWdQg7VKFMpBLlmYkIiIiIvMmC7xktfqhWbbMSoupLIEn60DL0pGPS3pLlCihklRZ0EBW7cluWUxZlSSr9adltSNZ3ICIiIiIzEtMTAzeeOMNlRfK3OQWkcwOGjRILSsoiezjMnBJfC9fvqzmiZV5X6W8QFbCadmy5WNbZiMjI9VSjmFhYWo+WFOQWmCpCZYVwbisH1kz7utkS7i/ky1JNPH+LvmaTIkqDZiPy9fMosxAVrCRdet37Njx2ERWSO2ErMQlZDaDs2fPqpkRskpmZR1rOWUk/whTH3y0eE4iLXBfJ1vC/Z1siZOJ9ndDnkPTZFYahWXBgVWrVqkFDMqVK5enx5GW2rStr0RERERkGzRNZmVarmXLluGvv/5SswuEhISoy6U2ws3NTW336dNH1cdKy6uQvzLPbIUKFVQCu3btWjXP7OzZs7V8KURERERka8msPgHNWB6wYMEC9OvXT20HBwenm5JB5qAdPHgwrl+/rhLeqlWrYsmSJejZs6eJoyciIiIirWleZvA4Un6Q1sSJE9WJiIiIiEjTFcCIiIiIiJ4Ek1kiIiIislhMZomIiIjIYjGZJSIiIiKLxWSWiIjIQMkpOuwPCsfhMDv1V84TkTbMYgUwIiIiS7H+1C2M/+cMbkXEAXDA4guHUMzbFeO6VkPHGsW0Do/I5rBlloiIyIBEdtCSI48S2f8XEhGnLpfrici0mMwSERHlgpQSSItsVgUF+svkepYcEJkWk1kiIqJcOBAUnqlFNi1JYeV6uR0RmQ6TWSIiolwIjYrL19sRUf5gMktERJQLfp6u+Xo7IsofTGaJiIhyoWE5XzVrQU7kerkdEZkOk1kiIqJccLC3U9Nv5aS0rzvs7UwWEhExmSUiIso9LzenLC/39XBWSawsoPDlhkCTx0Vky7hoAhERUS6kpOgwac1Ztd376dLoWM0PG3fuR/tmjdC4oh9WHLmOj/88gVnbLqGYjxtef7qM1iET2QQms0RERLmw8ugNnL4ZCU8XR7zftjK8XOxx96wOjcr5qhKEl+uXwq37cfhm83mM++sUinq6oH11f63DJrJ6LDMgIiJ6jJiEJHz1qHxgSOuKKFTAJcvbDWtTEb0aloKsmzDst6M4EnzPxJES2R4ms0RERI/x844ghETGoWRBN/RrUjbb29nZ2WFCtxpoXdUPcYkpGLjwIC7fiTZprES2hsksERFRDm5HxuHH7ZfU9icdq8LVySHH2zs62GPmq3VQq6Q37sUkou+CA7gTFW+iaIlsD5NZIiKiHEzfGIjYxGTUKe2DZ2sVy9V93J0dMb9fAzVV17XwWAxYeBAP4pOMHiuRLWIyS0RElI0zNyOx/PB1tf1pl2qqjCC3ChdwwaIBDdW0XSdvRGDIsiNITE4xYrREtonJLBERURZ0Oh0mrT0DnQ7oUqsY6pUpaPBjlCvsgXl968PVyR7bAu/g01Wn1OMSUf5hMktERJSFrYGh2H3xLpwd7DGyY9U8P06d0gUxs1ddtajC74euYcZ/F/I1TiJbx2SWiIgoAykH0C+Q0L9pWZTydX+ix2tbrSgmdK+htr/dfAG/HwzOlziJiMksERFRJr8dCMalOw9UvevgVhXz5TFfa1QGQ1pVUNujV53C1nOh+fK4RLaOySwREVEakXGJ+Gbzw1KA99pWgrebU7499oftq6BH3RJITtFh8NIjOHH9fr49NpGtYjJLRESUxg9bLyL8QQIqFPFAr4al8/WxZTaEqT1qoVmlwmq6L5myK/huTL4+B5GtYTJLRET0yLXwGCzYdUVtj+4cACeH/P+adHa0x+ze9VCtmBfCohPUogqSPBNR3jCZJSIiemTahkAkJKegSYVCaklaYyng4oiF/RughI8bgsIeYOCig4hNSDba8xFZMyazREREAI4E38M/x29C1kUY0yXAoAUS8sLPyxWLBjRQNblHg+9j2G9HVS0tERmGySwREdk8Wchg4r9n1PaLdUuienFvkzxvRT9PzO1bX5UebDpzG+P+5qIKRIZiMktERDZvzclbOBJ8H25ODviwQxWTPneDsr6Y0fMp1SK8ZF8wZm+/ZNLnJ7J0TGaJiMimxSUm44v159T22y3Ko6iXq8lj6FSzGD57tpranrY+ECuPXDd5DESWisksERHZtEV7ruBaeCyKerngreblNYujf9Nyqc//8Z8nsOtCmGaxEFkSJrNERGSzZEqsmVsvpi5o4O7sqGk8IztWRdfaxZGUosM7Sw7j9M0ITeMhsgRMZomIyGbN2HweUXFJas7XF+qW1Doc2Nvb4auXauHp8r6Ijk9C/wUHcf0eF1UgygmTWSIiskkXQ6OxZH+w2v60S4BKJM2Bi6MDfnq9PqoU9URoVDz6LTiIiJhErcMiMltMZomIyCZNXXdWzevaNsAPTSoWhjmRuWcX9G8Afy9XlXS/ufiQGqhGRJkxmSUiIpuz52IYNp8NhaO9HUZ1DoA5Ku7jhoUDGsDTxREHroRjxB/HkcJFFYgyYTJLREQ2RVpjJ645q7Zfa1QaFYoUgLmq6u+Fn/rUg5ODnZoLVx83Ef0/JrNERGRTZA7XM7ci4enqiOFtK8PcNalQGF+9VFttz98dhLk7L2sdEpFZYTJLREQ2IyYhCV9uCFTbQ1tXhK+HMyxBt6dKYFSnqmpbWmf/OX5T65CIzAaTWSIishlzdlxWMwSU8nVD3yZlYUlkQYV+j2KW+tl9l+9qHRKRWWAyS0RENuF2ZBx+2v6wi35kxwA1BZYlsbOzw9hnq6FjdX8kJKfgrcWHcP52lNZhEWmOySwREdmErzYEIjYxGfXKFETnmv6wRA72dvj2ladQv0xBRMYloe/8AwiJiNM6LCJNMZklIiKrJ8vC/nnkutoe0yVAtXJaKlcnB/zcpz7KF/HArYg49FtwAJFxXFSBbBeTWSIismo6nQ6T1pyFTgd0rV0cdUsXhKUr6OGMRf0booinC86FROGdXw4jISlF67CINMFkloiIrNqWc6HYc+kunB3t8XGHKrAWpXzdsaBfA3g4O6jX9/GfXFSBbBOTWSIislqJySmYtPbhQgMDmpZTCaA1qVHCG7N711Mrma0+dhPTHk07RmRLmMwSEZHV+vVAMC7feaDmkx3cqgKsUfPKRTD1hVpq+8ftl7B47xWtQyIyKSazRERklSJiE/HNpvNq+/12leHl6gRr9WK9khjR7uFqZuP+Po31p0K0DonIZJjMEhGRVZq19SLuxSSiol8B9GpQCtbu3dYV0athaTXQbfhvR3H4arjWIRFZfzI7ZcoUNGjQAJ6envDz80P37t0RGJhzvc/PP/+MZs2aoWDBgurUtm1bHDhwwGQxExGR+bsWHoMFux92t4/pHABHB+tvu5HpxiZ0q462AX6IT0rBwEWHcOlOtNZhERmdpp/u7du3Y8iQIdi3bx82bdqExMREtG/fHg8ePMj2Ptu2bUOvXr2wdetW7N27F6VKlVL3uXHjhkljJyIi8zV1/Tm1StYzFQujZZUisBWStH/Xqw5ql/LB/ZhEtahCaBQXVSDr5qjlk69fvz7d+YULF6oW2sOHD6N58+ZZ3mfp0qXpzs+dOxcrVqzAf//9hz59+hg1XiIiMn+Hr97DmhO3IOsijO5s2Qsk5IW7syPm962PF2bvwZW7MRiw8CB+e6sxCrho+pVPZDRmtWdHRESov76+vrm+T0xMjGrRze4+8fHx6qQXGRmp/sp95GQK+ucx1fMRaYX7OpnDAgkT/j2ttl+sWwKVirgZbX805/3dy8Uec1+vi5d/3o9TNyIx6JdD+Kl3HTjZQLkFwSr2d0Oex04nn3wzkJKSgueeew7379/Hrl27cn2/wYMHY8OGDTh9+jRcXV0zXf+///0P48ePz3T5smXL4O5uXfMNEhHZuiNhdlh0wQHO9jp8WicZ3s6waVejgJlnHJCQYoeGRVLwaoUU1WJNZO6ksfLVV19VDZ1eXl6WkcwOGjQI69atU4lsyZIlc3WfqVOnYtq0aaqOtlath3Ps5aZlVupsw8LCHvvm5OevC6kJbteuHZycrHdqGCLu66Sl+MRkdPhuN27cj8Pw1hXwrpHnlbWU/X1L4B0MWnoUsjjYuy3LY3ibilqHRBYo0cT7u+RrhQsXzlUyaxZlBu+++y7+/fdf7NixI9eJ7FdffaWS2c2bN2ebyAoXFxd1ykj+EaY++GjxnERa4L5OWpi3J1glsv5erninZSU4OTmY5HnNfX/vUKM4Jj2fhFErT2Lmtsso4euhpvAiMuf93ZDn0LR4RhqFJZFdtWoVtmzZgnLlyuXqftIaO2HCBDWArH79+kaPk4iIzNvd6Hj8sOWi2v6wQxW4OZsmkbUUkrwOa/2wRfbT1aew5dxtrUMiyjeaJrMyLdeSJUtU/arMNRsSEqJOsbGxqbeRGQpGjRqVev6LL77A2LFjMX/+fJQtWzb1PtHRnEuPiMhWfbv5AqLik1CjhBd61CmhdThmSVZBk5XCklN0GLL0KI5fu691SESWn8zOnj1b1UK0bNkSxYoVSz39/vvvqbcJDg7GrVu30t0nISEBL774Yrr7SNkBERHZnouhUVh2IFhtj+lcDfb2HOGUFZmibEqPmmheuQhiE5PVlF1XwrKf153IUmhaM5ubsWcyuCutK1ceruhCREQkJq89p1ob21UrisYVCmkdjlmTqblmvVYXr8zZq6bs6rfgAFYMaoJCBTKPLSGyFJxwjoiILNauC2HYci4UjvZ2GNWpqtbhWARZPGF+vwYoWdDt4aIKiw4hNiFZ67CI8ozJLBERWSRpjZ245oza7v10GZQvUkDrkCyGn6crFg1oCB93J1U7O/TXI0hKTtE6LKI8YTJLREQWacXh6zgXEgUvV0cMb1NJ63AsToUiBTCvb324ONpj89lQfPb36VyV/xGZGyazRERkcR7EJ+GrjYFqe2jrSijoYeNLfeVRvTK+mPFKHbUq2LL9wfhh68PpzYgsCZNZIiKyOD/tuIzQqHiU9nVHnyZltA7HonWs4Y//da2utr/aeB5/Hr6udUhEBmEyS0REFiUkIg5zdlxS2yM7VYWLIxdIeFJ9m5TF2y3Kq+2RK05gx/k7WodElGtMZomIyKJ8uSEQcYkpqF+mIDrV8Nc6HKvxSYeq6P5UcSSl6DBoyWGcuhGhdUhEucJkloiILIYkWCuPPuwG//TZamohAMofstjEtBdro0mFQniQkIz+Cw/iWniM1mERPRaTWSIisggy0l6m4pIB992eKo6nSvloHZLVcXa0x4+v10NVf0/ciYpXiyrcj0nQOiyiHDGZJSIiiyDTR+27HK4Sro86VNE6HKvl5eqEBf0boJi3Ky7deYA3Fh1CXCIXVSDzxWSWiIjMXmJyCqasPau2Bz5TDiULumsdklUr5u2mFlXwdHXEoav38N5vx9QiFUTmiMksERGZvaX7ruJy2AMU8nDG4JYVtA7HJlQu6omf+9SHs4M91p8OwYR/pcSDCS2ZHyazRERk1iJiEjHjvwtq+/12leHp6qR1SDbj6fKFMP3l2mp74Z4r+HnnZa1DIsqEySwREZm1mVsv4F5MIir5FcArDUppHY7N6Vq7OMZ0DlDbk9eew1/HbmgdElE6TGaJiMhsBd+NwaI9V9X26C4BcHTg15YW3mhWDv2bllXbHy4/jj2XwrQOiSgVjwpERGS2vlh/DgnJKWhWqTBaVi6idTg2S+bzHdulGjrX9Edisg5vLz6McyGRWodFpDCZJSIis3ToSjjWnLwFeztgTJcALpBgBosqfP3yU2hY1hdR8UnoN/8gbkXEah0WEZNZIiIyPykpOkxY83Aqrpfrl0JVfy+tQyIArk4OmNOnHir6FUBIZJxKaCNiE7UOi2wck1kiIjI7/5y4iePX7sPd2QEftK+sdTiUho+7Mxb2bwA/TxcE3o7C278cQnwSF1Ug7TCZJSIisyKrTU1bH6i2B7WoAD9PV61Dogxk0QpZJayAi6Nale3D5SdUazqRFpjMEhGRWZm/Owg37seq5VTfaFZe63AoG9WLe2N277pwtLfDP8dvqsF6RFpgMktERGYjLDoes7ZeUtsfdagCN2cHrUOiHDSrVATTXqyltn/acRkLdwdpHRLZICazRERkNr7dfB7R8UmoWcIb3Z8qoXU4lAs96pZUPzzE+H/PYN3JW1qHRDaGySwREZmFC7ejsGx/sNqWqbhkKiiyDINbVkDvp0tDpwOG/34MB6+Eax0S2RAms0REZBYmrz0LGUPUvlpRPF2+kNbhkAFkDuDxz9VA24CiSEhKwRuLDuFiaJTWYZGNYDJLRESa23nhDrYG3lGDiUZ1DtA6HMoDB3s7fN+rDuqU9lFzz/adfxChkXFah0U2gMksERFpKjlFh0mPFkh4vXEZlCvsoXVIlEcyYG9e3wbqfygzUvRbcFDVQBMZE5NZIiLS1PJD13AuJArebk4Y3qaS1uHQE/L1cMai/g1RuIAzztyKxKAlh5GYnKJ1WGTFmMwSEZFmHsQnYfqm82p7aOuKanUpsnylC7ljfr8GcHNywM4LYfhkxQnoZHQYkREwmSUiIs38tP0S7kTFo0whd/RpXFbrcCgf1Srpg1mv1VW1tCuP3MD0jQ9/tBDlNyazRESkiVsRsZiz87LaHtWpKpwd+ZVkbVpV9cPk52uo7ZlbL2Lp/qtah0RWiEcOIiLSxJcbAhGXmIKGZX3Robq/1uGQkfRsUDq1Fnrs6lPYfOa21iGRlWEyS0REJnfyeoTqetYvkCDzlJL1eq9tJfSsX0rNI/zur0dwNPie1iGRFWEyS0REJiUDgSauOaO2uz9VHLVL+WgdEhmZ/FiZ+HwNtKxSRLXGD1x0CEFhD7QOi6wEk1kiIjKpTWduY39QOFwc7fFRx6pah0Mm4uRgjx9erYuaJbwR/iAB/RYcQFh0vNZhkRVgMktERCYjS51OWXdObb/RrBxK+LhpHRKZkIeLo5qyq5SvG67ejcHAhQcRk8BFFejJMJklIiKTkdHs0r0sE+oPallR63BIA0U8XdSiCgXdnXD8egTeXXYUSVxUgZ4Ak1kiIjKJiJhEzPjvgtr+oF0VFHBx1Dok0kj5IgUwt28DVWqy5Vwoxv51iosqUJ4xmSUiIpP4fssF3I9JROWiBfBy/ZJah0Maq1emIL7vVQf2dsCvB67h+y0XtQ6JLBSTWSIiMrorYQ+waO8VtT2mSzU4OvDrh4D21f0x/rnqavvrTefxx6FrWodEFohHEyIiMrov1p9DYrIOzSsXQYvKRbQOh8zI643LYlDLCmp71MqT2BYYqnVIZGGYzBIRkVEdvBKOdadCVHfymM4BWodDZujjDlXwfJ0SSE7RYfDSIzh1I0LrkMiCMJklIiKjSUnRYeK/Z1KXNa3i76l1SGSmiyp88UItPFOxMGISktFvwUFcC4/ROiyyEExmiYjIaP45cVNNv+Th7IAP2lXWOhwyY86O9pjduy6q+nuqxRT6LjiAew8StA6LLACTWSIiMoq4xGR88WiBhMGtKqr5RYly4unqhEUDGqK4tysu33mAgYsOqv2IKCdMZomIyCjm7QrCzYg4lZgMfKac1uGQhSjq5aoSWi9XRxwJvo9hvx5VtbRE2WEyS0RE+e5OVDxmbX04b+jHHavC1clB65DIglQq6omf+9SHs4M9Np65jfH/nOaiCpQtJrNERJTvvtl8Hg8SklGrpDeeq11c63DIAjUqXwjf9HwKdnbA4r1X8dOOy1qHRGaKySwREeWr87ej8NuBYLX9aZdqsJc5uYjyoEutYmofElPXncNfx25oHRKZISazRESUryatOQspcexY3R8Ny/lqHQ5ZOKm3fuNRzfWHy49j98UwrUMiM8NkloiI8s3283fUycnBDiM7VdU6HLISozsHqFZaWUXunV8O4+ytSK1DIjPCZJaIiPKFjDifvOas2u7TuCzKFvbQOiSyElKqMv2l2qqlPyo+Cf0WHMCN+7Fah0VmgsksERHliz8OXUPg7Sh4uzlhaOuKWodDVkZmxPj59fqoXLQAbkfGo9/8A4iISdQ6LLK0ZDYpKQmff/45rl+/ni9PPmXKFDRo0ACenp7w8/ND9+7dERgYmON9Tp8+jRdeeAFly5ZVy999++23+RILERHlXXR8EqZvPK+2h7epBB93Z61DIivk7e6Ehf0boqiXCy6ERuOtXw4hPomLKtg6g5JZR0dHfPnllyqpzQ/bt2/HkCFDsG/fPmzatAmJiYlo3749Hjx4kO19YmJiUL58eUydOhX+/v75EgcRET2ZH7ddUkuQli3kjt5Pl9E6HLJixX3cVEJbwMUR+4PC8cEfx5HCRRVsmqOhd2jdurVKQqVl9EmtX78+3fmFCxeqFtrDhw+jefPmWd5HWnLlJEaOHPnY54iPj1cnvcjIh0XjkjjLyRT0z2Oq5yPSCvd123QrIg4/73w4B+hH7SvBTpeMRBtYgpT7u3YqFnbDD71q441fjmDNiVsoWsAZozpV0Tosq5Zo4v3dkOcxOJnt1KmTSiJPnjyJevXqwcMjfYH/c889h7yKiIhQf319828qFyllGD9+fKbLN27cCHd3d5iStD4T2QLu67bllwv2iE+yRwVPHRKDDmPtFdgU7u/aeaWcHX656ID5e67i3s3LaFmMLbTWsr9LT3xu2ekMXB/O3j77ygSpYU1Oztuv8ZSUFJUI379/H7t27crVfaR1+L333lMnQ1pmS5UqhbCwMHh5ecFUvy7kn9+uXTs4OTmZ5DmJtMB93facvBGBHj/uV9sr32mEmiW8YSu4v5uHn3YE4atNF9RKYTNeroVONViCaA37u+RrhQsXVg2dj8vXHPOSdBqD1M6eOnUq14lsbrm4uKhTRvKPMPXBR4vnJNIC93XbIG0hU9dfUNs96pRA3bKFYYu4v2trSOtKCI1OUEvefrjiFPx9PLhYhxXs74Y8h1lMzfXuu+/i33//xdatW1GyZEmtwyEiolzYcPo2DlwJh4ujPT7swHpF0ob0Co/rWh3tqxVFQlIK3lh0EBduR2kdFplQnpJZGQDWtWtXVKxYUZ2kPGDnzp15+lUvieyqVauwZcsWlCv3cLk6IiIyb5I0TF33cIGEN5uVVyPMibTiYG+H73rVQd3SPoiMk0UVDuJ2ZJzWYZG5JrNLlixB27Zt1eCpYcOGqZObmxvatGmDZcuWGVxaII8n95O5ZkNCQtQpNvb/V/Xo06cPRo0alXo+ISEBx44dUyfZvnHjhtq+ePGioS+FiIjy6Jd9V3HlbgwKF3DBOy0raB0OkVpUYV7fBihf2EOtDtZ3/gFExXGmCVtgcDI7adIkTJs2Db///ntqMivbMu/rhAkTDHqs2bNnq8Leli1bolixYqkneTy94OBg3Lp1K/X8zZs3UadOHXWSy7/66iu1/cYbbxj6UoiIKA/uxyTgu/8e1sqOaF9ZzfdJZA4Kejhj0YCG6kfWuZAoDFpyRPUikHUz+Ah0+fJlVWKQkZQajB492qDHys1ECtu2bcs0g4GBEzAQEVE++u6/i4iITURVf0+8XL+U1uEQpVPK1x0L+jVAzzl7setiGEauOIHpL9dWtbVknQxumZVprf77779Ml2/evFldR0RE1iso7AF+2fdwItnRnQNUrSKRualZ0huzXqur9s+VR2/gyw2BWodE5tQyO2LECFVaIHWqTZo0UZft3r1brd41Y8YMY8RIRERmQgZ9JSbr0LJKETSvXETrcIiy1bKKH6b0qImP/zyBWdsuoZiPG17nUstWyeBkdtCgQfD398f06dPxxx9/qMsCAgJUnWu3bt2MESMREZmB/Zfvqum4pDFWWmWJzJ2Uwdy6H4dvNp/HuL9OoainC9pX56IKNp3MJiUlYfLkyRgwYEC+L25ARETmKyVFh0lrH07F9UrD0qhc1FPrkIhyZVibigiJjMWvB65h6K9HsezNp1GvTEGtwyKtamYdHR3VTAaS1BIRke346/gNnLgeoWYueL9tZa3DIco1Gfg1oVsNtK7qh/hHiypcvhOtdVik5QAwmU9WFk0gIiLbEJuQjGnrHw6gGdSyAop4Zl4inMicOTrYY+ardVC7pDfuxSSi74IDuBMVr3VYpFXNbKdOnTBy5EicPHkS9erVg4eHR6YpuoiIyHrM23UZtyLiUMLHDQOf4UqNZJncnR0xr18D9Ji1B8HhMRiw8CB+e+tpeHCeZItn8H9w8ODB6u/XX3+dZVN+cnJy/kRGRESaC42Kw+xtl9T2xx2rqFWWiCyVLKYgiyq8MHsPTt6IwJBlR/Bzn/pwcjC4o5rMiMH/vZSUlGxPTGSJiKzLN5su4EFCMmqX8kHXWsW1DofoiZUr7IF5fevD1cke2wLvYMyqk1yMyZaS2cTERDUI7NSpU8aLiIiIzEJgSBR+Pxistsd2CYA9F0ggK1GndEHM7FVXTTP3x6HrmPFoeWaygWTWyckJpUuXZgssEZENkKm4UnRApxr+qF/WV+twiPJV22pFMaF7DbX97eYLqT/cyAbKDMaMGYPRo0cjPDzcOBEREZHmtgWGYsf5O3BysMPITlW1DofIKF5rVAbvtqqotkevOoWt50K1DolMMQBs5syZuHjxIooXL44yZcpkms3gyJEjeYmDiIjMRFJyCiY/WiChb+OyKFMo/XGeyJqMaF8ZNyNisfLIDQxeegS/v/00apX00TosMmYy2717d0PvQkREFuT3Q9dw/nY0fNydMLR1Ja3DITIqmYlpao9aat7ZnRfC1JRdKwc1RelC7lqHRsZKZseNG2foXYiIyEJExSXim03n1fbwNpXg7e6kdUhERufsaI/Zvevh5R/34sytSLWowopBTeDr4ax1aJSfNbMHDhzIceBXfHw8/vjjj9w+HBERmaEft19CWHSCmr5I6gmJbIUs1bywfwO1OEhQ2AMMXHRQrX5HVpTMNm7cGHfv3k097+XlhcuXL6eev3//Pnr16pX/ERIRkUncuB+LuTuD1PaoTlVVaxWRLfHzcsWiAQ3g7eaEo8H3Mey3o0iWKT3IrOX6SJVxQuGsJhjmpMNERJbry/XnEJ+UgkblfNGuWlGtwyHSREU/T8ztW1/9mNt05jbG/X2K+Y2Zs8/vImoiIrI8x67dx+pjNyGH8bHPVuPxnGxag7K+mNHzKfV5WLIvGLMeLelM5ol9SERENk5anSatOaO2n69TAjVKeGsdEpHmOtUshs+eraa2v9wQiJVHrmsdEuXHbAZnzpxBSEhI6sHv3LlziI6OVufDwsIMeSgiIjIT60+F4OCVe2qt+o86VNE6HCKz0b9pOdyKiMOcHZfx8Z8n4OfpimcqFdY6LHqSZLZNmzbp6kaeffZZ9Ve6o+RydksREVmWhKQUTF1/Tm2/1aw8inm7aR0SkVkZ2bGqSmj/OX4T7yw5rBZVqF6cvRcWmcwGBT0c4UpERNZj8d4ruHo3BkU8XfB2iwpah0Nkduzt7fDVS7KoQhz2XQ5H/wUHsXJwE5QsyEUVLC6ZlaVriYjIetx7kIDv/rugtj9sXxkeLgavo0NkE1wcHfDT6/XVogqBt6PQb8FB/PlOY/i4c1EFc8ABYERENuq7LRcQGZeEqv6eeLFeKa3DITJrMvfsgv4N4O/liouh0Xhr8WHEJXJRBXPAZJaIyAZdvhONX/ZeVdufdqkGB3uOeSB6nOI+blg4oAE8XRxx4Eo4PvjjGFK4qILmmMwSEdmgqevOISlFh1ZVinB0NpEBqvp74ac+9eDsYI+1J0Mwcc1ZrUOyeUxmiYhszL7Ld7HxzG3VGju6c4DW4RBZnCYVCuPLl2qp7fm7gzB352WtQ7JpTGaJiGyIdIlOfLRAQq+GpVCpqKfWIRFZpG5PlcCoTlXVtrTOytRdpI1cDV2tU6dOrueQPXLkyJPGRERERrL62A2cuhGJAi6OeK9tZa3DIbJobzUvr+agXbjnCkb8cRyFC7igcYVCWodlc3KVzHbv3j11Oy4uDrNmzUK1atXQuHFjddm+fftw+vRpDB482HiREhHRE4lNSMa09YFqe0iriuqLl4jyThr6xj5bDSERcVh/OgRv/XIIKwY1QWX2eJhfMjtu3LjU7TfeeAPDhg3DhAkTMt3m2rVr+R8hERHlC6nrC4mMQwkfN/RvWlbrcIisgtSef/vKU+g9dz8OXb2HvvMPYNXgpvD3dtU6NJthcM3s8uXL0adPn0yX9+7dGytWrMivuIiIKB+FRsZh9vZLavuTTlXh6uSgdUhEVkM+T3P71keFIh6q7KDfggOIjEvUOiybYXAy6+bmht27d2e6XC5zdeWvECIic/T1pvOISUjGU6V80LVWMa3DIbI6shrYwv4N1dLQ50Ki8M4vh5GQlKJ1WDbB4LUL33vvPQwaNEgN9GrYsKG6bP/+/Zg/fz7Gjh1rjBiJiOgJnL0ViT8OPSwDG/tsQK4H9BKRYUr5umNBvwbo+dNe7Ll0Fx/9eRzfvPwU7LkoiXklsyNHjkT58uUxY8YMLFmyRF0WEBCABQsW4OWXXzZGjERElEc6nQ6T156FLFLUpWYx1Cvjq3VIRFatRglvzO5dDwMWHsRfx26imLcbRj6awovMJJkVkrQycSUiMn/bzt/BzgtharWiTzryC5XIFJpXLoKpL9TCh8uP48ftl1DcxxV9GnPQpVktmnD//n3MnTsXo0ePRnh4uLpMyg5u3LiR3/EREVEeJSWnYNKjpTb7NS2L0oXctQ6JyGa8WK8kPmz/cC7ncX+fxvpTIVqHZLUMTmZPnDiBypUr44svvsCXX36pEluxcuVKjBo1yhgxEhFRHvx28BouhkajoLuTmleWiExLPne9GpaGTgcM/+0oDl992ABIGiezH3zwAfr164cLFy6km72gc+fO2LFjRz6HR0REeREVl4hvNp1X27LSl7ebk9YhEdkcGWw5oVt1tA3wQ3xSCgYuOoRLd6K1DsvqGJzMHjx4EG+//Xamy0uUKIGQEDahExGZg1nbLuHugwSUL+KBVxuV1jocIpvl6GCP73rVQe1SPrgfk6gWVQiNitM6LNtOZl1cXBAZGZnp8vPnz6NIkSL5FRcREeXR9XsxmLcrSG2P6hQAJ4c8DY8gonzi7uyI+X3ro2whd1y/F6tmOoiOT9I6LKth8BHuueeew+eff47ExMTUJvTg4GB88skneOGFF4wRIxERGWDa+kA1WXvj8oVU9yYRaa9QARcsGtAQhTyccepGJAYvPYLEZC6qoEkyO336dERHR8PPzw+xsbFo0aIFKlasCE9PT0yaNClfgiIiorw5GnwPfx+/CVkXYUwXLpBAZE7KFPLAvH4N4ObkgB3n72DUypNqLmgy8Tyz3t7e2LRpk1q+9vjx4yqxrVu3Ltq2bfuEoRAR0ZOQL8WJj6bieqFuSTV5OxGZF1lSeuardfDm4kP48/B1FPd2xQftq2gdlu0ks1Ja4ObmhmPHjqFp06bqRERE5mHdqRAcvnpPtfp8yC9HIrPVJqAoJj1fU7XMfrflIor5uKkpvMgEZQZOTk4oXbo0kpOT8/h0RERkDPFJyZi67pzafqt5efh7///UiURkfiR5Hdb64fzPn64+hS3nbmsdku3UzI4ZMybdyl9ERKS9xXuuIjg8Bn6eLni7RXmtwyGiXHi/XWW1Ulhyig5Dlh7F8WsPF6IiI9fMzpw5ExcvXkTx4sVRpkwZeHh4pLtelrUlIiLTCX+QgO+2XFDbUl4g0wARkfmTAZpTetREaFS8GhAmU3atGNQEZQunz60oZwYf8bp3727oXYiIyIi+++8CouKSEFDMCy/UK6l1OERkAJkHetZrdfHKnL1qyq5+Cw6ohFam8iIjJbPjxo0z9C5ERGQksjTmkn1X1fanXQLgYM+puIgsTQEXR8zv1wA9Zu3BlbsxGLDoEH59sxF7WXKJy8IQEVmwKWvPISlFhzZV/dC0YmGtwyGiPPLzdFWLKvi4O6na2aHLjiKJiyoYJ5mVmQy++uorNGzYEP7+/vD19U13MsSUKVPQoEEDteCCLMIgJQyBgYGPvd/y5ctRtWpVuLq6ombNmli7dq2hL4OIyOLtvXQXm8/eVq2xozoHaB0OET2hCkUKYF7f+nBxtMd/50Lx2d+nuaiCMZLZ8ePH4+uvv0bPnj0RERGBDz74AD169IC9vT3+97//GfRY27dvx5AhQ7Bv3z61EIPMY9u+fXs8ePAg2/vs2bMHvXr1wsCBA3H06FGVAMvp1KlThr4UIiKLlZIiCyScUduvNiyNin4FtA6JiPJBvTK+mPFKHbWK37L9wfhh60WtQ7K+ZHbp0qX4+eefMWLECDg6OqrEcu7cufjss89UUmqI9evXo1+/fqhevTpq166NhQsXIjg4GIcPH872PjNmzEDHjh3x0UcfISAgABMmTFArkMksC0REtmLl0Rs4fTMSni6OeK9tJa3DIaJ81LGGP/7Xtbra/mrjebVSGGXP4MrikJAQ1bUvChQooFpnxbPPPouxY8fiSegfK6dyhb1796rW4LQ6dOiA1atXZ3n7+Ph4ddKLjIxUf6UVWE6moH8eUz0fkVa4r5tGTEISvtzwcIGEd1qUg5eLPd9zDXB/J2N6tUEJXA9/gJ93XcHIFSfg6+6AZhrWxSeaeH835HkMTmZLliyJW7duqZXAKlSogI0bN6qW0YMHD8LFJe/TSKSkpOC9995TS+TWqFEjx2S6aNGi6S6T83J5dnW5UhqRkcTt7u4OU5JSCiJbwH3duNZfs8PtSAf4uuhQNOIs1q49q3VINo37OxlLNR1Qr7A9DofZY9AvhzGsRjJKetjG/h4TE2O8ZPb555/Hf//9h0aNGmHo0KHo3bs35s2bp8oD3n//feSV1M5K3euuXbuQn0aNGpWuJVdaZkuVKqVqc728vGCqXxfyz2/Xrp1aEpjIWnFfN77bkXEY+a0cJ1PwWbfa6FLTX+uQbBb3dzKF9kkpeOOXI9h7ORwLL7vjj7caoWRBN6vf3yMf9aQbJZmdOnVq6rYMApMWWun6r1SpErp27Yq8ePfdd/Hvv/9ix44dquU3JzKDwu3b6dcvlvNyeVaktTirFmP5R5j64KPFcxJpgfu68Xy39QxiE1NQp7QPutUpqVYQIm1xfydjkl3rpz718fKPe3EuJEoltrKogo+7s1Xv704GPMcTzzPbuHFj1fKZl0RWppuQRHbVqlXYsmULypUrl6vnk5bhtOSXglxORGTNztyMxPJHA0E+7VKNiSyRjfBydcKC/g1QzNsVl+48wBuLDiEuMVnrsMyGwS2zixcvzvH6Pn36GFRasGzZMvz1119qrll93au3tzfc3NxSH69EiRKq9lUMHz4cLVq0wPTp09GlSxf89ttvOHToEObMmWPoSyEishjy43/S2jOQKSe71CqGemUKah0SEZlQMW83tajCC7P34NDVe3jvt2P44bW6XPUvL8msJJMZayikSNfZ2VkNqDIkmZ09e7b627Jly3SXL1iwQE3ZJaQWV+aw1WvSpIlKgD/99FOMHj1alTfITAY5DRojIrJ0WwNDsfviXTg72GNkx6pah0NEGqhc1BM/96mPPvMOYP3pEEz49wzGdWUvjcHJ7L179zJdduHCBQwaNEjN/WqI3KxqsW3btkyXvfTSS+pERGQLEpNTMGnNwxkL+jcti1K+pp2JhYjMx9PlC2H6y7Ux9NejWLjnCor7uOKt5hVgy564ZlZI66gMDMvYaktERE/utwPBqk7O18MZg1tV1DocItJY19rF8WmXh0tYT157Dn8duwFbli/JrJDVwG7evJlfD0dERDI9TVwivtl8QW3LSl/ebhw1T0TAwGfKqZ4a8eHy49hzKQy2yuAyg7///jtTqYAsoiDLycqCB0RElH9mbb2E8AcJqFDEA70altY6HCIyE1InO7ZLNTX39NqTIXh78WEsH9QYVf1NM4e+RSez3bt3z/RmFilSBK1bt1YzDBARUf64Fh6D+buC1PbozgFwcsi3zjQisgL29nb4+uWnEBZ1AAeuhKPf/INYNaSJmvnAltjnZdnZtKfk5GQ1pZbMMFCsWDHjRElEZIOmbQhEQnIKmlQohNZV/bQOh4jMkKuTA+b0qYeKfgUQEhmnEtqI2ETYEv7MJyIyQ0eC7+Gf4zchM+6M6RJg81PvEFH2fNydsbB/A/h5uiDwdhTe/uUQ4pNsZ1EFg8sMZLWv3Pr6668NfXgiIpsnYxEm/ntGbb9YtySqF/fWOiQiMnMlC7qrVcJ6/rQP+y6H48PlJzCj51OqFMHaGZzMHj16VJ1ksYQqVaqoy86fPw8HBwfUrVs39XZsRSAiyps1J2/hSPB9uDk54MMOD4+zRESPU724N2b3rov+Cw6qnh1Z/lbq7a2dwcls165d1dKzixYtQsGCBVMXUujfvz+aNWuGESNGGCNOIiKbIF2DX6w/p7bfblEeRb1ctQ6JiCxIs0pFMO3FWvjgj+OYs+OySmj7Ny0Ha2ZwzazMWDBlypTURFbI9sSJEzmbARHRE1q05wquhceiqJcL3mpeXutwiMgC9ahbEh896tX5/N8zWHfyFqyZwclsZGQk7ty5k+lyuSwqKiq/4iIisjkyn+z3Wy6q7Q/bV4G7s8GdZ0REyuCWFdD76dLQ6YDhvx/DwSvhsFYGJ7PPP/+8KilYuXIlrl+/rk4rVqzAwIED0aNHD+NESURkA2ZsPo+ouCRUK+aFF+qW1DocIrJgdnZ2GP9cDbSrVhQJSSl4Y9EhXAy1zkZHg5PZH3/8EZ06dcKrr76KMmXKqJNsd+zYEbNmzTJOlEREVu5iaDSW7A9W27Lmui2MQCYi43Kwt8N3r9RBndI+au7ZvvMPIjQyDrD1ZNbd3V0lrXfv3k2d2SA8PFxd5uHhYZwoiYis3NR1Z5GcokPbAD80qVhY63CIyEq4OTtgXt8GKFfYAzfux6LfgoOIirOuRRXyvGiCJK61atWCt7c3rl69qlYDIyIiw+25GIbNZ0PhaG+HUTYwjQ4RmZavhzMW9W+IwgWcceZWJAYvPYLE5BTbS2bnz5+faRGEt956C+XLl0fNmjVRo0YNXLt2zRgxEhFZLWmNnbjmrNp+rVFpVChSQOuQiMgKlS7kjvn9GsDd2QE7L4ThkxUn1AItNpXMzpkzJ910XOvXr8eCBQuwePFiHDx4ED4+Phg/fryx4iQiskorj1xXLSWero4Y3ray1uEQkRWrVdIHP7xaV9XSrjxyA9M3nodNJbMXLlxA/fr1U8//9ddf6NatG1577TW18tfkyZPx33//GStOIiKrE5OQhC83BKrtoa0rqq5AIiJjalXVD5Ofr6G2Z269iKX7r8JmktnY2Fh4eXmlnt+zZw+aN2+eel7KDUJCQvI/QiIiKyWr84RGxaOUrxv6NimrdThEZCN6NiiN4W0qqe2xq09h05nbsIlkVqbgOnz4sNoOCwvD6dOn0bRp09TrJZGVwWBERPR4tyPj8NP2y2p7ZMcAuDg6aB0SEdmQ99pWQs/6pZCiA4b+egRHg+/BUuV6eZm+fftiyJAhKondsmULqlatinr16qVrqZVBYERE9HhfbQhEbGIy6pUpiM41/bUOh4hscFGFic/XwO2oOGwLvIOBiw5hxaAmagovq22Z/fjjj/Hmm2+qlb9cXV2xfPnydNfv3r0bvXr1MkaMRERW5fTNCPx55LraHtMlQH2pEBGZmpODvRoQVrOEt1pOu9+CAwiLjofVJrP29vb4/PPP1SIJ69atQ0BA+rkQJbmVJW2JiCh7MhXOpDVn1XrpXWsXR93S/z9LDBGRqXm4OKopu6R2/+rdGAxceFANTrWJRROIiMhwW86FYs+lu3B2tMfHHapoHQ4REYp4uqhFFQq6O+H49QgMWXoESRa0qAKTWSIiE5EVdyatfbhAwoCm5VDK113rkIiIlPJFCmBu3wZwcbTH1sA7GPvXKYtZVIHJLBGRifx6IBiX7zxQ88kOblVB63CIiNKRAanf96oDezs5Xl3D91suwhIwmSUiMoGI2ER8s+nhajvvt6sML1cnrUMiIsqkfXV/jO/2cHaqrzedxx+Hrqllt/cHheNwmJ36K+ctcmouIiLKu1lbL+JeTCIq+hVArwaltA6HiChbrz9dBjfvx2L2tksYueIEpqw9q45fgAMWXziEYt6uGNe1GjrWKAaLTGaTk5OxcOFCtXRtaGgoUlLSFwjLHLRERPT/roXHYMHuK2p7TOcAODqwU4yIzNvHHarg8NV7OBAU/iiR/X8hEXEYtOQIZveuaxYJrcHJ7PDhw1Uy26VLF7VIAudHJCLK2dT155CQnIJnKhZGyypFtA6HiOixpJIg+G5MltdJkYFkf+P/OYN21fzhIEW2lpTM/vbbb/jjjz/QuXNn40RERGRFpGVjzYlbkN/9oztzgQQisgwHgsIREhmX7fWS0N6KiFO3a1yhELRkcF+Xs7MzKlasaJxoiIisiExrM3HNGbX9cr1SqFbcS+uQiIhyJTQqLl9vZ1bJ7IgRIzBjxgyLmXuMiEgr/564haPB9+Hu7IAR7StrHQ4RUa75ebrm6+3Mqsxg165d2Lp1q1rStnr16nBySj+9zMqVK/MzPiIiixSXmIwv1p9T2++0qAA/L+0P+EREudWwnK+atUAGe2XVfCkFU/7erup2FpfM+vj44PnnnzdONEREVmLhniu4fi8W/l6ueLNZea3DISIyiAzqkum3ZNYCSVzTJrT6yn+5XuvBX3lKZhcsWGCcSIiIrMTd6Hj88GjlnA87VIGbs4PWIRERGUym3ZLpt2TWAhnspedv6fPMEhFRzr7dfAFR8UmoUcILPeqU0DocIqI8k4RVpt/aezEUG3fuR/tmjdC4op9ZtMg+UTL7559/qum5goODkZCQkO66I0eO5FdsREQW52JoFJYdCFbbYzpXg70ZHfCJiPJCEtdG5Xxx96xO/TWnRDZPsxl899136N+/P4oWLYqjR4+iYcOGKFSoEC5fvoxOnToZJ0oiIgsxee05tW55u2pFNZ97kYjIFhiczM6aNQtz5szB999/r+ac/fjjj7Fp0yYMGzYMERERxomSiMgC7L4Yhi3nQuFob4dRnapqHQ4RkU0wOJmV0oImTZqobTc3N0RFRant119/Hb/++mv+R0hEZAGkNXbimrNqu/fTZVC+SAGtQyIisgkGJ7P+/v4IDw9X26VLl8a+ffvUdlBQEBdSICKbteLwdZy9FQkvV0cMb1NJ63CIiGyGwcls69at8ffff6ttqZ19//330a5dO/Ts2ZPzzxKRTXoQn4SvNgaq7aGtK6Ggh7PWIRER2QyDZzOQetmUlBS1PWTIEDX4a8+ePXjuuefw9ttvGyNGIiKz9tOOywiNikdpX3f0aVJG63CIiGyKwcmsvb29Oum98sor6kREZItkqcc5Oy6p7ZGdqsLFkQskEBGZdZmB2LlzJ3r37o3GjRvjxo0b6rJffvkFu3btyu/4iIjM2pcbAhGXmIL6ZQqiUw1/rcMhIrI5BiezK1asQIcOHdRMBjLPbHx8vLpcpuWaPHmyMWIkIjJLp25EYOXR62r702erwc7OvCYSJyKyBQYnsxMnTsSPP/6In3/+GU5OTqmXN23alKt/EZHNkNlbJq05C5nEpdtTxfFUKR+tQyIiskkGJ7OBgYFo3rx5psu9vb1x//79/IqLiMisbT4bir2X78LZ0R4fdaiidThERDYrT/PMXrx4MdPlUi9bvnz5/IqLiMhsJSanYMrahwskDHymHEoWdNc6JCIim2VwMvvmm29i+PDh2L9/v6oPu3nzJpYuXYoPP/wQgwYNMk6URERmZOm+q7gc9gCFPJwxuGUFrcMhIrJpBk/NNXLkSDXPbJs2bRATE6NKDlxcXFQyO3ToUONESURkJiJiEzHjvwtq+/12leHp+v9jB4iIyAJaZqU1dsyYMWpJ21OnTqnlbO/cuYMJEyYY/OQ7duxA165dUbx4cfW4q1evfux9fvjhBwQEBKjZFKpUqYLFixcb/LxERHn1w9aLuBeTiEp+BfBKg1Jah0NEZPMMbpnVc3Z2RrVq1Z7oyR88eIDatWtjwIAB6NGjx2NvP3v2bIwaNUrNpNCgQQMcOHBAlT0ULFhQJcVERMYUfDcGC3dfUdujuwTA0SFPU3UTEZEWyawknLkxf/78XD95p06d1Cm3ZGEGWTK3Z8+e6rwMODt48CC++OILJrNEZHRfrD+HhOQUNKtUGC0rF9E6HCIiMiSZXbhwIcqUKYM6deqo+RW1IAs0uLq6prtMyg2khTYxMTHdvLdp76Nf2EFERkaqv3J7OZmC/nlM9XxEWrHmff3w1XtYc/IW7O2AT9pXQlJSktYhkcaseX8n0np/N+R5cp3MykwFv/76K4KCgtC/f3+1nK2vry9MSVYemzt3Lrp37466devi8OHD6ry84LCwMBQrVizTfaZMmYLx48dnunzjxo1wdzftdDqbNm0y6fMRacXa9vUUHfDtKQcZNYBGRVJw6chOXNI6KDIb1ra/E5nD/i6TDOSWnc6AZlZp4Vy5cqUqJdizZw+6dOmCgQMHon379k+8jKPcf9WqVSpRzU5sbCyGDBmiyg0k7KJFi6qketq0aQgJCVHnc9MyW6pUKZX8enl5wRQk2ZZ/frt27bJsPSayFta6r/9z4hY+WH4S7s4O2PzeMyji6aJ1SGQGrHV/JzKH/V3ytcKFCyMiIuKx+ZpBA8BkCq5evXqp09WrV1XpweDBg1V32+nTp1GgQAEYk5QUSCL9008/4fbt26olds6cOfD09ESRIkWyjVlOGck/wtQHHy2ek0gL1rSvxyUmY/qmhwvFDGpRAcV9jXucI8tjTfs7kbns74Y8R55nM7C3t1etqdJCmpycDFOSF1iyZEm1/dtvv+HZZ59V8RAR5bcFu6/gxv1YFPN2xRvNuMohEZG5MSgDlO56qZuVJubKlSvj5MmTmDlzJoKDg/PUKhsdHY1jx46pk5B6XNmWxxMyDVefPn1Sb3/+/HksWbIEFy5cUIO+XnnlFTXX7eTJkw1+biKixwmLjlfzyoqPOlSBm7PUzRIRkTnJdcuslBNIK6jUm8o0XZLUSi3Dkzh06BBatWqVev6DDz5Qf/v27atKGG7dupWa2AppAZ4+fToCAwNV66zcV2p3y5Yt+0RxEBFl5dvN5xEdn4SaJbzR/akSWodDRERPksz++OOPKF26tJrbdfv27eqUFRkgllstW7bMcZovSWjTkpW/jh49muvHJyLKqwu3o7Bs/8Mf02O6BMBe5uQiIiLLTWalu/9JZywgIrIUk9eeVVNyta9WFE+XL6R1OERElB+LJhAR2YKdF+5ga+AdONrbYVTnAK3DISKiHHAKACKiNJJTdJi05qzafr1xGZQr7KF1SERElAMms0REafx5+BrOhUTB280Jw9tU0jocIiJ6DCazRESPPIhPwlcbz6vtoa0rwsfdWeuQiIjoMZjMEhE98tP2S7gTFY8yhdzRpzGn/CMisgRMZomIANyKiMWcnZfV9qhOVeHsyMMjEZEl4NGaiAjAlxsCEZeYgoZlfdGhur/W4RARUS4xmSUim3fyegRWHrmRukAC59QmIrIcTGaJyKbJKoQT15xR292fKo7apXy0DomIiAzAZJaIbNqmM7exPygcLo72+KhjVa3DISIiAzGZJSKblZCUginrzqntN5qVQwkfN61DIiIiAzGZJSKbtXT/VQSFPUDhAs4Y1LKi1uEQEVEeMJklIpsUEZOIGf9dUNsftKuCAi6OWodERER5wGSWiGzS91su4H5MIioXLYCX65fUOhwiIsojJrNEZHOu3n2ARXuvqO0xXarB0YGHQiIiS8UjOBHZnKnrziExWYfmlYugReUiWodDRERPgMksEdmUg1fCse5UCOztgDGdA7QOh4iInhCTWSKyGSkpOkz89+ECCT0blEYVf0+tQyIioifEZJaIbMY/J27i+PUIeDg74IN2lbUOh4iI8gGTWSKyCXGJyfji0QIJg1tVRBFPF61DIiKifMBklohswrxdQbgZEYfi3q4Y+Ew5rcMhIqJ8wmSWiKzenah4zN52SW1/3LEqXJ0ctA6JiIjyCZNZIrJ632w+j+j4JNQq6Y3nahfXOhwiIspHTGaJyKqdvx2F3w4Eq+1Pu1SDvczJRUREVoPJLBFZtUlrziJFB3Ss7o+G5Xy1DoeIiPIZk1kislo7zt/B9vN34ORgh5GdqmodDhERGQGTWSKySskpOtUqK/o0LouyhT20DomIiIyAySwRWaU/Dl1D4O0oeLs5YWjrilqHQ0RERsJkloisjsxcMH3jebU9rE0l+Lg7ax0SEREZCZNZIrI6P267hLDoeJQt5I7Xny6jdThERGRETGaJyKrcvB+Ln3deVtsjOwXA2ZGHOSIia8ajPBFZlS83BCI+KUVNw9WhelGtwyEiIiNjMktEVuPE9ftYdfSG2v60SwDs7LhAAhGRtWMyS0RWQafTYeKjqbh61CmBWiV9tA6JiIhMgMksEVmFDadv40BQOFwc7fFhhypah0NERCbCZJaILF5CUgqmrnvYKvtms/Io7uOmdUhERGQiTGaJyOL9su8qrtyNQeECLninZQWtwyEiIhNiMktEFu1+TAK++++C2h7RvjIKuDhqHRIREZkQk1kismjf/XcREbGJqOrviZfrl9I6HCIiMjEms0Rksa6EPcAv+66o7dGdA+Bgz6m4iIhsDZNZIrJYU9edQ2KyDi2rFEHzykW0DoeIiDTAZJaILNL+y3ex/nQIpDFWWmWJiMg2MZklIouTkqLDpLUPp+J6pWFpVC7qqXVIRESkESazRGRx/jp+AyeuR6iZC95vW1nrcIiISENMZonIosQlJuPL9YFqe1DLCiji6aJ1SEREpCEms0RkUebtCsLNiDiU8HHDwGfKaR0OERFpjMksEVmM0Kg4zNp6UW1/3LEKXJ0ctA6JiIg0xmSWiCzGN5su4EFCMmqX9EbXWsW1DoeIiMwAk1kisgiBIVH4/WCw2v702Wqw5wIJRETEZJaILIVMxZWiAzrV8EeDsr5ah0NERGaCySwRmb1tgaHYcf4OnBzsMLJTVa3DISIiM8JklojMWlJyCiY/WiChb+OyKFPIQ+uQiIjIjGiazO7YsQNdu3ZF8eLFYWdnh9WrVz/2PkuXLkXt2rXh7u6OYsWKYcCAAbh7965J4iUi0/vj0HWcvx0NH3cnDG1dSetwiIjIzGiazD548EAlpj/88EOubr9792706dMHAwcOxOnTp7F8+XIcOHAAb775ptFjJSLTi4pLxNebHi6QMLxNJXi7O2kdEhERmRlHLZ+8U6dO6pRbe/fuRdmyZTFs2DB1vly5cnj77bfxxRdfZHuf+Ph4ddKLjIxUfxMTE9XJFPTPY6rnI9JKfu/rs7ZcQFh0AsoWcsfLdYvzM0Rmhcd2siWJJt7fDXkeTZNZQzVu3BijR4/G2rVrVRIcGhqKP//8E507d872PlOmTMH48eMzXb5x40ZVqmBKmzZtMunzEWklP/b18Hhg7lFZFMEObQtHYfPG9fkSG1F+47GdbMkmE+3vMTExub6tnU6n08EMSM3sqlWr0L179xxvJ6UFUicbFxeHpKQkVXO7YsUKODk55bpltlSpUggLC4OXlxdM9etC/vnt2rXLNk4ia5Cf+/qI5Sfx94lbaFi2IJYMqK+OEUTmhMd2siWJJt7fJV8rXLgwIiIiHpuvWVTL7JkzZzB8+HB89tln6NChA27duoWPPvoI77zzDubNm5flfVxcXNQpI/lHmPrgo8VzEmnhSff1Y9fuq0RW8tfPulaHs7NzvsZHlJ94bCdb4mSi/d2Q57CoZFZKBpo2baoSWFGrVi14eHigWbNmmDhxoprdgIgsm3QWTVpzRm0/X6cEapTw1jokIiIyYxY1z6zUT9jbpw/ZwcEh9QuQiCzfhtMhOHjlHlyd7PFRhypah0NERGZO02Q2Ojoax44dUycRFBSktoODH66/PmrUKDUVl57Ux65cuRKzZ8/G5cuX1VRdMrNBw4YN1Vy1RGTZEpJSMGXdObX9VrPyKObtpnVIRERk5jQtMzh06BBatWqVev6DDz5Qf/v27YuFCxeqmlh9Yiv69euHqKgozJw5EyNGjICPjw9at26d49RcRGQ5Fu+9gqt3Y1DE0wVvt6igdThERGQBNE1mW7ZsmWN5gCS0GQ0dOlSdiMi63HuQgO/+u6C2P2xfGR4uFlXST0REGrGomlkisl7fbbmAyLgkVPX3xIv1SmkdDhERWQgms0Skuct3ovHL3qtq+9Mu1eBgzzlliYgod5jMEpHmpq47h6QUHVpVKYJnKhXWOhwiIrIgTGaJSFP7Lt/FxjO3VWvs6M4BWodDREQWhsksEWkmJUWHiY8WSOjVsBQqFfXUOiQiIrIwTGaJSDOrj93AqRuRKODiiPfaVtY6HCIiskBMZolIE7EJyZi2PlBtD2lVEYULuGgdEhERWSAms0Skibk7LyMkMg4lfNzQv2lZrcMhIiILxWSWiEwuNCoOs7dfUtufdKoKVycHrUMiIiILxWSWiEzu643nEZOQjKdK+aBrrWJah0NERBaMySwRmdTZW5H449A1tT322QDY2XGBBCIiyjsms0RkMjqdDpPXnkWKDuhSsxjqlfHVOiQiIrJwTGaJyGS2nb+DnRfC4Oxgj086VtU6HCIisgJMZonIJJKSUzBpzVm13a9pWZQu5K51SEREZAWYzBKRSfx28BouhkajoLuTmleWiIgoPzCZJSKji4pLxDebzqttWenL281J65CIiMhKMJklIqObte0S7j5IQPkiHni1UWmtwyEiIivCZJaIjOr6vRjM2xWktkd1CoCTAw87RESUf/itQkRGNW19IBKSUtC4fCG0DfDTOhwiIrIyTGaJyGiOXbuPv4/fhKyLMKYLF0ggIqL8x2SWiIy2QMLEf8+o7RfqlkSNEt5ah0RERFaIySwRGcW6UyE4dPUe3Jwc8GH7KlqHQ0REVorJLBHlu/ikFExdd05tv9W8PPy9XbUOiYiIrJSj1gEQkXVITtFhf1A4DofZYd/acwgOj4GfpwveblFe69CIiMiKMZkloie2/tQtjP/nDG5FxAFwkAm51OUdqvvD3ZmHGSIiMh6WGRDREyeyg5YceZTIprdk31V1PRERkbEwmSWiPJcVhEbG4dPVp6DL4XbSYiu3JSIiMgb2/xERUlJ0iIxLRPiDBNyLSUD4g0Tce5CA8JiH59W2XKbfjklARGwidI/JUeVqabE9EBSOxhUKmerlEBGRDWEyS2SF87tGxyfh3oPEh8moSkT1SWqav2mul8uM2XgaGpW5BIGIiCg/MJklMvPENDYxOVPymTE5levSnk9Mzltm6uniCB8PJ/i6O6Ogh/P///VwRkF3+ev06O/Dy8/dikTveQce+7h+npyai4iIjIPJLJEJxSUm435MYjYtpdJ9/6h7P83lMmdrXshiBQ+TzjQJaJpE9GGi6qTOy7aPuzOcHQ0ro29coTCKebsiJCIuy7pZWbxW5phtWM43T6+BiIjocZjMEuVRYnJKaqto5qQ06+Q0JiE5T8/l7GD//0lohuS0oLtThtbTh3/dnGWKLONysLfDuK7V1GwGkrimTWjlvJDr5XZERETGwGSW6NHI/Pv6wU76ltO0SWmGbnz5GxWXlKfnksQuqy77/+/Sz9yS6u7sADs780wIO9Yohtm966aZZ/YhaZGVRFauJyIiMhYms2SVI/Ml0QzPsqU07yPzsyL5pb51NOtu/P9PTtXJwxlero5mm5jmlSSs7ar5Y+/FUGzcuR/tmzVC44p+bJElIiKjYzJLFjsyP9MUUqmXJ+Z5XlNvN31S+igBzWHwkySrXm5OTNgekfehUTlf3D2rU3/5vhARkSkwmSWTik1IznpEfmpCmnlwVF5H5hdwcXw4wCmXI/N93Jzg6MB1RIiIiCwJk1nKs/ik5CyTT31yKi2kGZPVuEQjjsxPMxDKx90JLo7GHwBFRERE2mIya2TS3b0/KByHw+xQSFZBMtM6QhmZL1NGZTkiP4vBT3L5gyccmS8JZ6b6Ug1H5hMREZHlYTJrROtP3UozwtsBiy8cUnNyGnuEtyTQMqAp2+mi0iSn9x/9jeTIfCIiIrJATGaNmMjK3JsZqz1lcnm5XKYyyk1Cqx+Zr5LPTLWm6Qc/6f/eN9LI/KxaUq1xZD4RERFZDiazRmoZlRbZrPJJ/WWfrj4FJwf7DC2o+TsyXxLNzC2lHJlPRERE1oPJrBEcCApPN3l8VsKiEzBw0SGjjMz3edSKKskyERERkTVjMmsEoVE5J7J6JQu6oVxhjww1pU6ZklWOzCciIiLKGpNZI/DzdM3V7b58sTYaVyhk9HiIiIiIrBX7oY2gYTlfNWtBdtWncrlcL7cjIiIiorxjMmsEMohKpt8SGRNa/Xm5noOtiIiIiJ4Mk1kjkWm3ZPotf+/0JQdyPrfTchERERFRzlgza0SSsLar5o+9F0Oxced+tG/WyGxXACMiIiKyRExmjUwS10blfHH3rE79ZSJLRERElH9YZkBEREREFovJLBERERFZLCazRERERGSxNE1md+zYga5du6J48eKws7PD6tWrc7x9v3791O0ynqpXr26ymImIiIjIfGiazD548AC1a9fGDz/8kKvbz5gxA7du3Uo9Xbt2Db6+vnjppZeMHisRERERmR9NZzPo1KmTOuWWt7e3OulJS+69e/fQv39/I0VIRERERObMoqfmmjdvHtq2bYsyZcpke5v4+Hh10ouMjFR/ExMT1ckU9M9jqucj0gr3dbIl3N/JliSaeH835HksNpm9efMm1q1bh2XLluV4uylTpmD8+PGZLt+4cSPc3d1hSps2bTLp8xFphfs62RLu72RLNplof4+JibH+ZHbRokXw8fFB9+7dc7zdqFGj8MEHH6RrmS1VqhTat28PLy8vk/26kH9+u3bt4OTkZJLnJNIC93WyJdzfyZYkmnh/1/ekW20yq9PpMH/+fLz++utwdnbO8bYuLi7qlJH8I0x98NHiOYm0wH2dbAn3d7IlTiba3w15DotMZrdv346LFy9i4MCBeUqEDc348+PXjDSXy3PygEfWjPs62RLu72RLEk28v+vzNH3eZrbJbHR0tEpK9YKCgnDs2DE13Vbp0qVVicCNGzewePHiTAO/GjVqhBo1ahj8nFFRUeqvlBoQERERkfmSvC3tTFZml8weOnQIrVq1Sj2vr23t27cvFi5cqOaSDQ4OTnefiIgIrFixQs05mxeyQIPMT+vp6akWXDAFfZ2uPK+p6nSJtMB9nWwJ93eyJZEm3t+lRVYSWcnbHsdOl5v2W3riHUB+VUgizgMeWTPu62RLuL+TLYk04/1d0xXAiIiIiIieBJNZIiIiIrJYTGZNQKYGGzduXJZThBFZE+7rZEu4v5MtcTHj/Z01s0RERERksdgyS0REREQWi8ksEREREVksJrNEREREZLGYzBKRSV25ckUtWCKr/RFpRfbB1atXax0Gtm3bpmK5f/9+treRRYR8fHxMGhfZnjlz5qhFEezt7fHtt9/m+XG02F+ZzOZSv3791AFHTrImcbly5fDxxx8jLi7uib/AczqYlS1b9ol2KiJD6ffz7E7/+9//tA6R6LHu3LmDQYMGqaXRZfS1v78/OnTogN27d6vrZYXJTp06aR0mmjRpomJ53HKdRE+yv+dmQYR3330Xn3zyCW7cuIG33noLLVu2xHvvvQdLoOlytpamY8eOWLBgARITE3H48GG17K58uX/xxRdah0aUb+SLVe/333/HZ599hsDAwNTLChQooFFkRLn3wgsvICEhAYsWLUL58uVx+/Zt/Pfff7h79666Xr7szYGzs7PZxELWu78/TnBwsMptunTpgmLFisHSsGXWAPpfO9IM3717d7Rt2xabNm1S16WkpGDKlCmqxdbNzQ21a9fGn3/+qXXIRAaTfVx/ktYi+cGmP//gwQO89tprKFq0qEpqGzRogM2bN2fqTZg8eTIGDBgAT09P1VIg3VcZXb58Ga1atYK7u7v6vOzdu9eEr5KsmfRy7dy5UzU0yD5WpkwZNGzYEKNGjcJzzz2XZZnBnj178NRTT8HV1RX169dX16XtTdP3oG3YsAF16tRRx/nWrVsjNDQU69atQ0BAgFri89VXX0VMTEzq48bHx2PYsGHw8/NTj/3MM8/g4MGDOfbMSTetfG7ks/H888/nOiEh23Q/F/u7JKvdunVTx23ZT19++WWV8Or3t5o1a6ptSYRlf5Te6O3bt2PGjBmpvXLSw6zfX9esWYNatWqpffrpp5/GqVOnso1PHktyprSkxVdafvUkX5IY5HNVqFAhlV/J901uMZnNI/nHycFPflULSWQXL16MH3/8EadPn8b777+P3r17q52ByFpER0ejc+fO6hf/0aNHVW9F165d1YEyrenTp6uEQG4zePBg1f2VtnVXjBkzBh9++KFKFipXroxevXohKSnJxK+IrJF8YctJElJJJnPTxSr7sXyZHjlyBBMmTFDdrVmRMpuZM2eq4/+1a9dUUiClYMuWLVNf8Bs3bsT333+fenspR1uxYoVqMZPHrlixour+DQ8Pz/Lx9+/fj4EDB6ouX/lsSHIyceLEJ3g3yNb395SUFJXIyj4nOYk0wkljQs+ePdX18lffKHHgwAHVOydJbOPGjfHmm2+q83KShjy9jz76SB3n5YdZkSJF1OdHWnbzQh5bjv/SAHL27FmVMPfo0QMGLYMgiybQ4/Xt21fn4OCg8/Dw0Lm4uMg7rLO3t9f9+eefuri4OJ27u7tuz5496e4zcOBAXa9evdR2UFCQus/Ro0czPfbWrVvVdffu3ct0XZkyZXTffPONEV8ZUfYWLFig8/b2zvE21atX133//ffp9tnevXunnk9JSdH5+fnpZs+ene6zMHfu3NTbnD59Wl129uxZo7wOsj1ybC5YsKDO1dVV16RJE92oUaN0x48fT71e9rdVq1apbdk3CxUqpIuNjU29/ueff053zNYfpzdv3px6mylTpqjLLl26lHrZ22+/revQoYPajo6O1jk5OemWLl2aen1CQoKuePHiumnTpmV5/JfvjM6dO6d7LT179nzs55Bs25857O8bN25U+UtwcHCmY+6BAwfUednP5bwcn/VatGihGz58eLrn0e+vv/32W+pld+/e1bm5uel+//33LL83JH/q1q1buseRx5XHF4cPH1aPeeXKlTy/frbMGkB+IcsvZfnlLPWy/fv3V3UqFy9eVN1K7dq1S/2FJCdpqb106ZLWYRPla8ustKZKl6qMVpX9XH5JZ2yZle4nPX2ZgnTHZncbfY1WxtsQ5ZUcm2/evIm///5b9SBIa0/dunVVl2pG0mug7zLVk27arKTdb6XcRkoBpGs27WX6/ViO/9Ja1bRp09TrZQCxPLZ8brIilzdq1CjdZdJCRpTX/f3s2bOqVTVty2q1atXUMTy7/fBx0u6Tvr6+qFKlSp4fS8rM2rRpo3pGXnrpJfz888+4d++eQY/BZNYAHh4eqotI3vj58+erpHbevHnqC15IF5Mku/rTmTNnclU3K/UrIiIiIstaGI5yJXMhieyqVatUTazUaMl+LgcgGXiQlnxhpyUJrXR1ZXcbuV5kvA3Rk5DkVBoZxo4dq8oCpHZP1pZ/Ehn329zs60SWur/nB5nqK2PJQNqSBAcHB1X6ILXnkmRLmY4kx0FBQbl/jnyJ1AbJP2f06NH49NNP1Zsvg8OkdUqS3bSntL+EslOpUiX1eDJDQlpS0yIJrtQTEpkDmeZFDpAyKEWSWGlxlUEBRJZAjtVZDSqRL86TJ0+mqzdMO0grrypUqKDGVaSdHkm+xOWxJZasSK+HNJSktW/fvieOhWx3fw8ICFD13XLSk8Y2aSzLbj8Usu8mJydneV3afVJaUc+fP6+eJytSU5t2lhyRcZpS+REoPRjjx49XYy3kuaXhJLc4NdcTkOZwKYL+6aefVIuVDPqSX+QyWlWSUDmASaurlCToZRwEI6pXr4433ngDI0aMgKOjo0oSZKeTAQgySlDmISQyB/LDa+XKlarYXw4+0gLAVigyNzL6X47PMqBEygJkVo1Dhw5h2rRpaiBMRjIDgQxIlLk1R44cqRomvvrqq3S9BnntzZPBj/I9IV2xMkOBxCBlaTLIKysy84F8qcvzS6wye8L69evzHANZv7uP2d9lZgDJK2QmGhmsKANtZWBuixYt1EDd7MjMNPLDShospKRM9mG9zz//XM06IGU18tkpXLhwphkL9GTWjy+//FKVXkp5wpIlS9QgepkVRMhzyKDi9u3bq1k/5LzMm5tdcpwVJrNPQBJPGXEqO4w0h8uvD5nVQFpUpRZF6lWk9TatV155JdPjSOIqIwenTp2qEtirV6+qFi/pLpg0adITHUyJ8tPXX3+tDpjyA0sOXrK/ykhwInMiX7xSd/rNN9+k1q1KL5mMzM54TBbS6PDPP/+oxFOm55IvfplfWZLctHW0eSHHdfnB9/rrryMqKkolD5KgFixYMMvbSwOG1AxK97DEIImI9ADKDAtEednf7ezs8Ndff2Ho0KFo3ry56gmWutq0s25kRRrppDFOWm9jY2PTdfvLfj18+HBcuHBBfWbk86Of3Skjmb1DGj70C03Jd0ifPn1Ub4j+87djxw6VaMv3iUwtJjMlGLKoiZ2MAsv1rYmIiGzA0qVL1SBf6WWTuS+JCGpgmQyGl9ICc1pimS2zRERk86QLVGYlKFGiBI4fP656HWQOWSayROaPySwREdm8kJAQ1a0vf2WqOKlBlDIvIjJ/LDMgIiIiIovFqbmIiIiIyGIxmSUiIiIii8VkloiIiIgsFpNZIiIiIrJYTGaJiIiIyGIxmSUiMjGZ/klW+JPlTs1p4nFj+t///qdWCiIiym9MZonIaskyjjmdJMHSgiw7eevWLRw7dgznz5/P9xV6snqtsiSqqcjzrV69OtPSmLL+OhFRfuOiCURktSRh1Pv999/VpPiBgYHp1jTXkym3k5OT4eho/MOirJ9er149VKpUKc+PkZCQkO1a6EJep6x5ntVr1YI8v9YxEJF1YsssEVktf3//1JO3t7dqMdSfP3fuHDw9PbFu3TqVWLq4uGDXrl0q0ezWrRuKFi2qkq8GDRpg8+bN6R63bNmymDx5MgYMGKAeo3Tp0pgzZ066RPPdd99VK0m5urqiTJkymDJlSup9V6xYoZZPlXj69eunLr9//z7eeOMNFClSRCWhrVu3VsuqZuymnzt3LsqVK6ceNyd+fn7pXr+8Fn2rrTyXnrQOy2VXrlxR5xcuXKhKHzZs2ICAgAB1v44dO6b7YSDmz5+P6tWrq/dNXqe8Xv3rE88//7x6XP35jGUGKSkp+Pzzz1GyZEn1GHLd+vXrU6+XeOT+K1euVGvBu7u7o3bt2ti7d68BewAR2QIms0Rk00aOHImpU6fi7NmzqFWrFqKjo9G5c2fVJX706FGVyHXt2hXBwcHp7jd9+nTUr19f3Wbw4MEYNGhQaqvvd999h7///ht//PGHumzp0qWpSd3BgwfVY7788ssqQZwxY4a6XJZPDQ0NVcn14cOHUbduXbRp0wbh4eGpz3nx4kWVCEuCJ0moscTExOCrr77CL7/8gh07dqjXLmUCerNnz8aQIUPw1ltv4eTJk+q1VqxYMfX1iQULFqjXpz+fkbxueQ/leU6cOIEOHTrgueeew4ULF9LdbsyYMeq55fVWrlwZvXr1QlJSktFeOxFZIFnOlojI2i1YsEDn7e2den7r1q2ylLdu9erVj71v9erVdd9//33q+TJlyuh69+6dej4lJUXn5+enmz17tjo/dOhQXevWrdXlWenWrZuub9++qed37typ8/Ly0sXFxaW7XYUKFXQ//fST2h43bpzOyclJFxoammOs+tfl4eGR7hQWFpZ63b1791Jvf/ToUXVZUFBQ6vsk5y9evJh6mx9++EFXtGjR1PPFixfXjRkzJtsY5P6rVq1Kd5nEX7t27XSPMWnSpHS3adCggW7w4MFqW+KRx5k7d27q9adPn1aXnT17Nsf3gIhsC2tmicimSetqWtIyK13ia9asUS2L0goYGxubqWVWWnH19OUL0rIqpHRAZiuoUqWKaoV99tln0b59+2xjkHICed5ChQqlu1yeV8oe9KRcQcoQcmPnzp2qBEKvYMGCyC3p0q9QoULqeSkj0L82+Xvz5k3VapxXkZGR6jGaNm2a7nI5n7a0IuP7LHHoY6hatWqen5+IrAuTWSKyaTI9VlrSpb1p0ybV/S1d525ubnjxxRdVHWxaTk5O6c5LQit1oEJKBIKCglTJgNTbSklB27Zt8eeff2YZgySykqhJTWtGaafuyhhrTqSuNuO0X/b2DyvLHjaePpSYmJjpvlm9Nv195P0wpbSxSBxC/z4TEQkms0REaezevVu1rMoAJn2iqR8cZQgZxNWzZ091kmRYWmil/tXX1zfTbSX5lblnZSYFfW2tMehbdaXFWd9Sa2jtrbT2SoxSUywDs7JLQGVmiJzem+LFi6v3ukWLFqmXy/mGDRsaFA8REZNZIqI0ZLosGWAlg76kJXDs2LEGtwR+/fXXqqW1Tp06qjV0+fLlqgwhuwUSpNW2cePG6N69O6ZNm6YGOkk3vJQ6SFKdsRQir6SluVSpUqqMYtKkSWqOWxmEZSi5/zvvvKNmTOjUqROioqJUIjp06FB1vT7ZlbIBmakgqxKHjz76COPGjVPlDDKTgQwYk8RaBssRERmCsxkQEWVIRCX5atKkiUpoZZS9tJwa2nopSakkoTK1l7Tsrl27NrWbPyNJmuX65s2bo3///iqZfeWVV3D16lU1RVh+kRbTX3/9VU1LJrWoX3zxBSZOnGjw4/Tt2xfffvstZs2apabnkprgtLMQSIIspRqSOEtCn5Vhw4bhgw8+wIgRI1CzZk01LZfMivAkc+8SkW2yk1FgWgdBRERERJQXbJklIiIiIovFZJaIiIiILBaTWSIiIiKyWExmiYiIiMhiMZklIiIiIovFZJaIiIiILBaTWSIiIiKyWExmiYiIiMhiMZklIiIiIovFZJaIiIiILBaTWSIiIiKCpfo/4oRHqgO9ERIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test different activation functions\n",
    "transfer_functions = {\n",
    "    'relu': 'ReLU',\n",
    "    'tanh': 'Tanh', \n",
    "    'sigmoid': 'Sigmoid',\n",
    "    'softplus': 'Softplus'\n",
    "}\n",
    "\n",
    "mse_results = []\n",
    "\n",
    "for activation, name in transfer_functions.items():\n",
    "    # Clear session and reset seeds for reproducibility\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    \n",
    "    # Build model with current activation function\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train_z.shape[1],)))\n",
    "    model.add(Dense(16, activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='tanh'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_z, y_train_s,\n",
    "              validation_data=(X_val_z, y_val_s),\n",
    "              batch_size=16, epochs=200, verbose=0)\n",
    "    \n",
    "    # Make predictions and convert back to original scale\n",
    "    y_pred_s = model.predict(X_test_z, verbose=0)\n",
    "    y_pred = inv_y(y_pred_s)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_results.append(mse)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(list(transfer_functions.values()), mse_results, marker='o', linestyle='-')\n",
    "plt.title('Mean MSE (Mn & Mw) vs. Transfer Function')\n",
    "plt.xlabel('Transfer Function')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky2flHEEBSUj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEyyme3-BSSL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhVOphxKBSPj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM6viJ1X4oRLwr65SDqw9Ni",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
