{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (2.20.0rc0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.11.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\brian\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas tensorflow scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23ab7a65-f2cc-4229-9ce9-a21876f50ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4c6ed1-9799-4a43-bd34-2d2122e25985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Factor A</th>\n",
       "      <th>Factor B</th>\n",
       "      <th>Factor C</th>\n",
       "      <th>Factor D</th>\n",
       "      <th>Response 1 (Experimental)</th>\n",
       "      <th>Response 2 (Experimental)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1127.19</td>\n",
       "      <td>1321.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1024.97</td>\n",
       "      <td>1339.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>60</td>\n",
       "      <td>1950.00</td>\n",
       "      <td>2878.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>60</td>\n",
       "      <td>2223.17</td>\n",
       "      <td>2989.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1845.60</td>\n",
       "      <td>2690.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run  Factor A  Factor B  Factor C  Factor D  Response 1 (Experimental)  \\\n",
       "0    1       110         7        50        10                    1127.19   \n",
       "1    2        85        13        50        10                    1024.97   \n",
       "2    3       101         1       500        60                    1950.00   \n",
       "3    4       101         1       500        60                    2223.17   \n",
       "4    5        50        10        50        10                    1845.60   \n",
       "\n",
       "   Response 2 (Experimental)  \n",
       "0                    1321.65  \n",
       "1                    1339.35  \n",
       "2                    2878.90  \n",
       "3                    2989.00  \n",
       "4                    2690.50  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Load your data\n",
    "data = pd.read_csv('Exp_Mn_Mw_Value.txt', sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42c2920-cb72-47af-903e-d08c81ab57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare the data\n",
    "# Replace these column names with your actual column names:\n",
    "input_columns = ['factor A', 'factor B', 'factor C', 'factor D']  # Change these names\n",
    "output_columns = ['Response 1 (Experimental)', 'Response 2 (Experimental)']           # Change these names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3907ce8b-c6f6-452b-bd8d-3073247f1516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Run', 'Factor A', 'Factor B', 'Factor C', 'Factor D', 'Response 1 (Experimental)', 'Response 2 (Experimental)']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "116d69d5-1b4e-405b-9d60-42ebfe8c0fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (X): (25, 4)\n",
      "Output shape (y): (25, 2)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Split data into inputs (X) and outputs (y)\n",
    "X = data.iloc[:, 1:5].values   # columns 1–4: Factor A–D\n",
    "y = data.iloc[:, 5:7].values   # columns 5–6: Responses Mn, Mw\n",
    "\n",
    "print(f\"Input shape (X): {X.shape}\")\n",
    "print(f\"Output shape (y): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e79371-b5f0-4895-b0cc-f3ba9e3081cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 10 samples\n",
      "Validation data: 6 samples\n",
      "Testing data: 9 samples\n",
      "\n",
      "Detailed shapes:\n",
      "X_train: (10, 4), y_train: (10, 2)\n",
      "X_val:   (6, 4),   y_val:   (6, 2)\n",
      "X_test:  (9, 4),  y_test:  (9, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "SEED = 5\n",
    "\n",
    "# Step 1: Split into train_val (65%) and test (35%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.35, shuffle=True, random_state=SEED\n",
    ")\n",
    "\n",
    "# Step 2: Split train_val into train (~42%) and val (~22%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.35, shuffle=True, random_state=SEED\n",
    ")\n",
    "\n",
    "# Show shapes of each split\n",
    "print(f\"Training data: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation data: {X_val.shape[0]} samples\")\n",
    "print(f\"Testing data: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Optional: sanity check on all shapes\n",
    "print(\"\\nDetailed shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val:   {X_val.shape},   y_val:   {y_val.shape}\")\n",
    "print(f\"X_test:  {X_test.shape},  y_test:  {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c0cb66-2bad-4ecf-a8e7-2e9515f0cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (10, 4)\n",
      "y_train_scaled shape: (10, 2)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Scale the data (normalize)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale X (inputs)\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled   = scaler_X.transform(X_val)\n",
    "X_test_scaled  = scaler_X.transform(X_test)\n",
    "\n",
    "# Scale y (outputs)\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_val_scaled   = scaler_y.transform(y_val)\n",
    "y_test_scaled  = scaler_y.transform(y_test)\n",
    "\n",
    "# Sanity check (optional)\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"y_train_scaled shape:\", y_train_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7545e9f-7187-43a6-9256-ac9d21abfc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network model with extra layers created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\PycharmProjects\\PythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m80\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m72\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m18\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">306</span> (1.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m306\u001b[0m (1.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">306</span> (1.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m306\u001b[0m (1.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 8: Create a neural network with more layers, dropout, and L2 regularization\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(16, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-5),\n",
    "                 input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.1),\n",
    "    layers.Dense(8, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-5)),\n",
    "    Dropout(0.1),\n",
    "    layers.Dense(8, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-5)),\n",
    "    Dropout(0.1),\n",
    "    layers.Dense(2, activation='tanh')  # 2 outputs: Mn and Mw\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape'])\n",
    "\n",
    "print(\"Neural network model with extra layers created!\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a6ae21c-c269-41a2-a084-866a4c0e32d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1387 - mae: 0.8887 - mape: 424.6519 - val_loss: 0.9073 - val_mae: 0.7460 - val_mape: 179.8048\n",
      "Epoch 2/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.0437 - mae: 0.8413 - mape: 501.8436 - val_loss: 0.9004 - val_mae: 0.7442 - val_mape: 179.7010\n",
      "Epoch 3/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.9584 - mae: 0.8031 - mape: 177.7425 - val_loss: 0.8925 - val_mae: 0.7421 - val_mape: 179.6347\n",
      "Epoch 4/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.2554 - mae: 0.9335 - mape: 359.9770 - val_loss: 0.8863 - val_mae: 0.7400 - val_mape: 179.1840\n",
      "Epoch 5/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8161 - mae: 0.7263 - mape: 156.5361 - val_loss: 0.8801 - val_mae: 0.7383 - val_mape: 179.0983\n",
      "Epoch 6/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9409 - mae: 0.7721 - mape: 308.8373 - val_loss: 0.8734 - val_mae: 0.7364 - val_mape: 178.8994\n",
      "Epoch 7/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9277 - mae: 0.7847 - mape: 419.0939 - val_loss: 0.8665 - val_mae: 0.7345 - val_mape: 178.9017\n",
      "Epoch 8/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.1053 - mae: 0.8485 - mape: 328.1462 - val_loss: 0.8611 - val_mae: 0.7333 - val_mape: 179.0848\n",
      "Epoch 9/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.1615 - mae: 0.8291 - mape: 251.1420 - val_loss: 0.8559 - val_mae: 0.7321 - val_mape: 179.2014\n",
      "Epoch 10/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9405 - mae: 0.7357 - mape: 136.6349 - val_loss: 0.8511 - val_mae: 0.7311 - val_mape: 179.3792\n",
      "Epoch 11/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.9260 - mae: 0.8188 - mape: 481.9614 - val_loss: 0.8467 - val_mae: 0.7302 - val_mape: 179.6103\n",
      "Epoch 12/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.0233 - mae: 0.7772 - mape: 414.4999 - val_loss: 0.8428 - val_mae: 0.7294 - val_mape: 179.8066\n",
      "Epoch 13/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8392 - mae: 0.7380 - mape: 209.3258 - val_loss: 0.8379 - val_mae: 0.7283 - val_mape: 180.1226\n",
      "Epoch 14/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.9787 - mae: 0.8276 - mape: 344.3874 - val_loss: 0.8327 - val_mae: 0.7269 - val_mape: 180.2773\n",
      "Epoch 15/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8425 - mae: 0.7146 - mape: 158.8092 - val_loss: 0.8277 - val_mae: 0.7257 - val_mape: 180.5462\n",
      "Epoch 16/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8599 - mae: 0.7445 - mape: 255.2204 - val_loss: 0.8227 - val_mae: 0.7245 - val_mape: 180.8610\n",
      "Epoch 17/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.0017 - mae: 0.7759 - mape: 331.1253 - val_loss: 0.8177 - val_mae: 0.7233 - val_mape: 181.2601\n",
      "Epoch 18/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9735 - mae: 0.7662 - mape: 324.6851 - val_loss: 0.8129 - val_mae: 0.7223 - val_mape: 181.7094\n",
      "Epoch 19/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8437 - mae: 0.7596 - mape: 295.4028 - val_loss: 0.8080 - val_mae: 0.7212 - val_mape: 182.2410\n",
      "Epoch 20/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.9574 - mae: 0.7275 - mape: 367.7791 - val_loss: 0.8038 - val_mae: 0.7205 - val_mape: 182.8473\n",
      "Epoch 21/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.0275 - mae: 0.8133 - mape: 357.3016 - val_loss: 0.7991 - val_mae: 0.7192 - val_mape: 183.1102\n",
      "Epoch 22/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.7399 - mae: 0.7054 - mape: 332.1507 - val_loss: 0.7944 - val_mae: 0.7179 - val_mape: 183.3621\n",
      "Epoch 23/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.0254 - mae: 0.7897 - mape: 406.4641 - val_loss: 0.7901 - val_mae: 0.7167 - val_mape: 183.5530\n",
      "Epoch 24/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8499 - mae: 0.7367 - mape: 179.8193 - val_loss: 0.7854 - val_mae: 0.7153 - val_mape: 183.7531\n",
      "Epoch 25/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8535 - mae: 0.7421 - mape: 395.8129 - val_loss: 0.7810 - val_mae: 0.7141 - val_mape: 184.0874\n",
      "Epoch 26/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9376 - mae: 0.7869 - mape: 511.4724 - val_loss: 0.7765 - val_mae: 0.7130 - val_mape: 184.5948\n",
      "Epoch 27/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.9794 - mae: 0.8051 - mape: 349.6461 - val_loss: 0.7717 - val_mae: 0.7115 - val_mape: 184.7640\n",
      "Epoch 28/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8315 - mae: 0.7470 - mape: 509.9276 - val_loss: 0.7675 - val_mae: 0.7102 - val_mape: 184.9061\n",
      "Epoch 29/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8103 - mae: 0.7140 - mape: 486.4975 - val_loss: 0.7633 - val_mae: 0.7089 - val_mape: 185.1212\n",
      "Epoch 30/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8424 - mae: 0.7333 - mape: 342.1771 - val_loss: 0.7591 - val_mae: 0.7076 - val_mape: 185.3791\n",
      "Epoch 31/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.9513 - mae: 0.7550 - mape: 216.9717 - val_loss: 0.7548 - val_mae: 0.7062 - val_mape: 185.4863\n",
      "Epoch 32/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7878 - mae: 0.6968 - mape: 483.2123 - val_loss: 0.7505 - val_mae: 0.7047 - val_mape: 185.5921\n",
      "Epoch 33/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8564 - mae: 0.6913 - mape: 171.5894 - val_loss: 0.7460 - val_mae: 0.7030 - val_mape: 185.6018\n",
      "Epoch 34/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8399 - mae: 0.7233 - mape: 200.6624 - val_loss: 0.7416 - val_mae: 0.7015 - val_mape: 185.6767\n",
      "Epoch 35/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6777 - mae: 0.6479 - mape: 332.0816 - val_loss: 0.7371 - val_mae: 0.6998 - val_mape: 185.7065\n",
      "Epoch 36/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8900 - mae: 0.7042 - mape: 178.4517 - val_loss: 0.7324 - val_mae: 0.6978 - val_mape: 185.5604\n",
      "Epoch 37/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8736 - mae: 0.7085 - mape: 344.4971 - val_loss: 0.7278 - val_mae: 0.6959 - val_mape: 185.4330\n",
      "Epoch 38/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9244 - mae: 0.7293 - mape: 172.4061 - val_loss: 0.7235 - val_mae: 0.6940 - val_mape: 185.2999\n",
      "Epoch 39/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8291 - mae: 0.6872 - mape: 391.6789 - val_loss: 0.7200 - val_mae: 0.6929 - val_mape: 185.5339\n",
      "Epoch 40/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9617 - mae: 0.7106 - mape: 292.3626 - val_loss: 0.7162 - val_mae: 0.6918 - val_mape: 185.8464\n",
      "Epoch 41/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7712 - mae: 0.7067 - mape: 478.1480 - val_loss: 0.7124 - val_mae: 0.6908 - val_mape: 186.1644\n",
      "Epoch 42/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7590 - mae: 0.7145 - mape: 367.3775 - val_loss: 0.7087 - val_mae: 0.6897 - val_mape: 186.5250\n",
      "Epoch 43/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6622 - mae: 0.6443 - mape: 364.1838 - val_loss: 0.7050 - val_mae: 0.6887 - val_mape: 186.9350\n",
      "Epoch 44/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.7128 - mae: 0.6381 - mape: 496.4387 - val_loss: 0.7016 - val_mae: 0.6879 - val_mape: 187.3996\n",
      "Epoch 45/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7032 - mae: 0.6530 - mape: 205.2547 - val_loss: 0.6981 - val_mae: 0.6870 - val_mape: 187.8842\n",
      "Epoch 46/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7010 - mae: 0.6076 - mape: 339.8163 - val_loss: 0.6946 - val_mae: 0.6862 - val_mape: 188.4161\n",
      "Epoch 47/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7476 - mae: 0.6848 - mape: 274.0163 - val_loss: 0.6912 - val_mae: 0.6853 - val_mape: 188.9524\n",
      "Epoch 48/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6183 - mae: 0.6175 - mape: 381.0626 - val_loss: 0.6881 - val_mae: 0.6847 - val_mape: 189.6026\n",
      "Epoch 49/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6667 - mae: 0.6281 - mape: 331.0716 - val_loss: 0.6853 - val_mae: 0.6843 - val_mape: 190.3645\n",
      "Epoch 50/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6645 - mae: 0.6489 - mape: 423.8307 - val_loss: 0.6826 - val_mae: 0.6839 - val_mape: 191.1195\n",
      "Epoch 51/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6172 - mae: 0.6090 - mape: 196.6814 - val_loss: 0.6799 - val_mae: 0.6835 - val_mape: 191.9191\n",
      "Epoch 52/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6345 - mae: 0.5684 - mape: 269.8083 - val_loss: 0.6776 - val_mae: 0.6833 - val_mape: 192.8720\n",
      "Epoch 53/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8215 - mae: 0.6900 - mape: 329.1739 - val_loss: 0.6758 - val_mae: 0.6835 - val_mape: 193.9150\n",
      "Epoch 54/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6840 - mae: 0.6783 - mape: 425.1848 - val_loss: 0.6743 - val_mae: 0.6837 - val_mape: 194.9872\n",
      "Epoch 55/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5977 - mae: 0.5973 - mape: 270.3709 - val_loss: 0.6729 - val_mae: 0.6840 - val_mape: 196.0922\n",
      "Epoch 56/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6627 - mae: 0.6423 - mape: 352.7435 - val_loss: 0.6718 - val_mae: 0.6845 - val_mape: 197.2778\n",
      "Epoch 57/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6109 - mae: 0.6239 - mape: 420.2962 - val_loss: 0.6710 - val_mae: 0.6852 - val_mape: 198.5376\n",
      "Epoch 58/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7315 - mae: 0.6969 - mape: 370.7886 - val_loss: 0.6702 - val_mae: 0.6858 - val_mape: 199.7866\n",
      "Epoch 59/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7328 - mae: 0.6408 - mape: 301.6371 - val_loss: 0.6693 - val_mae: 0.6863 - val_mape: 200.9702\n",
      "Epoch 60/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8577 - mae: 0.7115 - mape: 372.1972 - val_loss: 0.6685 - val_mae: 0.6868 - val_mape: 202.0516\n",
      "Epoch 61/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6892 - mae: 0.6045 - mape: 377.9247 - val_loss: 0.6674 - val_mae: 0.6871 - val_mape: 203.0711\n",
      "Epoch 62/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7578 - mae: 0.6695 - mape: 347.3452 - val_loss: 0.6665 - val_mae: 0.6874 - val_mape: 204.1039\n",
      "Epoch 63/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7619 - mae: 0.6462 - mape: 332.8661 - val_loss: 0.6660 - val_mae: 0.6880 - val_mape: 205.2104\n",
      "Epoch 64/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9060 - mae: 0.6894 - mape: 143.9031 - val_loss: 0.6649 - val_mae: 0.6881 - val_mape: 206.0589\n",
      "Epoch 65/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7512 - mae: 0.6631 - mape: 155.8998 - val_loss: 0.6636 - val_mae: 0.6881 - val_mape: 206.8451\n",
      "Epoch 66/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6257 - mae: 0.6168 - mape: 220.8453 - val_loss: 0.6625 - val_mae: 0.6882 - val_mape: 207.7332\n",
      "Epoch 67/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6397 - mae: 0.6530 - mape: 434.6701 - val_loss: 0.6613 - val_mae: 0.6883 - val_mape: 208.5898\n",
      "Epoch 68/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7890 - mae: 0.7055 - mape: 183.7154 - val_loss: 0.6609 - val_mae: 0.6888 - val_mape: 209.6613\n",
      "Epoch 69/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6296 - mae: 0.6543 - mape: 274.4258 - val_loss: 0.6600 - val_mae: 0.6891 - val_mape: 210.6197\n",
      "Epoch 70/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.7537 - mae: 0.6616 - mape: 519.5580 - val_loss: 0.6596 - val_mae: 0.6896 - val_mape: 211.7229\n",
      "Epoch 71/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6165 - mae: 0.6388 - mape: 324.2047 - val_loss: 0.6592 - val_mae: 0.6902 - val_mape: 212.8195\n",
      "Epoch 72/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7445 - mae: 0.6804 - mape: 366.5475 - val_loss: 0.6585 - val_mae: 0.6904 - val_mape: 213.7968\n",
      "Epoch 73/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8098 - mae: 0.7501 - mape: 360.3214 - val_loss: 0.6584 - val_mae: 0.6910 - val_mape: 214.8709\n",
      "Epoch 74/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8894 - mae: 0.6443 - mape: 261.8980 - val_loss: 0.6582 - val_mae: 0.6916 - val_mape: 215.8577\n",
      "Epoch 75/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7073 - mae: 0.6770 - mape: 368.9117 - val_loss: 0.6582 - val_mae: 0.6923 - val_mape: 216.8927\n",
      "Epoch 76/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5719 - mae: 0.5918 - mape: 449.9299 - val_loss: 0.6587 - val_mae: 0.6932 - val_mape: 218.0484\n",
      "Epoch 77/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8231 - mae: 0.6851 - mape: 300.7466 - val_loss: 0.6588 - val_mae: 0.6939 - val_mape: 219.0700\n",
      "Epoch 78/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6013 - mae: 0.6576 - mape: 333.9268 - val_loss: 0.6591 - val_mae: 0.6946 - val_mape: 220.1164\n",
      "Epoch 79/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7402 - mae: 0.6429 - mape: 200.1679 - val_loss: 0.6589 - val_mae: 0.6951 - val_mape: 221.0817\n",
      "Epoch 80/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.9053 - mae: 0.6891 - mape: 253.1667 - val_loss: 0.6588 - val_mae: 0.6956 - val_mape: 222.0012\n",
      "Epoch 81/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4902 - mae: 0.5148 - mape: 262.9382 - val_loss: 0.6586 - val_mae: 0.6960 - val_mape: 222.9350\n",
      "Epoch 82/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6387 - mae: 0.6045 - mape: 192.7480 - val_loss: 0.6584 - val_mae: 0.6964 - val_mape: 223.8413\n",
      "Epoch 83/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8105 - mae: 0.7177 - mape: 399.3398 - val_loss: 0.6584 - val_mae: 0.6969 - val_mape: 224.7240\n",
      "Epoch 84/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7669 - mae: 0.6974 - mape: 461.3826 - val_loss: 0.6582 - val_mae: 0.6972 - val_mape: 225.5015\n",
      "Epoch 85/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5795 - mae: 0.5866 - mape: 380.3518 - val_loss: 0.6579 - val_mae: 0.6975 - val_mape: 226.3074\n",
      "Epoch 86/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5016 - mae: 0.5530 - mape: 293.6691 - val_loss: 0.6581 - val_mae: 0.6980 - val_mape: 227.2150\n",
      "Epoch 87/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6821 - mae: 0.6900 - mape: 281.5565 - val_loss: 0.6578 - val_mae: 0.6982 - val_mape: 228.0153\n",
      "Epoch 88/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5434 - mae: 0.5590 - mape: 198.2828 - val_loss: 0.6577 - val_mae: 0.6985 - val_mape: 228.8652\n",
      "Epoch 89/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4842 - mae: 0.5371 - mape: 281.2302 - val_loss: 0.6577 - val_mae: 0.6988 - val_mape: 229.7127\n",
      "Epoch 90/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5080 - mae: 0.5423 - mape: 194.9927 - val_loss: 0.6574 - val_mae: 0.6990 - val_mape: 230.5127\n",
      "Epoch 91/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4634 - mae: 0.5045 - mape: 226.6971 - val_loss: 0.6571 - val_mae: 0.6992 - val_mape: 231.2970\n",
      "Epoch 92/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5853 - mae: 0.5959 - mape: 354.8760 - val_loss: 0.6566 - val_mae: 0.6993 - val_mape: 232.0215\n",
      "Epoch 93/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6927 - mae: 0.6164 - mape: 236.6725 - val_loss: 0.6563 - val_mae: 0.6994 - val_mape: 232.7847\n",
      "Epoch 94/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6468 - mae: 0.7021 - mape: 381.4185 - val_loss: 0.6562 - val_mae: 0.6997 - val_mape: 233.5352\n",
      "Epoch 95/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6379 - mae: 0.6570 - mape: 400.5193 - val_loss: 0.6562 - val_mae: 0.7000 - val_mape: 234.2530\n",
      "Epoch 96/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5303 - mae: 0.5637 - mape: 328.2461 - val_loss: 0.6567 - val_mae: 0.7005 - val_mape: 235.0578\n",
      "Epoch 97/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6378 - mae: 0.5298 - mape: 127.6547 - val_loss: 0.6570 - val_mae: 0.7009 - val_mape: 235.8056\n",
      "Epoch 98/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5780 - mae: 0.6281 - mape: 306.1291 - val_loss: 0.6570 - val_mae: 0.7011 - val_mape: 236.4260\n",
      "Epoch 99/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5670 - mae: 0.5971 - mape: 231.8186 - val_loss: 0.6573 - val_mae: 0.7013 - val_mape: 237.0670\n",
      "Epoch 100/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7720 - mae: 0.6272 - mape: 273.9081 - val_loss: 0.6572 - val_mae: 0.7014 - val_mape: 237.6156\n",
      "Epoch 101/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5603 - mae: 0.5701 - mape: 301.6108 - val_loss: 0.6572 - val_mae: 0.7015 - val_mape: 238.1908\n",
      "Epoch 102/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6539 - mae: 0.5758 - mape: 137.2842 - val_loss: 0.6572 - val_mae: 0.7016 - val_mape: 238.7830\n",
      "Epoch 103/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5888 - mae: 0.5678 - mape: 171.9959 - val_loss: 0.6569 - val_mae: 0.7016 - val_mape: 239.3527\n",
      "Epoch 104/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6975 - mae: 0.6603 - mape: 286.9557 - val_loss: 0.6563 - val_mae: 0.7014 - val_mape: 239.8016\n",
      "Epoch 105/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5146 - mae: 0.5611 - mape: 217.2884 - val_loss: 0.6559 - val_mae: 0.7013 - val_mape: 240.3113\n",
      "Epoch 106/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5399 - mae: 0.5757 - mape: 245.2427 - val_loss: 0.6557 - val_mae: 0.7013 - val_mape: 240.8645\n",
      "Epoch 107/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5227 - mae: 0.5751 - mape: 185.1924 - val_loss: 0.6554 - val_mae: 0.7012 - val_mape: 241.3245\n",
      "Epoch 108/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7337 - mae: 0.6212 - mape: 203.2586 - val_loss: 0.6548 - val_mae: 0.7009 - val_mape: 241.6816\n",
      "Epoch 109/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6786 - mae: 0.6524 - mape: 258.1397 - val_loss: 0.6543 - val_mae: 0.7005 - val_mape: 242.0052\n",
      "Epoch 110/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5791 - mae: 0.5982 - mape: 278.8525 - val_loss: 0.6538 - val_mae: 0.7002 - val_mape: 242.3576\n",
      "Epoch 111/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8130 - mae: 0.6714 - mape: 430.2636 - val_loss: 0.6532 - val_mae: 0.6998 - val_mape: 242.7461\n",
      "Epoch 112/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6577 - mae: 0.6372 - mape: 203.2783 - val_loss: 0.6520 - val_mae: 0.6992 - val_mape: 243.0058\n",
      "Epoch 113/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6828 - mae: 0.6498 - mape: 379.8422 - val_loss: 0.6503 - val_mae: 0.6981 - val_mape: 243.0944\n",
      "Epoch 114/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6509 - mae: 0.5696 - mape: 240.9921 - val_loss: 0.6496 - val_mae: 0.6976 - val_mape: 243.4513\n",
      "Epoch 115/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5315 - mae: 0.5879 - mape: 187.2114 - val_loss: 0.6488 - val_mae: 0.6971 - val_mape: 243.7495\n",
      "Epoch 116/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4799 - mae: 0.5386 - mape: 210.3642 - val_loss: 0.6484 - val_mae: 0.6968 - val_mape: 244.1213\n",
      "Epoch 117/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7417 - mae: 0.6778 - mape: 188.4472 - val_loss: 0.6480 - val_mae: 0.6964 - val_mape: 244.4298\n",
      "Epoch 118/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5204 - mae: 0.6013 - mape: 301.9232 - val_loss: 0.6477 - val_mae: 0.6960 - val_mape: 244.7723\n",
      "Epoch 119/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6349 - mae: 0.5974 - mape: 290.0579 - val_loss: 0.6475 - val_mae: 0.6958 - val_mape: 245.1677\n",
      "Epoch 120/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8741 - mae: 0.6872 - mape: 250.6226 - val_loss: 0.6478 - val_mae: 0.6959 - val_mape: 245.6619\n",
      "Epoch 121/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6044 - mae: 0.5585 - mape: 184.0492 - val_loss: 0.6482 - val_mae: 0.6962 - val_mape: 246.2731\n",
      "Epoch 122/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6109 - mae: 0.5577 - mape: 207.2062 - val_loss: 0.6490 - val_mae: 0.6967 - val_mape: 247.0168\n",
      "Epoch 123/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4696 - mae: 0.5188 - mape: 321.7449 - val_loss: 0.6500 - val_mae: 0.6973 - val_mape: 247.8009\n",
      "Epoch 124/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6505 - mae: 0.5591 - mape: 154.3931 - val_loss: 0.6510 - val_mae: 0.6982 - val_mape: 248.7473\n",
      "Epoch 125/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7512 - mae: 0.6332 - mape: 286.2882 - val_loss: 0.6518 - val_mae: 0.6991 - val_mape: 249.6821\n",
      "Epoch 126/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5792 - mae: 0.5616 - mape: 424.7601 - val_loss: 0.6530 - val_mae: 0.7004 - val_mape: 250.8100\n",
      "Epoch 127/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6166 - mae: 0.6150 - mape: 363.6894 - val_loss: 0.6539 - val_mae: 0.7013 - val_mape: 251.7813\n",
      "Epoch 128/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4321 - mae: 0.4821 - mape: 109.0071 - val_loss: 0.6550 - val_mae: 0.7024 - val_mape: 252.8271\n",
      "Epoch 129/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8773 - mae: 0.6749 - mape: 300.1408 - val_loss: 0.6559 - val_mae: 0.7033 - val_mape: 253.7780\n",
      "Epoch 130/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5123 - mae: 0.5394 - mape: 164.1933 - val_loss: 0.6566 - val_mae: 0.7040 - val_mape: 254.6028\n",
      "Epoch 131/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5431 - mae: 0.5571 - mape: 216.3707 - val_loss: 0.6574 - val_mae: 0.7048 - val_mape: 255.5108\n",
      "Epoch 132/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5233 - mae: 0.5375 - mape: 224.4664 - val_loss: 0.6586 - val_mae: 0.7058 - val_mape: 256.3978\n",
      "Epoch 133/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4996 - mae: 0.5427 - mape: 180.3890 - val_loss: 0.6594 - val_mae: 0.7064 - val_mape: 257.1245\n",
      "Epoch 134/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6375 - mae: 0.5978 - mape: 179.4268 - val_loss: 0.6599 - val_mae: 0.7068 - val_mape: 257.7195\n",
      "Epoch 135/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6009 - mae: 0.5510 - mape: 150.9928 - val_loss: 0.6611 - val_mae: 0.7080 - val_mape: 258.7905\n",
      "Epoch 136/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5637 - mae: 0.5799 - mape: 193.4873 - val_loss: 0.6624 - val_mae: 0.7093 - val_mape: 259.9400\n",
      "Epoch 137/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5657 - mae: 0.5707 - mape: 257.6582 - val_loss: 0.6633 - val_mae: 0.7102 - val_mape: 260.8810\n",
      "Epoch 138/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6697 - mae: 0.6308 - mape: 287.2492 - val_loss: 0.6636 - val_mae: 0.7106 - val_mape: 261.5995\n",
      "Epoch 139/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4842 - mae: 0.5452 - mape: 153.7612 - val_loss: 0.6640 - val_mae: 0.7110 - val_mape: 262.2890\n",
      "Epoch 140/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5904 - mae: 0.5603 - mape: 195.5710 - val_loss: 0.6643 - val_mae: 0.7113 - val_mape: 262.8727\n",
      "Epoch 141/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6367 - mae: 0.6202 - mape: 218.2328 - val_loss: 0.6650 - val_mae: 0.7119 - val_mape: 263.6163\n",
      "Epoch 142/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3760 - mae: 0.4564 - mape: 337.2040 - val_loss: 0.6659 - val_mae: 0.7126 - val_mape: 264.4194\n",
      "Epoch 143/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5794 - mae: 0.5638 - mape: 459.5160 - val_loss: 0.6674 - val_mae: 0.7139 - val_mape: 265.4813\n",
      "Epoch 144/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6226 - mae: 0.5594 - mape: 159.8841 - val_loss: 0.6688 - val_mae: 0.7151 - val_mape: 266.5681\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Train the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae', 'mape']\n",
    ")\n",
    "\n",
    "# Set up early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=25,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_val_scaled, y_val_scaled),\n",
    "    epochs=500,\n",
    "    batch_size=16,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd2f9541-5d27-4ae4-97a5-7bc795b935a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Make predictions on scaled inputs\n",
    "y_train_pred_scaled = model.predict(X_train_scaled)\n",
    "y_val_pred_scaled   = model.predict(X_val_scaled)\n",
    "y_test_pred_scaled  = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse-transform predictions and true values back to original scale\n",
    "y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled)\n",
    "y_val_pred   = scaler_y.inverse_transform(y_val_pred_scaled)\n",
    "y_test_pred  = scaler_y.inverse_transform(y_test_pred_scaled)\n",
    "\n",
    "y_train_true = scaler_y.inverse_transform(y_train_scaled)\n",
    "y_val_true   = scaler_y.inverse_transform(y_val_scaled)\n",
    "y_test_true  = scaler_y.inverse_transform(y_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f8c6aec-80d1-4ce6-9603-ca1c746db778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 11: Evaluate the model\n",
    "def evaluate_model(y_true, y_pred, dataset_name):\n",
    "    \"\"\"\n",
    "    Calculate and print performance metrics for a 2-output regression model.\n",
    "    y_true and y_pred must be 2D arrays: [:, 0] = Mn, [:, 1] = Mw\n",
    "    \"\"\"\n",
    "    print(f\"\\n {dataset_name} Results:\")\n",
    "    \n",
    "    # Mn\n",
    "    mn_mse = mean_squared_error(y_true[:, 0], y_pred[:, 0])\n",
    "    mn_r2  = r2_score(y_true[:, 0], y_pred[:, 0])\n",
    "    print(f\"Mn - MSE: {mn_mse:.4f}, R²: {mn_r2:.4f}\")\n",
    "    \n",
    "    # Mw\n",
    "    mw_mse = mean_squared_error(y_true[:, 1], y_pred[:, 1])\n",
    "    mw_r2  = r2_score(y_true[:, 1], y_pred[:, 1])\n",
    "    print(f\"Mw - MSE: {mw_mse:.4f}, R²: {mw_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b21e2439-6b91-4ec6-be72-8d57d2ed16ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 First 10 predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_Mn</th>\n",
       "      <th>Predicted_Mn</th>\n",
       "      <th>Actual_Mw</th>\n",
       "      <th>Predicted_Mw</th>\n",
       "      <th>Mn_Error</th>\n",
       "      <th>Mw_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4663.77</td>\n",
       "      <td>2751.494873</td>\n",
       "      <td>5921.61</td>\n",
       "      <td>3860.809082</td>\n",
       "      <td>1912.275127</td>\n",
       "      <td>2060.800918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4663.04</td>\n",
       "      <td>2751.494873</td>\n",
       "      <td>5921.49</td>\n",
       "      <td>3860.809082</td>\n",
       "      <td>1911.545127</td>\n",
       "      <td>2060.680918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950.00</td>\n",
       "      <td>2952.078125</td>\n",
       "      <td>2878.90</td>\n",
       "      <td>4131.125977</td>\n",
       "      <td>1002.078125</td>\n",
       "      <td>1252.225977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2322.86</td>\n",
       "      <td>2355.532715</td>\n",
       "      <td>2987.28</td>\n",
       "      <td>2974.999756</td>\n",
       "      <td>32.672715</td>\n",
       "      <td>12.280244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1265.88</td>\n",
       "      <td>1967.965454</td>\n",
       "      <td>1458.13</td>\n",
       "      <td>2414.153076</td>\n",
       "      <td>702.085454</td>\n",
       "      <td>956.023076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3764.53</td>\n",
       "      <td>2752.531494</td>\n",
       "      <td>5752.15</td>\n",
       "      <td>3829.603271</td>\n",
       "      <td>1011.998506</td>\n",
       "      <td>1922.546729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2590.79</td>\n",
       "      <td>2826.128174</td>\n",
       "      <td>3517.86</td>\n",
       "      <td>3909.973877</td>\n",
       "      <td>235.338174</td>\n",
       "      <td>392.113877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2752.80</td>\n",
       "      <td>2370.553711</td>\n",
       "      <td>3129.61</td>\n",
       "      <td>3010.101562</td>\n",
       "      <td>382.246289</td>\n",
       "      <td>119.508438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2951.90</td>\n",
       "      <td>2742.733398</td>\n",
       "      <td>2965.54</td>\n",
       "      <td>3793.340576</td>\n",
       "      <td>209.166602</td>\n",
       "      <td>827.800576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual_Mn  Predicted_Mn  Actual_Mw  Predicted_Mw     Mn_Error     Mw_Error\n",
       "0    4663.77   2751.494873    5921.61   3860.809082  1912.275127  2060.800918\n",
       "1    4663.04   2751.494873    5921.49   3860.809082  1911.545127  2060.680918\n",
       "2    1950.00   2952.078125    2878.90   4131.125977  1002.078125  1252.225977\n",
       "3    2322.86   2355.532715    2987.28   2974.999756    32.672715    12.280244\n",
       "4    1265.88   1967.965454    1458.13   2414.153076   702.085454   956.023076\n",
       "5    3764.53   2752.531494    5752.15   3829.603271  1011.998506  1922.546729\n",
       "6    2590.79   2826.128174    3517.86   3909.973877   235.338174   392.113877\n",
       "7    2752.80   2370.553711    3129.61   3010.101562   382.246289   119.508438\n",
       "8    2951.90   2742.733398    2965.54   3793.340576   209.166602   827.800576"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 13: Create a DataFrame of actual vs predicted values and errors\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual_Mn': y_test_true[:, 0],\n",
    "    'Predicted_Mn': y_test_pred[:, 0],\n",
    "    'Actual_Mw': y_test_true[:, 1],\n",
    "    'Predicted_Mw': y_test_pred[:, 1]\n",
    "})\n",
    "\n",
    "# Compute absolute errors\n",
    "results_df['Mn_Error'] = abs(results_df['Actual_Mn'] - results_df['Predicted_Mn'])\n",
    "results_df['Mw_Error'] = abs(results_df['Actual_Mw'] - results_df['Predicted_Mw'])\n",
    "\n",
    "# Display first 10 predictions\n",
    "print(\"\\n📄 First 10 predictions:\")\n",
    "display(results_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481fe553-7971-4e28-ab1f-36120aee69df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
